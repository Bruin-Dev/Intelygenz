{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"CONCEPTS Monorepo send Semantic Release Infrastructure as code Datalake Kafka PIPELINES BASIC CONFIGURATIONS Semantic release AIVEN AWS Snowflake PIPELINES RULES Add new section Add new template DOCUMENTATION Organization Rules Tools MetTel Decisions Metrics definitions Diagrams Logging DEVELOPMENT RULES Branch name convention Semantic release WORK IN A LOCAL ENVIRONMENT Launch docker compose DATALAKE Create private key for a user/service Key rotation policy Add a new provider Rules MANUAL PROCEDURES Vendor access to the API Switch Automation Engine region MANUAL CONFIGURATIONS Init Automation Engine project AWS SSO Okta identity provider Revoke Session token AWS SSO Okta JWT token AUDIT EVENTS Automation Communication between services Messages Bus Use Cases Service outage BYOB IPA Queue HNOC forwarding SA forwarding to ASR TNBA Monitor Ticket severity Ticket creation outcomes Service affecting InterMapper Outage Monitoring Hawkeye Outage Monitoring Gateway Monitoring Last Contact Report Lumin Billing Report DiGi Reboot Report Bridges Bruin Bridge VeloCloud Bridge Notifications Bridge Email Bridge Service Now Bridge Dri Bridge DiGi Bridge Hawkeye Bridge Use cases with bridge capabilities Customer Cache Hawkeye Customer Cache Infrastructure Lambda Parameter-Replicator","title":"Development rules"},{"location":"CONCEPTS/","text":"","title":"Concepts"},{"location":"CREATE_NEW_METRIC/","text":"CREATE NEW METRIC This process describes step by step how to create a new metric, how to test it locally and how to verify that it's working in production. Feel free to skip step 1 if the metrics repository already exists in the service you want to add the new metric for. 1. Adding metrics repository to the service First thing you need to do is adding the metric repository to your service if it is not already there, for doing that you will need to follow the steps below: Add the repository in the app.py file from application.repositories.metrics_repository import MetricsRepository class Container: def __init__(self): [...] # METRICS self._metrics_repository = MetricsRepository() # ACTIONS self._my_service = MyService( self._event_bus, self._logger, self._scheduler, config, self._utils_repository, self._metrics_repository ) For more info please refer to CREATE_NEW_MICROSERVICE.md Once you have the metric repository in the service just create a new python file called metrics_repository.py 2. Adding a new metric Existing metrics repositories can be used as references for each metric type use case. Prometheus offers a great variety of metric types we can add to the project: Counter The counter metric type is used for any value that increases, such as a request count or error count. Importantly, a counter should never be used for a value that can decrease (for that see Gauges, below). from prometheus_client import Counter COMMON_LABELS = [ \"feature\" , \"system\" , \"topic\" , \"severity\" , \"event\" ] CREATE_LABELS = [] class MetricsRepository : _tasks_created = Counter ( \"tasks_created\" , \"Tasks created\" , COMMON_LABELS + CREATE_LABELS ) def __init__ ( self ): self . _STATIC_LABELS = { \"feature\" : \"Service name\" , \"system\" : \"System name\" , \"topic\" : \"Topic name\" , \"severity\" : \"<Integer>\" , } def increment_tasks_created ( self , ** labels ): labels = { ** labels , ** self . _STATIC_LABELS } self . _tasks_created . labels ( ** labels ) . inc () CREATE_LABELS list can be used to expand the metric labels you are going to use. Remember adding any no static label when calling the increment_tasks_created_method . The counter property tasks_created should create 1 new counter: tasks_created_total. By default, it is set to 0. We can use rate(task_created[5m]) to calculate the per second rate of creations averaged over the last 5 minutes. Gauge The gauge metric type can be used for values that go down as well as up, such as current memory usage or the number of items in a queue. from prometheus_client import Gauge COMMON_LABELS = [ \"feature\" , \"system\" , \"topic\" ] MEMORY_USAGE_LABELS = [] class MetricsRepository : _memory_usage = Gauge ( \"memory_usage\" , \"Memory Usage\" , COMMON_LABELS + MEMORY_USAGE_LABELS ) [ ... ] def increment_memory_usage ( self , ** labels ): labels = { ** labels , ** self . _STATIC_LABELS } self . _memory_usage . labels ( ** labels ) . inc () def decrement_memory_usage ( self , ** labels ): labels = { ** labels , ** self . _STATIC_LABELS } self . _memory_usage . labels ( ** labels ) . dec () def reset_memory_usage ( self , ** labels ): labels = { ** labels , ** self . _STATIC_LABELS } self . _memory_usage . labels ( ** labels ) . set ( 0 ) The gauge property memory_usage should create 1 new counter: memory_usage_inprogress. We can use the query avg_over_time(memory_usage[5m]) to calculate the average memory usage over the last 5 minutes. Histogram The histogram metric type measures the frequency of value observations that fall into specific predefined buckets. from prometheus_client import Histogram class MetricsRepository : _response_latency = Histogram ( \"response_latency\" , \"Response latency\" , buckets = [ 0.11 , 0.12 , 0.13 , 0.14 , 0.15 , 0.16 , 0.17 , 0.18 , 0.19 , 0.20 ] ) def response_latency ( self ): self . _response_latency . time () # action() def observe_latency ( self , time_amount ): self . _response_latency . observe ( time_amount ) The histogram property response_latency should create 3 new counters: response_latency_count, response_latency_sum, and response_latency_bucket. Time method times a block of code or function, and observe the duration in seconds. Can be used as a function decorator or context manager. We can use the following query to calculate the average response latency duration within the last 5 minutes: rate(response_latency_sum[5m]) / rate(response_latency_count[5m]) Summary Summaries and histograms share a lot of similarities. So, simply a Histogram is a Summary with quantiles and percentiles calculation feature added. Summaries preceded histograms, and the recommendation is very much to use histograms where possible. 3. Testing the new metric Add your service to the file metrics-dashboard/prometheus/config/prometheus-local.yml in order for Prometheus to start scraping metrics from it. - job_name: 'my-service' scrape_interval: 5s static_configs: - targets: ['my-service:9090'] After that you are ready to go, just run your service and prometheus with docker-compose up my-service prometheus . If you go to localhost:9090/targets you should be able to see all the services, and the status of yours should be UP . You can then go to localhost:9090/graph in order to monitor the metric you added and verify that it works as expected. 4. Verifying in production Once you release your MR with the new metric you can start monitoring it in production. Depending on how often the action we're measuring with the metric you added happens, it might take a while before it shows up. You can monitor through the Prometheus interface at prometheus.mettel-automation.net , or directly on Grafana through the explorer interface at grafana.mettel-automation.net/explore for a better UX. You'll need to be connected to the VPN in order to access either. 5. Querying your metric In order to query your metric you'll need to use PromQL. For each metric we add, Prometheus creates 2 under the hood: one for the date it was created and one for the actual value of the metric. They have the suffixes _created and _total . The most basic way to monitor your metric would be to query for my_metric_total , which will show the current value of that metric. Since most of the metrics we have are used across many services, you may want to filter yours with labels. For instance, my_metric_total{feature=\"My Service\"} would filter the results to just those collected by your service. For more information about PromQL please refer to prometheus.io/docs/prometheus/latest/querying/basics","title":"CREATE NEW METRIC"},{"location":"CREATE_NEW_METRIC/#create-new-metric","text":"This process describes step by step how to create a new metric, how to test it locally and how to verify that it's working in production. Feel free to skip step 1 if the metrics repository already exists in the service you want to add the new metric for.","title":"CREATE NEW METRIC"},{"location":"CREATE_NEW_METRIC/#1-adding-metrics-repository-to-the-service","text":"First thing you need to do is adding the metric repository to your service if it is not already there, for doing that you will need to follow the steps below: Add the repository in the app.py file from application.repositories.metrics_repository import MetricsRepository class Container: def __init__(self): [...] # METRICS self._metrics_repository = MetricsRepository() # ACTIONS self._my_service = MyService( self._event_bus, self._logger, self._scheduler, config, self._utils_repository, self._metrics_repository ) For more info please refer to CREATE_NEW_MICROSERVICE.md Once you have the metric repository in the service just create a new python file called metrics_repository.py","title":"1. Adding metrics repository to the service"},{"location":"CREATE_NEW_METRIC/#2-adding-a-new-metric","text":"Existing metrics repositories can be used as references for each metric type use case. Prometheus offers a great variety of metric types we can add to the project:","title":"2. Adding a new metric"},{"location":"CREATE_NEW_METRIC/#counter","text":"The counter metric type is used for any value that increases, such as a request count or error count. Importantly, a counter should never be used for a value that can decrease (for that see Gauges, below). from prometheus_client import Counter COMMON_LABELS = [ \"feature\" , \"system\" , \"topic\" , \"severity\" , \"event\" ] CREATE_LABELS = [] class MetricsRepository : _tasks_created = Counter ( \"tasks_created\" , \"Tasks created\" , COMMON_LABELS + CREATE_LABELS ) def __init__ ( self ): self . _STATIC_LABELS = { \"feature\" : \"Service name\" , \"system\" : \"System name\" , \"topic\" : \"Topic name\" , \"severity\" : \"<Integer>\" , } def increment_tasks_created ( self , ** labels ): labels = { ** labels , ** self . _STATIC_LABELS } self . _tasks_created . labels ( ** labels ) . inc () CREATE_LABELS list can be used to expand the metric labels you are going to use. Remember adding any no static label when calling the increment_tasks_created_method . The counter property tasks_created should create 1 new counter: tasks_created_total. By default, it is set to 0. We can use rate(task_created[5m]) to calculate the per second rate of creations averaged over the last 5 minutes.","title":"Counter"},{"location":"CREATE_NEW_METRIC/#gauge","text":"The gauge metric type can be used for values that go down as well as up, such as current memory usage or the number of items in a queue. from prometheus_client import Gauge COMMON_LABELS = [ \"feature\" , \"system\" , \"topic\" ] MEMORY_USAGE_LABELS = [] class MetricsRepository : _memory_usage = Gauge ( \"memory_usage\" , \"Memory Usage\" , COMMON_LABELS + MEMORY_USAGE_LABELS ) [ ... ] def increment_memory_usage ( self , ** labels ): labels = { ** labels , ** self . _STATIC_LABELS } self . _memory_usage . labels ( ** labels ) . inc () def decrement_memory_usage ( self , ** labels ): labels = { ** labels , ** self . _STATIC_LABELS } self . _memory_usage . labels ( ** labels ) . dec () def reset_memory_usage ( self , ** labels ): labels = { ** labels , ** self . _STATIC_LABELS } self . _memory_usage . labels ( ** labels ) . set ( 0 ) The gauge property memory_usage should create 1 new counter: memory_usage_inprogress. We can use the query avg_over_time(memory_usage[5m]) to calculate the average memory usage over the last 5 minutes.","title":"Gauge"},{"location":"CREATE_NEW_METRIC/#histogram","text":"The histogram metric type measures the frequency of value observations that fall into specific predefined buckets. from prometheus_client import Histogram class MetricsRepository : _response_latency = Histogram ( \"response_latency\" , \"Response latency\" , buckets = [ 0.11 , 0.12 , 0.13 , 0.14 , 0.15 , 0.16 , 0.17 , 0.18 , 0.19 , 0.20 ] ) def response_latency ( self ): self . _response_latency . time () # action() def observe_latency ( self , time_amount ): self . _response_latency . observe ( time_amount ) The histogram property response_latency should create 3 new counters: response_latency_count, response_latency_sum, and response_latency_bucket. Time method times a block of code or function, and observe the duration in seconds. Can be used as a function decorator or context manager. We can use the following query to calculate the average response latency duration within the last 5 minutes: rate(response_latency_sum[5m]) / rate(response_latency_count[5m])","title":"Histogram"},{"location":"CREATE_NEW_METRIC/#summary","text":"Summaries and histograms share a lot of similarities. So, simply a Histogram is a Summary with quantiles and percentiles calculation feature added. Summaries preceded histograms, and the recommendation is very much to use histograms where possible.","title":"Summary"},{"location":"CREATE_NEW_METRIC/#3-testing-the-new-metric","text":"Add your service to the file metrics-dashboard/prometheus/config/prometheus-local.yml in order for Prometheus to start scraping metrics from it. - job_name: 'my-service' scrape_interval: 5s static_configs: - targets: ['my-service:9090'] After that you are ready to go, just run your service and prometheus with docker-compose up my-service prometheus . If you go to localhost:9090/targets you should be able to see all the services, and the status of yours should be UP . You can then go to localhost:9090/graph in order to monitor the metric you added and verify that it works as expected.","title":"3. Testing the new metric"},{"location":"CREATE_NEW_METRIC/#4-verifying-in-production","text":"Once you release your MR with the new metric you can start monitoring it in production. Depending on how often the action we're measuring with the metric you added happens, it might take a while before it shows up. You can monitor through the Prometheus interface at prometheus.mettel-automation.net , or directly on Grafana through the explorer interface at grafana.mettel-automation.net/explore for a better UX. You'll need to be connected to the VPN in order to access either.","title":"4. Verifying in production"},{"location":"CREATE_NEW_METRIC/#5-querying-your-metric","text":"In order to query your metric you'll need to use PromQL. For each metric we add, Prometheus creates 2 under the hood: one for the date it was created and one for the actual value of the metric. They have the suffixes _created and _total . The most basic way to monitor your metric would be to query for my_metric_total , which will show the current value of that metric. Since most of the metrics we have are used across many services, you may want to filter yours with labels. For instance, my_metric_total{feature=\"My Service\"} would filter the results to just those collected by your service. For more information about PromQL please refer to prometheus.io/docs/prometheus/latest/querying/basics","title":"5. Querying your metric"},{"location":"CREATE_NEW_MICROSERVICE/","text":"CREATE NEW MICROSERVICE This process describes step by step how to create a new microservice, from the ECR repository to the helm chart templates that define the microservice. All of this is created from the Gitlab repository in the pipeline; no need for more tools or actions by the developer. Introduction The process requires that the steps be carried out in order. Basically, it is necessary to create the ECR repository first so that we can then start developing and testing our new microservice in ephemeral environments or in production. 1. Create ECR repository We can't create the ECR repository in the branch where we are developing because the creation or update of the ECR repositories is only in the Master branch. This means that the first thing that we need to do is make a little merge to master to create our new microservice repo, by that way we can deploy our microservice later in dev branches. create a new branch from master create a new terraform ECR repo file in the folder: infra-as-code/basic-infra/3-registry you can copy any of the other repos to have an example. this is an example: resource \"aws_ecr_repository\" \"new-bridge-repository\" { name = \"new-bridge\" tags = { Project = var.common_info.project Provisioning = var.common_info.provisioning Module = \"new-bridge\" } } merge the new repository to Master branch. The pipeline will run and create the new ECR repo new-bridge 2. Create our new microservice folder We can start working on our new microservice based on an existing one. It depends on if is a capability (bridges) or a use case . Select one or other depends on what are you developing. For example let's copy a capability \"bruing-bridge\" and paste in the root of the repo to change his name to \"new-bridge\". from this moment you can start to develop and do your tests locally. Every microservice must have the following directory structure: new-bridge \u251c\u2500\u2500 .gitlab-ci.yml \u251c\u2500\u2500 Dockerfile \u251c\u2500\u2500 README.md \u251c\u2500\u2500 package.json \u251c\u2500\u2500 requirements.txt \u251c\u2500\u2500 setup.py \u2514\u2500\u2500 src \u251c\u2500\u2500 app.py \u251c\u2500\u2500 application \u2502 \u2514\u2500\u2500 ... \u251c\u2500\u2500 config \u2502 \u2514\u2500\u2500 ... \u2514\u2500\u2500 tests \u2514\u2500\u2500 ... 3. Update CI-CD gitlab files with the proper values It's important to have the .gitlab-ci.yaml files correctly defined to enable pipelines: * new-bridge/.gitlab-ci.yml Change any reference of the template microservice to the new one: example find and replace \"bruin-bridge\" for \"new-bridge\" * .gitlab-ci.yml (the file in the root of the repository) Here we need to define the \"desired_tasks\" variable for this new micro (do it respecting the alphabetical order): ... NATS_SERVER_DESIRED_TASKS: \"1\" NATS_SERVER_1_DESIRED_TASKS: \"1\" NATS_SERVER_2_DESIRED_TASKS: \"1\" NEW_BRIDGE_DESIRED_TASKS: \"1\" <\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 here! SERVICE_AFFECTING_MONITOR_DESIRED_TASKS: \"1\" SERVICE_OUTAGE_MONITOR_1_DESIRED_TASKS: \"1\" ... 3. Configure semantic-release We need to edit a file in the new micro path: * new-bridge/package.json update the name of the micro with our new working name: { \"name\": \"new-bridge\", <\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 here! \"version\": \"0.0.1\", \"dependencies\": {}, \"devDependencies\": {} } 3. Configure logs We use 2 systems to storage logs, papertrail for 3 days and cloudwath for 1 month. Let's add those config in: * ci-utils/papertrail-provisioning/config.py just copy one block form other microservice and paste with the name of our new micro (do it respecting the alphabetical order): ... { \"query\": f\"lumin-billing-report AND {ENVIRONMENT_NAME} AND <BUILD_NUMBER>\", \"search_name\": f\"[lumin-billing-report] - logs\", \"repository\": \"lumin-billing-report\", }, { \u00af\u2502 \"query\": f\"new-bridge AND {ENVIRONMENT_NAME} AND <BUILD_NUMBER>\", \u2502 \"search_name\": f\"[new-bridge] - logs\", \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500> here! \"repository\": \"new-bridge\", \u2502 }, _\u2502 ... helm/charts/fluent-bit-custom/templates/configmap.yaml The same; copy one block form other microservice and paste with the name of our new micro (do it respecting the alphabetical order): ... [OUTPUT] Name cloudwatch Match kube.var.log.containers.lumin-billing-report* region {{ .Values.config.region }} log_group_name {{ .Values.config.logGroupName }} log_stream_name lumin-billing-report auto_create_group true [OUTPUT] \u00af\u2502 Name cloudwatch \u2502 Match kube.var.log.containers.new-bridge* \u2502 region {{ .Values.config.region }} \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500> here! log_group_name {{ .Values.config.logGroupName }} \u2502 log_stream_name new-bridge \u2502 auto_create_group true _\u2502 ... 3. Update docker-compose to enable local deployments docker-compose.yml here we define our container along with the rest of the microservices. Just add the definition of our container respecting the alphabetical order: ... new-bridge: \u00af\u2502 build: \u2502 # Context must be the root of the monorepo \u2502 context: . \u2502 dockerfile: new-bridge/Dockerfile \u2502 args: \u2502 REPOSITORY_URL: 374050862540.dkr.ecr.us-east-1.amazonaws.com \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500> here! env_file: \u2502 - new-bridge/src/config/env \u2502 depends_on: \u2502 - \"nats-server\" \u2502 - redis \u2502 ports: \u2502 - 5006:5000 _\u2502 ... 4. Add option to enable or disable our microservice helm/charts/automation-engine/Chart.yaml in this file we define our Automation-engine chart version and his dependencies. Let's add a condition for our microservice to have the possibility of disable or enable in our future deployments. ... - name: lumin-billing-report version: '*.*.*' condition: lumin-billing-report.enabled - name: new-bridge \u00af\u2502 version: '*.*.*' \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500> here! condition: new-bridge.enabled _\u2502 ... 5. Helm templates and variables Here we will define the infrastructure part of our microservice with a helm chart. Is very important to know that this \"how to\" is only to copy an existing microservice, therefore, we take the following statements for granted: 1. The microservice will not have a public endpoint (except email-tagger-monitor) 2. The microservice port will always be 5000 3. Depends on the base chart you use to copy & paste, you will have more or less kubernetes resources. although most microservices have: configmap, deployment, secret and service. Perfect, now let's copy and paste another chart to use as template, if we will develop a use-case, we must copy the most similar use-case. For this example we are creating a \"new-bridge\", so let's copy a \"bruin-bridge\" as a template: * BASE-FOLDER: copy this folder helm/charts/automation-engine/charts/bruin-bridge and paste here helm/charts/automation-engine/charts/ we will have something like bruin-bridge copy change the name to new-bridge . PREPARE BASE_FOLDER: now let's do a find and replace in our new folder new-bridge . find bruin-bridge and replace for new-bridge . many substitutions should appear (at the moment of write this, i can see 46 substitutions in 10 files but over time, this can change). Just remember to do this in the new-bridge folder context to evoid modify other resources. DEPENDENCIES and CHECKS: Now we have to customize our new microservice, first we must ask ourselves, what dependency does my new microservice have on other services? for example, bruin-bridge have a dependency with Nats and Redis, so it have a few checks to see if those services are available and if they are, it can be deployed. We can find this checks in the deployment.yaml file. Specifically in this part: ... initContainers: - name: wait-nats-server image: busybox:1.28 command: ['sh', '-c', 'until wget --spider -S http://automation-engine-nats:8222/varz; do echo waiting for nats-server; sleep 2; done'] - name: wait-redis image: busybox:1.28 command: ['sh', '-c', 'until printf \"PING\\r\\n\" | nc ${REDIS_HOSTNAME} 6379; do echo waiting for redis; sleep 2; done'] envFrom: - configMapRef: name: {{ include \"new-bridge.configmapName\" . }} ... We can add or remove all the init containers we want. Even, it is very possible that all the dependencies that we need already have the microservice that we use as a base or some other microservice already developed. So we can navigate through the folders of the rest of the microservices and copy any other dependency check and use it in ours. I will add a new dependency for notifications-bridge copied from other microservice, and my file will look like the following: ... initContainers: - name: wait-nats-server image: busybox:1.28 command: ['sh', '-c', 'until wget --spider -S http://automation-engine-nats:8222/varz; do echo waiting for nats-server; sleep 2; done'] - name: wait-redis image: busybox:1.28 command: ['sh', '-c', 'until printf \"PING\\r\\n\" | nc ${REDIS_HOSTNAME} 6379; do echo waiting for redis; sleep 2; done'] envFrom: - configMapRef: name: {{ include \"new-bridge.configmapName\" . }} {{- if .Values.config.capabilities_enabled.notifications_bridge }} \u00af\u2502 - name: wait-notifications-bridge \u2502 image: busybox:1.28 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500> here! command: ['sh', '-c', 'until wget --spider -S http://notifications-bridge:5000/_health; do echo waiting for notifications-bridge; sleep 2; done'] \u2502 {{- end }} _\u2502 ... Note that we have a if condition. You will see this in some check, we use this because if we deploy only some microservices, we must contemplate this. If the notifications-bridge does not exist, the check will not be created. Nats and Redis are always required, that's wy don't have the conditional. VARIABLES: time to update the variables that will use our microservice, this involves various files: helm/charts/automation-engine/charts/new-bridge/templates/configmap.yaml this file always will be part of the deployment, it contains the variables base and the variables with no sensitive information. let's add a new variable NEW_VAR: ... CURRENT_ENVIRONMENT: {{ .Values.global.current_environment }} ENVIRONMENT_NAME: \"{{ .Values.global.environment }}\" NATS_SERVER1: {{ .Values.global.nats_server }} NEW_VAR: \"{{ .Values.config.new_var }}\" <\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 here! REDIS_HOSTNAME: {{ .Values.global.redis_hostname }} PAPERTRAIL_ACTIVE: \"{{ .Values.global.papertrail_active }}\" PAPERTRAIL_HOST: {{ .Values.global.papertrail_host }} PAPERTRAIL_PORT: \"{{ .Values.global.papertrail_port }}\" PAPERTRAIL_PREFIX: \"{{ .Values.config.papertrail_prefix }}\" ... You can see here two important things, 1. there are variables with quotes and without quotes: this depends on your needs, if you don't put quotes, YAML will interpret the best case for you.. example, if you put a number like 5 as a value, YAML will interpret this as an integer, but careful, this could be a danger if your application expects a string variable; if this is the case, use quotes to define your var. 2. Additionally, we have variables of two types: \"global\" and \"config\". The global ones are common for all microservices, and the \"config\" is specific for this microservice. All the additional variables that we add will be of the type \"config\" helm/charts/automation-engine/charts/new-bridge/templates/secret.yaml this file may or may not exist in the chart and contains variables that have sensitive information. This info will be encoded with base64 to no show in clear text. let's add a new variable NEW_SENSITIVE_VAR: apiVersion: v1 kind: Secret metadata: name: {{ include \"new-bridge.secretName\" . }} labels: {{- include \"new-bridge.labels\" . | nindent 4 }} annotations: reloader.stakater.com/match: \"true\" data: NEW_SENSITIVE_VAR: {{ .Values.config.new_sensitive_var | b64enc }} <\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 here! helm/charts/automation-engine/charts/new-bridge/values.yaml Now that we add our new variable in the configmap.yaml, we have to define it in our values file in order to use it. As you can see above, the definition of our variable points to the values file of our microservice; \"Values.config.new_var\" so let's go update it: ... config: <\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 in config section!!! papertrail_prefix: \"\" # -- New useful variable with no sensitive information \u00af\u2502______________ here the configmap variable! new_var: \"\" _\u2502 # -- New useful variable with sensitive information \u00af\u2502______________ and here the secret variable! new_sensitive_var: \"\" _\u2502 ... Check that we only define the variable but no put any value, although we can also set a default value if we want. helm/charts/automation-engine/values.yaml This is the values template off the entire automation-engine application. This only have the structure of the values and no contain any real value. For this part we will copy the content of the values file that we just created and paste in the place that correspond (respecting the alphabetical order). It's important to note that we are pasting the values inside another Yaml, so we must adapt the indentation for the destiny file: ... # -- lumin-billing-report subchart specific configuration lumin-billing-report: # -- Field to indicate if the lumin-billing-report module is going to be deployed enabled: true # -- Number of replicas of lumin-billing-report module replicaCount: 1 config: # -- Papertrail prefix for create logs definition papertrail_prefix: \"\" # -- URI of Lumin API lumin_uri: \"\" # -- Token credentials for Lumin API lumin_token: \"\" # -- Name of customer to generate lumin-billing-report customer_name: \"\" # -- Email address to send lumin-billing-report billing_recipient: \"\" image: repository: 374050862540.dkr.ecr.us-east-1.amazonaws.com/lumin-billing-report pullPolicy: Always # Overrides the image tag whose default is the chart appVersion. tag: \"\" service: type: ClusterIP port: 5000 resources: limits: cpu: 200m memory: 256Mi requests: cpu: 100m memory: 128Mi # -- new-bridge subchart specific configuration \u00af\u2502 new-bridge: \u2502 replicaCount: 1 \u2502 enabled: true \u2502 config: \u2502 papertrail_prefix: \"\" \u2502 # -- New useful variable with no sensitive information \u2502 new_var: \"\" \u2502 # -- New useful variable with sensitive information \u2502 new_sensitive_var: \"\" \u2502 image: \u2502 repository: 374050862540.dkr.ecr.us-east-1.amazonaws.com/new-bridge \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500> here! pullPolicy: Always \u2502 # Overrides the image tag whose default is the chart appVersion. \u2502 tag: \"\" \u2502 service: \u2502 type: ClusterIP \u2502 port: 5000 \u2502 resources: \u2502 limits: \u2502 cpu: 200m \u2502 memory: 256Mi \u2502 requests: \u2502 cpu: 100m \u2502 memory: 128Mi _\u2502 ... Things to check: first the indentation!!.. second, the \"global\" config is not set here; it is defined at the beginning of the values file and is common for all microservices. and finally, we remove blank and default configurations to get a shorter file (things removed: autoscaling, the default is false, so we can omit it. nodeSelector. tolerations and affinity). PD: You can keep autoscaling if you will enable it. helm/charts/automation-engine/values.yaml.tpl This is the most important file, it contains the values that will be parsed and used to deploy the Automation-Engine application. Basically it's the same file of values.yaml, but with the variables that will be replaced in the pipeline to deploy a production or develop environment. Let's add our new micro with the variables: ... # -- lumin-billing-report subchart specific configuration lumin-billing-report: enabled: ${LUMIN_BILLING_REPORT_ENABLED} replicaCount: ${LUMIN_BILLING_REPORT_DESIRED_TASKS} config: # -- Papertrail prefix for create logs definition papertrail_prefix: \"lumin-billing-report-${LUMIN_BILLING_REPORT_BUILD_NUMBER}\" # -- URI of Lumin API lumin_uri: ${LUMIN_URI} # -- Token credentials for Lumin API lumin_token: ${LUMIN_TOKEN} # -- Name of customer to generate lumin-billing-report customer_name: ${CUSTOMER_NAME_BILLING_REPORT} # -- Email address to send lumin-billing-report billing_recipient: ${BILLING_RECIPIENT} image: repository: 374050862540.dkr.ecr.us-east-1.amazonaws.com/lumin-billing-report pullPolicy: Always # Overrides the image tag whose default is the chart appVersion. tag: ${LUMIN_BILLING_REPORT_BUILD_NUMBER} service: type: ClusterIP port: 5000 resources: limits: cpu: 200m memory: 256Mi requests: cpu: 100m memory: 128Mi # -- new-bridge subchart specific configuration \u00af\u2502 new-bridge: \u2502 replicaCount: ${NEW_BRIDGE_DESIRED_TASKS} \u2502 enabled: ${NEW_BRIDGE_ENABLED} \u2502 config: \u2502 papertrail_prefix: \"new-bridge-${NEW_BRIDGE_BUILD_NUMBER}\" \u2502 # -- New useful variable with no sensitive information \u2502 new_var: ${NEW_BRIDGE_NEW_VAR} \u2502 # -- New useful variable with sensitive information \u2502 new_sensitive_var: ${NEW_BRIDGE_NEW_SENSITIVE_VAR} \u2502 image: \u2502 repository: 374050862540.dkr.ecr.us-east-1.amazonaws.com/new-bridge \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500> here! pullPolicy: Always \u2502 # Overrides the image tag whose default is the chart appVersion. \u2502 tag: ${NEW_BRIDGE_BUILD_NUMBER} \u2502 service: \u2502 type: ClusterIP \u2502 port: 5000 \u2502 resources: \u2502 limits: \u2502 cpu: 200m \u2502 memory: 256Mi \u2502 requests: \u2502 cpu: 100m \u2502 memory: 128Mi _\u2502 ... With this, we have the entire template of our new microservice. Now we need to set in the pipeline the variables that we just created. ci-utils/environments/deploy_environment_vars.sh In this file, we define the variables that will be used in the values file. Most of the cases are variables that we create in GitLab with the value of dev and production environments. This file is a bash script that has multiple functions to define the variables, each function is for the microservice that requires those variables. If we are adding a new micro that requires variables, we need to define the function and in the bottom of the file execute that function. PD: no all microservices needs specific variables, so in some cases, we wouldn't need to touch this file or even create a secret.yaml. Rebember to respect the alphabetical order: ... function lumin_billing_report_variables() { if [[ \"${CI_COMMIT_REF_SLUG}\" != \"master\" ]]; then # lumin-billing-report environment variables for ephemeral environments export BILLING_RECIPIENT=${BILLING_RECIPIENT_REPORT_DEV} else # lumin-billing-report environment variables for production environment export BILLING_RECIPIENT=${BILLING_RECIPIENT_REPORT_PROD} fi } function new_bridge_variables() { \u00af\u2502 if [[ \"${CI_COMMIT_REF_SLUG}\" != \"master\" ]]; then \u2502 # new-bridge environment variables for ephemeral environments \u2502 export NEW_BRIDGE_NEW_VARIABLE=${NEW_BRIDGE_NEW_VARIABLE_DEV} \u2502 export NEW_BRIDGE_NEW_SENSITIVE_VARIABLE=${NEW_BRIDGE_NEW_SENSITIVE_VARIABLE_DEV} \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500> here! else \u2502 # new-bridge environment variables for production environment \u2502 export NEW_BRIDGE_NEW_VARIABLE=${NEW_BRIDGE_NEW_VARIABLE_PRO} \u2502 export NEW_BRIDGE_NEW_SENSITIVE_VARIABLE=${NEW_BRIDGE_NEW_SENSITIVE_VARIABLE_PRO} \u2502 fi \u2502 } _\u2502 ... function environments_assign() { # assign enabled variable for each subchart create_enabled_var_for_each_subchart # assign common environment variables for each environment common_variables_by_environment # assign specific environment variables for each subchart bruin_bridge_variables cts_bridge_variables digi_bridge_variables digi_reboot_report_variables email_tagger_monitor_variables hawkeye_bridge_variables links_metrics_api_variables lit_bridge_variables lumin_billing_report_variables new_bridge_variables <\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 and here! t7_bridge_variables velocloud_bridge_variables } ... add the variables in gitlab-ci finally, we have all the path until the real value in Gitlab. Let's go to the repository settings/ci-cd section and create the new variables: That's all, with this and the proper commit message the pipeline will run and deploy an ephemeral environment.","title":"CREATE NEW MICROSERVICE"},{"location":"CREATE_NEW_MICROSERVICE/#create-new-microservice","text":"This process describes step by step how to create a new microservice, from the ECR repository to the helm chart templates that define the microservice. All of this is created from the Gitlab repository in the pipeline; no need for more tools or actions by the developer.","title":"CREATE NEW MICROSERVICE"},{"location":"CREATE_NEW_MICROSERVICE/#introduction","text":"The process requires that the steps be carried out in order. Basically, it is necessary to create the ECR repository first so that we can then start developing and testing our new microservice in ephemeral environments or in production.","title":"Introduction"},{"location":"CREATE_NEW_MICROSERVICE/#1-create-ecr-repository","text":"We can't create the ECR repository in the branch where we are developing because the creation or update of the ECR repositories is only in the Master branch. This means that the first thing that we need to do is make a little merge to master to create our new microservice repo, by that way we can deploy our microservice later in dev branches. create a new branch from master create a new terraform ECR repo file in the folder: infra-as-code/basic-infra/3-registry you can copy any of the other repos to have an example. this is an example: resource \"aws_ecr_repository\" \"new-bridge-repository\" { name = \"new-bridge\" tags = { Project = var.common_info.project Provisioning = var.common_info.provisioning Module = \"new-bridge\" } } merge the new repository to Master branch. The pipeline will run and create the new ECR repo new-bridge","title":"1. Create ECR repository"},{"location":"CREATE_NEW_MICROSERVICE/#2-create-our-new-microservice-folder","text":"We can start working on our new microservice based on an existing one. It depends on if is a capability (bridges) or a use case . Select one or other depends on what are you developing. For example let's copy a capability \"bruing-bridge\" and paste in the root of the repo to change his name to \"new-bridge\". from this moment you can start to develop and do your tests locally. Every microservice must have the following directory structure: new-bridge \u251c\u2500\u2500 .gitlab-ci.yml \u251c\u2500\u2500 Dockerfile \u251c\u2500\u2500 README.md \u251c\u2500\u2500 package.json \u251c\u2500\u2500 requirements.txt \u251c\u2500\u2500 setup.py \u2514\u2500\u2500 src \u251c\u2500\u2500 app.py \u251c\u2500\u2500 application \u2502 \u2514\u2500\u2500 ... \u251c\u2500\u2500 config \u2502 \u2514\u2500\u2500 ... \u2514\u2500\u2500 tests \u2514\u2500\u2500 ...","title":"2. Create our new microservice folder"},{"location":"CREATE_NEW_MICROSERVICE/#3-update-ci-cd-gitlab-files-with-the-proper-values","text":"It's important to have the .gitlab-ci.yaml files correctly defined to enable pipelines: * new-bridge/.gitlab-ci.yml Change any reference of the template microservice to the new one: example find and replace \"bruin-bridge\" for \"new-bridge\" * .gitlab-ci.yml (the file in the root of the repository) Here we need to define the \"desired_tasks\" variable for this new micro (do it respecting the alphabetical order): ... NATS_SERVER_DESIRED_TASKS: \"1\" NATS_SERVER_1_DESIRED_TASKS: \"1\" NATS_SERVER_2_DESIRED_TASKS: \"1\" NEW_BRIDGE_DESIRED_TASKS: \"1\" <\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 here! SERVICE_AFFECTING_MONITOR_DESIRED_TASKS: \"1\" SERVICE_OUTAGE_MONITOR_1_DESIRED_TASKS: \"1\" ...","title":"3. Update CI-CD gitlab files with the proper values"},{"location":"CREATE_NEW_MICROSERVICE/#3-configure-semantic-release","text":"We need to edit a file in the new micro path: * new-bridge/package.json update the name of the micro with our new working name: { \"name\": \"new-bridge\", <\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 here! \"version\": \"0.0.1\", \"dependencies\": {}, \"devDependencies\": {} }","title":"3. Configure semantic-release"},{"location":"CREATE_NEW_MICROSERVICE/#3-configure-logs","text":"We use 2 systems to storage logs, papertrail for 3 days and cloudwath for 1 month. Let's add those config in: * ci-utils/papertrail-provisioning/config.py just copy one block form other microservice and paste with the name of our new micro (do it respecting the alphabetical order): ... { \"query\": f\"lumin-billing-report AND {ENVIRONMENT_NAME} AND <BUILD_NUMBER>\", \"search_name\": f\"[lumin-billing-report] - logs\", \"repository\": \"lumin-billing-report\", }, { \u00af\u2502 \"query\": f\"new-bridge AND {ENVIRONMENT_NAME} AND <BUILD_NUMBER>\", \u2502 \"search_name\": f\"[new-bridge] - logs\", \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500> here! \"repository\": \"new-bridge\", \u2502 }, _\u2502 ... helm/charts/fluent-bit-custom/templates/configmap.yaml The same; copy one block form other microservice and paste with the name of our new micro (do it respecting the alphabetical order): ... [OUTPUT] Name cloudwatch Match kube.var.log.containers.lumin-billing-report* region {{ .Values.config.region }} log_group_name {{ .Values.config.logGroupName }} log_stream_name lumin-billing-report auto_create_group true [OUTPUT] \u00af\u2502 Name cloudwatch \u2502 Match kube.var.log.containers.new-bridge* \u2502 region {{ .Values.config.region }} \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500> here! log_group_name {{ .Values.config.logGroupName }} \u2502 log_stream_name new-bridge \u2502 auto_create_group true _\u2502 ...","title":"3. Configure logs"},{"location":"CREATE_NEW_MICROSERVICE/#3-update-docker-compose-to-enable-local-deployments","text":"docker-compose.yml here we define our container along with the rest of the microservices. Just add the definition of our container respecting the alphabetical order: ... new-bridge: \u00af\u2502 build: \u2502 # Context must be the root of the monorepo \u2502 context: . \u2502 dockerfile: new-bridge/Dockerfile \u2502 args: \u2502 REPOSITORY_URL: 374050862540.dkr.ecr.us-east-1.amazonaws.com \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500> here! env_file: \u2502 - new-bridge/src/config/env \u2502 depends_on: \u2502 - \"nats-server\" \u2502 - redis \u2502 ports: \u2502 - 5006:5000 _\u2502 ...","title":"3. Update docker-compose to enable local deployments"},{"location":"CREATE_NEW_MICROSERVICE/#4-add-option-to-enable-or-disable-our-microservice","text":"helm/charts/automation-engine/Chart.yaml in this file we define our Automation-engine chart version and his dependencies. Let's add a condition for our microservice to have the possibility of disable or enable in our future deployments. ... - name: lumin-billing-report version: '*.*.*' condition: lumin-billing-report.enabled - name: new-bridge \u00af\u2502 version: '*.*.*' \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500> here! condition: new-bridge.enabled _\u2502 ...","title":"4. Add option to enable or disable our microservice"},{"location":"CREATE_NEW_MICROSERVICE/#5-helm-templates-and-variables","text":"Here we will define the infrastructure part of our microservice with a helm chart. Is very important to know that this \"how to\" is only to copy an existing microservice, therefore, we take the following statements for granted: 1. The microservice will not have a public endpoint (except email-tagger-monitor) 2. The microservice port will always be 5000 3. Depends on the base chart you use to copy & paste, you will have more or less kubernetes resources. although most microservices have: configmap, deployment, secret and service. Perfect, now let's copy and paste another chart to use as template, if we will develop a use-case, we must copy the most similar use-case. For this example we are creating a \"new-bridge\", so let's copy a \"bruin-bridge\" as a template: * BASE-FOLDER: copy this folder helm/charts/automation-engine/charts/bruin-bridge and paste here helm/charts/automation-engine/charts/ we will have something like bruin-bridge copy change the name to new-bridge . PREPARE BASE_FOLDER: now let's do a find and replace in our new folder new-bridge . find bruin-bridge and replace for new-bridge . many substitutions should appear (at the moment of write this, i can see 46 substitutions in 10 files but over time, this can change). Just remember to do this in the new-bridge folder context to evoid modify other resources. DEPENDENCIES and CHECKS: Now we have to customize our new microservice, first we must ask ourselves, what dependency does my new microservice have on other services? for example, bruin-bridge have a dependency with Nats and Redis, so it have a few checks to see if those services are available and if they are, it can be deployed. We can find this checks in the deployment.yaml file. Specifically in this part: ... initContainers: - name: wait-nats-server image: busybox:1.28 command: ['sh', '-c', 'until wget --spider -S http://automation-engine-nats:8222/varz; do echo waiting for nats-server; sleep 2; done'] - name: wait-redis image: busybox:1.28 command: ['sh', '-c', 'until printf \"PING\\r\\n\" | nc ${REDIS_HOSTNAME} 6379; do echo waiting for redis; sleep 2; done'] envFrom: - configMapRef: name: {{ include \"new-bridge.configmapName\" . }} ... We can add or remove all the init containers we want. Even, it is very possible that all the dependencies that we need already have the microservice that we use as a base or some other microservice already developed. So we can navigate through the folders of the rest of the microservices and copy any other dependency check and use it in ours. I will add a new dependency for notifications-bridge copied from other microservice, and my file will look like the following: ... initContainers: - name: wait-nats-server image: busybox:1.28 command: ['sh', '-c', 'until wget --spider -S http://automation-engine-nats:8222/varz; do echo waiting for nats-server; sleep 2; done'] - name: wait-redis image: busybox:1.28 command: ['sh', '-c', 'until printf \"PING\\r\\n\" | nc ${REDIS_HOSTNAME} 6379; do echo waiting for redis; sleep 2; done'] envFrom: - configMapRef: name: {{ include \"new-bridge.configmapName\" . }} {{- if .Values.config.capabilities_enabled.notifications_bridge }} \u00af\u2502 - name: wait-notifications-bridge \u2502 image: busybox:1.28 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500> here! command: ['sh', '-c', 'until wget --spider -S http://notifications-bridge:5000/_health; do echo waiting for notifications-bridge; sleep 2; done'] \u2502 {{- end }} _\u2502 ... Note that we have a if condition. You will see this in some check, we use this because if we deploy only some microservices, we must contemplate this. If the notifications-bridge does not exist, the check will not be created. Nats and Redis are always required, that's wy don't have the conditional. VARIABLES: time to update the variables that will use our microservice, this involves various files: helm/charts/automation-engine/charts/new-bridge/templates/configmap.yaml this file always will be part of the deployment, it contains the variables base and the variables with no sensitive information. let's add a new variable NEW_VAR: ... CURRENT_ENVIRONMENT: {{ .Values.global.current_environment }} ENVIRONMENT_NAME: \"{{ .Values.global.environment }}\" NATS_SERVER1: {{ .Values.global.nats_server }} NEW_VAR: \"{{ .Values.config.new_var }}\" <\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 here! REDIS_HOSTNAME: {{ .Values.global.redis_hostname }} PAPERTRAIL_ACTIVE: \"{{ .Values.global.papertrail_active }}\" PAPERTRAIL_HOST: {{ .Values.global.papertrail_host }} PAPERTRAIL_PORT: \"{{ .Values.global.papertrail_port }}\" PAPERTRAIL_PREFIX: \"{{ .Values.config.papertrail_prefix }}\" ... You can see here two important things, 1. there are variables with quotes and without quotes: this depends on your needs, if you don't put quotes, YAML will interpret the best case for you.. example, if you put a number like 5 as a value, YAML will interpret this as an integer, but careful, this could be a danger if your application expects a string variable; if this is the case, use quotes to define your var. 2. Additionally, we have variables of two types: \"global\" and \"config\". The global ones are common for all microservices, and the \"config\" is specific for this microservice. All the additional variables that we add will be of the type \"config\" helm/charts/automation-engine/charts/new-bridge/templates/secret.yaml this file may or may not exist in the chart and contains variables that have sensitive information. This info will be encoded with base64 to no show in clear text. let's add a new variable NEW_SENSITIVE_VAR: apiVersion: v1 kind: Secret metadata: name: {{ include \"new-bridge.secretName\" . }} labels: {{- include \"new-bridge.labels\" . | nindent 4 }} annotations: reloader.stakater.com/match: \"true\" data: NEW_SENSITIVE_VAR: {{ .Values.config.new_sensitive_var | b64enc }} <\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 here! helm/charts/automation-engine/charts/new-bridge/values.yaml Now that we add our new variable in the configmap.yaml, we have to define it in our values file in order to use it. As you can see above, the definition of our variable points to the values file of our microservice; \"Values.config.new_var\" so let's go update it: ... config: <\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 in config section!!! papertrail_prefix: \"\" # -- New useful variable with no sensitive information \u00af\u2502______________ here the configmap variable! new_var: \"\" _\u2502 # -- New useful variable with sensitive information \u00af\u2502______________ and here the secret variable! new_sensitive_var: \"\" _\u2502 ... Check that we only define the variable but no put any value, although we can also set a default value if we want. helm/charts/automation-engine/values.yaml This is the values template off the entire automation-engine application. This only have the structure of the values and no contain any real value. For this part we will copy the content of the values file that we just created and paste in the place that correspond (respecting the alphabetical order). It's important to note that we are pasting the values inside another Yaml, so we must adapt the indentation for the destiny file: ... # -- lumin-billing-report subchart specific configuration lumin-billing-report: # -- Field to indicate if the lumin-billing-report module is going to be deployed enabled: true # -- Number of replicas of lumin-billing-report module replicaCount: 1 config: # -- Papertrail prefix for create logs definition papertrail_prefix: \"\" # -- URI of Lumin API lumin_uri: \"\" # -- Token credentials for Lumin API lumin_token: \"\" # -- Name of customer to generate lumin-billing-report customer_name: \"\" # -- Email address to send lumin-billing-report billing_recipient: \"\" image: repository: 374050862540.dkr.ecr.us-east-1.amazonaws.com/lumin-billing-report pullPolicy: Always # Overrides the image tag whose default is the chart appVersion. tag: \"\" service: type: ClusterIP port: 5000 resources: limits: cpu: 200m memory: 256Mi requests: cpu: 100m memory: 128Mi # -- new-bridge subchart specific configuration \u00af\u2502 new-bridge: \u2502 replicaCount: 1 \u2502 enabled: true \u2502 config: \u2502 papertrail_prefix: \"\" \u2502 # -- New useful variable with no sensitive information \u2502 new_var: \"\" \u2502 # -- New useful variable with sensitive information \u2502 new_sensitive_var: \"\" \u2502 image: \u2502 repository: 374050862540.dkr.ecr.us-east-1.amazonaws.com/new-bridge \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500> here! pullPolicy: Always \u2502 # Overrides the image tag whose default is the chart appVersion. \u2502 tag: \"\" \u2502 service: \u2502 type: ClusterIP \u2502 port: 5000 \u2502 resources: \u2502 limits: \u2502 cpu: 200m \u2502 memory: 256Mi \u2502 requests: \u2502 cpu: 100m \u2502 memory: 128Mi _\u2502 ... Things to check: first the indentation!!.. second, the \"global\" config is not set here; it is defined at the beginning of the values file and is common for all microservices. and finally, we remove blank and default configurations to get a shorter file (things removed: autoscaling, the default is false, so we can omit it. nodeSelector. tolerations and affinity). PD: You can keep autoscaling if you will enable it. helm/charts/automation-engine/values.yaml.tpl This is the most important file, it contains the values that will be parsed and used to deploy the Automation-Engine application. Basically it's the same file of values.yaml, but with the variables that will be replaced in the pipeline to deploy a production or develop environment. Let's add our new micro with the variables: ... # -- lumin-billing-report subchart specific configuration lumin-billing-report: enabled: ${LUMIN_BILLING_REPORT_ENABLED} replicaCount: ${LUMIN_BILLING_REPORT_DESIRED_TASKS} config: # -- Papertrail prefix for create logs definition papertrail_prefix: \"lumin-billing-report-${LUMIN_BILLING_REPORT_BUILD_NUMBER}\" # -- URI of Lumin API lumin_uri: ${LUMIN_URI} # -- Token credentials for Lumin API lumin_token: ${LUMIN_TOKEN} # -- Name of customer to generate lumin-billing-report customer_name: ${CUSTOMER_NAME_BILLING_REPORT} # -- Email address to send lumin-billing-report billing_recipient: ${BILLING_RECIPIENT} image: repository: 374050862540.dkr.ecr.us-east-1.amazonaws.com/lumin-billing-report pullPolicy: Always # Overrides the image tag whose default is the chart appVersion. tag: ${LUMIN_BILLING_REPORT_BUILD_NUMBER} service: type: ClusterIP port: 5000 resources: limits: cpu: 200m memory: 256Mi requests: cpu: 100m memory: 128Mi # -- new-bridge subchart specific configuration \u00af\u2502 new-bridge: \u2502 replicaCount: ${NEW_BRIDGE_DESIRED_TASKS} \u2502 enabled: ${NEW_BRIDGE_ENABLED} \u2502 config: \u2502 papertrail_prefix: \"new-bridge-${NEW_BRIDGE_BUILD_NUMBER}\" \u2502 # -- New useful variable with no sensitive information \u2502 new_var: ${NEW_BRIDGE_NEW_VAR} \u2502 # -- New useful variable with sensitive information \u2502 new_sensitive_var: ${NEW_BRIDGE_NEW_SENSITIVE_VAR} \u2502 image: \u2502 repository: 374050862540.dkr.ecr.us-east-1.amazonaws.com/new-bridge \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500> here! pullPolicy: Always \u2502 # Overrides the image tag whose default is the chart appVersion. \u2502 tag: ${NEW_BRIDGE_BUILD_NUMBER} \u2502 service: \u2502 type: ClusterIP \u2502 port: 5000 \u2502 resources: \u2502 limits: \u2502 cpu: 200m \u2502 memory: 256Mi \u2502 requests: \u2502 cpu: 100m \u2502 memory: 128Mi _\u2502 ... With this, we have the entire template of our new microservice. Now we need to set in the pipeline the variables that we just created. ci-utils/environments/deploy_environment_vars.sh In this file, we define the variables that will be used in the values file. Most of the cases are variables that we create in GitLab with the value of dev and production environments. This file is a bash script that has multiple functions to define the variables, each function is for the microservice that requires those variables. If we are adding a new micro that requires variables, we need to define the function and in the bottom of the file execute that function. PD: no all microservices needs specific variables, so in some cases, we wouldn't need to touch this file or even create a secret.yaml. Rebember to respect the alphabetical order: ... function lumin_billing_report_variables() { if [[ \"${CI_COMMIT_REF_SLUG}\" != \"master\" ]]; then # lumin-billing-report environment variables for ephemeral environments export BILLING_RECIPIENT=${BILLING_RECIPIENT_REPORT_DEV} else # lumin-billing-report environment variables for production environment export BILLING_RECIPIENT=${BILLING_RECIPIENT_REPORT_PROD} fi } function new_bridge_variables() { \u00af\u2502 if [[ \"${CI_COMMIT_REF_SLUG}\" != \"master\" ]]; then \u2502 # new-bridge environment variables for ephemeral environments \u2502 export NEW_BRIDGE_NEW_VARIABLE=${NEW_BRIDGE_NEW_VARIABLE_DEV} \u2502 export NEW_BRIDGE_NEW_SENSITIVE_VARIABLE=${NEW_BRIDGE_NEW_SENSITIVE_VARIABLE_DEV} \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500> here! else \u2502 # new-bridge environment variables for production environment \u2502 export NEW_BRIDGE_NEW_VARIABLE=${NEW_BRIDGE_NEW_VARIABLE_PRO} \u2502 export NEW_BRIDGE_NEW_SENSITIVE_VARIABLE=${NEW_BRIDGE_NEW_SENSITIVE_VARIABLE_PRO} \u2502 fi \u2502 } _\u2502 ... function environments_assign() { # assign enabled variable for each subchart create_enabled_var_for_each_subchart # assign common environment variables for each environment common_variables_by_environment # assign specific environment variables for each subchart bruin_bridge_variables cts_bridge_variables digi_bridge_variables digi_reboot_report_variables email_tagger_monitor_variables hawkeye_bridge_variables links_metrics_api_variables lit_bridge_variables lumin_billing_report_variables new_bridge_variables <\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 and here! t7_bridge_variables velocloud_bridge_variables } ... add the variables in gitlab-ci finally, we have all the path until the real value in Gitlab. Let's go to the repository settings/ci-cd section and create the new variables: That's all, with this and the proper commit message the pipeline will run and deploy an ephemeral environment.","title":"5. Helm templates and variables"},{"location":"DOCUMENTATION/","text":"1. DOCS Organization Folder structure diagrams : In this folder you will encounter all the diagrams Intelygenz has done. decisions : Folder where Intelygenz store the decisions made by the team. metrics-definitions : Here is where all the metrics of the project are defined. images : Folder to store images to be use on other MD files. logging : 2. Rules This is the Main source of truth. Docs must be in the docs folder. Always make atomic commits. All the documentation must be reviewed and approved. Before start the code of a new metric, document it, and work on it only after approved by another team member. Organization of the documentation matters. Discuss with your team where is the best place to put new stuff. Always link a new MD file in an index README.md where makes sense. Diagrams are important, before start coding a new system/infrastructure, update the diagrams. 3. Tools Diagrams To create good diagrams centralized in the repository we use diagrams.net , this tool has plugins for the two main IDE that the company use: * IntelliJ * VSCode","title":"Organization"},{"location":"DOCUMENTATION/#1-docs-organization","text":"","title":"1. DOCS Organization"},{"location":"DOCUMENTATION/#folder-structure","text":"diagrams : In this folder you will encounter all the diagrams Intelygenz has done. decisions : Folder where Intelygenz store the decisions made by the team. metrics-definitions : Here is where all the metrics of the project are defined. images : Folder to store images to be use on other MD files. logging :","title":"Folder structure"},{"location":"DOCUMENTATION/#2-rules","text":"This is the Main source of truth. Docs must be in the docs folder. Always make atomic commits. All the documentation must be reviewed and approved. Before start the code of a new metric, document it, and work on it only after approved by another team member. Organization of the documentation matters. Discuss with your team where is the best place to put new stuff. Always link a new MD file in an index README.md where makes sense. Diagrams are important, before start coding a new system/infrastructure, update the diagrams.","title":"2. Rules"},{"location":"DOCUMENTATION/#3-tools","text":"","title":"3. Tools"},{"location":"DOCUMENTATION/#diagrams","text":"To create good diagrams centralized in the repository we use diagrams.net , this tool has plugins for the two main IDE that the company use: * IntelliJ * VSCode","title":"Diagrams"},{"location":"INFRASTRUCTURE_AS_CODE/","text":"INFRASTRUCTURE AS CODE Infrastructure as Code (IaC) is the management of infrastructure (networks, virtual machines, load balancers, and connection topology) in a descriptive model, using the same versioning as DevOps team uses for source code. Like the principle that the same source code generates the same binary, an IaC model generates the same environment every time it is applied. IaC is a key DevOps practice and is used in conjunction with continuous delivery. Azure Introduction Infrastructure as Code enables DevOps to test the deployment of environments before use it in production. IaC can deliver stable environments rapidly and at scale. Avoiding manual configuration of environments and enforce consistency by representing the desired state of their environments via code. This technique improves the automatic deployments in automation-engine, each time the pipelines launch the Continuous delivery will create, update or destroy the infrastructure if it's necessary. IaC in MetTel Automation Automation-engine runs IaC with terraform , this task is/will be included in the automation pipelines . Terraform save the state of the infrastructure in a storage, these files have the extension .tfstate . In MetTel Automation we saves these files in a protected Cloud storage to centralize the states and be accessible each time the pipeline needs to deploy/update the infrastructure. Folder structure infra-as-code/ \u251c\u2500\u2500 basic-infra # basic infrastructure in AWS \u2514\u2500\u2500 data-collector # data-collector infrastructre in AWS \u2514\u2500\u2500 dev # AWS resources for each environment (ECS Cluster, ElastiCache Cluster, etc.) \u2514\u2500\u2500 kre # kre infrastructure \u2514\u2500\u2500 0 -create-bucket # bucket to store EKS information \u2514\u2500\u2500 1 -eks-roles # IAM roles infrastructure for EKS cluster \u2514\u2500\u2500 2 -smtp # SES infrastructure folder \u2514\u2500\u2500 kre-runtimes # kre runtimes infrastructure \u2514\u2500\u2500 modules # custom terraform modules folders used for create KRE infrastructure \u2514\u2500\u2500 runtimes # KRE runtimes folders \u2514\u2500\u2500 network-resources # network resources infrastructure in AWS Al terraform files are located inside ./infra-as-code , in this folder there are four additional folders, basic-infra , dev , ecs-services and network-resources . basic-infra : there are the necessary terraform files to create the Docker images repositories in ECS, and the roles and policies necessary for use these. data-collector : there are the necessary terraform files to create a Lambda, a DocumentDB Cluster, as well as an API Gateway to call the necessary and all the necessary resources to perform the conexion between these elements. These resources will only be created for production environment dev : there are the necessary terraform files for create the resources used for each environment in AWS, these are as follows An ECS Cluster , the ECS Services and its Task Definition for all the microservices present in the project Three ElastiCache Redis Clusters An ALB A record in Route53 A CloudWatch Log Group An Service Discovery Service for each ECS Service of the ECS Cluster created for this environment and a Service Discovery Namespace to logically group these Service Discovery Services . A set of resources related to the metrics of the environment: CloudWatch Alarms CloudWatch Dashboard CloudWatch Log Filters A CloudFormation Stack for create the SNS topic that will be used by CloudWatch Alarms notifications of this environment A set of Security Groups for all the resources created by the terraform files present in this folder A set of null_resource Terraform type resources to execute the python script in charge of health checking the task instances created in the deployment of capabilities microservices. kre : there are the necessary terraform files for create the infrastructure for the kre component of konstellation , as well as all the components it needs at AWS. There is a series of folders with terraform code that have a number in their names, these will be used to deploy the components in a certain order and are detailed below: 0-create-bucket : In this folder the terraform code is available to create a bucket for each environment and save information about the cluster, such as the SSH key to connect to the worker nodes of the EKS cluster that is going to be created. 1-eks-roles : In this folder the terraform code is available to create different IAM roles to map with EKS users and assign specific permissions for each one, for this purpose, a cli will be used later. 2-create-eks-cluster : In this folder the terraform code is available to create the following resources An EKS cluster to be able to deploy the different kre components designed for Kubernetes An AutoScaling Group to have the desired number of Kubernetes worker nodes A hosted zone on Route53 for the corresponding kre environment A SSH key to connect to any worker node of EKS 3-smtp : In this folder the terraform code to create a SMTP service through Amazon SES and all the necessary components of it. kre-runtimes : there are the necessary terraform files for create the infrastructure needed by a KRE runtime: modules : Contains the terraform code for custom modules created for provision a KRE runtimes. It will create the following for each KRE runtime: A Route53 Hosted Zone in mettel-automation.net domain. runtimes : Contains the terraform code files for deploy KRE runtimes used the custom module located in modules folder. network-resources : there are the necessary terraform files for create the VPC and all related resources in the environment used for deployment, these being the following: Internet Gateway Elastic IP Addresses NAT Gateways Subnets Route tables for the created subnets A set of Security Groups for all the resources created by the terraform files present in this folder","title":"INFRASTRUCTURE AS CODE"},{"location":"INFRASTRUCTURE_AS_CODE/#infrastructure-as-code","text":"Infrastructure as Code (IaC) is the management of infrastructure (networks, virtual machines, load balancers, and connection topology) in a descriptive model, using the same versioning as DevOps team uses for source code. Like the principle that the same source code generates the same binary, an IaC model generates the same environment every time it is applied. IaC is a key DevOps practice and is used in conjunction with continuous delivery. Azure","title":"INFRASTRUCTURE AS CODE"},{"location":"INFRASTRUCTURE_AS_CODE/#introduction","text":"Infrastructure as Code enables DevOps to test the deployment of environments before use it in production. IaC can deliver stable environments rapidly and at scale. Avoiding manual configuration of environments and enforce consistency by representing the desired state of their environments via code. This technique improves the automatic deployments in automation-engine, each time the pipelines launch the Continuous delivery will create, update or destroy the infrastructure if it's necessary.","title":"Introduction"},{"location":"INFRASTRUCTURE_AS_CODE/#iac-in-mettel-automation","text":"Automation-engine runs IaC with terraform , this task is/will be included in the automation pipelines . Terraform save the state of the infrastructure in a storage, these files have the extension .tfstate . In MetTel Automation we saves these files in a protected Cloud storage to centralize the states and be accessible each time the pipeline needs to deploy/update the infrastructure.","title":"IaC in MetTel Automation"},{"location":"INFRASTRUCTURE_AS_CODE/#folder-structure","text":"infra-as-code/ \u251c\u2500\u2500 basic-infra # basic infrastructure in AWS \u2514\u2500\u2500 data-collector # data-collector infrastructre in AWS \u2514\u2500\u2500 dev # AWS resources for each environment (ECS Cluster, ElastiCache Cluster, etc.) \u2514\u2500\u2500 kre # kre infrastructure \u2514\u2500\u2500 0 -create-bucket # bucket to store EKS information \u2514\u2500\u2500 1 -eks-roles # IAM roles infrastructure for EKS cluster \u2514\u2500\u2500 2 -smtp # SES infrastructure folder \u2514\u2500\u2500 kre-runtimes # kre runtimes infrastructure \u2514\u2500\u2500 modules # custom terraform modules folders used for create KRE infrastructure \u2514\u2500\u2500 runtimes # KRE runtimes folders \u2514\u2500\u2500 network-resources # network resources infrastructure in AWS Al terraform files are located inside ./infra-as-code , in this folder there are four additional folders, basic-infra , dev , ecs-services and network-resources . basic-infra : there are the necessary terraform files to create the Docker images repositories in ECS, and the roles and policies necessary for use these. data-collector : there are the necessary terraform files to create a Lambda, a DocumentDB Cluster, as well as an API Gateway to call the necessary and all the necessary resources to perform the conexion between these elements. These resources will only be created for production environment dev : there are the necessary terraform files for create the resources used for each environment in AWS, these are as follows An ECS Cluster , the ECS Services and its Task Definition for all the microservices present in the project Three ElastiCache Redis Clusters An ALB A record in Route53 A CloudWatch Log Group An Service Discovery Service for each ECS Service of the ECS Cluster created for this environment and a Service Discovery Namespace to logically group these Service Discovery Services . A set of resources related to the metrics of the environment: CloudWatch Alarms CloudWatch Dashboard CloudWatch Log Filters A CloudFormation Stack for create the SNS topic that will be used by CloudWatch Alarms notifications of this environment A set of Security Groups for all the resources created by the terraform files present in this folder A set of null_resource Terraform type resources to execute the python script in charge of health checking the task instances created in the deployment of capabilities microservices. kre : there are the necessary terraform files for create the infrastructure for the kre component of konstellation , as well as all the components it needs at AWS. There is a series of folders with terraform code that have a number in their names, these will be used to deploy the components in a certain order and are detailed below: 0-create-bucket : In this folder the terraform code is available to create a bucket for each environment and save information about the cluster, such as the SSH key to connect to the worker nodes of the EKS cluster that is going to be created. 1-eks-roles : In this folder the terraform code is available to create different IAM roles to map with EKS users and assign specific permissions for each one, for this purpose, a cli will be used later. 2-create-eks-cluster : In this folder the terraform code is available to create the following resources An EKS cluster to be able to deploy the different kre components designed for Kubernetes An AutoScaling Group to have the desired number of Kubernetes worker nodes A hosted zone on Route53 for the corresponding kre environment A SSH key to connect to any worker node of EKS 3-smtp : In this folder the terraform code to create a SMTP service through Amazon SES and all the necessary components of it. kre-runtimes : there are the necessary terraform files for create the infrastructure needed by a KRE runtime: modules : Contains the terraform code for custom modules created for provision a KRE runtimes. It will create the following for each KRE runtime: A Route53 Hosted Zone in mettel-automation.net domain. runtimes : Contains the terraform code files for deploy KRE runtimes used the custom module located in modules folder. network-resources : there are the necessary terraform files for create the VPC and all related resources in the environment used for deployment, these being the following: Internet Gateway Elastic IP Addresses NAT Gateways Subnets Route tables for the created subnets A set of Security Groups for all the resources created by the terraform files present in this folder","title":"Folder structure"},{"location":"LOGGING_AND_MONITORING/","text":"Logging and Monitoring Cloudwatch Cloudwatch Log Groups A log group is created in Cloudwatch for the different environments deployed in AWS: Production environment : A log group will be created with the name automation-master in which the different logStreams will be created to store the logs of the different ECS services for the production environment. Ephemeral environments : A log group will be created with the name automation-<branch_identifier> for ephemeral environments, being branch_identifier the result of applying echo -n \"<branch_name>\" | sha256sum | cut -c1-8 on the branch name related to the ephemeral environment, the logStreams required for the different ECS services deployed in that environment will be created using the mentioned log group . Cloudwatch Log Streams As mentioned in the previous section, the different logStreams of the deployed services will be stored in a specific logGroup for each environment. A logStream will be created for each of the ECS cluster services tasks created in each environment, which will follow the following scheme <environment_name>-<microservice_image_build_number>/<microservice_name>/<ecs_tasks_id> environment_name : The names for environments are automation-master for production, as well as automation-<branch_identifier> for ephemeral environments, being branch_identifier the result of applying echo -n \"<branch_name>\" | sha256sum | cut -c1-8 on the branch name related to the ephemeral environment. microservice_image_build_number : The pipeline number is used as build number to build the image of those microservices that need to build a new docker image. microservice_name : The name of the microservice deployed in ECS, e.g. bruin-bridge . ecs_task_id> : For each ECS service, one or several tasks are created, depending on the desired number in the service, these tasks are identified with an identifier formed by number and letters, e.g. 961ef51b61834a2e9dd804db564a9fe0 . Cloudwatch Retention Period All environments deployed on AWS have been configured to use Cloudwatch to record the logs of the microservices present in them, although it is important to note the following differences: Production environment : The retention period of the log group created for such an environment is 90 days. Ephemeral environments : The retention period of the log group created for such an environment is 14 days. This retention period is configured in the infra-as-code/dev/logs.tf file. Cloudwatch logs retrieval tool It is possible to obtain the events in logs of a logGroup through a tool designed for this purpose available in Github called log-stream-filter . Download and install This tool is available for Linux, MacOS and Windows, it is possible to download the latest binary for each of these OSs: Linux : It's possible download and install as a deb package curl -o log-stream-filter.deb -L $( curl -s https://api.github.com/repos/xoanmm/log-stream-filter/releases/latest | jq -r '.assets[] | select(.name | contains(\"linux_amd64.deb\")) | .browser_download_url' ) sudo dpkg -i log-stream-filter.deb It's also possible download and install as a simple binary curl -o log-stream-filter.tgz -L $( curl -s https://api.github.com/repos/xoanmm/log-stream-filter/releases/latest | jq -r '.assets[] | select(.name | contains(\"linux_64-bit.tar.gz\")) | .browser_download_url' ) tar -zxvf log-stream-filter.tgz chmod +x ./log-stream-filter && sudo mv ./log-stream-filter /usr/local/bin MacOS : curl -o log-stream-filter.tgz -L $( curl -s https://api.github.com/repos/xoanmm/log-stream-filter/releases/latest | jq -r '.assets[] | select(.name | contains(\"macOS\")) | .browser_download_url' ) tar -zxvf log-stream-filter.tgz chmod +x ./log-stream-filter && sudo mv ./log-stream-filter /usr/local/bin Windows : curl -o log-stream-filter.zip -L $( curl -s https://api.github.com/repos/xoanmm/log-stream-filter/releases/latest | jq -r '.assets[] | select(.name | contains(\"windows\")) | .browser_download_url' ) unzip log-stream-filter.zip Example of usage Example of search text Outage monitoring process finished between 04/06/2021 12:00:00 and 04/07/2021 12:00:00 in log group with name automation-master for log streams that match with name service-outage-monitor-1 using AWS profile with name mettel-automation : $ log-stream-filter -n \"automation-master\" -l \"service-outage-monitor-1\" -a \"mettel-automation\" -s \"04/06/2021 12:00:00\" -e \"04/07/2021 12:00:00\" -T \"Outage monitoring process finished\" -t true Filtering logs for logGroup automation-master params: [ aws-profile mettel-automation ] [ log-stream-filter: service-outage-monitor-1 ] [ search-term-search: true ] [ search-term: Outage monitoring process finished ] [ path: /tmp ] [ start-date: 04 /06/2021 12 :00:00 ] [ end-date: 04 /07/2021 12 :00:00 ] Getting logStreams for logGroup automation-master applying filter service-outage-monitor-1 Getting the logEvents for those logStreams whose last event was inserted between 04 /06/2021 12 :00:00 and 04 /07/2021 12 :00:00 **************************************************************************************************** LogStreamName: automation-master-75993/service-outage-monitor-1/75d4e2cbb3f64e84a97063d34ffe6177 CreationTime: 04 /05/2021 23 :08:29 LastEventTime: 04 /06/2021 12 :43:49 All log events are going to be retrieved in logGroup automation-master for logStream automation-master-75993/service-outage-monitor-1/75d4e2cbb3f64e84a97063d34ffe6177 from time 1617710400000 Event messages for stream automation-master-75993/service-outage-monitor-1/75d4e2cbb3f64e84a97063d34ffe6177 in log group automation-master are going to be saved in the following files - /tmp/automation-master-75993_service-outage-monitor-1_75d4e2cbb3f64e84a97063d34ffe6177-Outage_monitoring_process_finished **************************************************************************************************** **************************************************************************************************** LogStreamName: automation-master-76009/service-outage-monitor-1/aab10e3e029c44fcb08dddeb51431fa2 CreationTime: 04 /06/2021 12 :44:40 LastEventTime: 04 /07/2021 10 :39:16 All log events are going to be retrieved in logGroup automation-master for logStream automation-master-76009/service-outage-monitor-1/aab10e3e029c44fcb08dddeb51431fa2 from time 1617710400000 Event messages for stream automation-master-76009/service-outage-monitor-1/aab10e3e029c44fcb08dddeb51431fa2 in log group automation-master are going to be saved in the following files - /tmp/automation-master-76009_service-outage-monitor-1_aab10e3e029c44fcb08dddeb51431fa2-Outage_monitoring_process_finished **************************************************************************************************** **************************************************************************************************** LogStreamName: automation-master-76051/service-outage-monitor-1/c921aa5c9bf04d71b0fab6d8673946a3 CreationTime: 04 /07/2021 10 :41:22 LastEventTime: 04 /07/2021 11 :04:33 All log events are going to be retrieved in logGroup automation-master for logStream automation-master-76051/service-outage-monitor-1/c921aa5c9bf04d71b0fab6d8673946a3 from time 1617710400000 Event messages for stream automation-master-76051/service-outage-monitor-1/c921aa5c9bf04d71b0fab6d8673946a3 in log group automation-master are going to be saved in the following files - /tmp/automation-master-76051_service-outage-monitor-1_c921aa5c9bf04d71b0fab6d8673946a3-Outage_monitoring_process_finished **************************************************************************************************** 3 files generated for logs of logStreams filtered for logGroup automation-master Location of files where logs of logStream automation-master-75993/service-outage-monitor-1/75d4e2cbb3f64e84a97063d34ffe6177 were stored are the following - /tmp/automation-master-75993_service-outage-monitor-1_75d4e2cbb3f64e84a97063d34ffe6177-Outage_monitoring_process_finished Location of files where logs of logStream automation-master-76009/service-outage-monitor-1/aab10e3e029c44fcb08dddeb51431fa2 were stored are the following - /tmp/automation-master-76009_service-outage-monitor-1_aab10e3e029c44fcb08dddeb51431fa2-Outage_monitoring_process_finished Location of files where logs of logStream automation-master-76051/service-outage-monitor-1/c921aa5c9bf04d71b0fab6d8673946a3 were stored are the following - /tmp/automation-master-76051_service-outage-monitor-1_c921aa5c9bf04d71b0fab6d8673946a3-Outage_monitoring_process_finished To know all the options it is recommended to read the README of log-stream-filter in github. Papertrail There is a papertrail account used in the project for sending logs, but it will only be used for the production environment , this is because it is a high cost service and it is not feasible to have an account for all ephemeral environments due to its cost and the high volume of logs generated in these environments. Papertrail dashboards The system logs of the production environment are stored in papertrail, the account credentials are in the project's onepassword vault to which all people in the project have access. Below is a screenshot of the main screen of the system. In this system it's possible see three useful dashboards: [production] - master alarms : alarms are defined on different modules with notifications sent to slack through the mettel-alarms-papertrail-production channel, for example when the number of error messages in a module exceeds 100 times in an hour. Below is a screenshot where these alarms have been marked in a red rectangle. [production] - master logs : searches are defined to gather the logs of the replicas of each deployed microservice. Below is a screenshot where these searches have been marked in a red rectangle. [production] - master notifications : Searches on different modules are defined with their notification to slack through the mettel-notifications-papertrail-production channel. Below is a screenshot where these searches have been marked in a red rectangle. Papertrail logging configuration A certain configuration must be made for the microservices to use papertrail for sending logs in production, this configuration is made in the LOG_CONFIG section of the config.py file present in the src/config folder of each microservice, this configuration is shown below: LOG_CONFIG = { 'name' : '<microservice_name>' , 'level' : logging.DEBUG, 'stream_handler' : logging.StreamHandler ( sys.stdout ) , 'format' : f '%(asctime)s: {ENVIRONMENT_NAME}: %(hostname)s: %(module)s::%(lineno)d %(levelname)s: %(message)s' , 'papertrail' : { 'active' : True if os.getenv ( 'PAPERTRAIL_ACTIVE' ) == \"true\" else False, 'prefix' : os.getenv ( 'PAPERTRAIL_PREFIX' , f '{ENVIRONMENT_NAME}-<microservice_name>' ) , 'host' : os.getenv ( 'PAPERTRAIL_HOST' ) , 'port' : int ( os.getenv ( 'PAPERTRAIL_PORT' )) } , } It would be necessary to put the microservice name instead of microservice_name for each microservice in the project Papertrail searches configuration The papertrail-provisioning tool is available in the repository to configure the different groups of searches in papertrail, you must follow the procedure explained in the README of the same for its use. The above mentioned guide should be followed to add log searches for a specific microservice, it is also possible to configure alarms that will send notifications to slack.","title":"LOGGING AND MONITORING"},{"location":"LOGGING_AND_MONITORING/#logging-and-monitoring","text":"","title":"Logging and Monitoring"},{"location":"LOGGING_AND_MONITORING/#cloudwatch","text":"","title":"Cloudwatch"},{"location":"LOGGING_AND_MONITORING/#cloudwatch-log-groups","text":"A log group is created in Cloudwatch for the different environments deployed in AWS: Production environment : A log group will be created with the name automation-master in which the different logStreams will be created to store the logs of the different ECS services for the production environment. Ephemeral environments : A log group will be created with the name automation-<branch_identifier> for ephemeral environments, being branch_identifier the result of applying echo -n \"<branch_name>\" | sha256sum | cut -c1-8 on the branch name related to the ephemeral environment, the logStreams required for the different ECS services deployed in that environment will be created using the mentioned log group .","title":"Cloudwatch Log Groups"},{"location":"LOGGING_AND_MONITORING/#cloudwatch-log-streams","text":"As mentioned in the previous section, the different logStreams of the deployed services will be stored in a specific logGroup for each environment. A logStream will be created for each of the ECS cluster services tasks created in each environment, which will follow the following scheme <environment_name>-<microservice_image_build_number>/<microservice_name>/<ecs_tasks_id> environment_name : The names for environments are automation-master for production, as well as automation-<branch_identifier> for ephemeral environments, being branch_identifier the result of applying echo -n \"<branch_name>\" | sha256sum | cut -c1-8 on the branch name related to the ephemeral environment. microservice_image_build_number : The pipeline number is used as build number to build the image of those microservices that need to build a new docker image. microservice_name : The name of the microservice deployed in ECS, e.g. bruin-bridge . ecs_task_id> : For each ECS service, one or several tasks are created, depending on the desired number in the service, these tasks are identified with an identifier formed by number and letters, e.g. 961ef51b61834a2e9dd804db564a9fe0 .","title":"Cloudwatch Log Streams"},{"location":"LOGGING_AND_MONITORING/#cloudwatch-retention-period","text":"All environments deployed on AWS have been configured to use Cloudwatch to record the logs of the microservices present in them, although it is important to note the following differences: Production environment : The retention period of the log group created for such an environment is 90 days. Ephemeral environments : The retention period of the log group created for such an environment is 14 days. This retention period is configured in the infra-as-code/dev/logs.tf file.","title":"Cloudwatch Retention Period"},{"location":"LOGGING_AND_MONITORING/#cloudwatch-logs-retrieval-tool","text":"It is possible to obtain the events in logs of a logGroup through a tool designed for this purpose available in Github called log-stream-filter .","title":"Cloudwatch logs retrieval tool"},{"location":"LOGGING_AND_MONITORING/#download-and-install","text":"This tool is available for Linux, MacOS and Windows, it is possible to download the latest binary for each of these OSs: Linux : It's possible download and install as a deb package curl -o log-stream-filter.deb -L $( curl -s https://api.github.com/repos/xoanmm/log-stream-filter/releases/latest | jq -r '.assets[] | select(.name | contains(\"linux_amd64.deb\")) | .browser_download_url' ) sudo dpkg -i log-stream-filter.deb It's also possible download and install as a simple binary curl -o log-stream-filter.tgz -L $( curl -s https://api.github.com/repos/xoanmm/log-stream-filter/releases/latest | jq -r '.assets[] | select(.name | contains(\"linux_64-bit.tar.gz\")) | .browser_download_url' ) tar -zxvf log-stream-filter.tgz chmod +x ./log-stream-filter && sudo mv ./log-stream-filter /usr/local/bin MacOS : curl -o log-stream-filter.tgz -L $( curl -s https://api.github.com/repos/xoanmm/log-stream-filter/releases/latest | jq -r '.assets[] | select(.name | contains(\"macOS\")) | .browser_download_url' ) tar -zxvf log-stream-filter.tgz chmod +x ./log-stream-filter && sudo mv ./log-stream-filter /usr/local/bin Windows : curl -o log-stream-filter.zip -L $( curl -s https://api.github.com/repos/xoanmm/log-stream-filter/releases/latest | jq -r '.assets[] | select(.name | contains(\"windows\")) | .browser_download_url' ) unzip log-stream-filter.zip","title":"Download and install"},{"location":"LOGGING_AND_MONITORING/#example-of-usage","text":"Example of search text Outage monitoring process finished between 04/06/2021 12:00:00 and 04/07/2021 12:00:00 in log group with name automation-master for log streams that match with name service-outage-monitor-1 using AWS profile with name mettel-automation : $ log-stream-filter -n \"automation-master\" -l \"service-outage-monitor-1\" -a \"mettel-automation\" -s \"04/06/2021 12:00:00\" -e \"04/07/2021 12:00:00\" -T \"Outage monitoring process finished\" -t true Filtering logs for logGroup automation-master params: [ aws-profile mettel-automation ] [ log-stream-filter: service-outage-monitor-1 ] [ search-term-search: true ] [ search-term: Outage monitoring process finished ] [ path: /tmp ] [ start-date: 04 /06/2021 12 :00:00 ] [ end-date: 04 /07/2021 12 :00:00 ] Getting logStreams for logGroup automation-master applying filter service-outage-monitor-1 Getting the logEvents for those logStreams whose last event was inserted between 04 /06/2021 12 :00:00 and 04 /07/2021 12 :00:00 **************************************************************************************************** LogStreamName: automation-master-75993/service-outage-monitor-1/75d4e2cbb3f64e84a97063d34ffe6177 CreationTime: 04 /05/2021 23 :08:29 LastEventTime: 04 /06/2021 12 :43:49 All log events are going to be retrieved in logGroup automation-master for logStream automation-master-75993/service-outage-monitor-1/75d4e2cbb3f64e84a97063d34ffe6177 from time 1617710400000 Event messages for stream automation-master-75993/service-outage-monitor-1/75d4e2cbb3f64e84a97063d34ffe6177 in log group automation-master are going to be saved in the following files - /tmp/automation-master-75993_service-outage-monitor-1_75d4e2cbb3f64e84a97063d34ffe6177-Outage_monitoring_process_finished **************************************************************************************************** **************************************************************************************************** LogStreamName: automation-master-76009/service-outage-monitor-1/aab10e3e029c44fcb08dddeb51431fa2 CreationTime: 04 /06/2021 12 :44:40 LastEventTime: 04 /07/2021 10 :39:16 All log events are going to be retrieved in logGroup automation-master for logStream automation-master-76009/service-outage-monitor-1/aab10e3e029c44fcb08dddeb51431fa2 from time 1617710400000 Event messages for stream automation-master-76009/service-outage-monitor-1/aab10e3e029c44fcb08dddeb51431fa2 in log group automation-master are going to be saved in the following files - /tmp/automation-master-76009_service-outage-monitor-1_aab10e3e029c44fcb08dddeb51431fa2-Outage_monitoring_process_finished **************************************************************************************************** **************************************************************************************************** LogStreamName: automation-master-76051/service-outage-monitor-1/c921aa5c9bf04d71b0fab6d8673946a3 CreationTime: 04 /07/2021 10 :41:22 LastEventTime: 04 /07/2021 11 :04:33 All log events are going to be retrieved in logGroup automation-master for logStream automation-master-76051/service-outage-monitor-1/c921aa5c9bf04d71b0fab6d8673946a3 from time 1617710400000 Event messages for stream automation-master-76051/service-outage-monitor-1/c921aa5c9bf04d71b0fab6d8673946a3 in log group automation-master are going to be saved in the following files - /tmp/automation-master-76051_service-outage-monitor-1_c921aa5c9bf04d71b0fab6d8673946a3-Outage_monitoring_process_finished **************************************************************************************************** 3 files generated for logs of logStreams filtered for logGroup automation-master Location of files where logs of logStream automation-master-75993/service-outage-monitor-1/75d4e2cbb3f64e84a97063d34ffe6177 were stored are the following - /tmp/automation-master-75993_service-outage-monitor-1_75d4e2cbb3f64e84a97063d34ffe6177-Outage_monitoring_process_finished Location of files where logs of logStream automation-master-76009/service-outage-monitor-1/aab10e3e029c44fcb08dddeb51431fa2 were stored are the following - /tmp/automation-master-76009_service-outage-monitor-1_aab10e3e029c44fcb08dddeb51431fa2-Outage_monitoring_process_finished Location of files where logs of logStream automation-master-76051/service-outage-monitor-1/c921aa5c9bf04d71b0fab6d8673946a3 were stored are the following - /tmp/automation-master-76051_service-outage-monitor-1_c921aa5c9bf04d71b0fab6d8673946a3-Outage_monitoring_process_finished To know all the options it is recommended to read the README of log-stream-filter in github.","title":"Example of usage"},{"location":"LOGGING_AND_MONITORING/#papertrail","text":"There is a papertrail account used in the project for sending logs, but it will only be used for the production environment , this is because it is a high cost service and it is not feasible to have an account for all ephemeral environments due to its cost and the high volume of logs generated in these environments.","title":"Papertrail"},{"location":"LOGGING_AND_MONITORING/#papertrail-dashboards","text":"The system logs of the production environment are stored in papertrail, the account credentials are in the project's onepassword vault to which all people in the project have access. Below is a screenshot of the main screen of the system. In this system it's possible see three useful dashboards: [production] - master alarms : alarms are defined on different modules with notifications sent to slack through the mettel-alarms-papertrail-production channel, for example when the number of error messages in a module exceeds 100 times in an hour. Below is a screenshot where these alarms have been marked in a red rectangle. [production] - master logs : searches are defined to gather the logs of the replicas of each deployed microservice. Below is a screenshot where these searches have been marked in a red rectangle. [production] - master notifications : Searches on different modules are defined with their notification to slack through the mettel-notifications-papertrail-production channel. Below is a screenshot where these searches have been marked in a red rectangle.","title":"Papertrail dashboards"},{"location":"LOGGING_AND_MONITORING/#papertrail-logging-configuration","text":"A certain configuration must be made for the microservices to use papertrail for sending logs in production, this configuration is made in the LOG_CONFIG section of the config.py file present in the src/config folder of each microservice, this configuration is shown below: LOG_CONFIG = { 'name' : '<microservice_name>' , 'level' : logging.DEBUG, 'stream_handler' : logging.StreamHandler ( sys.stdout ) , 'format' : f '%(asctime)s: {ENVIRONMENT_NAME}: %(hostname)s: %(module)s::%(lineno)d %(levelname)s: %(message)s' , 'papertrail' : { 'active' : True if os.getenv ( 'PAPERTRAIL_ACTIVE' ) == \"true\" else False, 'prefix' : os.getenv ( 'PAPERTRAIL_PREFIX' , f '{ENVIRONMENT_NAME}-<microservice_name>' ) , 'host' : os.getenv ( 'PAPERTRAIL_HOST' ) , 'port' : int ( os.getenv ( 'PAPERTRAIL_PORT' )) } , } It would be necessary to put the microservice name instead of microservice_name for each microservice in the project","title":"Papertrail logging configuration"},{"location":"LOGGING_AND_MONITORING/#papertrail-searches-configuration","text":"The papertrail-provisioning tool is available in the repository to configure the different groups of searches in papertrail, you must follow the procedure explained in the README of the same for its use. The above mentioned guide should be followed to add log searches for a specific microservice, it is also possible to configure alarms that will send notifications to slack.","title":"Papertrail searches configuration"},{"location":"MONOREPO/","text":"Monorepo In revision control systems, a monorepo (syllabic abbreviation of monolithic repository) is a software development strategy where code for many projects are stored in the same repository. Wikipedia Advantages Simplified organization : The organization is simplified separating all the projects(called modules) in different folders that are stored in the root folder of the repository. Simplified automation : The automation gets easy with this approach, each time the repo has a commit in develop or master the automation will deploy all the necessary parts of the app to make it work correctly. Refactoring changes : When a project has a dependency with another in the monorepo, the changes are easier to be made. Atomic commits : When projects that work together are contained in separate repositories, releases need to determine which versions of one project are related to the other and then syncing them. Collaboration across team : The integration between projects will be easier thanks to the branches strategy Single source of truth : Like a developer you'll find all the available code, automation and documentation in the same place. What is not a monorepo about Monorepo is not the same that Monolith. Monolith is huge amount of coupled code of one application that is hell to maintain. This is not only a repository, it's a sum of good practices between automation, code and documentation.","title":"MONOREPO"},{"location":"MONOREPO/#monorepo","text":"In revision control systems, a monorepo (syllabic abbreviation of monolithic repository) is a software development strategy where code for many projects are stored in the same repository. Wikipedia","title":"Monorepo"},{"location":"MONOREPO/#advantages","text":"Simplified organization : The organization is simplified separating all the projects(called modules) in different folders that are stored in the root folder of the repository. Simplified automation : The automation gets easy with this approach, each time the repo has a commit in develop or master the automation will deploy all the necessary parts of the app to make it work correctly. Refactoring changes : When a project has a dependency with another in the monorepo, the changes are easier to be made. Atomic commits : When projects that work together are contained in separate repositories, releases need to determine which versions of one project are related to the other and then syncing them. Collaboration across team : The integration between projects will be easier thanks to the branches strategy Single source of truth : Like a developer you'll find all the available code, automation and documentation in the same place.","title":"Advantages"},{"location":"MONOREPO/#what-is-not-a-monorepo-about","text":"Monorepo is not the same that Monolith. Monolith is huge amount of coupled code of one application that is hell to maintain. This is not only a repository, it's a sum of good practices between automation, code and documentation.","title":"What is not a monorepo about"},{"location":"PIPELINES/","text":"Pipelines In this project is implemented Software delivery with total automation, thus avoiding manual intervention and therefore human errors in our product. Human error can and does occur when carrying out these boring and repetitive tasks manually and ultimately does affect the ability to meet deliverables. All of the automation is made with Gitlab CI technology, taking advantage of all the tools that Gitlab has. We separate the automatation in two parts, continuous integration and continuous delivery , that are explained in the next sections. To improve the speed and optimization of the pipelines, only the jobs and stages will be executed on those modules that change in each commit . Launch all jobs in a pipeline Exceptionally, it is possible to launch a pipeline with all the jobs and stages on a branch using the web interface, as shown in the following image . To do so, the following steps must be followed: From the project repository select the CI/CD option in the left sidebar and this Pipelines , as shown in the following image where these options are marked in red. Choose the Run Pipeline option, as shown in the image below in red. Indicate the branch where you want to run the pipeline in the Run for box and then click on Run pipeline . It's possible see an example in the following image, where the box Run for is shown in green and Run pipeline is shown in red. It is important to note that due to the extra time added by the tests of the dispacth-portal-frontend microservice, the tests of this one will only be executed when any of the files within it change or a pipeline with the Gitlab variable TEST_DISPATCH_PORTAL_FRONTEND with value true is executed. Environments Microservices Environments For the microservices there are the following environments Production : The environment is related to everything currently running in AWS related to the latest version of the master branch of the repository. Ephemerals : These environments are created from branches that start with name dev/feature or dev/fix . The name of any environment, regardless of the type, will identify all the resources created in the deployment process. The names for environments are automation-master for production, as well as automation-<branch_identifier> for ephemeral environments, being branch_identifier the result of applying echo -n \"<branch_name>\" | sha256sum | cut -c1-8 on the branch name related to the ephemeral environment. These names will identify all the resources created in AWS during the continuous delivery process, explained in the following sections. KRE Environments For KRE component there are the following environments: dev : This will be used for the various tests and calls made from the project's microservices in any ephemeral environment , ie from the microservices deployed in the ECS cluster with name automation-<environment_id> . production : This will be used for the different calls made from the project's microservices in the production environment , that is, from the microservices deployed in the ECS cluster with the name automation-master . Continuous integration (CI) Continuous Integration (CI) is a development practice where developers integrate code into a shared repository frequently, preferably several times a day. Each integration can then be verified by an automated build and automated tests. While automated testing is not strictly part of CI it is typically implied. Codeship Validation steps This stage checks the following: All python microservices comply with the rules of PEP8 Terraform files used to configure the infrastructure are valid from a syntactic point of view. The frontend modules comply with the linter configured for them Unit tests steps All the available unit tests for each service should be run in this stage of the CI process. If the coverage obtained from these tests for a service is not greater than or equal to 80%, it will cause this phase to fail, this will mean that the steps of the next stage will not be executed and the process will fail. In cases in which a module does not reach the minimum coverage mentioned above, a message like the following will be seen in the step executed for that module. Continuous delivery (CD) Continuous deployment is the next step of continuous delivery: Every change that passes the automated tests is deployed to production automatically. Continuous deployment should be the goal of most companies that are not constrained by regulatory or other requirements. Puppet.com Basic_infra steps This area covers the checking and creation, if necessary, of all the basic resources for the subsequent deployment, these being the specific image repositories in ECR Docker Container Registry , as well as the roles necessary in AWS to be able to display these images in ECS Container Orchestrator . In this stage there is also a job that must be executed manually if necessary, this is responsible for checking and creating if necessary network resources for the production environment or ephemeral environments. In this stage is also checked whether there are enough free resources in ECS to carry out the deployment with success or not. It's necessary run the basic-infra job the first time a new microservice is created in the project This has been done because ECR repositories are global resources and are stored in the same tfstate file, thus avoiding that when a microservice that creates a repository is created, it is not deleted by other branches that do not have it added. Basic_infra_kre steps In this stage will be the following jobs: * deploy-basic-infra-kre-dev for ephemeral environments and deploy-basic-infra-kre-production for the production environment, these are executed optionally manually . This job is responsible of checking and creation, if necessary, of the EKS cluster used by KRE in each environment and all the necessary resources related (RBAC configuration, helm charts needed for the KRE runtimes, etc) The process followed in this job is as follows: The necessary infrastructure is created in AWS for KRE, creating for them the following components: An S3 bucket for each environment and save information about the cluster, such as the SSH key to connect to the nodes. An EKS cluster to be able to deploy the different KRE components designed for Kubernetes An AutoScaling Group to have the desired number of Kubernetes worker nodes A SMTP service through Amazon SES and all the necessary components of it A set of IAM roles, one for each user with access to the project. These will be used to assign subsequent permissions in the Kubernetes cluster according to the role they belong to. These are stored as terraform output values , saving the list of user roles belonging to each role in their corresponding variable. Below is an example of a pipeline execution where it's possible see the IAM roles of users generated for each role in the project: Outputs: eks_developer_ops_privileged_roles = [ \"arn:aws:iam::374050862540:role/eks-developer-ops-mettel-automation-kre-xisco.capllonch\" , \"arn:aws:iam::374050862540:role/eks-developer-ops-mettel-automation-kre-xoan.mallon.developer\" , ] eks_developer_roles = [ \"arn:aws:iam::374050862540:role/eks-developer-mettel-automation-kre-brandon.samudio\" , \"arn:aws:iam::374050862540:role/eks-developer-mettel-automation-kre-daniel.fernandez\" , \"arn:aws:iam::374050862540:role/eks-developer-mettel-automation-kre-joseluis.vega\" , \"arn:aws:iam::374050862540:role/eks-developer-mettel-automation-kre-marc.vivancos\" , ] eks_devops_roles = [ \"arn:aws:iam::374050862540:role/eks-devops-mettel-automation-kre-alberto.iglesias\" , \"arn:aws:iam::374050862540:role/eks-devops-mettel-automation-kre-angel.costales\" , \"arn:aws:iam::374050862540:role/eks-devops-mettel-automation-kre-angel.luis.piquero\" , ] A set of helm charts necessary for any KRE runtime: external-dns , using the helm chart from bitnami repository external-dns is a Kubernetes addon that configures public DNS servers with information about exposed Kubernetes services to make them discoverable. It allows in a simple way that through the creation of an ingress in AWS you can create an entry in Route53 of type alias so that the calls to that ingress redirect to the value configured for the alias, being the most typical the DNS of the balancer created by the ingress. cert-mananger , using the helm chart from jetstack repository . This component automate the management lifecycle of all required certificates used by the KRE component in each environment. nginx ingress controller , using the helm chart from ingress-nginx repository . A series of configurations are provided so that the IP of clients in Kubernetes services can be known, since by default it will always use the internal IP in EKS of the load balancer for requests made from the Internet. A list of allowed IPs is also provided in the chart configuration through a specific configuration key, thus restricting access to the cluster's microservices. This component will create a Classic Load Balancer in AWS to expose nginx ingress component. hostpath provisioner , using the helm chart from rimusz repository Using a Python cli , permissions are assigned in Kubernetes Cluster created for KRE for each of the IAM roles created in the previous step. Deploy_kre_runtimes steps In this stage the KRE runtimes will be deployed in the corresponding environment, creating the necessary infrastructure and resources: A Hosted Zone in Route53 for the runtime in the specified environment using the mettel-automation.net domain name The kre helm chart with the necessary values for the environment creating a specific namespace in the EKS cluster for deploy the helm chart Build steps This area will cover all build steps of all necessary modules to deploy the app to the selected environment. It's typical to build the docker images and push to the repository in this step. Deploy steps In this stage there are one job: deploy-branches for ephemeral environments and deploy-master for the production environment, these are executed automatically . In which MetTel Automation modules in the monorepo will be deployed to the selected environment, as well as all the resources associated to that environment in AWS. The deploy steps will deploy the following in AWS: An ECS Cluster will be created for the environment with a set of resources An ECS Service that will use the new Docker image uploaded for each service of the project, being these services the specified below: bruin-bridge cts-bridge customer-cache dispatch-portal-backend dispatch-portal-frontend last-contact-report lit-bridge lumin-billing-report metrics-prometheus nats-server, nats-server-1, nats-server-2 email-bridge notifications-bridge service-affecting-monitor service-dispatch-monitor service-outage-monitor-1, service-outage-monitor-2, service-outage-monitor-3, service-outage-monitor-4, service-outage-monitor-triage t7-bridge tnba-feedback tnba-monitor velocloud-bridge A Task Definition for each of the above ECS Services In this process, a series of resources will also be created in AWS for the selected environment, as follows: Three ElastiCache Redis Clusters , which are detailed below: <environment> : used to save some data about dispatches, as well as to skip the limitation of messages of more than 1MB when passing them to NATS. <environment>-customer-cache-redis : used to save the mappings between Bruin clients and Velocloud edges, being able to use them between restarts if any occurs. <environment>-tnba-feedback-cache-redis : used to save ticket metrics sent to T7, so tnba-feedback can avoid sending them again afterwards. An ALB A record in Route53 A CloudWatch Log Group An Service Discovery Service for each ECS Service of the ECS Cluster created for this environment and a Service Discovery Namespace to logically group these Service Discovery Services . A set of resources related to the metrics of the environment: CloudWatch Alarms CloudWatch Dashboard CloudWatch Log Filters A CloudFormation Stack for create the SNS topic that will be used by CloudWatch Alarms notifications of this environment A S3 bucket to store the content of the metrics obtained by Thanos and displayed through Grafana . Also, resources of type null_resource are created to execute some Python scripts: The creation of ECS Services starts only if a Python script launched as a null_resource finishes with success. This script checks that the last ECS service created for NATS is running in HEALTHY state. If the previous step succeeded then ECS services related to capabilities microservices are created, with these being the following: bruin-bridge cts-bridge lit-bridge email-bridge notifications-bridge prometheus t7-bridge velocloud-bridge hawkeye-bridge Once created, the script used for NATS is launched through null_resource to check that the task instances for each of these ECS services were created successfully and are in RUNNING and HEALTHY status. Once all the scripts for the capabilities microservices have finished successfully, ECS services for the use-cases microservices are all created, with these being the following: customer-cache dispatch-portal-backend hawkeye-customer-cache hawkeye-outage-monitor last-contact-report lumin-billing-report service-affecting-monitor service-dispatch-monitor service-outage-monitor-1 service-outage-monitor-2 service-outage-monitor-3 service-outage-monitor-4 service-outage-monitor-triage tnba-feedback tnba-monitor This is achieved by defining explicit dependencies between the ECS services for the capabilities microservices and the set of null resources that perform the healthcheck of the capabilities microservices.\u200b The following is an example of a definition for the use-case microservice service-affecting-monitor using Terraform . Here, the dependency between the corresponding null_resource type resources in charge of performing the health check of the different capabilities microservices in Terraform code for this microservice is established. resource \"aws_ecs_service\" \"automation-service-affecting-monitor\" { . . . depends_on = [ null_resource.bruin-bridge-healthcheck , null_resource.cts-bridge-healthcheck , null_resource.lit-bridge-healthcheck , null_resource.velocloud-bridge-healthcheck , null_resource.hawkeye-bridge-healthcheck , null_resource.t7-bridge-healthcheck , null_resource.email-bridge-healthcheck , null_resource.notifications-bridge-healthcheck , null_resource.metrics-prometheus-healthcheck ] . . . } This procedure has been done to ensure that use case microservices are not created in ECS until new versions of the capability-type microservices are properly deployed, as use case microservices need to use capability-type microservices. Following the same procedure as in the previous step, a dependency is established between the microservice dispatch-portal-frontend and dispatch-portal-backend . The reason for this is that the dispatch-portal-frontend microservice needs to know the corresponding IP with the DNS entry in Route53 for the dispatch-portal-backend microservice, since if the previous deployment is saved, the new IP corresponding to the DNS entry is not updated. The following is the configuration in the terraform code of the service in ECS for the dispatch-portal-frontend microservice, where the necessary configuration to comply with this restriction can be seen. resource \"aws_ecs_service\" \"automation-dispatch-portal-frontend\" { . . . depends_on = [ null_resource.bruin-bridge-healthcheck , null_resource.cts-bridge-healthcheck , null_resource.lit-bridge-healthcheck , null_resource.velocloud-bridge-healthcheck , null_resource.hawkeye-bridge-healthcheck , null_resource.t7-bridge-healthcheck , null_resource.email-bridge-healthcheck , null_resource.notifications-bridge-healthcheck , null_resource.metrics-prometheus-healthcheck , null_resource.dispatch-portal-backend-healthcheck , aws_lb.automation-alb ] } The provisioning of the different groups and the searches included in each one of them is done through a python utility , this makes calls to the util go-papertrail-cli who is in charge of the provisioning of the elements mentioned in Papertrail . Destroy steps In this stage a series of manual jobs are available to destroy what was created in the previous stage, both for KRE and for the microservices of the repository in AWS. These are detailed below: destroy-branches for ephemeral environments or destroy-master for the production environment: This job will destroy everything created by Terraform in the previous stage by the job deploy-branches or deploy-master depending on the environment. destroy-branches-aws-nuke : This job is only available for ephemeral environments, it generates a yml file using a specific script to be used by aws-nuke to destroy all the infrastructure created for an ephemeral environment in AWS. This job should only be used when the `destroy-branches' job fails. destroy-basic-infra-kre-dev for ephemeral environments or destroy-basic-infra-kre-production for the production environment: This job will destroy everything created by Terraform in the previous stage by the job deploy-kre-dev or deploy-kre-production depending on the environment.","title":"PIPELINES"},{"location":"PIPELINES/#pipelines","text":"In this project is implemented Software delivery with total automation, thus avoiding manual intervention and therefore human errors in our product. Human error can and does occur when carrying out these boring and repetitive tasks manually and ultimately does affect the ability to meet deliverables. All of the automation is made with Gitlab CI technology, taking advantage of all the tools that Gitlab has. We separate the automatation in two parts, continuous integration and continuous delivery , that are explained in the next sections. To improve the speed and optimization of the pipelines, only the jobs and stages will be executed on those modules that change in each commit .","title":"Pipelines"},{"location":"PIPELINES/#launch-all-jobs-in-a-pipeline","text":"Exceptionally, it is possible to launch a pipeline with all the jobs and stages on a branch using the web interface, as shown in the following image . To do so, the following steps must be followed: From the project repository select the CI/CD option in the left sidebar and this Pipelines , as shown in the following image where these options are marked in red. Choose the Run Pipeline option, as shown in the image below in red. Indicate the branch where you want to run the pipeline in the Run for box and then click on Run pipeline . It's possible see an example in the following image, where the box Run for is shown in green and Run pipeline is shown in red. It is important to note that due to the extra time added by the tests of the dispacth-portal-frontend microservice, the tests of this one will only be executed when any of the files within it change or a pipeline with the Gitlab variable TEST_DISPATCH_PORTAL_FRONTEND with value true is executed.","title":"Launch all jobs in a pipeline"},{"location":"PIPELINES/#environments","text":"","title":"Environments"},{"location":"PIPELINES/#microservices-environments","text":"For the microservices there are the following environments Production : The environment is related to everything currently running in AWS related to the latest version of the master branch of the repository. Ephemerals : These environments are created from branches that start with name dev/feature or dev/fix . The name of any environment, regardless of the type, will identify all the resources created in the deployment process. The names for environments are automation-master for production, as well as automation-<branch_identifier> for ephemeral environments, being branch_identifier the result of applying echo -n \"<branch_name>\" | sha256sum | cut -c1-8 on the branch name related to the ephemeral environment. These names will identify all the resources created in AWS during the continuous delivery process, explained in the following sections.","title":"Microservices Environments"},{"location":"PIPELINES/#kre-environments","text":"For KRE component there are the following environments: dev : This will be used for the various tests and calls made from the project's microservices in any ephemeral environment , ie from the microservices deployed in the ECS cluster with name automation-<environment_id> . production : This will be used for the different calls made from the project's microservices in the production environment , that is, from the microservices deployed in the ECS cluster with the name automation-master .","title":"KRE Environments"},{"location":"PIPELINES/#continuous-integration-ci","text":"Continuous Integration (CI) is a development practice where developers integrate code into a shared repository frequently, preferably several times a day. Each integration can then be verified by an automated build and automated tests. While automated testing is not strictly part of CI it is typically implied. Codeship","title":"Continuous integration (CI)"},{"location":"PIPELINES/#validation-steps","text":"This stage checks the following: All python microservices comply with the rules of PEP8 Terraform files used to configure the infrastructure are valid from a syntactic point of view. The frontend modules comply with the linter configured for them","title":"Validation steps"},{"location":"PIPELINES/#unit-tests-steps","text":"All the available unit tests for each service should be run in this stage of the CI process. If the coverage obtained from these tests for a service is not greater than or equal to 80%, it will cause this phase to fail, this will mean that the steps of the next stage will not be executed and the process will fail. In cases in which a module does not reach the minimum coverage mentioned above, a message like the following will be seen in the step executed for that module.","title":"Unit tests steps"},{"location":"PIPELINES/#continuous-delivery-cd","text":"Continuous deployment is the next step of continuous delivery: Every change that passes the automated tests is deployed to production automatically. Continuous deployment should be the goal of most companies that are not constrained by regulatory or other requirements. Puppet.com","title":"Continuous delivery (CD)"},{"location":"PIPELINES/#basic_infra-steps","text":"This area covers the checking and creation, if necessary, of all the basic resources for the subsequent deployment, these being the specific image repositories in ECR Docker Container Registry , as well as the roles necessary in AWS to be able to display these images in ECS Container Orchestrator . In this stage there is also a job that must be executed manually if necessary, this is responsible for checking and creating if necessary network resources for the production environment or ephemeral environments. In this stage is also checked whether there are enough free resources in ECS to carry out the deployment with success or not. It's necessary run the basic-infra job the first time a new microservice is created in the project This has been done because ECR repositories are global resources and are stored in the same tfstate file, thus avoiding that when a microservice that creates a repository is created, it is not deleted by other branches that do not have it added.","title":"Basic_infra steps"},{"location":"PIPELINES/#basic_infra_kre-steps","text":"In this stage will be the following jobs: * deploy-basic-infra-kre-dev for ephemeral environments and deploy-basic-infra-kre-production for the production environment, these are executed optionally manually . This job is responsible of checking and creation, if necessary, of the EKS cluster used by KRE in each environment and all the necessary resources related (RBAC configuration, helm charts needed for the KRE runtimes, etc) The process followed in this job is as follows: The necessary infrastructure is created in AWS for KRE, creating for them the following components: An S3 bucket for each environment and save information about the cluster, such as the SSH key to connect to the nodes. An EKS cluster to be able to deploy the different KRE components designed for Kubernetes An AutoScaling Group to have the desired number of Kubernetes worker nodes A SMTP service through Amazon SES and all the necessary components of it A set of IAM roles, one for each user with access to the project. These will be used to assign subsequent permissions in the Kubernetes cluster according to the role they belong to. These are stored as terraform output values , saving the list of user roles belonging to each role in their corresponding variable. Below is an example of a pipeline execution where it's possible see the IAM roles of users generated for each role in the project: Outputs: eks_developer_ops_privileged_roles = [ \"arn:aws:iam::374050862540:role/eks-developer-ops-mettel-automation-kre-xisco.capllonch\" , \"arn:aws:iam::374050862540:role/eks-developer-ops-mettel-automation-kre-xoan.mallon.developer\" , ] eks_developer_roles = [ \"arn:aws:iam::374050862540:role/eks-developer-mettel-automation-kre-brandon.samudio\" , \"arn:aws:iam::374050862540:role/eks-developer-mettel-automation-kre-daniel.fernandez\" , \"arn:aws:iam::374050862540:role/eks-developer-mettel-automation-kre-joseluis.vega\" , \"arn:aws:iam::374050862540:role/eks-developer-mettel-automation-kre-marc.vivancos\" , ] eks_devops_roles = [ \"arn:aws:iam::374050862540:role/eks-devops-mettel-automation-kre-alberto.iglesias\" , \"arn:aws:iam::374050862540:role/eks-devops-mettel-automation-kre-angel.costales\" , \"arn:aws:iam::374050862540:role/eks-devops-mettel-automation-kre-angel.luis.piquero\" , ] A set of helm charts necessary for any KRE runtime: external-dns , using the helm chart from bitnami repository external-dns is a Kubernetes addon that configures public DNS servers with information about exposed Kubernetes services to make them discoverable. It allows in a simple way that through the creation of an ingress in AWS you can create an entry in Route53 of type alias so that the calls to that ingress redirect to the value configured for the alias, being the most typical the DNS of the balancer created by the ingress. cert-mananger , using the helm chart from jetstack repository . This component automate the management lifecycle of all required certificates used by the KRE component in each environment. nginx ingress controller , using the helm chart from ingress-nginx repository . A series of configurations are provided so that the IP of clients in Kubernetes services can be known, since by default it will always use the internal IP in EKS of the load balancer for requests made from the Internet. A list of allowed IPs is also provided in the chart configuration through a specific configuration key, thus restricting access to the cluster's microservices. This component will create a Classic Load Balancer in AWS to expose nginx ingress component. hostpath provisioner , using the helm chart from rimusz repository Using a Python cli , permissions are assigned in Kubernetes Cluster created for KRE for each of the IAM roles created in the previous step.","title":"Basic_infra_kre steps"},{"location":"PIPELINES/#deploy_kre_runtimes-steps","text":"In this stage the KRE runtimes will be deployed in the corresponding environment, creating the necessary infrastructure and resources: A Hosted Zone in Route53 for the runtime in the specified environment using the mettel-automation.net domain name The kre helm chart with the necessary values for the environment creating a specific namespace in the EKS cluster for deploy the helm chart","title":"Deploy_kre_runtimes steps"},{"location":"PIPELINES/#build-steps","text":"This area will cover all build steps of all necessary modules to deploy the app to the selected environment. It's typical to build the docker images and push to the repository in this step.","title":"Build steps"},{"location":"PIPELINES/#deploy-steps","text":"In this stage there are one job: deploy-branches for ephemeral environments and deploy-master for the production environment, these are executed automatically . In which MetTel Automation modules in the monorepo will be deployed to the selected environment, as well as all the resources associated to that environment in AWS. The deploy steps will deploy the following in AWS: An ECS Cluster will be created for the environment with a set of resources An ECS Service that will use the new Docker image uploaded for each service of the project, being these services the specified below: bruin-bridge cts-bridge customer-cache dispatch-portal-backend dispatch-portal-frontend last-contact-report lit-bridge lumin-billing-report metrics-prometheus nats-server, nats-server-1, nats-server-2 email-bridge notifications-bridge service-affecting-monitor service-dispatch-monitor service-outage-monitor-1, service-outage-monitor-2, service-outage-monitor-3, service-outage-monitor-4, service-outage-monitor-triage t7-bridge tnba-feedback tnba-monitor velocloud-bridge A Task Definition for each of the above ECS Services In this process, a series of resources will also be created in AWS for the selected environment, as follows: Three ElastiCache Redis Clusters , which are detailed below: <environment> : used to save some data about dispatches, as well as to skip the limitation of messages of more than 1MB when passing them to NATS. <environment>-customer-cache-redis : used to save the mappings between Bruin clients and Velocloud edges, being able to use them between restarts if any occurs. <environment>-tnba-feedback-cache-redis : used to save ticket metrics sent to T7, so tnba-feedback can avoid sending them again afterwards. An ALB A record in Route53 A CloudWatch Log Group An Service Discovery Service for each ECS Service of the ECS Cluster created for this environment and a Service Discovery Namespace to logically group these Service Discovery Services . A set of resources related to the metrics of the environment: CloudWatch Alarms CloudWatch Dashboard CloudWatch Log Filters A CloudFormation Stack for create the SNS topic that will be used by CloudWatch Alarms notifications of this environment A S3 bucket to store the content of the metrics obtained by Thanos and displayed through Grafana . Also, resources of type null_resource are created to execute some Python scripts: The creation of ECS Services starts only if a Python script launched as a null_resource finishes with success. This script checks that the last ECS service created for NATS is running in HEALTHY state. If the previous step succeeded then ECS services related to capabilities microservices are created, with these being the following: bruin-bridge cts-bridge lit-bridge email-bridge notifications-bridge prometheus t7-bridge velocloud-bridge hawkeye-bridge Once created, the script used for NATS is launched through null_resource to check that the task instances for each of these ECS services were created successfully and are in RUNNING and HEALTHY status. Once all the scripts for the capabilities microservices have finished successfully, ECS services for the use-cases microservices are all created, with these being the following: customer-cache dispatch-portal-backend hawkeye-customer-cache hawkeye-outage-monitor last-contact-report lumin-billing-report service-affecting-monitor service-dispatch-monitor service-outage-monitor-1 service-outage-monitor-2 service-outage-monitor-3 service-outage-monitor-4 service-outage-monitor-triage tnba-feedback tnba-monitor This is achieved by defining explicit dependencies between the ECS services for the capabilities microservices and the set of null resources that perform the healthcheck of the capabilities microservices.\u200b The following is an example of a definition for the use-case microservice service-affecting-monitor using Terraform . Here, the dependency between the corresponding null_resource type resources in charge of performing the health check of the different capabilities microservices in Terraform code for this microservice is established. resource \"aws_ecs_service\" \"automation-service-affecting-monitor\" { . . . depends_on = [ null_resource.bruin-bridge-healthcheck , null_resource.cts-bridge-healthcheck , null_resource.lit-bridge-healthcheck , null_resource.velocloud-bridge-healthcheck , null_resource.hawkeye-bridge-healthcheck , null_resource.t7-bridge-healthcheck , null_resource.email-bridge-healthcheck , null_resource.notifications-bridge-healthcheck , null_resource.metrics-prometheus-healthcheck ] . . . } This procedure has been done to ensure that use case microservices are not created in ECS until new versions of the capability-type microservices are properly deployed, as use case microservices need to use capability-type microservices. Following the same procedure as in the previous step, a dependency is established between the microservice dispatch-portal-frontend and dispatch-portal-backend . The reason for this is that the dispatch-portal-frontend microservice needs to know the corresponding IP with the DNS entry in Route53 for the dispatch-portal-backend microservice, since if the previous deployment is saved, the new IP corresponding to the DNS entry is not updated. The following is the configuration in the terraform code of the service in ECS for the dispatch-portal-frontend microservice, where the necessary configuration to comply with this restriction can be seen. resource \"aws_ecs_service\" \"automation-dispatch-portal-frontend\" { . . . depends_on = [ null_resource.bruin-bridge-healthcheck , null_resource.cts-bridge-healthcheck , null_resource.lit-bridge-healthcheck , null_resource.velocloud-bridge-healthcheck , null_resource.hawkeye-bridge-healthcheck , null_resource.t7-bridge-healthcheck , null_resource.email-bridge-healthcheck , null_resource.notifications-bridge-healthcheck , null_resource.metrics-prometheus-healthcheck , null_resource.dispatch-portal-backend-healthcheck , aws_lb.automation-alb ] } The provisioning of the different groups and the searches included in each one of them is done through a python utility , this makes calls to the util go-papertrail-cli who is in charge of the provisioning of the elements mentioned in Papertrail .","title":"Deploy steps"},{"location":"PIPELINES/#destroy-steps","text":"In this stage a series of manual jobs are available to destroy what was created in the previous stage, both for KRE and for the microservices of the repository in AWS. These are detailed below: destroy-branches for ephemeral environments or destroy-master for the production environment: This job will destroy everything created by Terraform in the previous stage by the job deploy-branches or deploy-master depending on the environment. destroy-branches-aws-nuke : This job is only available for ephemeral environments, it generates a yml file using a specific script to be used by aws-nuke to destroy all the infrastructure created for an ephemeral environment in AWS. This job should only be used when the `destroy-branches' job fails. destroy-basic-infra-kre-dev for ephemeral environments or destroy-basic-infra-kre-production for the production environment: This job will destroy everything created by Terraform in the previous stage by the job deploy-kre-dev or deploy-kre-production depending on the environment.","title":"Destroy steps"},{"location":"README_AUTOMATION/","text":"Documentation directory System overview System architecture Monorepo Pipelines Launch all jobs in a pipeline Environments CI CD Infrastructure as code Infrastructure Environment infrastructure Network infrastructure Logging and monitoring Cloudwatch Cloudwatch Log Groups Cloudwatch Log Streams Cloudwatch Retention Periord Cloudwatch logs retrieval tool Papertrail Papertrail Dashboards Papertrail Logging Configuration Papertrail Searches Configuration","title":"README AUTOMATION"},{"location":"README_AUTOMATION/#documentation-directory","text":"System overview System architecture Monorepo Pipelines Launch all jobs in a pipeline Environments CI CD Infrastructure as code Infrastructure Environment infrastructure Network infrastructure Logging and monitoring Cloudwatch Cloudwatch Log Groups Cloudwatch Log Streams Cloudwatch Retention Periord Cloudwatch logs retrieval tool Papertrail Papertrail Dashboards Papertrail Logging Configuration Papertrail Searches Configuration","title":"Documentation directory"},{"location":"SYSTEM_CONFIGURATIONS_THROUGH_AWS_PARAM_KEYS/","text":"Context Configurations are stored in AWS Systems Manager Parameter Store . Parameter Store is a capability of AWS Systems Manager that allows storing configuration values in hierarchical structures. It also provides the ability to encrypt these values through AWS KMS keys, and allows keeping track of configuration changes / versions for auditing purposes. From a pricing perspective, parameters can be defined either as simple or advanced : - Simple . This kind of parameters come with no additional charges, and can hold up to 4KB of data. Parameter Store allows defining up to 10,000 simple parameters per account and region. - Advanced . AWS charges $0.05 per advanced parameter per month. These can hold up to 8KB of data, and Parameter Store allows defining up to 100,000 of them per account and region. Attending to their type, parameters can be defined as: * String . These parameters consist of a block of text. Nothing else. * StringList . These parameters hold comma-separated values, but bear in mind that this is just a convention. AWS will not turn the value into an array before returning it through Parameter Store API; that is, it will be kept as a string. * SecureString . Essentially, these are the same as String parameters, but empowered with encryption features thanks to KMS keys. Conventions Please, take some time to go through the following conventions before publishing new parameters to Parameter Store. Parameter names Any new configuration published to Parameter Store must match the following pattern: /automation-engine/<environment>/<service-name>/<parameter> where: * environment refers to the Kubernetes context whose namespaces will take this parameter. Allowed values are dev , pro and common . * service-name refers to the name of the service this parameter will be loaded to. Examples of allowed values would be bruin-bridge , tnba-monitor , repair-tickets-monitor , and so on. * parameter refers to the name of the parameter that will be loaded to the service through an environment variable. Most configurations will follow the previous pattern, but if the business logic of a service carries out several tasks related to the same domain concept, an alternate form can be used: /automation-engine/<environment>/<domain>/<task>/<parameter> where: * domain refers to a domain concept that can represent multiple tasks accurately. An example would be service-affecting , which is a domain area that represents strongly related tasks (in this case, tasks related to Service Affecting troubles). * task refers to the underlying piece of logic that is independent of other tasks, but is still suitable to have under the subpath defined by domain . Considering that domain is set to service-affecting , acceptable values for task would be monitor , daily-bandwidth-report , or reoccurring-trouble-report . As a rule of thumb, choose the first pattern to name parameters if possible. However, if there is a strong reason to choose the second pattern over the first one, that is totally fine. If there are doubts about choosing one or the other, it can be brought up to discussion with the rest of the team. Values Before getting into how to define new configurations, bear these considerations in mind to keep certain consistency and avoid confusion / potential errors: * Values representing a time duration must always be expressed in seconds. * 24 should not be used to represent the hours in a period of 1 day. * 86400 should be used to represent the hours in a period of 1 day. Values representing percentages must always be expressed in their integer form. 0.75 should not be used to represent the value 75% . 75 should be used to represent the value 75% . JSON-like values must adhere to the JSON specification . The most relevant considerations are: All keys in an object-like JSON must be strings, even if they represent numbers. Example: // NOT valid { 1 : \"foo\" , 2 : \"bar\" } // Valid { \"1\" : \"foo\" , \"2\" : \"bar\" } // Valid { \"foo\" : \"bar\" , \"baz\" : \"hey\" } 2. An array-like JSON can hold a combination of values with different types, be them integers, floats, boolean, arrays, objects, and so on. Example: [ 1 , \"foo\" , 0.75 , \"2\" , \"bar\" , true , [ \"hello\" , \"world\" ], { \"hello\" : \"world\" } ] Consider prettifying JSON-like configurations before publishing to Parameter Store. This enhances readability when dealing with huge JSONs. Developers are responsible for making any necessary transformations related to data types, time conversions, etc. in the config files of a particular service . Encryption A parameter must be encrypted if it holds: * Personally Identifiable Information. This includes e-mail addresses, names, surnames, phone numbers, and so on. * Authentication credentials of any kind. * URLs from third party services. * Information related to application domains, such as: * IDs (even incremental ones) * Organization names * Domain-related values that potentially expose internal details about third party systems Publishing configurations to Parameter Store Adding new configurations to Parameter Store is pretty straightforward. The process should be as easy as: 1. Access the AWS Management Console. 2. Go to the AWS Systems Manager Parameter Store dashboard. 3. Hit Create parameter . 4. Give the parameter a Name that complies with any of the patterns under the Parameter names section. 5. Make sure to add a meaningful Description to the parameter. This is extremely important to give context to anyone in need of making changes to parameters, so take some time to think about a good, meaningful description. 6. Choose the tier that fits better for this parameter: 1. If the parameter is small and is not expected to grow much as time passes, choose Standard . 2. On the other hand, if the parameter is large enough and is expected to grow, choose Advanced . 7. Choose the type that fits better for this parameter: 1. If the parameter is safe to stay unencrypted in AWS: 1. Choose String . 2. Set the Data Type field to text . 2. On the other hand, if the parameter needs to be encrypted (see the Encryption section): 1. Choose SecureString . 2. Set the KMS Key Source field to My current account to pick a KMS key registered in the current account. 3. Set the KMS Key ID field to alias/aws/ssm to pick the default KMS key for Parameter Store. In general, avoid using StringList parameters. These are special cases of the String type, which essentially means that String can be used to create parameters based on comma-separated values as well. 8. Give the parameter a value that adheres to the conventions specified in the Values section. 9. Finally, hit Create parameter to save it. About the different environments When creating a new parameter in the Parameter Store, please decide if it will be different on dev and pro or if it will be same in both environments. If they're different, you should create a parameter for each environment. Otherwise, just create one under common . In general, most parameters will share the same value, unless there is a strong reason to keep them different. For example, parameters used to point to third party systems may differ if their app has not only a Production system, but also a Development / Test one. In that case, the pro version of the parameter should aim at the third party's Production system, and the dev version should aim at their Development / Test system. Hooking AWS Parameter Store with Kubernetes clusters Pre-requisites Before moving on, make sure to install k9s in your system. k9s is a powerful terminal UI that lets users manage Kubernetes clusters from their own machines, and even edit Kubernetes objects in place to reflect those changes immediately. After installing k9s , follow these steps to install a plugin that allows editing decoded Secret objects (more in the next section): 1. Install krew , following the instructions for the desired OS. 2. Install kubectl 's plugin kubectl-modify-secret , following the instructions for the desired OS. 3. Integrate kubectl-modify-secret into k9s 's plugin system: 1. In a terminal, run k9s info to check which folder holds k9s configurations. 2. Create file plugin.yml under that folder, if it does not exist yet. 3. Add the following snippet: plugin : edit-secret : shortCut : Ctrl-X confirm : false description : \"Edit Decoded Secret\" scopes : - secrets command : kubectl background : false args : - modify-secret - --namespace - $NAMESPACE - --context - $CONTEXT - $NAME > By default, the shortcut to edit decoded secrets is set to Ctrl + X . If needed, set a custom one instead. Kubernetes: Secrets and ConfigMaps Secret and ConfigMap objects are the Kubernetes objects used to inject environment variables to one or multiple pods. Like other Kubernetes objects, they are defined through .yaml files. These objects hold mappings between environment variables and their values, along with some metadata. Here is an example of a ConfigMap definition: apiVersion : v1 data : CURRENT_ENVIRONMENT : production ENVIRONMENT_NAME : production REDIS_HOSTNAME : redis.pro.somewhere.com kind : ConfigMap metadata : annotations : meta.helm.sh/release-name : automation-engine meta.helm.sh/release-namespace : automation-engine reloader.stakater.com/match : \"true\" creationTimestamp : \"2021-08-30T15:08:12Z\" labels : app.kubernetes.io/instance : automation-engine app.kubernetes.io/managed-by : Helm app.kubernetes.io/name : some-fancy-bridge app.kubernetes.io/version : 1.16.0 component : some-fancy-bridge current-environment : production environment-name : production helm.sh/chart : some-fancy-bridge-0.1.0 microservice-type : case-of-use project : mettel-automation name : some-fancy-bridge-configmap namespace : automation-engine resourceVersion : \"83171937\" selfLink : /api/v1/namespaces/automation-engine/configmaps/some-fancy-bridge-configmap uid : ba625451-8ba4-4ac7-a8da-593cc938eae7 And here is an example of a Secret definition: apiVersion : v1 data : THIRD_PARTY_API_USERNAME : aGVsbG8K THIRD_PARTY_API_PASSWORD : d29ybGQK kind : Secret metadata : annotations : meta.helm.sh/release-name : automation-engine meta.helm.sh/release-namespace : automation-engine reconcile.external-secrets.io/data-hash : 3162fd065a6777587e9a3a604e0c56e2 reloader.stakater.com/match : \"true\" creationTimestamp : \"2022-03-08T18:31:36Z\" labels : app.kubernetes.io/instance : automation-engine app.kubernetes.io/managed-by : Helm app.kubernetes.io/name : some-fancy-bridge app.kubernetes.io/version : 1.16.0 component : some-fancy-bridge current-environment : production environment-name : production helm.sh/chart : some-fancy-bridge-0.1.0 microservice-type : capability project : mettel-automation name : some-fancy-bridge-secret namespace : automation-engine ownerReferences : - apiVersion : external-secrets.io/v1alpha1 blockOwnerDeletion : true controller : true kind : ExternalSecret name : some-fancy-bridge-secret uid : 42bdad1c-37c4-4890-b86b-d9623333df18 resourceVersion : \"82588568\" selfLink : /api/v1/namespaces/automation-engine/secrets/some-fancy-bridge-secret uid : 81ad3356-8696-406e-bba0-c4ec389676ee type : Opaque Both objects have a data field where the different configurations are stored. The main difference between both objects is that all fields under data remain clear in ConfigMap objects, but in Secret ones, these fields are base64-encoded. These objects lack of mechanisms to pull configurations from external sources, so an additional tool is needed to hook them with AWS Parameter Store. External secrets The (External Secrets Operator)[https://github.com/external-secrets/external-secrets] is a tool that allows setting up Secret objects based on external references through a new kind of object called ExternalSecret . ExternalSecret objects define the external source to pull configurations from, and the references that should be resolved. After these references have been resolved, the ExternalSecret will create a regular Secret object with a data section whose key-value pairs are based on the environment variables the pod expects to see, and the values gotten after resolving the references from the external source. Aside from that, ExternalSecret objects pull configuration values from the external source periodically to keep secrets up to date, also known as reconciling secrets . An example of ExternalSecret object would be this one: apiVersion : external-secrets.io/v1alpha1 kind : ExternalSecret metadata : annotations : meta.helm.sh/release-name : automation-engine meta.helm.sh/release-namespace : automation-engine reloader.stakater.com/match : \"true\" creationTimestamp : \"2022-03-08T18:11:02Z\" generation : 1 labels : app.kubernetes.io/instance : automation-engine app.kubernetes.io/managed-by : Helm app.kubernetes.io/name : some-fancy-bridge app.kubernetes.io/version : 1.16.0 component : some-fancy-bridge current-environment : production environment-name : production helm.sh/chart : some-fancy-bridge-0.1.0 microservice-type : capability project : mettel-automation name : some-fancy-bridge-secret namespace : automation-engine resourceVersion : \"83201847\" selfLink : /apis/external-secrets.io/v1alpha1/namespaces/automation-engine/externalsecrets/some-fancy-bridge-secret uid : ca5c1faf-1b76-4f59-b57f-e10e43154ace spec : data : - remoteRef : key : /automation-engine/pro/some-fancy-bridge/some-common-value secretKey : SOME_COMMON_VALUE - remoteRef : key : /automation-engine/pro/some-fancy-bridge/some-env-specific-value secretKey : SOME_ENV_SPECIFIC_VALUE status : conditions : - lastTransitionTime : \"2022-03-08T18:11:10Z\" message : Secret was synced reason : SecretSynced status : \"True\" type : Ready refreshTime : \"2022-03-10T13:29:12Z\" syncedResourceVersion : 1-3efb62db37d8b935be922ecc6f7ed99f In this example, there are two items under the data section. Each item refers to an external / remote reference (field remoteRef::key ), and the environment variable that the value behind that remote reference should be loaded to (field secretKey ). Manipulating external secrets in the Automation system To add, remove, or update external secrets for a particular service in the Automation system, head to helm/charts/automation-engine/<service>/templates/external-secret.yaml and make the appropriate changes under the data section. For example, consider the following external-secret.yaml : {{ - if and .Values.global.externalSecrets.enabled - }} apiVersion : external-secrets.io/v1alpha1 kind : ExternalSecret metadata : name : {{ include \"some-fancy-bridge.secretName\" . }} labels : {{ - include \"some-fancy-bridge.labels\" . | nindent 4 }} annotations : reloader.stakater.com/match : \"true\" spec : secretStoreRef : name : {{ .Values.global.environment }} -parameter-store kind : SecretStore target : creationPolicy : 'Owner' Valid time units are \"ns\", \"us\" (or \"\u00b5s\"), \"ms\", \"s\", \"m\", \"h\" (from time.ParseDuration) May be set to zero to fetch and create it {{ - if eq .Values.global.current_environment \"dev\" }} refreshInterval : \"0\" {{ else }} refreshInterval : \"5m\" {{ - end }} data : {{ - with .Values.global.externalSecrets.envPath }} - remoteRef : key : {{ .commonPath }} /some-fancy-bridge/some-common-value secretKey : SOME_COMMON_VALUE - remoteRef : key : {{ .envPath }} /some-fancy-bridge/some-env-specific-value secretKey : SOME_ENV_SPECIFIC_VALUE {{ - end }} {{ - end }} If a new configuration called THIRD_PARTY_API_URL must be added to the underlying Secret created by this ExternalSecret , a new item should be placed under the data section, and it should look like this: - remoteRef : key : {{ . }} /some-fancy-bridge/third-party-api-url secretKey : THIRD_PARTY_API_URL The change can then be deployed to the Kubernetes cluster. A word of caution about ephemeral environments Although external-secrets is part of the EKS cluster for production and the cluster for ephemeral environments, the truth is it behaves differently across contexts. In the production cluster, ExternalSecret objects are configured to pull configurations from AWS Parameter Store every 5 minutes . That way, if a developer adds, removes, or updated a parameter in AWS, the cluster will realize about that event to update the regular Secret object created by the ExternalSecret with the most recent value. This will trigger another piece in the cluster called reloader , which ultimately will kill any pod that relies on the updated secret to spin up a new one with the configurations in the updated Secret . In ephemeral environments however, this is completely different. The ExternalSecret object will create a Secret object only when the ephemeral environment is deployed for the first time. After it has been deployed, control and management of Secret objects is delegated to developers; that is, external-secrets will never pull parameters from AWS again. The reasoning behind this behavior is that these parameters are shared by all ephemeral environments, so if one of them were to be updated in AWS and the polling rate was set to 5 minutes , all ephemeral environments would be updated because they all share the same reference. So essentially, the set of configurations for ephemeral environments that are stored in AWS are used as a template to populate ExternalSecret and Secret objects in ephemeral environments. If a secret needs to be updated, k9s should be used to edit the Secret in place. Using an AWS param key in our services Add the new variable to automation-engine/installation-utils/environment_files_generator.py SERVICE__DOMAIN__PARAM_KEY_NAME = parameters [ 'environment' ][ 'service' ][ 'domain' ][ 'param-key-name' ] And inside the env dictionary in the same file f 'DOMAIN__PARAM_KEY_NAME= { SERVICE__DOMAIN__PARAM_KEY_NAME } ' , Add the new variable as a template to services/<service>/src/config/.template.env DOMAIN__PARAM_KEY_NAME = Add the new variable retrieving the value from the environment to services/<service>/src/config/config.py 'param_key_name' : ( os . environ [ 'DOMAIN__PARAM_KEY_NAME' ] ), Any parameter that should be used with a primitive type other than str , should be cast here. We MUST use primitive types. DO NOT convert values to complex types like timedelta or datetime . Consumers of the service configuration should be responsible for doing that. Add the new variable to services/<service>/src/config/testconfig.py for being available when testing 'param_key_name' : 86400 After that you can use it in the service self . _config . MONITOR_CONFIG [ 'param_key_name' ] And while testing param_key_name = action . _config . MONITOR_CONFIG [ 'param_key_name' ]","title":"SYSTEM CONFIGURATIONS THROUGH AWS PARAM KEYS"},{"location":"SYSTEM_CONFIGURATIONS_THROUGH_AWS_PARAM_KEYS/#context","text":"Configurations are stored in AWS Systems Manager Parameter Store . Parameter Store is a capability of AWS Systems Manager that allows storing configuration values in hierarchical structures. It also provides the ability to encrypt these values through AWS KMS keys, and allows keeping track of configuration changes / versions for auditing purposes. From a pricing perspective, parameters can be defined either as simple or advanced : - Simple . This kind of parameters come with no additional charges, and can hold up to 4KB of data. Parameter Store allows defining up to 10,000 simple parameters per account and region. - Advanced . AWS charges $0.05 per advanced parameter per month. These can hold up to 8KB of data, and Parameter Store allows defining up to 100,000 of them per account and region. Attending to their type, parameters can be defined as: * String . These parameters consist of a block of text. Nothing else. * StringList . These parameters hold comma-separated values, but bear in mind that this is just a convention. AWS will not turn the value into an array before returning it through Parameter Store API; that is, it will be kept as a string. * SecureString . Essentially, these are the same as String parameters, but empowered with encryption features thanks to KMS keys.","title":"Context"},{"location":"SYSTEM_CONFIGURATIONS_THROUGH_AWS_PARAM_KEYS/#conventions","text":"Please, take some time to go through the following conventions before publishing new parameters to Parameter Store.","title":"Conventions"},{"location":"SYSTEM_CONFIGURATIONS_THROUGH_AWS_PARAM_KEYS/#parameter-names","text":"Any new configuration published to Parameter Store must match the following pattern: /automation-engine/<environment>/<service-name>/<parameter> where: * environment refers to the Kubernetes context whose namespaces will take this parameter. Allowed values are dev , pro and common . * service-name refers to the name of the service this parameter will be loaded to. Examples of allowed values would be bruin-bridge , tnba-monitor , repair-tickets-monitor , and so on. * parameter refers to the name of the parameter that will be loaded to the service through an environment variable. Most configurations will follow the previous pattern, but if the business logic of a service carries out several tasks related to the same domain concept, an alternate form can be used: /automation-engine/<environment>/<domain>/<task>/<parameter> where: * domain refers to a domain concept that can represent multiple tasks accurately. An example would be service-affecting , which is a domain area that represents strongly related tasks (in this case, tasks related to Service Affecting troubles). * task refers to the underlying piece of logic that is independent of other tasks, but is still suitable to have under the subpath defined by domain . Considering that domain is set to service-affecting , acceptable values for task would be monitor , daily-bandwidth-report , or reoccurring-trouble-report . As a rule of thumb, choose the first pattern to name parameters if possible. However, if there is a strong reason to choose the second pattern over the first one, that is totally fine. If there are doubts about choosing one or the other, it can be brought up to discussion with the rest of the team.","title":"Parameter names"},{"location":"SYSTEM_CONFIGURATIONS_THROUGH_AWS_PARAM_KEYS/#values","text":"Before getting into how to define new configurations, bear these considerations in mind to keep certain consistency and avoid confusion / potential errors: * Values representing a time duration must always be expressed in seconds. * 24 should not be used to represent the hours in a period of 1 day. * 86400 should be used to represent the hours in a period of 1 day. Values representing percentages must always be expressed in their integer form. 0.75 should not be used to represent the value 75% . 75 should be used to represent the value 75% . JSON-like values must adhere to the JSON specification . The most relevant considerations are: All keys in an object-like JSON must be strings, even if they represent numbers. Example: // NOT valid { 1 : \"foo\" , 2 : \"bar\" } // Valid { \"1\" : \"foo\" , \"2\" : \"bar\" } // Valid { \"foo\" : \"bar\" , \"baz\" : \"hey\" } 2. An array-like JSON can hold a combination of values with different types, be them integers, floats, boolean, arrays, objects, and so on. Example: [ 1 , \"foo\" , 0.75 , \"2\" , \"bar\" , true , [ \"hello\" , \"world\" ], { \"hello\" : \"world\" } ] Consider prettifying JSON-like configurations before publishing to Parameter Store. This enhances readability when dealing with huge JSONs. Developers are responsible for making any necessary transformations related to data types, time conversions, etc. in the config files of a particular service .","title":"Values"},{"location":"SYSTEM_CONFIGURATIONS_THROUGH_AWS_PARAM_KEYS/#encryption","text":"A parameter must be encrypted if it holds: * Personally Identifiable Information. This includes e-mail addresses, names, surnames, phone numbers, and so on. * Authentication credentials of any kind. * URLs from third party services. * Information related to application domains, such as: * IDs (even incremental ones) * Organization names * Domain-related values that potentially expose internal details about third party systems","title":"Encryption"},{"location":"SYSTEM_CONFIGURATIONS_THROUGH_AWS_PARAM_KEYS/#publishing-configurations-to-parameter-store","text":"Adding new configurations to Parameter Store is pretty straightforward. The process should be as easy as: 1. Access the AWS Management Console. 2. Go to the AWS Systems Manager Parameter Store dashboard. 3. Hit Create parameter . 4. Give the parameter a Name that complies with any of the patterns under the Parameter names section. 5. Make sure to add a meaningful Description to the parameter. This is extremely important to give context to anyone in need of making changes to parameters, so take some time to think about a good, meaningful description. 6. Choose the tier that fits better for this parameter: 1. If the parameter is small and is not expected to grow much as time passes, choose Standard . 2. On the other hand, if the parameter is large enough and is expected to grow, choose Advanced . 7. Choose the type that fits better for this parameter: 1. If the parameter is safe to stay unencrypted in AWS: 1. Choose String . 2. Set the Data Type field to text . 2. On the other hand, if the parameter needs to be encrypted (see the Encryption section): 1. Choose SecureString . 2. Set the KMS Key Source field to My current account to pick a KMS key registered in the current account. 3. Set the KMS Key ID field to alias/aws/ssm to pick the default KMS key for Parameter Store. In general, avoid using StringList parameters. These are special cases of the String type, which essentially means that String can be used to create parameters based on comma-separated values as well. 8. Give the parameter a value that adheres to the conventions specified in the Values section. 9. Finally, hit Create parameter to save it.","title":"Publishing configurations to Parameter Store"},{"location":"SYSTEM_CONFIGURATIONS_THROUGH_AWS_PARAM_KEYS/#about-the-different-environments","text":"When creating a new parameter in the Parameter Store, please decide if it will be different on dev and pro or if it will be same in both environments. If they're different, you should create a parameter for each environment. Otherwise, just create one under common . In general, most parameters will share the same value, unless there is a strong reason to keep them different. For example, parameters used to point to third party systems may differ if their app has not only a Production system, but also a Development / Test one. In that case, the pro version of the parameter should aim at the third party's Production system, and the dev version should aim at their Development / Test system.","title":"About the different environments"},{"location":"SYSTEM_CONFIGURATIONS_THROUGH_AWS_PARAM_KEYS/#hooking-aws-parameter-store-with-kubernetes-clusters","text":"","title":"Hooking AWS Parameter Store with Kubernetes clusters"},{"location":"SYSTEM_CONFIGURATIONS_THROUGH_AWS_PARAM_KEYS/#pre-requisites","text":"Before moving on, make sure to install k9s in your system. k9s is a powerful terminal UI that lets users manage Kubernetes clusters from their own machines, and even edit Kubernetes objects in place to reflect those changes immediately. After installing k9s , follow these steps to install a plugin that allows editing decoded Secret objects (more in the next section): 1. Install krew , following the instructions for the desired OS. 2. Install kubectl 's plugin kubectl-modify-secret , following the instructions for the desired OS. 3. Integrate kubectl-modify-secret into k9s 's plugin system: 1. In a terminal, run k9s info to check which folder holds k9s configurations. 2. Create file plugin.yml under that folder, if it does not exist yet. 3. Add the following snippet: plugin : edit-secret : shortCut : Ctrl-X confirm : false description : \"Edit Decoded Secret\" scopes : - secrets command : kubectl background : false args : - modify-secret - --namespace - $NAMESPACE - --context - $CONTEXT - $NAME > By default, the shortcut to edit decoded secrets is set to Ctrl + X . If needed, set a custom one instead.","title":"Pre-requisites"},{"location":"SYSTEM_CONFIGURATIONS_THROUGH_AWS_PARAM_KEYS/#kubernetes-secrets-and-configmaps","text":"Secret and ConfigMap objects are the Kubernetes objects used to inject environment variables to one or multiple pods. Like other Kubernetes objects, they are defined through .yaml files. These objects hold mappings between environment variables and their values, along with some metadata. Here is an example of a ConfigMap definition: apiVersion : v1 data : CURRENT_ENVIRONMENT : production ENVIRONMENT_NAME : production REDIS_HOSTNAME : redis.pro.somewhere.com kind : ConfigMap metadata : annotations : meta.helm.sh/release-name : automation-engine meta.helm.sh/release-namespace : automation-engine reloader.stakater.com/match : \"true\" creationTimestamp : \"2021-08-30T15:08:12Z\" labels : app.kubernetes.io/instance : automation-engine app.kubernetes.io/managed-by : Helm app.kubernetes.io/name : some-fancy-bridge app.kubernetes.io/version : 1.16.0 component : some-fancy-bridge current-environment : production environment-name : production helm.sh/chart : some-fancy-bridge-0.1.0 microservice-type : case-of-use project : mettel-automation name : some-fancy-bridge-configmap namespace : automation-engine resourceVersion : \"83171937\" selfLink : /api/v1/namespaces/automation-engine/configmaps/some-fancy-bridge-configmap uid : ba625451-8ba4-4ac7-a8da-593cc938eae7 And here is an example of a Secret definition: apiVersion : v1 data : THIRD_PARTY_API_USERNAME : aGVsbG8K THIRD_PARTY_API_PASSWORD : d29ybGQK kind : Secret metadata : annotations : meta.helm.sh/release-name : automation-engine meta.helm.sh/release-namespace : automation-engine reconcile.external-secrets.io/data-hash : 3162fd065a6777587e9a3a604e0c56e2 reloader.stakater.com/match : \"true\" creationTimestamp : \"2022-03-08T18:31:36Z\" labels : app.kubernetes.io/instance : automation-engine app.kubernetes.io/managed-by : Helm app.kubernetes.io/name : some-fancy-bridge app.kubernetes.io/version : 1.16.0 component : some-fancy-bridge current-environment : production environment-name : production helm.sh/chart : some-fancy-bridge-0.1.0 microservice-type : capability project : mettel-automation name : some-fancy-bridge-secret namespace : automation-engine ownerReferences : - apiVersion : external-secrets.io/v1alpha1 blockOwnerDeletion : true controller : true kind : ExternalSecret name : some-fancy-bridge-secret uid : 42bdad1c-37c4-4890-b86b-d9623333df18 resourceVersion : \"82588568\" selfLink : /api/v1/namespaces/automation-engine/secrets/some-fancy-bridge-secret uid : 81ad3356-8696-406e-bba0-c4ec389676ee type : Opaque Both objects have a data field where the different configurations are stored. The main difference between both objects is that all fields under data remain clear in ConfigMap objects, but in Secret ones, these fields are base64-encoded. These objects lack of mechanisms to pull configurations from external sources, so an additional tool is needed to hook them with AWS Parameter Store.","title":"Kubernetes: Secrets and ConfigMaps"},{"location":"SYSTEM_CONFIGURATIONS_THROUGH_AWS_PARAM_KEYS/#external-secrets","text":"The (External Secrets Operator)[https://github.com/external-secrets/external-secrets] is a tool that allows setting up Secret objects based on external references through a new kind of object called ExternalSecret . ExternalSecret objects define the external source to pull configurations from, and the references that should be resolved. After these references have been resolved, the ExternalSecret will create a regular Secret object with a data section whose key-value pairs are based on the environment variables the pod expects to see, and the values gotten after resolving the references from the external source. Aside from that, ExternalSecret objects pull configuration values from the external source periodically to keep secrets up to date, also known as reconciling secrets . An example of ExternalSecret object would be this one: apiVersion : external-secrets.io/v1alpha1 kind : ExternalSecret metadata : annotations : meta.helm.sh/release-name : automation-engine meta.helm.sh/release-namespace : automation-engine reloader.stakater.com/match : \"true\" creationTimestamp : \"2022-03-08T18:11:02Z\" generation : 1 labels : app.kubernetes.io/instance : automation-engine app.kubernetes.io/managed-by : Helm app.kubernetes.io/name : some-fancy-bridge app.kubernetes.io/version : 1.16.0 component : some-fancy-bridge current-environment : production environment-name : production helm.sh/chart : some-fancy-bridge-0.1.0 microservice-type : capability project : mettel-automation name : some-fancy-bridge-secret namespace : automation-engine resourceVersion : \"83201847\" selfLink : /apis/external-secrets.io/v1alpha1/namespaces/automation-engine/externalsecrets/some-fancy-bridge-secret uid : ca5c1faf-1b76-4f59-b57f-e10e43154ace spec : data : - remoteRef : key : /automation-engine/pro/some-fancy-bridge/some-common-value secretKey : SOME_COMMON_VALUE - remoteRef : key : /automation-engine/pro/some-fancy-bridge/some-env-specific-value secretKey : SOME_ENV_SPECIFIC_VALUE status : conditions : - lastTransitionTime : \"2022-03-08T18:11:10Z\" message : Secret was synced reason : SecretSynced status : \"True\" type : Ready refreshTime : \"2022-03-10T13:29:12Z\" syncedResourceVersion : 1-3efb62db37d8b935be922ecc6f7ed99f In this example, there are two items under the data section. Each item refers to an external / remote reference (field remoteRef::key ), and the environment variable that the value behind that remote reference should be loaded to (field secretKey ).","title":"External secrets"},{"location":"SYSTEM_CONFIGURATIONS_THROUGH_AWS_PARAM_KEYS/#manipulating-external-secrets-in-the-automation-system","text":"To add, remove, or update external secrets for a particular service in the Automation system, head to helm/charts/automation-engine/<service>/templates/external-secret.yaml and make the appropriate changes under the data section. For example, consider the following external-secret.yaml : {{ - if and .Values.global.externalSecrets.enabled - }} apiVersion : external-secrets.io/v1alpha1 kind : ExternalSecret metadata : name : {{ include \"some-fancy-bridge.secretName\" . }} labels : {{ - include \"some-fancy-bridge.labels\" . | nindent 4 }} annotations : reloader.stakater.com/match : \"true\" spec : secretStoreRef : name : {{ .Values.global.environment }} -parameter-store kind : SecretStore target : creationPolicy : 'Owner' Valid time units are \"ns\", \"us\" (or \"\u00b5s\"), \"ms\", \"s\", \"m\", \"h\" (from time.ParseDuration) May be set to zero to fetch and create it {{ - if eq .Values.global.current_environment \"dev\" }} refreshInterval : \"0\" {{ else }} refreshInterval : \"5m\" {{ - end }} data : {{ - with .Values.global.externalSecrets.envPath }} - remoteRef : key : {{ .commonPath }} /some-fancy-bridge/some-common-value secretKey : SOME_COMMON_VALUE - remoteRef : key : {{ .envPath }} /some-fancy-bridge/some-env-specific-value secretKey : SOME_ENV_SPECIFIC_VALUE {{ - end }} {{ - end }} If a new configuration called THIRD_PARTY_API_URL must be added to the underlying Secret created by this ExternalSecret , a new item should be placed under the data section, and it should look like this: - remoteRef : key : {{ . }} /some-fancy-bridge/third-party-api-url secretKey : THIRD_PARTY_API_URL The change can then be deployed to the Kubernetes cluster.","title":"Manipulating external secrets in the Automation system"},{"location":"SYSTEM_CONFIGURATIONS_THROUGH_AWS_PARAM_KEYS/#a-word-of-caution-about-ephemeral-environments","text":"Although external-secrets is part of the EKS cluster for production and the cluster for ephemeral environments, the truth is it behaves differently across contexts. In the production cluster, ExternalSecret objects are configured to pull configurations from AWS Parameter Store every 5 minutes . That way, if a developer adds, removes, or updated a parameter in AWS, the cluster will realize about that event to update the regular Secret object created by the ExternalSecret with the most recent value. This will trigger another piece in the cluster called reloader , which ultimately will kill any pod that relies on the updated secret to spin up a new one with the configurations in the updated Secret . In ephemeral environments however, this is completely different. The ExternalSecret object will create a Secret object only when the ephemeral environment is deployed for the first time. After it has been deployed, control and management of Secret objects is delegated to developers; that is, external-secrets will never pull parameters from AWS again. The reasoning behind this behavior is that these parameters are shared by all ephemeral environments, so if one of them were to be updated in AWS and the polling rate was set to 5 minutes , all ephemeral environments would be updated because they all share the same reference. So essentially, the set of configurations for ephemeral environments that are stored in AWS are used as a template to populate ExternalSecret and Secret objects in ephemeral environments. If a secret needs to be updated, k9s should be used to edit the Secret in place.","title":"A word of caution about ephemeral environments"},{"location":"SYSTEM_CONFIGURATIONS_THROUGH_AWS_PARAM_KEYS/#using-an-aws-param-key-in-our-services","text":"Add the new variable to automation-engine/installation-utils/environment_files_generator.py SERVICE__DOMAIN__PARAM_KEY_NAME = parameters [ 'environment' ][ 'service' ][ 'domain' ][ 'param-key-name' ] And inside the env dictionary in the same file f 'DOMAIN__PARAM_KEY_NAME= { SERVICE__DOMAIN__PARAM_KEY_NAME } ' , Add the new variable as a template to services/<service>/src/config/.template.env DOMAIN__PARAM_KEY_NAME = Add the new variable retrieving the value from the environment to services/<service>/src/config/config.py 'param_key_name' : ( os . environ [ 'DOMAIN__PARAM_KEY_NAME' ] ), Any parameter that should be used with a primitive type other than str , should be cast here. We MUST use primitive types. DO NOT convert values to complex types like timedelta or datetime . Consumers of the service configuration should be responsible for doing that. Add the new variable to services/<service>/src/config/testconfig.py for being available when testing 'param_key_name' : 86400 After that you can use it in the service self . _config . MONITOR_CONFIG [ 'param_key_name' ] And while testing param_key_name = action . _config . MONITOR_CONFIG [ 'param_key_name' ]","title":"Using an AWS param key in our services"},{"location":"SYSTEM_OVERVIEW/","text":"System overview Architecture Basic concepts It's a project based on microservices, in which two types are distinguished: Capabilities : They are in charge of carrying out certain common actions for the business logic. I.e.: Collect information from SD-WAN routers For example: Collect information from SD-WAN routers. Use cases : They use capabilities as a base to make specific use cases. I.e.: Obtain certain tickets from SD-WAN routers of a company, obtaining the information from the routers for the subsequent storage in the corresponding tickets. For example: Obtain certain tickets from SD-WAN routers of a company, obtaining the information from the routers for subsequent storage in the corresponding tickets. It is important to emphasize on the architecture of the system the use of NATS in it. Messaging system It's important to emphasize in the architecture of the system the use of NATS in it. NATS is a simple, secure and performant communications system for digital system, services and devices NATS is used in the microservices system as a communication center for all of them. NATS it's used in cluster mode to safistify more work to be done by it due to the high number of events in the system to be processed Microservices communications There are two types of microservices depending on the connection between them and NATS: Microservices that communicates with NATS , divided into three types: Those that take the role of replier in the context of NATS, usually microservices that contains capabilities : bruin-bridge cts-bridge hawkeye-bridge lit-bridge email-bridge notifications-bridge t7-bridge Those that take the role of requester in the context of NATS, usually microservices that contains use cases : dispatch-portal-backend grafana component, from metrics-prometheus microservice hawkeye-affecting-monitor hawkeye-outage-monitor last-contact-report service-affecting-monitor service-dispatch-monitor service-outage-monitor tnba-feedback tnba-monitor Those that take the role of both requester and replier in the context of NATS. These microservices can be considered a mixture between use use cases and capabilities : customer-cache hawkeye-customer-cache It's important take into account that all microservices that communicate with NATS can also communicate with the Redis Cluster. This is needed to bypass the limit size that NATS enforces for all messages it receives (1MB). Microservices that doesn't communicate with NATS : dispatch-portal-frontend lumin-billing-report prometheus and thanos components, from metrics-prometheus microservice redis cluster (Docker container in local environment or an Elasticache Redis Cluster in AWS environments) NATS is used in the microservice system as a communication center for all of them. It is used in cluster mode to satisfy more work to be done by it. In the following diagram it's possible see a graph with the relationships between the microservices explained previously in this section Relationships between microservices The services that are part of the previously explained architecture are related to each other, in the following diagram it's possible see the relationships between them. Capabilities microservices Bruin-bridge microservice This microservice is in charge of making requests to the bruin API, taking the role of replier in the context of NATS. When another microservice requests bruin data, it will be in charge of making response messages to the same and never of request, that is to say, it will always be a producer within a NATS topic and never a consumer. Bruin is a third-party system that allows creating and managing support tickets to deal with issues that appear in network devices, among other types of devices. The following diagram shows the dependencies or interactions of this microservice with the others, being in this case none, since it is in charge of one of the isolated microservices as explained above. Cts-bridge microservice This microservice is in charge of making requests to the CTS API, taking the role of replier in the context of NATS. When another microservice requests CTS data, it will be in charge of making response messages to the same and never of request, that is to say, it will always be a producer within a NATS topic and never a consumer. The following diagram shows the dependencies or interactions of this microservice with the others, being in this case none, since it is in charge of one of the isolated microservices as explained above. Digi-bridge microservice This microservice is in charge of making requests to the Digi Reboot API, taking the role of replier in the context of NATS. When another microservice asks to reboot a SD-WAN device, it will be in charge of making response messages to the same and never of request, that is to say, it will always be a producer within a NATS topic and never a consumer. The following diagram shows the dependencies or interactions of this microservice with the others, being in this case none, since it is in charge of one of the isolated microservices as explained above. Hawkeye-bridge microservice This microservice is in charge of making requests to the Hawkeye API, taking the role of replier in the context of NATS. When another microservice requests Hawkeye data, it will be in charge of making response messages to the same and never of request, that is to say, it will always be a producer within a NATS topic and never a consumer. The following diagram shows the dependencies or interactions of this microservice with the others, being in this case none, since it is in charge of one of the isolated microservices as explained above. Lit-bridge microservice This microservice is in charge of making requests to the LIT API, taking the role of replier in the context of NATS. When another microservice requests LIT data, it will be in charge of making response messages to the same and never of request, that is to say, it will always be a producer within a NATS topic and never a consumer. The following diagram shows the dependencies or interactions of this microservice with the others, being in this case none, since it is in charge of one of the isolated microservices as explained above. Email bridge microservice This microservice is in charge of sending emails. It is important to point out that it is not in charge of the composition of the messages to be sent, that is to say, of their content, but only of sending them. The following diagram shows the dependencies or interactions of this microservice with the others, being in this case none, since it is in charge of one of the isolated microservices as explained above. Notifications bridge microservice This microservice is in charge of sending notifications to third-party systems. It is important to point out that it is not in charge of the composition of the messages to be sent, that is to say, of their content, but only of sending them. The following diagram shows the dependencies or interactions of this microservice with the others, being in this case none, since it is in charge of one of the isolated microservices as explained above. T7-bridge microservice The function of this microservice is to embed in the notes of a ticket the prediction calculated by T7, this prediction will store information on the recommendations actions for the ticket. In order to carry out the mentioned actions, it communicates with the API of T7 to obtain the information about the prediction, as it can be seen in the following diagram . Velocloud-bridge microservice This microservice is in charge of making requests to the velocloud API, taking the role of replier in the context of NATS. When another microservice requests velocloud data, it will be in charge of making response messages to the same and never of request, that is to say, it will always be a producer within a NATS topic and never a consumer. The following diagram shows the dependencies or interactions of this microservice with the others, being in this case none, since it is in charge of one of the isolated microservices as explained above. Use cases microservices Dispatch-portal-backend microservice In conjunction with dispatch-portal-frontend , this service provides MetTel the ability to track the status of dispatch requests, as well as create and update them, so their technicians can assist customers when they report any issue related to a device. It also updates Bruin tickets to keep support people posted about the changes in the dispatch requests. It acts as an intermediary between dispatch-portal-frontend and CTS & LIT APIs by providing a REST API with multiple endpoints that, once they receive a payload from the frontend side, it modifies its fields with the help of some mappers to match the formats expected by CTS and LIT and then forward those customized payloads to their APIs. The following diagram shows the dependencies or interactions of this microservice with the others. Grafana microservice Although Grafana is a visualization tool for metrics, it needs to fetch some data from VeloCloud API to build dashboards for customer Titan America. The following diagram shows the dependencies or interactions of this microservice with the others. Hawkeye-outage-monitor microservice This service is responsible for resolving/unresolving outage tickets depending on the state of a Hawkeye device. It is triggered every 3 minutes. If a device is detected to be in outage state then it is scheduled for a recheck in the next 5 seconds. If the device is still in outage state, the system will try creating a new outage ticket. If Bruin reports back that an outage ticket with Resolved status exists already then it is unresolved; if not, a new outage ticket may have been created or an outage ticket with In Progress status may exist already, so no additional action will be taken. In case the device was detected to be healthy, the system looks for an open outage ticket for this device and resolves it in case it exists. In the following diagram it's possible see the relationship of this microservice with the others. Last-contact-report microservice The function to be performed by this microservice is to send a monthly report with information about routers that were last contacted more than 30 days ago. The following flow is used to make this report: The last-contact-report microservice communicates with the velocloud-bridge microservice to obtain events from an edge. Once the events are obtained from an edge, it communicates with the email-bridge microservice to send an email with this information. It is possible to see the relations between the mentioned services for the flow in the following diagram . Service-affecting-monitor microservice In this microservice are defined a series of scales and thresholds, the function of this will be to check if there is loss of packages, latencies or jitter measurements that exceed the thresholds defined. In case the thresholds are exceeded, it will communicate with the email-bridge service to send a notification by email and the notifications service to send a notification by slack, by means of which it will warn of the problems detected on a specific edge. This microservice also communicates with the bruin-bridge microservice to create tickets or add notes to an existing one, including in this information about the routers for which a problem is detected. In the following diagram it's possible see the relationships between this microservice and the others. Service-dispatch-monitor microservice This microservice monitor dispatches statuses for different vendors, at the time of writing this document LIT and CTS. Both processes are pretty much the same in concept but with differences in the implementation. A dispatch is general terms can have the following statuses: Requested Confirmed Tech on site Canceled Completed The main use is to monitor: Dispatch status changed Updates in the dispatch like the technician Send sms prior 2 and 12 hours before Send sms tech on site Cancel dispatch The basic algorithm behaves like this: Get all dispatches for a vendor Filter dispatches that are created through the dispatch-portal Discard invalid ticket ids or dispatches with not proper fields Split the dispatches by status and then send them to the function to process them, there are 3 general functions Confirmed dispatch: Send sms and append note to bruin when a dispatch is confirmed Send sms and append note to bruin 12 or 2 hours prior the dispatch Send sms and append note to bruin when a tech has changed Tech on site dispatch: Send sms and append note to bruin when tech on site Canceled dispatch: Append note to bruin when a dispatch is canceled Each vendor has it's own details like how to retrieve some fields or how we identify the tickets with the dispatches, all explained in the service-dispatch-monitor . In the following diagram it's possible see the relationships between this microservice and the others. Service-outage-monitor microservice This microservice orchestrates the execution of two different processes: Outage monitoring. This process is responsible for resolving/unresolving outage tickets depending on the state of an edge. It is triggered every 3 minutes. If an edge is detected to be in outage state then it is scheduled for a recheck in the next 5 seconds. If the edge is still in outage state, the system will try creating a new outage ticket. If Bruin reports back that an outage ticket with Resolved status exists already then it is unresolved; if not, a new outage ticket may have been created or an outage ticket with In Progress status may exist already, so no additional action will be taken. In case the edge was detected to be healthy, the system looks for an open outage ticket for this edge and resolves it in case it exists. Triage. This process is aimed at updating Bruin tickets with information related to recent edge events. It is triggered every 10 minutes. At the beginning, the process gathers all the open tickets related with the companies that are under triage monitoring. Tickets not related with edges belonging to these companies are discarded before going on. The process starts dealing with every ticket in the set collected in the previous step: * If the outage ticket does not have any triage note from a previous execution of the triage process then a triage note is appended with information of the events related to the edge corresponding to this ticket. Events correspond to the period between 7 days ago and the current moment. If the current environment is DEV instead of PRODUCTION then no note is appended to the ticket; instead, a notification with a summary of the triage results is delivered to a Slack channel. If the outage ticket already has a triage note from a previous execution then the process attempts to append new triage notes to the ticket but only if the last triage note was not appended recently (30 minutes or less ago). In case there's no recent triage note, edge events from the period between the creation date of the last triage note and the current moment are claimed to Velocloud and then they are included in the triage notes, which are finally appended to the ticket. Note that due to Bruin limitations it is not feasible to have a triage note with 1500 characters or more; that is the reason why several triage notes are appended to the ticket (instead of just appending one). In the following diagram it's possible see the relationship of this microservice with the others. TNBA-feedback microservice This microservice is in charge of collecting closed tickets that had a TNBA note appended by tnba-monitor at some point. After collecting them, they are sent to t7-bridge to retrain predictive models and hence improve the accuracy of predictions claimed by tnba-monitor . The following diagram shows the relationship between this microservice and the others. TNBA-monitor microservice This microservice is in charge of appending notes to Bruin tickets indicating what is T he N ext B est A ction a member of the support team of Bruin can take to move forward on the resolution of the ticket. It mostly communicates with bruin-bridge and t7-bridge to embed predictions into tickets, but it also communicates with other capabilities as shown in the following diagram . The following diagram shows the relationship between this microservice and the others. Special microservices (NATS Requester and Replier) Customer-cache microservice This microservice is in charge of crossing Bruin and Velocloud data. More specifically, it focus on associating Bruin customers with Velocloud edges. On the other hand, it also serves this information to the rest of services. This service is a special one, since it acts as a requester (to build and store caches) but also as a replier (to serve caches to services requesting them). The following diagram shows the dependencies or interactions of this microservice with the rest. From the point of view of services to the left of customer-cache , it plays the role of a replier as it answers to requests sent by them. From the point of view of services to the right of customer-cache , it plays the role of a requester as it asks for data to Velocloud and Bruin to cross it. Hawkeye-customer-cache microservice This microservice is in charge of crossing Bruin and Hawkeye data. More specifically, it focus on associating Bruin customers with Hawkeye devices. On the other hand, it also serves this information to the rest of services. This service is a special one, since it acts as a requester (to build and store caches) but also as a replier (to serve caches to services requesting them). The following diagram shows the dependencies or interactions of this microservice with the rest. From the point of view of services to the left of hawkeye-customer-cache , it plays the role of a replier as it answers to requests sent by them. From the point of view of services to the right of hawkeye-customer-cache , it plays the role of a requester as it asks for data to Hawkeye and Bruin to cross it. Microservices that don't communicate with NATS dispatch-portal-frontend In conjunction with dispatch-portal-backend , this service provides MetTel the ability to track the status of dispatch requests, as well as create and update them, so their technicians can assist customers when they report any issue related to a device. It exposes a UI that communicates directly with a REST API in dispatch-portal-backend to handle the visualization, creation and update of dispatch requests. The following diagram shows the relationship between this microservice and dispatch-portal-backend . lumin-billing-report This service automates requesting billing information for a given customer from the Lumin.AI service provider, generating a summary HTML email and attaching a csv with all data for the current billing period. This service is self-contained, i.e., it does not require access to NATS or Redis, or any other microservice within the Automation Engine. The following diagram shows the relationship between this service and the third-party services it uses. Prometheus & Thanos The purpose of Prometheus is to scrape metrics from HTTP servers placed in those services with the ability to write metrics, nothing else. Thanos is just another component that adds a layer of persistence to Prometheus, thus allowing to save metrics before they are lost when a service is re-deployed. These metrics can be restored after the deployment completes. Metrics are usually displayed in a Grafana instance with a few custom dashboards. The following diagram shows the relationship between Prometheus, the metrics servers it scrapes metrics, and Grafana. Redis Redis is an in-memory key-value store that, in this system, is used mostly for caching purposes, and also as a temporary storage for messages larger than 1 MB, which NATS cannot handle by itself. There are three Redis instances: * redis . Used to store NATS messages larger than 1 MB temporarily. All microservices that communicate with NATS in some way have the ability to store and retrieve messages from this Redis instance. redis-customer-cache . Used to turn customer-cache and hawkeye-customer-cache into fault-tolerant services, so if any of them fail caches will still be available to serve as soon as they come back. redis-tnba-feedback . Used to collect huge amounts of Bruin tickets' task histories before they are sent to T7 by the tnba-feedback service. Technologies and tools Code repository Intelygenz's Gitlab is used to store the project's code Gitlab CI is used as the CI/CD tool for the project Containerization The following containerization tools are used: Docker is used to create o container of this type by microservice > In the folder of each microservice there is a Dockerfile that allows to execute that microservice as a container Docker-compose is used for defining and running project microservices as a multi-container Docker application: > At the root of the repository there is a docker-compose.yml file that allows to run one or more microservices as docker containers Infrastructure Microservices Infrastructure For the microservices ECS is used to deploy a container for each microservice for all environments deployed, as each one has its own repository in the ECR registry used in the project. In the following diagram it's possible see how the microservices of the project are deployed, using the different images available in the registry created for the project in ECR. KRE Infrastructure In this project KRE is used, it has been deployed in an Kubernetes cluster using EKS for each of the necessary environments , as well as all the parts needed for this in AWS. In the following diagram it's possible see how is configured the KRE infrastructure in the project. Network infrastructure For the infrastructure of the network resources there is a distinction according to the microservice environments and also the kre-environmetns to deploy belongs to dev or production . In the following diagram it's possible see the infrastructure relative to the existing network resources in AWS created for the two type of environments. When deploying an environment it will use the resources belonging to the environment type. This approach has been implemented so that regardless of the number of ECS clusters being used, the same public IPs are always used to make requests outward from the different environments. KRE's clusters will also use the VPCs corresponding to each environment, i.e., dev or production .","title":"System overview"},{"location":"SYSTEM_OVERVIEW/#system-overview","text":"","title":"System overview"},{"location":"SYSTEM_OVERVIEW/#architecture","text":"","title":"Architecture"},{"location":"SYSTEM_OVERVIEW/#basic-concepts","text":"It's a project based on microservices, in which two types are distinguished: Capabilities : They are in charge of carrying out certain common actions for the business logic. I.e.: Collect information from SD-WAN routers For example: Collect information from SD-WAN routers. Use cases : They use capabilities as a base to make specific use cases. I.e.: Obtain certain tickets from SD-WAN routers of a company, obtaining the information from the routers for the subsequent storage in the corresponding tickets. For example: Obtain certain tickets from SD-WAN routers of a company, obtaining the information from the routers for subsequent storage in the corresponding tickets. It is important to emphasize on the architecture of the system the use of NATS in it.","title":"Basic concepts"},{"location":"SYSTEM_OVERVIEW/#messaging-system","text":"It's important to emphasize in the architecture of the system the use of NATS in it. NATS is a simple, secure and performant communications system for digital system, services and devices NATS is used in the microservices system as a communication center for all of them. NATS it's used in cluster mode to safistify more work to be done by it due to the high number of events in the system to be processed","title":"Messaging system"},{"location":"SYSTEM_OVERVIEW/#microservices-communications","text":"There are two types of microservices depending on the connection between them and NATS: Microservices that communicates with NATS , divided into three types: Those that take the role of replier in the context of NATS, usually microservices that contains capabilities : bruin-bridge cts-bridge hawkeye-bridge lit-bridge email-bridge notifications-bridge t7-bridge Those that take the role of requester in the context of NATS, usually microservices that contains use cases : dispatch-portal-backend grafana component, from metrics-prometheus microservice hawkeye-affecting-monitor hawkeye-outage-monitor last-contact-report service-affecting-monitor service-dispatch-monitor service-outage-monitor tnba-feedback tnba-monitor Those that take the role of both requester and replier in the context of NATS. These microservices can be considered a mixture between use use cases and capabilities : customer-cache hawkeye-customer-cache It's important take into account that all microservices that communicate with NATS can also communicate with the Redis Cluster. This is needed to bypass the limit size that NATS enforces for all messages it receives (1MB). Microservices that doesn't communicate with NATS : dispatch-portal-frontend lumin-billing-report prometheus and thanos components, from metrics-prometheus microservice redis cluster (Docker container in local environment or an Elasticache Redis Cluster in AWS environments) NATS is used in the microservice system as a communication center for all of them. It is used in cluster mode to satisfy more work to be done by it. In the following diagram it's possible see a graph with the relationships between the microservices explained previously in this section","title":"Microservices communications"},{"location":"SYSTEM_OVERVIEW/#relationships-between-microservices","text":"The services that are part of the previously explained architecture are related to each other, in the following diagram it's possible see the relationships between them.","title":"Relationships between microservices"},{"location":"SYSTEM_OVERVIEW/#capabilities-microservices","text":"","title":"Capabilities microservices"},{"location":"SYSTEM_OVERVIEW/#bruin-bridge-microservice","text":"This microservice is in charge of making requests to the bruin API, taking the role of replier in the context of NATS. When another microservice requests bruin data, it will be in charge of making response messages to the same and never of request, that is to say, it will always be a producer within a NATS topic and never a consumer. Bruin is a third-party system that allows creating and managing support tickets to deal with issues that appear in network devices, among other types of devices. The following diagram shows the dependencies or interactions of this microservice with the others, being in this case none, since it is in charge of one of the isolated microservices as explained above.","title":"Bruin-bridge microservice"},{"location":"SYSTEM_OVERVIEW/#cts-bridge-microservice","text":"This microservice is in charge of making requests to the CTS API, taking the role of replier in the context of NATS. When another microservice requests CTS data, it will be in charge of making response messages to the same and never of request, that is to say, it will always be a producer within a NATS topic and never a consumer. The following diagram shows the dependencies or interactions of this microservice with the others, being in this case none, since it is in charge of one of the isolated microservices as explained above.","title":"Cts-bridge microservice"},{"location":"SYSTEM_OVERVIEW/#digi-bridge-microservice","text":"This microservice is in charge of making requests to the Digi Reboot API, taking the role of replier in the context of NATS. When another microservice asks to reboot a SD-WAN device, it will be in charge of making response messages to the same and never of request, that is to say, it will always be a producer within a NATS topic and never a consumer. The following diagram shows the dependencies or interactions of this microservice with the others, being in this case none, since it is in charge of one of the isolated microservices as explained above.","title":"Digi-bridge microservice"},{"location":"SYSTEM_OVERVIEW/#hawkeye-bridge-microservice","text":"This microservice is in charge of making requests to the Hawkeye API, taking the role of replier in the context of NATS. When another microservice requests Hawkeye data, it will be in charge of making response messages to the same and never of request, that is to say, it will always be a producer within a NATS topic and never a consumer. The following diagram shows the dependencies or interactions of this microservice with the others, being in this case none, since it is in charge of one of the isolated microservices as explained above.","title":"Hawkeye-bridge microservice"},{"location":"SYSTEM_OVERVIEW/#lit-bridge-microservice","text":"This microservice is in charge of making requests to the LIT API, taking the role of replier in the context of NATS. When another microservice requests LIT data, it will be in charge of making response messages to the same and never of request, that is to say, it will always be a producer within a NATS topic and never a consumer. The following diagram shows the dependencies or interactions of this microservice with the others, being in this case none, since it is in charge of one of the isolated microservices as explained above.","title":"Lit-bridge microservice"},{"location":"SYSTEM_OVERVIEW/#email-bridge-microservice","text":"This microservice is in charge of sending emails. It is important to point out that it is not in charge of the composition of the messages to be sent, that is to say, of their content, but only of sending them. The following diagram shows the dependencies or interactions of this microservice with the others, being in this case none, since it is in charge of one of the isolated microservices as explained above.","title":"Email bridge microservice"},{"location":"SYSTEM_OVERVIEW/#notifications-bridge-microservice","text":"This microservice is in charge of sending notifications to third-party systems. It is important to point out that it is not in charge of the composition of the messages to be sent, that is to say, of their content, but only of sending them. The following diagram shows the dependencies or interactions of this microservice with the others, being in this case none, since it is in charge of one of the isolated microservices as explained above.","title":"Notifications bridge microservice"},{"location":"SYSTEM_OVERVIEW/#t7-bridge-microservice","text":"The function of this microservice is to embed in the notes of a ticket the prediction calculated by T7, this prediction will store information on the recommendations actions for the ticket. In order to carry out the mentioned actions, it communicates with the API of T7 to obtain the information about the prediction, as it can be seen in the following diagram .","title":"T7-bridge microservice"},{"location":"SYSTEM_OVERVIEW/#velocloud-bridge-microservice","text":"This microservice is in charge of making requests to the velocloud API, taking the role of replier in the context of NATS. When another microservice requests velocloud data, it will be in charge of making response messages to the same and never of request, that is to say, it will always be a producer within a NATS topic and never a consumer. The following diagram shows the dependencies or interactions of this microservice with the others, being in this case none, since it is in charge of one of the isolated microservices as explained above.","title":"Velocloud-bridge microservice"},{"location":"SYSTEM_OVERVIEW/#use-cases-microservices","text":"","title":"Use cases microservices"},{"location":"SYSTEM_OVERVIEW/#dispatch-portal-backend-microservice","text":"In conjunction with dispatch-portal-frontend , this service provides MetTel the ability to track the status of dispatch requests, as well as create and update them, so their technicians can assist customers when they report any issue related to a device. It also updates Bruin tickets to keep support people posted about the changes in the dispatch requests. It acts as an intermediary between dispatch-portal-frontend and CTS & LIT APIs by providing a REST API with multiple endpoints that, once they receive a payload from the frontend side, it modifies its fields with the help of some mappers to match the formats expected by CTS and LIT and then forward those customized payloads to their APIs. The following diagram shows the dependencies or interactions of this microservice with the others.","title":"Dispatch-portal-backend microservice"},{"location":"SYSTEM_OVERVIEW/#grafana-microservice","text":"Although Grafana is a visualization tool for metrics, it needs to fetch some data from VeloCloud API to build dashboards for customer Titan America. The following diagram shows the dependencies or interactions of this microservice with the others.","title":"Grafana microservice"},{"location":"SYSTEM_OVERVIEW/#hawkeye-outage-monitor-microservice","text":"This service is responsible for resolving/unresolving outage tickets depending on the state of a Hawkeye device. It is triggered every 3 minutes. If a device is detected to be in outage state then it is scheduled for a recheck in the next 5 seconds. If the device is still in outage state, the system will try creating a new outage ticket. If Bruin reports back that an outage ticket with Resolved status exists already then it is unresolved; if not, a new outage ticket may have been created or an outage ticket with In Progress status may exist already, so no additional action will be taken. In case the device was detected to be healthy, the system looks for an open outage ticket for this device and resolves it in case it exists. In the following diagram it's possible see the relationship of this microservice with the others.","title":"Hawkeye-outage-monitor microservice"},{"location":"SYSTEM_OVERVIEW/#last-contact-report-microservice","text":"The function to be performed by this microservice is to send a monthly report with information about routers that were last contacted more than 30 days ago. The following flow is used to make this report: The last-contact-report microservice communicates with the velocloud-bridge microservice to obtain events from an edge. Once the events are obtained from an edge, it communicates with the email-bridge microservice to send an email with this information. It is possible to see the relations between the mentioned services for the flow in the following diagram .","title":"Last-contact-report microservice"},{"location":"SYSTEM_OVERVIEW/#service-affecting-monitor-microservice","text":"In this microservice are defined a series of scales and thresholds, the function of this will be to check if there is loss of packages, latencies or jitter measurements that exceed the thresholds defined. In case the thresholds are exceeded, it will communicate with the email-bridge service to send a notification by email and the notifications service to send a notification by slack, by means of which it will warn of the problems detected on a specific edge. This microservice also communicates with the bruin-bridge microservice to create tickets or add notes to an existing one, including in this information about the routers for which a problem is detected. In the following diagram it's possible see the relationships between this microservice and the others.","title":"Service-affecting-monitor microservice"},{"location":"SYSTEM_OVERVIEW/#service-dispatch-monitor-microservice","text":"This microservice monitor dispatches statuses for different vendors, at the time of writing this document LIT and CTS. Both processes are pretty much the same in concept but with differences in the implementation. A dispatch is general terms can have the following statuses: Requested Confirmed Tech on site Canceled Completed The main use is to monitor: Dispatch status changed Updates in the dispatch like the technician Send sms prior 2 and 12 hours before Send sms tech on site Cancel dispatch The basic algorithm behaves like this: Get all dispatches for a vendor Filter dispatches that are created through the dispatch-portal Discard invalid ticket ids or dispatches with not proper fields Split the dispatches by status and then send them to the function to process them, there are 3 general functions Confirmed dispatch: Send sms and append note to bruin when a dispatch is confirmed Send sms and append note to bruin 12 or 2 hours prior the dispatch Send sms and append note to bruin when a tech has changed Tech on site dispatch: Send sms and append note to bruin when tech on site Canceled dispatch: Append note to bruin when a dispatch is canceled Each vendor has it's own details like how to retrieve some fields or how we identify the tickets with the dispatches, all explained in the service-dispatch-monitor . In the following diagram it's possible see the relationships between this microservice and the others.","title":"Service-dispatch-monitor microservice"},{"location":"SYSTEM_OVERVIEW/#service-outage-monitor-microservice","text":"This microservice orchestrates the execution of two different processes: Outage monitoring. This process is responsible for resolving/unresolving outage tickets depending on the state of an edge. It is triggered every 3 minutes. If an edge is detected to be in outage state then it is scheduled for a recheck in the next 5 seconds. If the edge is still in outage state, the system will try creating a new outage ticket. If Bruin reports back that an outage ticket with Resolved status exists already then it is unresolved; if not, a new outage ticket may have been created or an outage ticket with In Progress status may exist already, so no additional action will be taken. In case the edge was detected to be healthy, the system looks for an open outage ticket for this edge and resolves it in case it exists. Triage. This process is aimed at updating Bruin tickets with information related to recent edge events. It is triggered every 10 minutes. At the beginning, the process gathers all the open tickets related with the companies that are under triage monitoring. Tickets not related with edges belonging to these companies are discarded before going on. The process starts dealing with every ticket in the set collected in the previous step: * If the outage ticket does not have any triage note from a previous execution of the triage process then a triage note is appended with information of the events related to the edge corresponding to this ticket. Events correspond to the period between 7 days ago and the current moment. If the current environment is DEV instead of PRODUCTION then no note is appended to the ticket; instead, a notification with a summary of the triage results is delivered to a Slack channel. If the outage ticket already has a triage note from a previous execution then the process attempts to append new triage notes to the ticket but only if the last triage note was not appended recently (30 minutes or less ago). In case there's no recent triage note, edge events from the period between the creation date of the last triage note and the current moment are claimed to Velocloud and then they are included in the triage notes, which are finally appended to the ticket. Note that due to Bruin limitations it is not feasible to have a triage note with 1500 characters or more; that is the reason why several triage notes are appended to the ticket (instead of just appending one). In the following diagram it's possible see the relationship of this microservice with the others.","title":"Service-outage-monitor microservice"},{"location":"SYSTEM_OVERVIEW/#tnba-feedback-microservice","text":"This microservice is in charge of collecting closed tickets that had a TNBA note appended by tnba-monitor at some point. After collecting them, they are sent to t7-bridge to retrain predictive models and hence improve the accuracy of predictions claimed by tnba-monitor . The following diagram shows the relationship between this microservice and the others.","title":"TNBA-feedback microservice"},{"location":"SYSTEM_OVERVIEW/#tnba-monitor-microservice","text":"This microservice is in charge of appending notes to Bruin tickets indicating what is T he N ext B est A ction a member of the support team of Bruin can take to move forward on the resolution of the ticket. It mostly communicates with bruin-bridge and t7-bridge to embed predictions into tickets, but it also communicates with other capabilities as shown in the following diagram . The following diagram shows the relationship between this microservice and the others.","title":"TNBA-monitor microservice"},{"location":"SYSTEM_OVERVIEW/#special-microservices-nats-requester-and-replier","text":"","title":"Special microservices (NATS Requester and Replier)"},{"location":"SYSTEM_OVERVIEW/#customer-cache-microservice","text":"This microservice is in charge of crossing Bruin and Velocloud data. More specifically, it focus on associating Bruin customers with Velocloud edges. On the other hand, it also serves this information to the rest of services. This service is a special one, since it acts as a requester (to build and store caches) but also as a replier (to serve caches to services requesting them). The following diagram shows the dependencies or interactions of this microservice with the rest. From the point of view of services to the left of customer-cache , it plays the role of a replier as it answers to requests sent by them. From the point of view of services to the right of customer-cache , it plays the role of a requester as it asks for data to Velocloud and Bruin to cross it.","title":"Customer-cache microservice"},{"location":"SYSTEM_OVERVIEW/#hawkeye-customer-cache-microservice","text":"This microservice is in charge of crossing Bruin and Hawkeye data. More specifically, it focus on associating Bruin customers with Hawkeye devices. On the other hand, it also serves this information to the rest of services. This service is a special one, since it acts as a requester (to build and store caches) but also as a replier (to serve caches to services requesting them). The following diagram shows the dependencies or interactions of this microservice with the rest. From the point of view of services to the left of hawkeye-customer-cache , it plays the role of a replier as it answers to requests sent by them. From the point of view of services to the right of hawkeye-customer-cache , it plays the role of a requester as it asks for data to Hawkeye and Bruin to cross it.","title":"Hawkeye-customer-cache microservice"},{"location":"SYSTEM_OVERVIEW/#microservices-that-dont-communicate-with-nats","text":"","title":"Microservices that don't communicate with NATS"},{"location":"SYSTEM_OVERVIEW/#dispatch-portal-frontend","text":"In conjunction with dispatch-portal-backend , this service provides MetTel the ability to track the status of dispatch requests, as well as create and update them, so their technicians can assist customers when they report any issue related to a device. It exposes a UI that communicates directly with a REST API in dispatch-portal-backend to handle the visualization, creation and update of dispatch requests. The following diagram shows the relationship between this microservice and dispatch-portal-backend .","title":"dispatch-portal-frontend"},{"location":"SYSTEM_OVERVIEW/#lumin-billing-report","text":"This service automates requesting billing information for a given customer from the Lumin.AI service provider, generating a summary HTML email and attaching a csv with all data for the current billing period. This service is self-contained, i.e., it does not require access to NATS or Redis, or any other microservice within the Automation Engine. The following diagram shows the relationship between this service and the third-party services it uses.","title":"lumin-billing-report"},{"location":"SYSTEM_OVERVIEW/#prometheus-thanos","text":"The purpose of Prometheus is to scrape metrics from HTTP servers placed in those services with the ability to write metrics, nothing else. Thanos is just another component that adds a layer of persistence to Prometheus, thus allowing to save metrics before they are lost when a service is re-deployed. These metrics can be restored after the deployment completes. Metrics are usually displayed in a Grafana instance with a few custom dashboards. The following diagram shows the relationship between Prometheus, the metrics servers it scrapes metrics, and Grafana.","title":"Prometheus &amp; Thanos"},{"location":"SYSTEM_OVERVIEW/#redis","text":"Redis is an in-memory key-value store that, in this system, is used mostly for caching purposes, and also as a temporary storage for messages larger than 1 MB, which NATS cannot handle by itself. There are three Redis instances: * redis . Used to store NATS messages larger than 1 MB temporarily. All microservices that communicate with NATS in some way have the ability to store and retrieve messages from this Redis instance. redis-customer-cache . Used to turn customer-cache and hawkeye-customer-cache into fault-tolerant services, so if any of them fail caches will still be available to serve as soon as they come back. redis-tnba-feedback . Used to collect huge amounts of Bruin tickets' task histories before they are sent to T7 by the tnba-feedback service.","title":"Redis"},{"location":"SYSTEM_OVERVIEW/#technologies-and-tools","text":"","title":"Technologies and tools"},{"location":"SYSTEM_OVERVIEW/#code-repository","text":"Intelygenz's Gitlab is used to store the project's code Gitlab CI is used as the CI/CD tool for the project","title":"Code repository"},{"location":"SYSTEM_OVERVIEW/#containerization","text":"The following containerization tools are used: Docker is used to create o container of this type by microservice > In the folder of each microservice there is a Dockerfile that allows to execute that microservice as a container Docker-compose is used for defining and running project microservices as a multi-container Docker application: > At the root of the repository there is a docker-compose.yml file that allows to run one or more microservices as docker containers","title":"Containerization"},{"location":"SYSTEM_OVERVIEW/#infrastructure","text":"","title":"Infrastructure"},{"location":"SYSTEM_OVERVIEW/#microservices-infrastructure","text":"For the microservices ECS is used to deploy a container for each microservice for all environments deployed, as each one has its own repository in the ECR registry used in the project. In the following diagram it's possible see how the microservices of the project are deployed, using the different images available in the registry created for the project in ECR.","title":"Microservices Infrastructure"},{"location":"SYSTEM_OVERVIEW/#kre-infrastructure","text":"In this project KRE is used, it has been deployed in an Kubernetes cluster using EKS for each of the necessary environments , as well as all the parts needed for this in AWS. In the following diagram it's possible see how is configured the KRE infrastructure in the project.","title":"KRE Infrastructure"},{"location":"SYSTEM_OVERVIEW/#network-infrastructure","text":"For the infrastructure of the network resources there is a distinction according to the microservice environments and also the kre-environmetns to deploy belongs to dev or production . In the following diagram it's possible see the infrastructure relative to the existing network resources in AWS created for the two type of environments. When deploying an environment it will use the resources belonging to the environment type. This approach has been implemented so that regardless of the number of ECS clusters being used, the same public IPs are always used to make requests outward from the different environments. KRE's clusters will also use the VPCs corresponding to each environment, i.e., dev or production .","title":"Network infrastructure"},{"location":"WELCOME_PACK/","text":"Welcome Pack Team Composition Julia - Manager Dani - Tech Lead \u00c1ngel - Devops Brandon - Developer David - Developer Sergio - Developer Javier - Developer First steps Please request access to all the things listed below: Project repository https://gitlab.intelygenz.com/mettel/automation-engine/ , docker repository https://gitlab.intelygenz.com/mettel/docker_images/-/tree/master and One password to itcrowd@intelygenz.com through their ticketing system https://docs.google.com/document/d/1YLYdI9Dyq8tNlNy2iJ29InquKDz8r_Dw4XBsxI7pPiM/edit and CC your manager to allow the request Configure vpn https://docs.google.com/document/d/16_LFpkiBWN0mbfjAoqR4BaEB5kPNsuNHrUS7PtrWnEA/edit#heading=h.to49i8wu1vn3 AWS account creation to our devops Jira board to our manager Mettel's Slack channels to our tech lead Project overview Resources Check docs folder inside the mettel gitlab project and read carefully the readme for installing all the required programs and configure the project. After RRHH's on-boarding our team lead will give an overview of the project https://docs.google.com/presentation/d/1Y18vXn6lsSp-6pJVsB5swWg7UcTDWYrIYtXq8_brRMk/edit#slide=id.g6183830b53_0_5 Project guidelines This project uses Black and isort. You just need to install pip install pre-commit and then just run pre-commit run --all-files on the root folder. Please check pre-commit-config.yaml for more info about it. Another option (after adding the project poetry env as interpreter in pycharm) would be running poetry run black . and poetry run isort . on the root folder, the config options will be taken automatically from pyproject.toml . For adding this as autosave option please refer to https://black.readthedocs.io/en/stable/integrations/editors.html When updating a git branch please use rebase instead of merge. Tools k9s https://k9scli.io/ bash-completion","title":"Welcome Pack"},{"location":"WELCOME_PACK/#welcome-pack","text":"","title":"Welcome Pack"},{"location":"WELCOME_PACK/#team-composition","text":"Julia - Manager Dani - Tech Lead \u00c1ngel - Devops Brandon - Developer David - Developer Sergio - Developer Javier - Developer","title":"Team Composition"},{"location":"WELCOME_PACK/#first-steps","text":"Please request access to all the things listed below: Project repository https://gitlab.intelygenz.com/mettel/automation-engine/ , docker repository https://gitlab.intelygenz.com/mettel/docker_images/-/tree/master and One password to itcrowd@intelygenz.com through their ticketing system https://docs.google.com/document/d/1YLYdI9Dyq8tNlNy2iJ29InquKDz8r_Dw4XBsxI7pPiM/edit and CC your manager to allow the request Configure vpn https://docs.google.com/document/d/16_LFpkiBWN0mbfjAoqR4BaEB5kPNsuNHrUS7PtrWnEA/edit#heading=h.to49i8wu1vn3 AWS account creation to our devops Jira board to our manager Mettel's Slack channels to our tech lead","title":"First steps"},{"location":"WELCOME_PACK/#project-overview","text":"","title":"Project overview"},{"location":"WELCOME_PACK/#resources","text":"Check docs folder inside the mettel gitlab project and read carefully the readme for installing all the required programs and configure the project. After RRHH's on-boarding our team lead will give an overview of the project https://docs.google.com/presentation/d/1Y18vXn6lsSp-6pJVsB5swWg7UcTDWYrIYtXq8_brRMk/edit#slide=id.g6183830b53_0_5","title":"Resources"},{"location":"WELCOME_PACK/#project-guidelines","text":"This project uses Black and isort. You just need to install pip install pre-commit and then just run pre-commit run --all-files on the root folder. Please check pre-commit-config.yaml for more info about it. Another option (after adding the project poetry env as interpreter in pycharm) would be running poetry run black . and poetry run isort . on the root folder, the config options will be taken automatically from pyproject.toml . For adding this as autosave option please refer to https://black.readthedocs.io/en/stable/integrations/editors.html When updating a git branch please use rebase instead of merge.","title":"Project guidelines"},{"location":"WELCOME_PACK/#tools","text":"k9s https://k9scli.io/ bash-completion","title":"Tools"},{"location":"api/flows/1-authentication/","text":"Flow Diagram Requisites Okta account/user set up AWS login endpoint exposed to internet (Also whitelisted IP?) create a user on okta that has permissions to check the user and the token Description As a requirement we need to accomplish centralized users and groups in Okta. We must connect Okta with our authentication workflow. Flow User will launch a signin call to our API endpoint Our API endpoint will call to the auth endpoint of okta. create api token https://developer.okta.com/docs/guides/create-an-api-token/main/ https://developer.okta.com/docs/guides/create-an-api-token/main/ login with api token https://developer.okta.com/docs/reference/api/authn/#response-example-for-primary-authentication-with-public-application-factor-enroll token expiration https://developer.okta.com/docs/guides/create-an-api-token/main/ validate access token https://developer.okta.com/docs/guides/validate-access-tokens/python/main/ https://developer.okta.com/docs/guides/implement-grant-type/ropassword/main/#set-up-your-app","title":"1 authentication"},{"location":"api/flows/1-authentication/#flow-diagram","text":"","title":"Flow Diagram"},{"location":"api/flows/1-authentication/#requisites","text":"Okta account/user set up AWS login endpoint exposed to internet (Also whitelisted IP?) create a user on okta that has permissions to check the user and the token Description As a requirement we need to accomplish centralized users and groups in Okta. We must connect Okta with our authentication workflow.","title":"Requisites"},{"location":"api/flows/1-authentication/#flow","text":"User will launch a signin call to our API endpoint Our API endpoint will call to the auth endpoint of okta. create api token https://developer.okta.com/docs/guides/create-an-api-token/main/ https://developer.okta.com/docs/guides/create-an-api-token/main/ login with api token https://developer.okta.com/docs/reference/api/authn/#response-example-for-primary-authentication-with-public-application-factor-enroll token expiration https://developer.okta.com/docs/guides/create-an-api-token/main/ validate access token https://developer.okta.com/docs/guides/validate-access-tokens/python/main/ https://developer.okta.com/docs/guides/implement-grant-type/ropassword/main/#set-up-your-app","title":"Flow"},{"location":"backups/ECR_RECOVERY_PLAN/","text":"Pre requisites AWS user credentials AWS ECR CLI UNZIP tool Description The project at this moment is deployed in AWS infrastructure with all FEDRAMP requirements meet. To acompish this requirements the ECR repository must have a backup plan in case of losing the containers. Backup Plan When the pipeline runs, the projects copy the docker containers from the comercial environment with the keys to validate that the images are delived by the intelygenz team. The Pipeline will push the containers to the 3 regions(Primary, Secundary and Terciary) and create a ZIP file with the next format / - - .tar. The s3 bucket name that contains the containers is \"fedramp-ecr-backups\" Recovery Plan Before start, you must be loged on the AWS docker login. To recovery a ECR container in case is lost/deleted follow the next steps: - Identify the Activated region and go to s3 and find \"fedramp-ecr-backups\" bucket. - Download the file / - - .tar of the version needed. - Execute the next commands to recover the selected container of the : - docker image load -i - - .tar - docker image tag / : - docker push / : Test the recovery To test the recovery plan go to the ECR Repository on the AWS UI and check if the version of the container exists.","title":"ECR backup recovery"},{"location":"backups/ECR_RECOVERY_PLAN/#pre-requisites","text":"AWS user credentials AWS ECR CLI UNZIP tool","title":"Pre requisites"},{"location":"backups/ECR_RECOVERY_PLAN/#description","text":"The project at this moment is deployed in AWS infrastructure with all FEDRAMP requirements meet. To acompish this requirements the ECR repository must have a backup plan in case of losing the containers.","title":"Description"},{"location":"backups/ECR_RECOVERY_PLAN/#backup-plan","text":"When the pipeline runs, the projects copy the docker containers from the comercial environment with the keys to validate that the images are delived by the intelygenz team. The Pipeline will push the containers to the 3 regions(Primary, Secundary and Terciary) and create a ZIP file with the next format / - - .tar. The s3 bucket name that contains the containers is \"fedramp-ecr-backups\"","title":"Backup Plan"},{"location":"backups/ECR_RECOVERY_PLAN/#recovery-plan","text":"Before start, you must be loged on the AWS docker login. To recovery a ECR container in case is lost/deleted follow the next steps: - Identify the Activated region and go to s3 and find \"fedramp-ecr-backups\" bucket. - Download the file / - - .tar of the version needed. - Execute the next commands to recover the selected container of the : - docker image load -i - - .tar - docker image tag / : - docker push / :","title":"Recovery Plan"},{"location":"backups/ECR_RECOVERY_PLAN/#test-the-recovery","text":"To test the recovery plan go to the ECR Repository on the AWS UI and check if the version of the container exists.","title":"Test the recovery"},{"location":"backups/EKS_SSH_RECOVERY_PLAN/","text":"Pre requisites AWS user credentials AWS SSH keys credentials Description The project at this moment is deployed in AWS infrastructure with all FEDRAMP requirements meet. To acompish this requirements the SSH keys generated to access the EKS cluster need a backup plan and a recovery plan. Backup Plan Each region generate the SSH keys crendentials for their specific region, when pasive is activated will have diferent SSH keys to avoid the reuse of these keys. The backup is executed at the moment the terraform runs in the pipeline in a normal execution to deploy the infrastructure and software for the FEDRAMP environment. The Tertiary region only contains backups of the secundary region. Also it's important to notice that the ssh keys only get generated in case of the activation of a region Recovery Plan To recovery a SSH key in case is lost/deleted follow the next steps: - Identify the Activated region, if the region is the primary, the backup region will located in the secundary and if the region is the secundary the backup region will be at the Tertiary. - Download the key from the backup S3 called eks-ssh-keys- -backup - Upload the key to the S3 called eks-ssh-keys- of the activated region.","title":"EKS SSH recovery"},{"location":"backups/EKS_SSH_RECOVERY_PLAN/#pre-requisites","text":"AWS user credentials AWS SSH keys credentials","title":"Pre requisites"},{"location":"backups/EKS_SSH_RECOVERY_PLAN/#description","text":"The project at this moment is deployed in AWS infrastructure with all FEDRAMP requirements meet. To acompish this requirements the SSH keys generated to access the EKS cluster need a backup plan and a recovery plan.","title":"Description"},{"location":"backups/EKS_SSH_RECOVERY_PLAN/#backup-plan","text":"Each region generate the SSH keys crendentials for their specific region, when pasive is activated will have diferent SSH keys to avoid the reuse of these keys. The backup is executed at the moment the terraform runs in the pipeline in a normal execution to deploy the infrastructure and software for the FEDRAMP environment. The Tertiary region only contains backups of the secundary region. Also it's important to notice that the ssh keys only get generated in case of the activation of a region","title":"Backup Plan"},{"location":"backups/EKS_SSH_RECOVERY_PLAN/#recovery-plan","text":"To recovery a SSH key in case is lost/deleted follow the next steps: - Identify the Activated region, if the region is the primary, the backup region will located in the secundary and if the region is the secundary the backup region will be at the Tertiary. - Download the key from the backup S3 called eks-ssh-keys- -backup - Upload the key to the S3 called eks-ssh-keys- of the activated region.","title":"Recovery Plan"},{"location":"backups/GIT_RECOVERY_PLAN/","text":"Pre requisites AWS user credentials AWS git UNZIP tool Description The project at this moment is deployed in AWS infrastructure with all FEDRAMP requirements meet. To acompish this requirements the GIT repository must have a backup in case of losing the code in the repositories. Backup Plan When the pipeline runs, creates a zip in their region following the pattern name - .zip. Each region will have a copy of the ZIP file in a s3 bucket called \"git-backups-fedramp\" Recovery Plan To recovery a git repository in case is lost/deleted follow the next steps: - Identify the Activated region and go to s3 and find \"git-backups-fedramp\" bucket. - Download the file - .zip of the last version. - if the repository is already created with the name \"automation-fedramp\" use the next command: - git clone - unzip - .zip -d - - mv /.git - - cd - - git add . - git commit -m \"Backup recovery\" - git push -f origin main - if the repository does not exists: - create a repository using the AWS UI called \"automation-fedramp\". - unzip - .zip -d - - mv /.git - - cd - - git add . - git commit -m \"Backup recovery\" - git push -f origin main Test the recovery To test the recovery plan go to the recovered Repository \"automation-fedramp\" on the AWS UI and check if the commit \"Backup recovery\" exists.","title":"GIT recovery"},{"location":"backups/GIT_RECOVERY_PLAN/#pre-requisites","text":"AWS user credentials AWS git UNZIP tool","title":"Pre requisites"},{"location":"backups/GIT_RECOVERY_PLAN/#description","text":"The project at this moment is deployed in AWS infrastructure with all FEDRAMP requirements meet. To acompish this requirements the GIT repository must have a backup in case of losing the code in the repositories.","title":"Description"},{"location":"backups/GIT_RECOVERY_PLAN/#backup-plan","text":"When the pipeline runs, creates a zip in their region following the pattern name - .zip. Each region will have a copy of the ZIP file in a s3 bucket called \"git-backups-fedramp\"","title":"Backup Plan"},{"location":"backups/GIT_RECOVERY_PLAN/#recovery-plan","text":"To recovery a git repository in case is lost/deleted follow the next steps: - Identify the Activated region and go to s3 and find \"git-backups-fedramp\" bucket. - Download the file - .zip of the last version. - if the repository is already created with the name \"automation-fedramp\" use the next command: - git clone - unzip - .zip -d - - mv /.git - - cd - - git add . - git commit -m \"Backup recovery\" - git push -f origin main - if the repository does not exists: - create a repository using the AWS UI called \"automation-fedramp\". - unzip - .zip -d - - mv /.git - - cd - - git add . - git commit -m \"Backup recovery\" - git push -f origin main","title":"Recovery Plan"},{"location":"backups/GIT_RECOVERY_PLAN/#test-the-recovery","text":"To test the recovery plan go to the recovered Repository \"automation-fedramp\" on the AWS UI and check if the commit \"Backup recovery\" exists.","title":"Test the recovery"},{"location":"backups/PROMETHEUS_RECOVERY_PLAN/","text":"","title":"Prometheus recovery"},{"location":"backups/TERRAFORM_RECOVERY_PLAN/","text":"Pre requisites AWS user credentials AWS SSH keys credentials Description The project at this moment is deployed in AWS infrastructure with all FEDRAMP requirements meet. To acompish this requirements the SSH keys generated to access the EKS cluster need a backup plan and a recovery plan. The project generates the next TF state files and it's executed in order: - Global: Infrastructure that is global in AWS - Primary(regional): Infrastructure that is in the primary region. - secundary(regional): Infrastructure that is in the secundary region. - terciary(regional): Infrastructure that is in the terciary region. - Unions: Create links between regions of systems that must be connected(Like backups and replication) Backup Plan The pipeline will create a ZIP file containing the 5 terraform state files and replicate them into a S3 bucket in each region, the file will have this format .zip. Recovery Plan The recovery plan is: - download the last ZIP backup file ordered by date in the backed called fedramp-automation-infrastructure-backups - Unzip the file - Find the bucket called fedramp-automation-infrastructure in the activated - Upload the files to the S3 Bucket. Test the backup plan Follow the steps to recovery the backed files and run a deployment pipeline in the active region. If the pipeline works perfectly it's a signal that the files are working properly.","title":"Terraform recovery"},{"location":"backups/TERRAFORM_RECOVERY_PLAN/#pre-requisites","text":"AWS user credentials AWS SSH keys credentials","title":"Pre requisites"},{"location":"backups/TERRAFORM_RECOVERY_PLAN/#description","text":"The project at this moment is deployed in AWS infrastructure with all FEDRAMP requirements meet. To acompish this requirements the SSH keys generated to access the EKS cluster need a backup plan and a recovery plan. The project generates the next TF state files and it's executed in order: - Global: Infrastructure that is global in AWS - Primary(regional): Infrastructure that is in the primary region. - secundary(regional): Infrastructure that is in the secundary region. - terciary(regional): Infrastructure that is in the terciary region. - Unions: Create links between regions of systems that must be connected(Like backups and replication)","title":"Description"},{"location":"backups/TERRAFORM_RECOVERY_PLAN/#backup-plan","text":"The pipeline will create a ZIP file containing the 5 terraform state files and replicate them into a S3 bucket in each region, the file will have this format .zip.","title":"Backup Plan"},{"location":"backups/TERRAFORM_RECOVERY_PLAN/#recovery-plan","text":"The recovery plan is: - download the last ZIP backup file ordered by date in the backed called fedramp-automation-infrastructure-backups - Unzip the file - Find the bucket called fedramp-automation-infrastructure in the activated - Upload the files to the S3 Bucket.","title":"Recovery Plan"},{"location":"backups/TERRAFORM_RECOVERY_PLAN/#test-the-backup-plan","text":"Follow the steps to recovery the backed files and run a deployment pipeline in the active region. If the pipeline works perfectly it's a signal that the files are working properly.","title":"Test the backup plan"},{"location":"decisions/","text":"GLOBAL DECISIONS Dashboard infrastructure and architecture","title":"MetTel decisions"},{"location":"decisions/01-dashboards-infrastructure-and-architecture/","text":"1: Design of an isolated an unique dashboard user experience Status: Approved Decision: Future is to have an external Grafana that connects to an external Prometheus & InfluxDB 2 Implementation plan as following: - Prometheus will be deployed as an AWS Managed Prometheus. - Grafana will be deployed independently in AWS pointing to AWS Prometheus. - Konstellation KRE will be merged to a single KRE instance as soon as KRE allows it. - KRE will use a dedicated InfluxDB2 in AWS. - Grafana will connect to InfluxDB2 as additional data source. - Chronograf dashboards will be migrated to the dedicated Grafana in AWS. Miro diagram of affected systems: https://miro.com/app/board/uXjVO6bg-zY=/ Alternatives considered: Justification: Current dashboarding solution has several different interfaces, this is confusing for all kind of users. Current stability of dashboarding is dependent in the stability of our K8s deployments, losing all visibility if anything goes wrong on K8s. License limitations on InfluxDB OSS1 could become a problem. Consequences:","title":"**1: Design of an isolated an unique dashboard user experience**"},{"location":"decisions/01-dashboards-infrastructure-and-architecture/#1-design-of-an-isolated-an-unique-dashboard-user-experience","text":"Status: Approved Decision: Future is to have an external Grafana that connects to an external Prometheus & InfluxDB 2 Implementation plan as following: - Prometheus will be deployed as an AWS Managed Prometheus. - Grafana will be deployed independently in AWS pointing to AWS Prometheus. - Konstellation KRE will be merged to a single KRE instance as soon as KRE allows it. - KRE will use a dedicated InfluxDB2 in AWS. - Grafana will connect to InfluxDB2 as additional data source. - Chronograf dashboards will be migrated to the dedicated Grafana in AWS. Miro diagram of affected systems: https://miro.com/app/board/uXjVO6bg-zY=/ Alternatives considered: Justification: Current dashboarding solution has several different interfaces, this is confusing for all kind of users. Current stability of dashboarding is dependent in the stability of our K8s deployments, losing all visibility if anything goes wrong on K8s. License limitations on InfluxDB OSS1 could become a problem. Consequences:","title":"1: Design of an isolated an unique dashboard user experience"},{"location":"diagrams/TOOLS/","text":"https://github.com/mingrammer/diagrams","title":"TOOLS"},{"location":"kafka/LAUNCH_DOCKER_COMPOSE/","text":"1. How to run In this section we explain all the useful information that we can use when working in our local environment. In order to raise our system we will have to go to the root folder of our system and launch the following command docker-compose up This will launch our system by creating a local docker image and deploying our fetcher. It is important to keep in mind that this process launches a multitude of requests against the production environment and it is important to limit them all so as not to overload the system. To facilitate the work in local we also have several local configurations that allow us to test step by step our application avoiding possible problems of launching too many requests. To launch this configuration in Intellij you will need to verify that the following steps were done: - Go to Settings >> Build, Execution, Deployment >> Docker - Select \"TCP socket\" - Enter 'unix:///var/run/docker.sock' under \"Engine API URL\"","title":"Launch docker compose"},{"location":"kafka/LAUNCH_DOCKER_COMPOSE/#1-how-to-run","text":"In this section we explain all the useful information that we can use when working in our local environment. In order to raise our system we will have to go to the root folder of our system and launch the following command docker-compose up This will launch our system by creating a local docker image and deploying our fetcher. It is important to keep in mind that this process launches a multitude of requests against the production environment and it is important to limit them all so as not to overload the system. To facilitate the work in local we also have several local configurations that allow us to test step by step our application avoiding possible problems of launching too many requests. To launch this configuration in Intellij you will need to verify that the following steps were done: - Go to Settings >> Build, Execution, Deployment >> Docker - Select \"TCP socket\" - Enter 'unix:///var/run/docker.sock' under \"Engine API URL\"","title":"1. How to run"},{"location":"lambda/PARAMETER_REPLICATOR/","text":"1. Summary Parameter Store is a capability of AWS Systems Manager that provides secure, hierarchical storage for configuration data management and secrets management. This service is only available in the region where is deployed. We use it to set configuration of Automation-Engine app. But if a disaster occurs in the main region we need to have the parameters replicated en the stand-by region to redeploy the app. Parameter-replicator is a python lambda that replicate parameters from one region to another. If any parameter change, that change will be replicated in the other region, by this way we have a configuration ready to run the application in the mirror region. This lambda also run ones a day to create a parameter backup and store in S3. 1. Diagram parameter-replicator.drawio.svg","title":"PARAMETER REPLICATOR"},{"location":"lambda/PARAMETER_REPLICATOR/#1-summary","text":"Parameter Store is a capability of AWS Systems Manager that provides secure, hierarchical storage for configuration data management and secrets management. This service is only available in the region where is deployed. We use it to set configuration of Automation-Engine app. But if a disaster occurs in the main region we need to have the parameters replicated en the stand-by region to redeploy the app. Parameter-replicator is a python lambda that replicate parameters from one region to another. If any parameter change, that change will be replicated in the other region, by this way we have a configuration ready to run the application in the mirror region. This lambda also run ones a day to create a parameter backup and store in S3.","title":"1. Summary"},{"location":"lambda/PARAMETER_REPLICATOR/#1-diagram","text":"parameter-replicator.drawio.svg","title":"1. Diagram"},{"location":"lambda/ssm_backups/","text":"1. Summary We utilize the boto3 library to get the data from the parameter store. We utilize the describe_parameters function to get all the data from the Parameter store. Since the max size of the response is 50 items we need to loop a couple times calling describe_parameters . describe_parameters provides all the necessary data related to the parameter from the parameter store EXCEPT the value. In order to get the unencrypted value we need to call get_parameter for each parameter gotten from describe_parameters response. Once we have all the data for each parameter, we take each parameter name and value and place it in a dictionary with name being the key and the value being the value of that dictionary. We then format that dictionary in a file (ssm_backups.txt) looking something like: ssm_backups.txt some_parameter_name:12 ... ... Then we need to store that file in an aws s3 bucket using the boto3 function upload_file 2. Diagram","title":"1. Summary"},{"location":"lambda/ssm_backups/#1-summary","text":"We utilize the boto3 library to get the data from the parameter store. We utilize the describe_parameters function to get all the data from the Parameter store. Since the max size of the response is 50 items we need to loop a couple times calling describe_parameters . describe_parameters provides all the necessary data related to the parameter from the parameter store EXCEPT the value. In order to get the unencrypted value we need to call get_parameter for each parameter gotten from describe_parameters response. Once we have all the data for each parameter, we take each parameter name and value and place it in a dictionary with name being the key and the value being the value of that dictionary. We then format that dictionary in a file (ssm_backups.txt) looking something like:","title":"1. Summary"},{"location":"lambda/ssm_backups/#ssm_backupstxt","text":"some_parameter_name:12 ... ... Then we need to store that file in an aws s3 bucket using the boto3 function upload_file","title":"ssm_backups.txt"},{"location":"lambda/ssm_backups/#2-diagram","text":"","title":"2. Diagram"},{"location":"logging/","text":"","title":"Index"},{"location":"logging/events/0-messages-bus/","text":"Messages Bus Event Logging Description The messages bus is the central piece of communication between the services living in the Automation system. Services can talk to each other by publishing messages to subjects. When a service has interest on a particular subject, any messages published to that subject will be consumed by it. The bus provides two communication models for these services: Publish / Subscribe (a.k.a. PUB / SUB). As hinted above, a service publishes a message to a subject which is later consumed by another service with interest in that subject. Request / Reply. In this case, a service asks for data by publishing a message to a subject which is later consumed by another service with interest in that subject. This is pretty much a PUB/SUB flow. The difference here, however, is that the consumer of the message will reply with a response to the requestor. The requestor takes care of consuming that response message once it gets it. Since the messages bus won't allow publishing messages larger than 1MB+, and if necessary, all services take care of storing them to a temporary storage so consumers can restore the original message on their end. Process Workflows List of Decisions made by the Messages Bus PUB-SUB workflow Condition Decision Decision 1 Check for message size before publishing it Message is too large for the message bus to handle (1MB+) Message is small enough for the message bus to handle (<1MB) REQUEST-REPLY workflow Requestor Condition Decision Decision 1 Check for request message size before publishing it Message is too large for the message bus to handle (1MB+) Message is small enough for the message bus to handle (<1MB) 2 Check for response message size before consuming it Message has a token representing a large message (1MB+) Message doesn't have a token representing a large message (1MB+) Replier Condition Decision Decision 1 Check for request message size before consuming it Message has a token representing a large message (1MB+) Message doesn't have a token representing a large message (1MB+) 2 Check for response message size before publishing it Message is too large for the message bus to handle (1MB+) Message is small enough for the message bus to handle (<1MB) Event Descriptions Python 3.10 utils Connect to messages bus connect Subscribe to subject subscribe PUB/SUB workflow publish REQUEST/REPLY workflow request Python 3.6 utils Connect to messages bus connect Subscribe to subject subscribe_consumer PUB/SUB workflow publish_message REQUEST/REPLY workflow rpc_request","title":"Messages Bus Event Logging"},{"location":"logging/events/0-messages-bus/#messages-bus-event-logging","text":"","title":"Messages Bus Event Logging"},{"location":"logging/events/0-messages-bus/#description","text":"The messages bus is the central piece of communication between the services living in the Automation system. Services can talk to each other by publishing messages to subjects. When a service has interest on a particular subject, any messages published to that subject will be consumed by it. The bus provides two communication models for these services: Publish / Subscribe (a.k.a. PUB / SUB). As hinted above, a service publishes a message to a subject which is later consumed by another service with interest in that subject. Request / Reply. In this case, a service asks for data by publishing a message to a subject which is later consumed by another service with interest in that subject. This is pretty much a PUB/SUB flow. The difference here, however, is that the consumer of the message will reply with a response to the requestor. The requestor takes care of consuming that response message once it gets it. Since the messages bus won't allow publishing messages larger than 1MB+, and if necessary, all services take care of storing them to a temporary storage so consumers can restore the original message on their end.","title":"Description"},{"location":"logging/events/0-messages-bus/#process-workflows","text":"","title":"Process Workflows"},{"location":"logging/events/0-messages-bus/#list-of-decisions-made-by-the-messages-bus","text":"","title":"List of Decisions made by the Messages Bus"},{"location":"logging/events/0-messages-bus/#pub-sub-workflow","text":"Condition Decision Decision 1 Check for message size before publishing it Message is too large for the message bus to handle (1MB+) Message is small enough for the message bus to handle (<1MB)","title":"PUB-SUB workflow"},{"location":"logging/events/0-messages-bus/#request-reply-workflow","text":"","title":"REQUEST-REPLY workflow"},{"location":"logging/events/0-messages-bus/#requestor","text":"Condition Decision Decision 1 Check for request message size before publishing it Message is too large for the message bus to handle (1MB+) Message is small enough for the message bus to handle (<1MB) 2 Check for response message size before consuming it Message has a token representing a large message (1MB+) Message doesn't have a token representing a large message (1MB+)","title":"Requestor"},{"location":"logging/events/0-messages-bus/#replier","text":"Condition Decision Decision 1 Check for request message size before consuming it Message has a token representing a large message (1MB+) Message doesn't have a token representing a large message (1MB+) 2 Check for response message size before publishing it Message is too large for the message bus to handle (1MB+) Message is small enough for the message bus to handle (<1MB)","title":"Replier"},{"location":"logging/events/0-messages-bus/#event-descriptions","text":"","title":"Event Descriptions"},{"location":"logging/events/0-messages-bus/#python-310-utils","text":"","title":"Python 3.10 utils"},{"location":"logging/events/0-messages-bus/#connect-to-messages-bus","text":"connect","title":"Connect to messages bus"},{"location":"logging/events/0-messages-bus/#subscribe-to-subject","text":"subscribe","title":"Subscribe to subject"},{"location":"logging/events/0-messages-bus/#pubsub-workflow","text":"publish","title":"PUB/SUB workflow"},{"location":"logging/events/0-messages-bus/#requestreply-workflow","text":"request","title":"REQUEST/REPLY workflow"},{"location":"logging/events/0-messages-bus/#python-36-utils","text":"","title":"Python 3.6 utils"},{"location":"logging/events/0-messages-bus/#connect-to-messages-bus_1","text":"connect","title":"Connect to messages bus"},{"location":"logging/events/0-messages-bus/#subscribe-to-subject_1","text":"subscribe_consumer","title":"Subscribe to subject"},{"location":"logging/events/0-messages-bus/#pubsub-workflow_1","text":"publish_message","title":"PUB/SUB workflow"},{"location":"logging/events/0-messages-bus/#requestreply-workflow_1","text":"rpc_request","title":"REQUEST/REPLY workflow"},{"location":"logging/events/1-service-outage/","text":"IPA Event Logging Process Workflows List of Decisions made by the IPA System Service Outage Start of Service Outage process 1. Checking edge & link status for outage Outage is detected Outage is not detected Autoresolution 2. Checking for non-resolved task for Service Outage ticket A non-resolved task exists for the SD-WAN on a Service Outage ticket No non-resolved task exists for the SD-WAN 3. Checking for time at impacted site Time at impacted site is between 12am and 6am (NIGHT) Time at impacted site is between 6am and 12am (DAY) 4. Checking if time passed is more or less than 3 hrs More than 3 hours has passed since an outage was documented Less than 3 hours has passed since an outage was documented 5. Checking if time passed is more or less than 90 mins More than 90 mins has passed since an outage was documented Less than 90 mins has passed since an outage was documented 6. Checking how mamy time ticket has been autoresolved Ticket has been autoresolved less than 3 times Ticket has been autoresolved more than 3 times Ticket Creation 7. Checking the results of ticket creation attempt New ticket is created with a task for the SD-WAN and placed in an IPA queue Ticket already exists for the location 8. Determining what to do with an already existing ticket New task for SD-WAN is added to ticket SD-WAN task on existing ticket for is reopened In-progress tasks for SD-WAN already exists IPA queue 9. What type of Outage was caused Outage Detected is an EDGE DOWN Outage Detected is a LINK DOWN 10. Checking time at impacted site Time at impacted site is between 12am and 6am (NIGHT) Time at impacted site is between 6am and 12am (DAY) DiGi Reboot 11. Are there any DiGi links Edge has at least one offline DiGi link Edge has no offline DiGi links 12. Has a DiGi reboot been attempted DiGi reboot has not been attempted yet DiGi reboot has been attempted 13. Has the DiGi reboot attempt occur after 30 mins 30 min has passed since reboot started 30 min has not passed since reboot started Event Descriptions Service Outage start_service_outage_monitoring","title":"IPA Event Logging"},{"location":"logging/events/1-service-outage/#ipa-event-logging","text":"","title":"IPA Event Logging"},{"location":"logging/events/1-service-outage/#process-workflows","text":"","title":"Process Workflows"},{"location":"logging/events/1-service-outage/#list-of-decisions-made-by-the-ipa-system","text":"","title":"List of Decisions made by the IPA System"},{"location":"logging/events/1-service-outage/#service-outage","text":"","title":"Service Outage"},{"location":"logging/events/1-service-outage/#start-of-service-outage-process","text":"1. Checking edge & link status for outage Outage is detected Outage is not detected","title":"Start of Service Outage process"},{"location":"logging/events/1-service-outage/#autoresolution","text":"2. Checking for non-resolved task for Service Outage ticket A non-resolved task exists for the SD-WAN on a Service Outage ticket No non-resolved task exists for the SD-WAN 3. Checking for time at impacted site Time at impacted site is between 12am and 6am (NIGHT) Time at impacted site is between 6am and 12am (DAY) 4. Checking if time passed is more or less than 3 hrs More than 3 hours has passed since an outage was documented Less than 3 hours has passed since an outage was documented 5. Checking if time passed is more or less than 90 mins More than 90 mins has passed since an outage was documented Less than 90 mins has passed since an outage was documented 6. Checking how mamy time ticket has been autoresolved Ticket has been autoresolved less than 3 times Ticket has been autoresolved more than 3 times","title":"Autoresolution"},{"location":"logging/events/1-service-outage/#ticket-creation","text":"7. Checking the results of ticket creation attempt New ticket is created with a task for the SD-WAN and placed in an IPA queue Ticket already exists for the location 8. Determining what to do with an already existing ticket New task for SD-WAN is added to ticket SD-WAN task on existing ticket for is reopened In-progress tasks for SD-WAN already exists","title":"Ticket Creation"},{"location":"logging/events/1-service-outage/#ipa-queue","text":"9. What type of Outage was caused Outage Detected is an EDGE DOWN Outage Detected is a LINK DOWN 10. Checking time at impacted site Time at impacted site is between 12am and 6am (NIGHT) Time at impacted site is between 6am and 12am (DAY)","title":"IPA queue"},{"location":"logging/events/1-service-outage/#digi-reboot","text":"11. Are there any DiGi links Edge has at least one offline DiGi link Edge has no offline DiGi links 12. Has a DiGi reboot been attempted DiGi reboot has not been attempted yet DiGi reboot has been attempted 13. Has the DiGi reboot attempt occur after 30 mins 30 min has passed since reboot started 30 min has not passed since reboot started","title":"DiGi Reboot"},{"location":"logging/events/1-service-outage/#event-descriptions","text":"","title":"Event Descriptions"},{"location":"logging/events/1-service-outage/#service-outage_1","text":"start_service_outage_monitoring","title":"Service Outage"},{"location":"logging/events/10-hawkeye-outage-monitor/","text":"Hawkeye Outage Monitor Event Logging Description The Hawkeye Outage Monitor service is responsible for monitoring Ixia devices periodically. The monitoring process makes sure to create or re-open Service Outage tickets if these devices stay offline for some time, and it also takes care of auto-resolving any open tickets if the device comes back online. Process Workflows List of Decisions made by the Hawkeye Outage Monitor service Overall workflow Condition Decision Decision 1 Check for the status of Ixia devices Node to Node AND Real Service status are both 1 (Online) Node to Node OR Real Service status are 0 (Offline) 2 Check for the status of Ixia devices after sitting in the quarantine for some time Node to Node AND Real Service status are both 1 (Online) Node to Node OR Real Service status are still 0 (Offline) Workflow - Prepare data set for analysis Condition Decision Decision 1 Check for activity status of Ixia devices Any device is active None of the devices is currently active Workflow - Auto-Resolution Condition Decision Decision 1 Check for existing open Service Outage ticket for the Ixia device Open ticket found No open tickets found 2 Check for creator of the open ticket Ticket was created by the IPA system Ticket was NOT created by the IPA system 3 Check if the last outage was documented long time ago Less than 90 min have passed since the last outage was documented More than 90 min have passed since the last outage was documented 4 Check if the number of auto-resolves allowed for the ticket task has been maxed out already Ticket task linked to the device has been auto-resolved less than 3 times Ticket task linked to the device has been auto-resolved 3 times or more 5 Check if the ticket task linked to the Ixia device is already resolved Ticket task linked to the device is NOT resolved Ticket task linked to the device is already resolved Workflow - Ticket Creation / Task Re-Open Condition Decision Decision Decision Decision Decision 1 Check the status returned by Bruin after trying to create a ticket for the Ixia device Ticket was created (Bruin status 200) Ticket with open task already exists for the device (Bruin status 409) Ticket with Resolved task exists for the device, but Bruin couldn't re-open it automatically (Bruin status 471) Ticket with Resolved task exists for the device, and was automatically re-opened by Bruin (Bruin status 472) Resolved ticket exists for the device and site (physical location) - a new task was automatically added by Bruin (Bruin status 473) 2 Check if there's a Triage note appended for a task belonging to an existing open ticket Ticket task linked to the device has NOT a Triage note appended Ticket task linked to the device already has a Triage note appended Event Descriptions Schedule Hawkeye Outage Monitoring job start_hawkeye_outage_monitoring Run Hawkeye Outage Monitoring job _outage_monitoring_process","title":"Hawkeye Outage Monitor Event Logging"},{"location":"logging/events/10-hawkeye-outage-monitor/#hawkeye-outage-monitor-event-logging","text":"","title":"Hawkeye Outage Monitor Event Logging"},{"location":"logging/events/10-hawkeye-outage-monitor/#description","text":"The Hawkeye Outage Monitor service is responsible for monitoring Ixia devices periodically. The monitoring process makes sure to create or re-open Service Outage tickets if these devices stay offline for some time, and it also takes care of auto-resolving any open tickets if the device comes back online.","title":"Description"},{"location":"logging/events/10-hawkeye-outage-monitor/#process-workflows","text":"","title":"Process Workflows"},{"location":"logging/events/10-hawkeye-outage-monitor/#list-of-decisions-made-by-the-hawkeye-outage-monitor-service","text":"","title":"List of Decisions made by the Hawkeye Outage Monitor service"},{"location":"logging/events/10-hawkeye-outage-monitor/#overall-workflow","text":"Condition Decision Decision 1 Check for the status of Ixia devices Node to Node AND Real Service status are both 1 (Online) Node to Node OR Real Service status are 0 (Offline) 2 Check for the status of Ixia devices after sitting in the quarantine for some time Node to Node AND Real Service status are both 1 (Online) Node to Node OR Real Service status are still 0 (Offline)","title":"Overall workflow"},{"location":"logging/events/10-hawkeye-outage-monitor/#workflow-prepare-data-set-for-analysis","text":"Condition Decision Decision 1 Check for activity status of Ixia devices Any device is active None of the devices is currently active","title":"Workflow - Prepare data set for analysis"},{"location":"logging/events/10-hawkeye-outage-monitor/#workflow-auto-resolution","text":"Condition Decision Decision 1 Check for existing open Service Outage ticket for the Ixia device Open ticket found No open tickets found 2 Check for creator of the open ticket Ticket was created by the IPA system Ticket was NOT created by the IPA system 3 Check if the last outage was documented long time ago Less than 90 min have passed since the last outage was documented More than 90 min have passed since the last outage was documented 4 Check if the number of auto-resolves allowed for the ticket task has been maxed out already Ticket task linked to the device has been auto-resolved less than 3 times Ticket task linked to the device has been auto-resolved 3 times or more 5 Check if the ticket task linked to the Ixia device is already resolved Ticket task linked to the device is NOT resolved Ticket task linked to the device is already resolved","title":"Workflow - Auto-Resolution"},{"location":"logging/events/10-hawkeye-outage-monitor/#workflow-ticket-creation-task-re-open","text":"Condition Decision Decision Decision Decision Decision 1 Check the status returned by Bruin after trying to create a ticket for the Ixia device Ticket was created (Bruin status 200) Ticket with open task already exists for the device (Bruin status 409) Ticket with Resolved task exists for the device, but Bruin couldn't re-open it automatically (Bruin status 471) Ticket with Resolved task exists for the device, and was automatically re-opened by Bruin (Bruin status 472) Resolved ticket exists for the device and site (physical location) - a new task was automatically added by Bruin (Bruin status 473) 2 Check if there's a Triage note appended for a task belonging to an existing open ticket Ticket task linked to the device has NOT a Triage note appended Ticket task linked to the device already has a Triage note appended","title":"Workflow - Ticket Creation / Task Re-Open"},{"location":"logging/events/10-hawkeye-outage-monitor/#event-descriptions","text":"","title":"Event Descriptions"},{"location":"logging/events/10-hawkeye-outage-monitor/#schedule-hawkeye-outage-monitoring-job","text":"start_hawkeye_outage_monitoring","title":"Schedule Hawkeye Outage Monitoring job"},{"location":"logging/events/10-hawkeye-outage-monitor/#run-hawkeye-outage-monitoring-job","text":"_outage_monitoring_process","title":"Run Hawkeye Outage Monitoring job"},{"location":"logging/events/11-bruin-bridge/","text":"Bruin Bridge Event Logging Description The mission of this service is to act as a proxy to the Bruin API. It accepts requests from other services and yields the requested data back to those services so they can make the appropriate business decision. Process Workflows List of Decisions made by the Bruin Bridge Subject: bruin.ticket.request (aims at endpoint GET /api/Ticket ) Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from GET /api/Ticket HTTP response has status 200 HTTP response has NOT status 200 Subject: bruin.ticket.basic.request (aims at endpoint GET /api/Ticket/basic ) Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from GET /api/Ticket/basic HTTP response has status 200 HTTP response has NOT status 200 Subject: bruin.get.site (aims at endpoint GET /api/Site ) Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from GET /api/Site HTTP response has status 200 HTTP response has NOT status 200 3 Check for existence of site's data Site info was found for filters Site info was NOT found for filters Subject: bruin.change.ticket.severity (aims at endpoint PUT /api/Ticket/{ticketId}/severity ) Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from PUT /api/Ticket/{ticketId}/severity HTTP response has status 200 HTTP response has NOT status 200 Subject: bruin.single.basic.request (aims at endpoint GET /api/Ticket/basic ) Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from GET /api/Ticket/basic HTTP response has status 200 HTTP response has NOT status 200 Subject: bruin.ticket.detail.request (aims at endpoint GET /api/Ticket/{ticket_id}/details ) Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from GET /api/Ticket/{ticket_id}/details HTTP response has status 200 HTTP response has NOT status 200 Subject: bruin.ticket.note.append.request (aims at endpoint POST /api/Ticket/{ticket_id}/notes ) Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from POST /api/Ticket/{ticket_id}/notes HTTP response has status 200 HTTP response has NOT status 200 Subject: bruin.ticket.multiple.note.append.request (aims at endpoint POST /api/Ticket/{ticket_id}/notes/advanced ) Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from POST /api/Ticket/{ticket_id}/notes/advanced HTTP response has status 200 HTTP response has NOT status 200 Subject: bruin.ticket.creation.request (aims at endpoint POST /api/Ticket/ ) Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from POST /api/Ticket/ HTTP response has status 200 HTTP response has NOT status 200 Subject: bruin.ticket.status.open (aims at endpoint PUT /api/Ticket/{ticket_id}/details/{detail_id}/status ) Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from PUT /api/Ticket/{ticket_id}/details/{detail_id}/status HTTP response has status 200 HTTP response has NOT status 200 Subject: bruin.ticket.status.resolve (aims at endpoint PUT /api/Ticket/{ticket_id}/details/{detail_id}/status ) Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from PUT /api/Ticket/{ticket_id}/details/{detail_id}/status HTTP response has status 200 HTTP response has NOT status 200 Subject: bruin.inventory.attributes.serial (aims at endpoint GET /api/Inventory/Attribute ) Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from GET /api/Inventory/Attribute HTTP response has status 200 HTTP response has NOT status 200 3 Check for existence of serial number in attributes response Serial number is found Serial number is NOT found Subject: bruin.inventory.attributes.serial (aims at endpoint GET /api/Inventory/Attribute ) Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from GET /api/Inventory/Attribute HTTP response has status 200 HTTP response has NOT status 200 3 Check for existence of serial number in attributes response Serial number is found Serial number is NOT found Subject: bruin.inventory.management.status (aims at endpoint GET /api/Inventory/Attribute ) Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from PUT /api/Inventory/Attribute HTTP response has status 200 HTTP response has NOT status 200 3 Check for existence of Management Status in attributes response Management Status is found Management Status is NOT found Subject: bruin.ticket.creation.outage.request (aims at endpoint POST /api/Ticket/repair ) Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from POST /api/Ticket/repair HTTP response has status 200 HTTP response has NOT status 200 Condition Decision Decision Decision Decision Decision 3 Check errorCode field of a HTTP response that has a status 200 errorCode is not 409, 471, 472, or 473 errorCode is 409 errorCode is 471 errorCode is 472 errorCode is 473 Subject: bruin.customer.get.info (aims at endpoint GET /api/Inventory ) Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from GET /api/Inventory HTTP response has status 200 HTTP response has NOT status 200 Subject: bruin.customer.get.info_by_did (aims at endpoint GET /api/Inventory/phoneNumber/Lines ) Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from GET /api/Inventory/phoneNumber/Lines HTTP response has status 200 HTTP response has NOT status 200 Subject: bruin.ticket.change.work (aims at endpoint GET /api/Ticket/{ticket_id}/nextresult and PUT /api/Ticket/{ticket_id}/details/work ) Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format Condition Decision Decision Decision Decision Decision 2 Check for status and work queues' existence of response from GET api/Ticket/{ticket_id}/nextresult Work queue exists Ticket Id is already in that work queue No possible work queue exists No possible work queue exists with work queue name HTTP response has NOT status 200 Condition Decision Decision 3 Check for status of response from /api/Ticket/{ticket_id}/details/work HTTP response has status 200 HTTP response has NOT status 200 Subject: bruin.ticket.get.task.history (aims at endpoint GET /api/Ticket/AITicketData ) Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from GET /api/Ticket/AITicketData HTTP response has status 200 HTTP response has NOT status 200 Subject: bruin.ticket.detail.get.next.result (aims at endpoint GET /api/Ticket/{ticket_id}/nextresult ) Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from GET /api/Ticket/{ticket_id}/nextresult HTTP response has status 200 HTTP response has NOT status 200 Subject: bruin.ticket.unpause (aims at endpoint POST /api/Ticket/{ticket_id}/detail/unpause ) Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from POST /api/Ticket/{ticket_id}/detail/unpause HTTP response has status 200 HTTP response has NOT status 200 Subject: bruin.email.tag.request (aims at endpoint POST api/Email/{email_id}/tag/{tag_id} ) Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from POST api/Email/{email_id}/tag/{tag_id} HTTP response has status 200 HTTP response has NOT status 200 Subject: bruin.get.circuit.id (aims at endpoint GET /api/Inventory/circuit ) Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from GET /api/Inventory/circuit HTTP response has status 200 HTTP response has NOT status 200 Subject: bruin.get.circuit.id (aims at endpoint GET /api/Inventory/circuit ) Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from GET /api/Inventory/circuit HTTP response has status 200 HTTP response has NOT status 200 Subject: bruin.mark.email.done (aims at endpoint POST /api/Email/status ) Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from POST /api/Email/status HTTP response has status 200 HTTP response has NOT status 200 3 Check for existence of success field success field exists success field does NOT exists Subject: bruin.link.ticket.email (aims at endpoint POST /api/Email/{email_id}/link/ticket/{ticket_id} ) Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from POST /api/Email/{email_id}/link/ticket/{ticket_id} HTTP response has status 200 HTTP response has NOT status 200 3 Check for existence of success field success field exists success field does NOT exists Subject: bruin.notification.email.milestone (aims at endpoint POST /api/Notification/email/milestone ) Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from POST /api/Notification/email/milestone HTTP response has status 200 HTTP response has NOT status 200 Subject: bruin.get.asset.topics (aims at endpoint GET /api/Ticket/topics ) Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from GET /api/Ticket/topics HTTP response has status 200 HTTP response has NOT status 200 Subject: bruin.subscribe.user (aims at endpoint POST /api/Ticket/{ticket_id}/subscribeUser ) Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from POST /api/Ticket/{ticket_id}/subscribeUser HTTP response has status 200 HTTP response has NOT status 200 Subject: bruin.email.status (aims at endpoint POST /api/Email/status ) Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from POST /api/Email/status HTTP response has status 200 HTTP response has NOT status 200 Subject: bruin.email.reply (aims at endpoint GET /api/Notification/email/ReplyAll ) Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from GET /api/Notification/email/ReplyAll HTTP response has status 200 HTTP response has NOT status 200 Event Descriptions Subject: bruin.ticket.request get_tickets Subject: bruin.ticket.basic.request get_tickets_basic_info Subject: bruin.get.site get_site Subject: bruin.change.ticket.severity change_ticket_severity Subject: bruin.single_ticket.basic.request get_single_ticket_basic_info Subject: bruin.ticket.details.request get_ticket_details Subject: bruin.ticket.overview.request get_ticket_overview Subject: bruin.ticket.note.append.request post_note Subject: bruin.ticket.multiple.notes.append.request post_multiple_note Subject: bruin.ticket.creation.request post_ticket Subject: bruin.ticket.status.open open_ticket Subject: bruin.ticket.status.resolve resolve_ticket Subject: bruin.inventory.attributes.serial get_attributes_serial Subject: bruin.inventory.management.status get_management_status Subject: bruin.ticket.creation.outage.request post_outage_ticket Subject: bruin.customer.get.info get_client_info Subject: bruin.customer.get.info_by_did get_client_info_by_did Subject: bruin.ticket.change.work change_detail_work_queue Subject: bruin.ticket.get.task.history get_ticket_task_history Subject: bruin.ticket.detail.get.next.results get_next_results_for_ticket_details Subject: bruin.ticket.unpause unpause_ticket Subject: bruin.email.tag.request post_email_tag Subject: bruin.get.circuit.id get_circuit_id Subject: bruin.mark.email.done mark_email_as_done Subject: bruin.link.ticket.email link_ticket_to_email Subject: bruin.notification.email.milestone post_notification_email_milestone Subject: bruin.get.asset.topics get_asset_topics Subject: bruin.subscribe.user subscribe_user Subject: bruin.email.status post_email_status Subject: bruin.email.reply post_email_reply","title":"Bruin Bridge Event Logging"},{"location":"logging/events/11-bruin-bridge/#bruin-bridge-event-logging","text":"","title":"Bruin Bridge Event Logging"},{"location":"logging/events/11-bruin-bridge/#description","text":"The mission of this service is to act as a proxy to the Bruin API. It accepts requests from other services and yields the requested data back to those services so they can make the appropriate business decision.","title":"Description"},{"location":"logging/events/11-bruin-bridge/#process-workflows","text":"","title":"Process Workflows"},{"location":"logging/events/11-bruin-bridge/#list-of-decisions-made-by-the-bruin-bridge","text":"","title":"List of Decisions made by the Bruin Bridge"},{"location":"logging/events/11-bruin-bridge/#subject-bruinticketrequest-aims-at-endpoint-get-apiticket","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from GET /api/Ticket HTTP response has status 200 HTTP response has NOT status 200","title":"Subject: bruin.ticket.request (aims at endpoint GET /api/Ticket)"},{"location":"logging/events/11-bruin-bridge/#subject-bruinticketbasicrequest-aims-at-endpoint-get-apiticketbasic","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from GET /api/Ticket/basic HTTP response has status 200 HTTP response has NOT status 200","title":"Subject: bruin.ticket.basic.request (aims at endpoint GET /api/Ticket/basic)"},{"location":"logging/events/11-bruin-bridge/#subject-bruingetsite-aims-at-endpoint-get-apisite","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from GET /api/Site HTTP response has status 200 HTTP response has NOT status 200 3 Check for existence of site's data Site info was found for filters Site info was NOT found for filters","title":"Subject: bruin.get.site (aims at endpoint GET /api/Site)"},{"location":"logging/events/11-bruin-bridge/#subject-bruinchangeticketseverity-aims-at-endpoint-put-apiticketticketidseverity","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from PUT /api/Ticket/{ticketId}/severity HTTP response has status 200 HTTP response has NOT status 200","title":"Subject: bruin.change.ticket.severity (aims at endpoint PUT /api/Ticket/{ticketId}/severity)"},{"location":"logging/events/11-bruin-bridge/#subject-bruinsinglebasicrequest-aims-at-endpoint-get-apiticketbasic","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from GET /api/Ticket/basic HTTP response has status 200 HTTP response has NOT status 200","title":"Subject: bruin.single.basic.request (aims at endpoint GET /api/Ticket/basic)"},{"location":"logging/events/11-bruin-bridge/#subject-bruinticketdetailrequest-aims-at-endpoint-get-apiticketticket_iddetails","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from GET /api/Ticket/{ticket_id}/details HTTP response has status 200 HTTP response has NOT status 200","title":"Subject: bruin.ticket.detail.request (aims at endpoint GET /api/Ticket/{ticket_id}/details)"},{"location":"logging/events/11-bruin-bridge/#subject-bruinticketnoteappendrequest-aims-at-endpoint-post-apiticketticket_idnotes","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from POST /api/Ticket/{ticket_id}/notes HTTP response has status 200 HTTP response has NOT status 200","title":"Subject: bruin.ticket.note.append.request (aims at endpoint POST /api/Ticket/{ticket_id}/notes)"},{"location":"logging/events/11-bruin-bridge/#subject-bruinticketmultiplenoteappendrequest-aims-at-endpoint-post-apiticketticket_idnotesadvanced","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from POST /api/Ticket/{ticket_id}/notes/advanced HTTP response has status 200 HTTP response has NOT status 200","title":"Subject: bruin.ticket.multiple.note.append.request (aims at endpoint POST /api/Ticket/{ticket_id}/notes/advanced)"},{"location":"logging/events/11-bruin-bridge/#subject-bruinticketcreationrequest-aims-at-endpoint-post-apiticket","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from POST /api/Ticket/ HTTP response has status 200 HTTP response has NOT status 200","title":"Subject: bruin.ticket.creation.request (aims at endpoint POST /api/Ticket/)"},{"location":"logging/events/11-bruin-bridge/#subject-bruinticketstatusopen-aims-at-endpoint-put-apiticketticket_iddetailsdetail_idstatus","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from PUT /api/Ticket/{ticket_id}/details/{detail_id}/status HTTP response has status 200 HTTP response has NOT status 200","title":"Subject: bruin.ticket.status.open (aims at endpoint PUT /api/Ticket/{ticket_id}/details/{detail_id}/status)"},{"location":"logging/events/11-bruin-bridge/#subject-bruinticketstatusresolve-aims-at-endpoint-put-apiticketticket_iddetailsdetail_idstatus","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from PUT /api/Ticket/{ticket_id}/details/{detail_id}/status HTTP response has status 200 HTTP response has NOT status 200","title":"Subject: bruin.ticket.status.resolve (aims at endpoint PUT /api/Ticket/{ticket_id}/details/{detail_id}/status)"},{"location":"logging/events/11-bruin-bridge/#subject-bruininventoryattributesserial-aims-at-endpoint-get-apiinventoryattribute","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from GET /api/Inventory/Attribute HTTP response has status 200 HTTP response has NOT status 200 3 Check for existence of serial number in attributes response Serial number is found Serial number is NOT found","title":"Subject: bruin.inventory.attributes.serial (aims at endpoint GET /api/Inventory/Attribute)"},{"location":"logging/events/11-bruin-bridge/#subject-bruininventoryattributesserial-aims-at-endpoint-get-apiinventoryattribute_1","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from GET /api/Inventory/Attribute HTTP response has status 200 HTTP response has NOT status 200 3 Check for existence of serial number in attributes response Serial number is found Serial number is NOT found","title":"Subject: bruin.inventory.attributes.serial (aims at endpoint GET /api/Inventory/Attribute)"},{"location":"logging/events/11-bruin-bridge/#subject-bruininventorymanagementstatus-aims-at-endpoint-get-apiinventoryattribute","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from PUT /api/Inventory/Attribute HTTP response has status 200 HTTP response has NOT status 200 3 Check for existence of Management Status in attributes response Management Status is found Management Status is NOT found","title":"Subject: bruin.inventory.management.status (aims at endpoint GET /api/Inventory/Attribute)"},{"location":"logging/events/11-bruin-bridge/#subject-bruinticketcreationoutagerequest-aims-at-endpoint-post-apiticketrepair","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from POST /api/Ticket/repair HTTP response has status 200 HTTP response has NOT status 200 Condition Decision Decision Decision Decision Decision 3 Check errorCode field of a HTTP response that has a status 200 errorCode is not 409, 471, 472, or 473 errorCode is 409 errorCode is 471 errorCode is 472 errorCode is 473","title":"Subject: bruin.ticket.creation.outage.request (aims at endpoint POST /api/Ticket/repair)"},{"location":"logging/events/11-bruin-bridge/#subject-bruincustomergetinfo-aims-at-endpoint-get-apiinventory","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from GET /api/Inventory HTTP response has status 200 HTTP response has NOT status 200","title":"Subject: bruin.customer.get.info (aims at endpoint GET /api/Inventory)"},{"location":"logging/events/11-bruin-bridge/#subject-bruincustomergetinfo_by_did-aims-at-endpoint-get-apiinventoryphonenumberlines","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from GET /api/Inventory/phoneNumber/Lines HTTP response has status 200 HTTP response has NOT status 200","title":"Subject: bruin.customer.get.info_by_did (aims at endpoint GET /api/Inventory/phoneNumber/Lines)"},{"location":"logging/events/11-bruin-bridge/#subject-bruinticketchangework-aims-at-endpoint-get-apiticketticket_idnextresult-and-put-apiticketticket_iddetailswork","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format Condition Decision Decision Decision Decision Decision 2 Check for status and work queues' existence of response from GET api/Ticket/{ticket_id}/nextresult Work queue exists Ticket Id is already in that work queue No possible work queue exists No possible work queue exists with work queue name HTTP response has NOT status 200 Condition Decision Decision 3 Check for status of response from /api/Ticket/{ticket_id}/details/work HTTP response has status 200 HTTP response has NOT status 200","title":"Subject: bruin.ticket.change.work (aims at endpoint GET /api/Ticket/{ticket_id}/nextresult and PUT /api/Ticket/{ticket_id}/details/work)"},{"location":"logging/events/11-bruin-bridge/#subject-bruinticketgettaskhistory-aims-at-endpoint-get-apiticketaiticketdata","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from GET /api/Ticket/AITicketData HTTP response has status 200 HTTP response has NOT status 200","title":"Subject: bruin.ticket.get.task.history (aims at endpoint GET /api/Ticket/AITicketData)"},{"location":"logging/events/11-bruin-bridge/#subject-bruinticketdetailgetnextresult-aims-at-endpoint-get-apiticketticket_idnextresult","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from GET /api/Ticket/{ticket_id}/nextresult HTTP response has status 200 HTTP response has NOT status 200","title":"Subject: bruin.ticket.detail.get.next.result (aims at endpoint GET /api/Ticket/{ticket_id}/nextresult)"},{"location":"logging/events/11-bruin-bridge/#subject-bruinticketunpause-aims-at-endpoint-post-apiticketticket_iddetailunpause","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from POST /api/Ticket/{ticket_id}/detail/unpause HTTP response has status 200 HTTP response has NOT status 200","title":"Subject: bruin.ticket.unpause (aims at endpoint POST /api/Ticket/{ticket_id}/detail/unpause)"},{"location":"logging/events/11-bruin-bridge/#subject-bruinemailtagrequest-aims-at-endpoint-post-apiemailemail_idtagtag_id","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from POST api/Email/{email_id}/tag/{tag_id} HTTP response has status 200 HTTP response has NOT status 200","title":"Subject: bruin.email.tag.request (aims at endpoint POST api/Email/{email_id}/tag/{tag_id})"},{"location":"logging/events/11-bruin-bridge/#subject-bruingetcircuitid-aims-at-endpoint-get-apiinventorycircuit","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from GET /api/Inventory/circuit HTTP response has status 200 HTTP response has NOT status 200","title":"Subject: bruin.get.circuit.id (aims at endpoint GET /api/Inventory/circuit)"},{"location":"logging/events/11-bruin-bridge/#subject-bruingetcircuitid-aims-at-endpoint-get-apiinventorycircuit_1","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from GET /api/Inventory/circuit HTTP response has status 200 HTTP response has NOT status 200","title":"Subject: bruin.get.circuit.id (aims at endpoint GET /api/Inventory/circuit)"},{"location":"logging/events/11-bruin-bridge/#subject-bruinmarkemaildone-aims-at-endpoint-post-apiemailstatus","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from POST /api/Email/status HTTP response has status 200 HTTP response has NOT status 200 3 Check for existence of success field success field exists success field does NOT exists","title":"Subject: bruin.mark.email.done (aims at endpoint POST /api/Email/status)"},{"location":"logging/events/11-bruin-bridge/#subject-bruinlinkticketemail-aims-at-endpoint-post-apiemailemail_idlinkticketticket_id","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from POST /api/Email/{email_id}/link/ticket/{ticket_id} HTTP response has status 200 HTTP response has NOT status 200 3 Check for existence of success field success field exists success field does NOT exists","title":"Subject: bruin.link.ticket.email (aims at endpoint POST /api/Email/{email_id}/link/ticket/{ticket_id})"},{"location":"logging/events/11-bruin-bridge/#subject-bruinnotificationemailmilestone-aims-at-endpoint-post-apinotificationemailmilestone","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from POST /api/Notification/email/milestone HTTP response has status 200 HTTP response has NOT status 200","title":"Subject: bruin.notification.email.milestone (aims at endpoint POST /api/Notification/email/milestone)"},{"location":"logging/events/11-bruin-bridge/#subject-bruingetassettopics-aims-at-endpoint-get-apitickettopics","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from GET /api/Ticket/topics HTTP response has status 200 HTTP response has NOT status 200","title":"Subject: bruin.get.asset.topics (aims at endpoint GET /api/Ticket/topics)"},{"location":"logging/events/11-bruin-bridge/#subject-bruinsubscribeuser-aims-at-endpoint-post-apiticketticket_idsubscribeuser","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from POST /api/Ticket/{ticket_id}/subscribeUser HTTP response has status 200 HTTP response has NOT status 200","title":"Subject: bruin.subscribe.user (aims at endpoint POST /api/Ticket/{ticket_id}/subscribeUser)"},{"location":"logging/events/11-bruin-bridge/#subject-bruinemailstatus-aims-at-endpoint-post-apiemailstatus","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from POST /api/Email/status HTTP response has status 200 HTTP response has NOT status 200","title":"Subject: bruin.email.status (aims at endpoint POST /api/Email/status)"},{"location":"logging/events/11-bruin-bridge/#subject-bruinemailreply-aims-at-endpoint-get-apinotificationemailreplyall","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from GET /api/Notification/email/ReplyAll HTTP response has status 200 HTTP response has NOT status 200","title":"Subject: bruin.email.reply (aims at endpoint GET /api/Notification/email/ReplyAll)"},{"location":"logging/events/11-bruin-bridge/#event-descriptions","text":"","title":"Event Descriptions"},{"location":"logging/events/11-bruin-bridge/#subject-bruinticketrequest","text":"get_tickets","title":"Subject: bruin.ticket.request"},{"location":"logging/events/11-bruin-bridge/#subject-bruinticketbasicrequest","text":"get_tickets_basic_info","title":"Subject: bruin.ticket.basic.request"},{"location":"logging/events/11-bruin-bridge/#subject-bruingetsite","text":"get_site","title":"Subject: bruin.get.site"},{"location":"logging/events/11-bruin-bridge/#subject-bruinchangeticketseverity","text":"change_ticket_severity","title":"Subject: bruin.change.ticket.severity"},{"location":"logging/events/11-bruin-bridge/#subject-bruinsingle_ticketbasicrequest","text":"get_single_ticket_basic_info","title":"Subject: bruin.single_ticket.basic.request"},{"location":"logging/events/11-bruin-bridge/#subject-bruinticketdetailsrequest","text":"get_ticket_details","title":"Subject: bruin.ticket.details.request"},{"location":"logging/events/11-bruin-bridge/#subject-bruinticketoverviewrequest","text":"get_ticket_overview","title":"Subject: bruin.ticket.overview.request"},{"location":"logging/events/11-bruin-bridge/#subject-bruinticketnoteappendrequest","text":"post_note","title":"Subject: bruin.ticket.note.append.request"},{"location":"logging/events/11-bruin-bridge/#subject-bruinticketmultiplenotesappendrequest","text":"post_multiple_note","title":"Subject: bruin.ticket.multiple.notes.append.request"},{"location":"logging/events/11-bruin-bridge/#subject-bruinticketcreationrequest","text":"post_ticket","title":"Subject: bruin.ticket.creation.request"},{"location":"logging/events/11-bruin-bridge/#subject-bruinticketstatusopen","text":"open_ticket","title":"Subject: bruin.ticket.status.open"},{"location":"logging/events/11-bruin-bridge/#subject-bruinticketstatusresolve","text":"resolve_ticket","title":"Subject: bruin.ticket.status.resolve"},{"location":"logging/events/11-bruin-bridge/#subject-bruininventoryattributesserial","text":"get_attributes_serial","title":"Subject: bruin.inventory.attributes.serial"},{"location":"logging/events/11-bruin-bridge/#subject-bruininventorymanagementstatus","text":"get_management_status","title":"Subject: bruin.inventory.management.status"},{"location":"logging/events/11-bruin-bridge/#subject-bruinticketcreationoutagerequest","text":"post_outage_ticket","title":"Subject: bruin.ticket.creation.outage.request"},{"location":"logging/events/11-bruin-bridge/#subject-bruincustomergetinfo","text":"get_client_info","title":"Subject: bruin.customer.get.info"},{"location":"logging/events/11-bruin-bridge/#subject-bruincustomergetinfo_by_did","text":"get_client_info_by_did","title":"Subject: bruin.customer.get.info_by_did"},{"location":"logging/events/11-bruin-bridge/#subject-bruinticketchangework","text":"change_detail_work_queue","title":"Subject: bruin.ticket.change.work"},{"location":"logging/events/11-bruin-bridge/#subject-bruinticketgettaskhistory","text":"get_ticket_task_history","title":"Subject: bruin.ticket.get.task.history"},{"location":"logging/events/11-bruin-bridge/#subject-bruinticketdetailgetnextresults","text":"get_next_results_for_ticket_details","title":"Subject: bruin.ticket.detail.get.next.results"},{"location":"logging/events/11-bruin-bridge/#subject-bruinticketunpause","text":"unpause_ticket","title":"Subject: bruin.ticket.unpause"},{"location":"logging/events/11-bruin-bridge/#subject-bruinemailtagrequest","text":"post_email_tag","title":"Subject: bruin.email.tag.request"},{"location":"logging/events/11-bruin-bridge/#subject-bruingetcircuitid","text":"get_circuit_id","title":"Subject: bruin.get.circuit.id"},{"location":"logging/events/11-bruin-bridge/#subject-bruinmarkemaildone","text":"mark_email_as_done","title":"Subject: bruin.mark.email.done"},{"location":"logging/events/11-bruin-bridge/#subject-bruinlinkticketemail","text":"link_ticket_to_email","title":"Subject: bruin.link.ticket.email"},{"location":"logging/events/11-bruin-bridge/#subject-bruinnotificationemailmilestone","text":"post_notification_email_milestone","title":"Subject: bruin.notification.email.milestone"},{"location":"logging/events/11-bruin-bridge/#subject-bruingetassettopics","text":"get_asset_topics","title":"Subject: bruin.get.asset.topics"},{"location":"logging/events/11-bruin-bridge/#subject-bruinsubscribeuser","text":"subscribe_user","title":"Subject: bruin.subscribe.user"},{"location":"logging/events/11-bruin-bridge/#subject-bruinemailstatus","text":"post_email_status","title":"Subject: bruin.email.status"},{"location":"logging/events/11-bruin-bridge/#subject-bruinemailreply","text":"post_email_reply","title":"Subject: bruin.email.reply"},{"location":"logging/events/12-velocloud-bridge/","text":"VeloCloud Bridge Event Logging Description The mission of this service is to act as a proxy to the VeloCloud API. It accepts requests from other services and yields the requested data back to those services, so they can make the appropriate business decision. Process Workflows List of Decisions made by the VeloCloud Bridge Subject: alert.request.event.edge (aims at endpoint POST /event/getEnterpriseEvents ) Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from POST /event/getEnterpriseEvents HTTP response has status 200 HTTP response has NOT status 200 Subject: request.enterprises.edges (aims at endpoint POST /enterprise/getEnterpriseEdges ) Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from POST /enterprise/getEnterpriseEdges HTTP response has status 200 HTTP response has NOT status 200 Subject: alert.request.event.enterprise (aims at endpoint POST /event/getEnterpriseEvents ) Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from POST /event/getEnterpriseEvents HTTP response has status 200 HTTP response has NOT status 200 Subject: request.enterprises.names (aims at endpoint POST /monitoring/getAggregates ) Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from POST /monitoring/getAggregates HTTP response has status 200 HTTP response has NOT status 200 Subject: request.edge.links.series (aims at endpoint POST /metrics/getEdgeLinkSeries ) Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from POST /metrics/getEdgeLinkSeries HTTP response has status 200 HTTP response has NOT status 200 Subject: request.links.configuration (aims at endpoint POST /edge/getEdgeConfigurationModules ) Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from POST /edge/getEdgeConfigurationModules HTTP response has status 200 HTTP response has NOT status 200 3 Check for existence of WAN module in response WAN configuration exists WAN configuration does NOT exist 4 Check for existence of links configurations in WAN module Links config defined in WAN configuration Links config NOT defined in WAN configuration Subject: get.links.metric.info (aims at endpoint POST /monitoring/getAggregateEdgeLinkMetrics ) Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from POST /monitoring/getAggregateEdgeLinkMetrics HTTP response has status 200 HTTP response has NOT status 200 Subject: get.links.with.edge.info (aims at endpoint POST /monitoring/getEnterpriseEdgeLinkStatus ) Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from POST /monitoring/getEnterpriseEdgeLinkStatus HTTP response has status 200 HTTP response has NOT status 200 Subject: request.network.enterprise.edges (aims at endpoint POST /network/getNetworkEnterprises ) Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from POST /network/getNetworkEnterprises HTTP response has status 200 HTTP response has NOT status 200 3 Check enterprise was found for specified filters Enterprise found for filters Enterprise NOT found for filters 4 Check enterprise has edges Edges found for enterprises Edges NOT found for enterprises Subject: request.network.gateway.list (aims at endpoint POST /network/getNetworkGateways ) Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from POST /network/getNetworkGateways HTTP response has status 200 HTTP response has NOT status 200 Subject: request.gateway.status.metrics (aims at endpoint POST /metrics/getGatewayStatusMetrics ) Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from POST /metrics/getGatewayStatusMetrics HTTP response has status 200 HTTP response has NOT status 200 Event Descriptions Subject: alert.request.event.edge edge_events_for_alert Subject: request.enterprises.edges enterprise_edge_list Subject: alert.request.event.enterprise enterprise_events_for_alert Subject: request.enterprises.names enterprise_name_list_response Subject: request.edge.links.series get_edge_links_series Subject: request.links.configuration links_configuration Subject: get.links.metric.info links_metric_info Subject: get.links.with.edge.info links_with_edge_info Subject: request.network.enterprise.edges network_enterprise_edge_list Subject: request.network.gateway.list network_gateway_list Subject: request.gateway.status.metrics gateway_status_metrics","title":"VeloCloud Bridge Event Logging"},{"location":"logging/events/12-velocloud-bridge/#velocloud-bridge-event-logging","text":"","title":"VeloCloud Bridge Event Logging"},{"location":"logging/events/12-velocloud-bridge/#description","text":"The mission of this service is to act as a proxy to the VeloCloud API. It accepts requests from other services and yields the requested data back to those services, so they can make the appropriate business decision.","title":"Description"},{"location":"logging/events/12-velocloud-bridge/#process-workflows","text":"","title":"Process Workflows"},{"location":"logging/events/12-velocloud-bridge/#list-of-decisions-made-by-the-velocloud-bridge","text":"","title":"List of Decisions made by the VeloCloud Bridge"},{"location":"logging/events/12-velocloud-bridge/#subject-alertrequesteventedge-aims-at-endpoint-post-eventgetenterpriseevents","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from POST /event/getEnterpriseEvents HTTP response has status 200 HTTP response has NOT status 200","title":"Subject: alert.request.event.edge (aims at endpoint POST /event/getEnterpriseEvents)"},{"location":"logging/events/12-velocloud-bridge/#subject-requestenterprisesedges-aims-at-endpoint-post-enterprisegetenterpriseedges","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from POST /enterprise/getEnterpriseEdges HTTP response has status 200 HTTP response has NOT status 200","title":"Subject: request.enterprises.edges (aims at endpoint POST /enterprise/getEnterpriseEdges)"},{"location":"logging/events/12-velocloud-bridge/#subject-alertrequestevententerprise-aims-at-endpoint-post-eventgetenterpriseevents","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from POST /event/getEnterpriseEvents HTTP response has status 200 HTTP response has NOT status 200","title":"Subject: alert.request.event.enterprise (aims at endpoint POST /event/getEnterpriseEvents)"},{"location":"logging/events/12-velocloud-bridge/#subject-requestenterprisesnames-aims-at-endpoint-post-monitoringgetaggregates","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from POST /monitoring/getAggregates HTTP response has status 200 HTTP response has NOT status 200","title":"Subject: request.enterprises.names (aims at endpoint POST /monitoring/getAggregates)"},{"location":"logging/events/12-velocloud-bridge/#subject-requestedgelinksseries-aims-at-endpoint-post-metricsgetedgelinkseries","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from POST /metrics/getEdgeLinkSeries HTTP response has status 200 HTTP response has NOT status 200","title":"Subject: request.edge.links.series (aims at endpoint POST /metrics/getEdgeLinkSeries)"},{"location":"logging/events/12-velocloud-bridge/#subject-requestlinksconfiguration-aims-at-endpoint-post-edgegetedgeconfigurationmodules","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from POST /edge/getEdgeConfigurationModules HTTP response has status 200 HTTP response has NOT status 200 3 Check for existence of WAN module in response WAN configuration exists WAN configuration does NOT exist 4 Check for existence of links configurations in WAN module Links config defined in WAN configuration Links config NOT defined in WAN configuration","title":"Subject: request.links.configuration (aims at endpoint POST /edge/getEdgeConfigurationModules)"},{"location":"logging/events/12-velocloud-bridge/#subject-getlinksmetricinfo-aims-at-endpoint-post-monitoringgetaggregateedgelinkmetrics","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from POST /monitoring/getAggregateEdgeLinkMetrics HTTP response has status 200 HTTP response has NOT status 200","title":"Subject: get.links.metric.info (aims at endpoint POST /monitoring/getAggregateEdgeLinkMetrics)"},{"location":"logging/events/12-velocloud-bridge/#subject-getlinkswithedgeinfo-aims-at-endpoint-post-monitoringgetenterpriseedgelinkstatus","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from POST /monitoring/getEnterpriseEdgeLinkStatus HTTP response has status 200 HTTP response has NOT status 200","title":"Subject: get.links.with.edge.info (aims at endpoint POST /monitoring/getEnterpriseEdgeLinkStatus)"},{"location":"logging/events/12-velocloud-bridge/#subject-requestnetworkenterpriseedges-aims-at-endpoint-post-networkgetnetworkenterprises","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from POST /network/getNetworkEnterprises HTTP response has status 200 HTTP response has NOT status 200 3 Check enterprise was found for specified filters Enterprise found for filters Enterprise NOT found for filters 4 Check enterprise has edges Edges found for enterprises Edges NOT found for enterprises","title":"Subject: request.network.enterprise.edges (aims at endpoint POST /network/getNetworkEnterprises)"},{"location":"logging/events/12-velocloud-bridge/#subject-requestnetworkgatewaylist-aims-at-endpoint-post-networkgetnetworkgateways","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from POST /network/getNetworkGateways HTTP response has status 200 HTTP response has NOT status 200","title":"Subject: request.network.gateway.list (aims at endpoint POST /network/getNetworkGateways)"},{"location":"logging/events/12-velocloud-bridge/#subject-requestgatewaystatusmetrics-aims-at-endpoint-post-metricsgetgatewaystatusmetrics","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from POST /metrics/getGatewayStatusMetrics HTTP response has status 200 HTTP response has NOT status 200","title":"Subject: request.gateway.status.metrics (aims at endpoint POST /metrics/getGatewayStatusMetrics)"},{"location":"logging/events/12-velocloud-bridge/#event-descriptions","text":"","title":"Event Descriptions"},{"location":"logging/events/12-velocloud-bridge/#subject-alertrequesteventedge","text":"edge_events_for_alert","title":"Subject: alert.request.event.edge"},{"location":"logging/events/12-velocloud-bridge/#subject-requestenterprisesedges","text":"enterprise_edge_list","title":"Subject: request.enterprises.edges"},{"location":"logging/events/12-velocloud-bridge/#subject-alertrequestevententerprise","text":"enterprise_events_for_alert","title":"Subject: alert.request.event.enterprise"},{"location":"logging/events/12-velocloud-bridge/#subject-requestenterprisesnames","text":"enterprise_name_list_response","title":"Subject: request.enterprises.names"},{"location":"logging/events/12-velocloud-bridge/#subject-requestedgelinksseries","text":"get_edge_links_series","title":"Subject: request.edge.links.series"},{"location":"logging/events/12-velocloud-bridge/#subject-requestlinksconfiguration","text":"links_configuration","title":"Subject: request.links.configuration"},{"location":"logging/events/12-velocloud-bridge/#subject-getlinksmetricinfo","text":"links_metric_info","title":"Subject: get.links.metric.info"},{"location":"logging/events/12-velocloud-bridge/#subject-getlinkswithedgeinfo","text":"links_with_edge_info","title":"Subject: get.links.with.edge.info"},{"location":"logging/events/12-velocloud-bridge/#subject-requestnetworkenterpriseedges","text":"network_enterprise_edge_list","title":"Subject: request.network.enterprise.edges"},{"location":"logging/events/12-velocloud-bridge/#subject-requestnetworkgatewaylist","text":"network_gateway_list","title":"Subject: request.network.gateway.list"},{"location":"logging/events/12-velocloud-bridge/#subject-requestgatewaystatusmetrics","text":"gateway_status_metrics","title":"Subject: request.gateway.status.metrics"},{"location":"logging/events/13-notifications-bridge/","text":"Notifications Bridge Event Logging Description The mission of this service is to act as a proxy to third-party systems focused on notifications' delivery. It accepts requests from other services and yields the requested data back to those services, so they can make the appropriate business decision. Process Workflows List of Decisions made by the Notifications Bridge Subject: notification.slack.request (aims at endpoint slack webhook defined in the AWS params store) Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from the slack webhook HTTP response has status 200 HTTP response has NOT status 200 Event Descriptions Subject: notification.slack.request send_to_slack","title":"Notifications Bridge Event Logging"},{"location":"logging/events/13-notifications-bridge/#notifications-bridge-event-logging","text":"","title":"Notifications Bridge Event Logging"},{"location":"logging/events/13-notifications-bridge/#description","text":"The mission of this service is to act as a proxy to third-party systems focused on notifications' delivery. It accepts requests from other services and yields the requested data back to those services, so they can make the appropriate business decision.","title":"Description"},{"location":"logging/events/13-notifications-bridge/#process-workflows","text":"","title":"Process Workflows"},{"location":"logging/events/13-notifications-bridge/#list-of-decisions-made-by-the-notifications-bridge","text":"","title":"List of Decisions made by the Notifications Bridge"},{"location":"logging/events/13-notifications-bridge/#subject-notificationslackrequest-aims-at-endpoint-slack-webhook-defined-in-the-aws-params-store","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from the slack webhook HTTP response has status 200 HTTP response has NOT status 200","title":"Subject: notification.slack.request (aims at endpoint slack webhook defined in the AWS params store)"},{"location":"logging/events/13-notifications-bridge/#event-descriptions","text":"","title":"Event Descriptions"},{"location":"logging/events/13-notifications-bridge/#subject-notificationslackrequest","text":"send_to_slack","title":"Subject: notification.slack.request"},{"location":"logging/events/14-email-bridge/","text":"Email Bridge Event Logging Description The mission of this service is to act as a proxy to the email server. It accepts requests from other services and yields the requested data back to those services, so they can make the appropriate business decision. Process Workflows List of Decisions made by the Email Bridge Subject: get.email.request (aims at the email server smtp.gmail.com:587) Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for the email and password from the request Password was found Password was not found 3 Check for status of response from the email server IMAP response has status OK IMAP response has NOT status OK Subject: notification.email.request (aims at the email server smtp.gmail.com:587) Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Send the email to the email account and password in our settings IMAP response has status OK IMAP response has NOT status OK 3 Check for status of response from the email server IMAP response has status OK IMAP response has NOT status OK Subject: mark.email.read.request (aims at the email server smtp.gmail.com:587) Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 E-mail account from request E-mail account monitorable E-mail account not monitorable 3 Check for status of response from the email server to mark the email(s) as seen IMAP response has status OK IMAP response has NOT status OK Event Descriptions Subject: get.email.request get_emails Subject: notification.email.request send_to_email Subject: mark.email.read.request mark_email_as_read","title":"Email Bridge Event Logging"},{"location":"logging/events/14-email-bridge/#email-bridge-event-logging","text":"","title":"Email Bridge Event Logging"},{"location":"logging/events/14-email-bridge/#description","text":"The mission of this service is to act as a proxy to the email server. It accepts requests from other services and yields the requested data back to those services, so they can make the appropriate business decision.","title":"Description"},{"location":"logging/events/14-email-bridge/#process-workflows","text":"","title":"Process Workflows"},{"location":"logging/events/14-email-bridge/#list-of-decisions-made-by-the-email-bridge","text":"","title":"List of Decisions made by the Email Bridge"},{"location":"logging/events/14-email-bridge/#subject-getemailrequest-aims-at-the-email-server-smtpgmailcom587","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for the email and password from the request Password was found Password was not found 3 Check for status of response from the email server IMAP response has status OK IMAP response has NOT status OK","title":"Subject: get.email.request (aims at the email server smtp.gmail.com:587)"},{"location":"logging/events/14-email-bridge/#subject-notificationemailrequest-aims-at-the-email-server-smtpgmailcom587","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Send the email to the email account and password in our settings IMAP response has status OK IMAP response has NOT status OK 3 Check for status of response from the email server IMAP response has status OK IMAP response has NOT status OK","title":"Subject: notification.email.request (aims at the email server smtp.gmail.com:587)"},{"location":"logging/events/14-email-bridge/#subject-markemailreadrequest-aims-at-the-email-server-smtpgmailcom587","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 E-mail account from request E-mail account monitorable E-mail account not monitorable 3 Check for status of response from the email server to mark the email(s) as seen IMAP response has status OK IMAP response has NOT status OK","title":"Subject: mark.email.read.request (aims at the email server smtp.gmail.com:587)"},{"location":"logging/events/14-email-bridge/#event-descriptions","text":"","title":"Event Descriptions"},{"location":"logging/events/14-email-bridge/#subject-getemailrequest","text":"get_emails","title":"Subject: get.email.request"},{"location":"logging/events/14-email-bridge/#subject-notificationemailrequest","text":"send_to_email","title":"Subject: notification.email.request"},{"location":"logging/events/14-email-bridge/#subject-markemailreadrequest","text":"mark_email_as_read","title":"Subject: mark.email.read.request"},{"location":"logging/events/15-gateway-monitor/","text":"Intermapper Event Logging Description The mission of this service is to analyze VeloCloud gateways' statuses and metrics, and report issues to ServiceNow (if any). Process Workflows List of Decisions made by the Gateway Monitor Process Gateway workflow Condition Decision Decision 1 Check for current gateway status Gateway is Down Gateway is Up 2 Check for availability of metrics for a particular gateway VCO doesn't have any metrics recorded for this gateway VCO has metrics recorded for this gateway 3 Check for metrics being within thresholds All metrics are within thresholds Any metric is not within its threshold Event Descriptions Start Gateway Monitoring start_monitoring Process VeloCloud host _process_host","title":"Intermapper Event Logging"},{"location":"logging/events/15-gateway-monitor/#intermapper-event-logging","text":"","title":"Intermapper Event Logging"},{"location":"logging/events/15-gateway-monitor/#description","text":"The mission of this service is to analyze VeloCloud gateways' statuses and metrics, and report issues to ServiceNow (if any).","title":"Description"},{"location":"logging/events/15-gateway-monitor/#process-workflows","text":"","title":"Process Workflows"},{"location":"logging/events/15-gateway-monitor/#list-of-decisions-made-by-the-gateway-monitor","text":"","title":"List of Decisions made by the Gateway Monitor"},{"location":"logging/events/15-gateway-monitor/#process-gateway-workflow","text":"Condition Decision Decision 1 Check for current gateway status Gateway is Down Gateway is Up 2 Check for availability of metrics for a particular gateway VCO doesn't have any metrics recorded for this gateway VCO has metrics recorded for this gateway 3 Check for metrics being within thresholds All metrics are within thresholds Any metric is not within its threshold","title":"Process Gateway workflow"},{"location":"logging/events/15-gateway-monitor/#event-descriptions","text":"","title":"Event Descriptions"},{"location":"logging/events/15-gateway-monitor/#start-gateway-monitoring","text":"start_monitoring","title":"Start Gateway Monitoring"},{"location":"logging/events/15-gateway-monitor/#process-velocloud-host","text":"_process_host","title":"Process VeloCloud host"},{"location":"logging/events/16-servicenow-bridge/","text":"Service Now Bridge Event Logging Description The servicenow-bridge is used to call to the ServiceNow API. Process Workflows List of Decisions made by the Service Now Bridge Subject: servicenow.incident.report.request Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from POST /api/g_mtcm/intelygenz HTTP response has status 200 HTTP response has NOT status 200 Event Descriptions Subject: servicenow.incident.report.request report_incident","title":"Service Now Bridge Event Logging"},{"location":"logging/events/16-servicenow-bridge/#service-now-bridge-event-logging","text":"","title":"Service Now Bridge Event Logging"},{"location":"logging/events/16-servicenow-bridge/#description","text":"The servicenow-bridge is used to call to the ServiceNow API.","title":"Description"},{"location":"logging/events/16-servicenow-bridge/#process-workflows","text":"","title":"Process Workflows"},{"location":"logging/events/16-servicenow-bridge/#list-of-decisions-made-by-the-service-now-bridge","text":"","title":"List of Decisions made by the Service Now Bridge"},{"location":"logging/events/16-servicenow-bridge/#subject-servicenowincidentreportrequest","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from POST /api/g_mtcm/intelygenz HTTP response has status 200 HTTP response has NOT status 200","title":"Subject: servicenow.incident.report.request"},{"location":"logging/events/16-servicenow-bridge/#event-descriptions","text":"","title":"Event Descriptions"},{"location":"logging/events/16-servicenow-bridge/#subject-servicenowincidentreportrequest_1","text":"report_incident","title":"Subject: servicenow.incident.report.request"},{"location":"logging/events/17-dri-bridge/","text":"DRI Bridge Event Logging Description DRI Bridge is used to make calls to the DRI API. The main call includes get_dri_parameters which comprises three different endpoint calls to the DRI API. Process Workflows List of Decisions made by the DRI Bridge Subject: dri.parameters.request Condition Decision Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from POST /acs/device/{serial_number}/parameter_tid?transactionid={task_id} HTTP response has status 200 HTTP response has NOT status 200 3 Check for status of response from POST /acs/device/{serial_number}/parameter_returnid?data={parameters} HTTP response has status 200 HTTP response has NOT status 200 4 Check for status of response from POST /acs/device/{serial_number}/taskpending HTTP response has status 200 HTTP response has NOT status 200 5 Check for existence of task ID in IPA system's Redis Task ID exists Task ID does NOT exist 6 Check for existence of pending task ID in DRI system Pending task exists in DRI Pending task does NOT exist in DRI 7 Check for status of in-progress task Task was completed in DRI Task was rejected Task is still in progress Event Descriptions Subject: dri.parameters.request get_dri_parameters","title":"DRI Bridge Event Logging"},{"location":"logging/events/17-dri-bridge/#dri-bridge-event-logging","text":"","title":"DRI Bridge Event Logging"},{"location":"logging/events/17-dri-bridge/#description","text":"DRI Bridge is used to make calls to the DRI API. The main call includes get_dri_parameters which comprises three different endpoint calls to the DRI API.","title":"Description"},{"location":"logging/events/17-dri-bridge/#process-workflows","text":"","title":"Process Workflows"},{"location":"logging/events/17-dri-bridge/#list-of-decisions-made-by-the-dri-bridge","text":"","title":"List of Decisions made by the DRI Bridge"},{"location":"logging/events/17-dri-bridge/#subject-driparametersrequest","text":"Condition Decision Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from POST /acs/device/{serial_number}/parameter_tid?transactionid={task_id} HTTP response has status 200 HTTP response has NOT status 200 3 Check for status of response from POST /acs/device/{serial_number}/parameter_returnid?data={parameters} HTTP response has status 200 HTTP response has NOT status 200 4 Check for status of response from POST /acs/device/{serial_number}/taskpending HTTP response has status 200 HTTP response has NOT status 200 5 Check for existence of task ID in IPA system's Redis Task ID exists Task ID does NOT exist 6 Check for existence of pending task ID in DRI system Pending task exists in DRI Pending task does NOT exist in DRI 7 Check for status of in-progress task Task was completed in DRI Task was rejected Task is still in progress","title":"Subject: dri.parameters.request"},{"location":"logging/events/17-dri-bridge/#event-descriptions","text":"","title":"Event Descriptions"},{"location":"logging/events/17-dri-bridge/#subject-driparametersrequest_1","text":"get_dri_parameters","title":"Subject: dri.parameters.request"},{"location":"logging/events/18-digi-bridge/","text":"Digi Bridge Event Logging Description The DiGi bridge is mainly used to call the DiGi API to reboot DiGi devices. Process Workflows List of Decisions made by the Digi Bridge Subject: digi.reboot (aims at endpoint GET /DeviceManagement_API/rest/Recovery/RecoverDevice) Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from GET /DeviceManagement_API/rest/Recovery/RecoverDevice HTTP response has status 200 HTTP response has NOT status 200 Subject: get.digi.recovery.logs (aims at endpoint GET /DeviceManagement_API/rest/Recovery/Logs) Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from GET /DeviceManagement_API/rest/Recovery/Logs HTTP response has status 200 HTTP response has NOT status 200 Event Descriptions Authentication management Schedule DiGi Login job login_job Bridge capabilities Subject: digi.reboot digi_reboot Subject: get.digi.recovery.logs get_digi_recovery_logs","title":"Digi Bridge Event Logging"},{"location":"logging/events/18-digi-bridge/#digi-bridge-event-logging","text":"","title":"Digi Bridge Event Logging"},{"location":"logging/events/18-digi-bridge/#description","text":"The DiGi bridge is mainly used to call the DiGi API to reboot DiGi devices.","title":"Description"},{"location":"logging/events/18-digi-bridge/#process-workflows","text":"","title":"Process Workflows"},{"location":"logging/events/18-digi-bridge/#list-of-decisions-made-by-the-digi-bridge","text":"","title":"List of Decisions made by the Digi Bridge"},{"location":"logging/events/18-digi-bridge/#subject-digireboot-aims-at-endpoint-get-devicemanagement_apirestrecoveryrecoverdevice","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from GET /DeviceManagement_API/rest/Recovery/RecoverDevice HTTP response has status 200 HTTP response has NOT status 200","title":"Subject: digi.reboot (aims at endpoint GET /DeviceManagement_API/rest/Recovery/RecoverDevice)"},{"location":"logging/events/18-digi-bridge/#subject-getdigirecoverylogs-aims-at-endpoint-get-devicemanagement_apirestrecoverylogs","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from GET /DeviceManagement_API/rest/Recovery/Logs HTTP response has status 200 HTTP response has NOT status 200","title":"Subject: get.digi.recovery.logs (aims at endpoint GET /DeviceManagement_API/rest/Recovery/Logs)"},{"location":"logging/events/18-digi-bridge/#event-descriptions","text":"","title":"Event Descriptions"},{"location":"logging/events/18-digi-bridge/#authentication-management","text":"","title":"Authentication management"},{"location":"logging/events/18-digi-bridge/#schedule-digi-login-job","text":"login_job","title":"Schedule DiGi Login job"},{"location":"logging/events/18-digi-bridge/#bridge-capabilities","text":"","title":"Bridge capabilities"},{"location":"logging/events/18-digi-bridge/#subject-digireboot","text":"digi_reboot","title":"Subject: digi.reboot"},{"location":"logging/events/18-digi-bridge/#subject-getdigirecoverylogs","text":"get_digi_recovery_logs","title":"Subject: get.digi.recovery.logs"},{"location":"logging/events/2-BYOB-IPA-queue/","text":"IPA Event Logging Process Workflows List of Decisions made by the IPA System BYOB IPA queue Start of BYOB workflow 1. Determining whether or not there is an ongoing trouble or not Trouble is detected Trouble stabilized Trouble is detected 2. Determining what kind of trouble occurred Trouble is on the link Trouble is on the Edge 3. Determining what VCO does the troubled device belong too VCO 1, 2, 3 VCO 4 4. Determining if link name includes \"BYOB\" or \"Customer Provided\" Link name includes \"BYOB\" or \"Customer Provided\" Link name doesn't include \"BYOB\" or \"Customer Provided\" Trouble stabilized 5. Determining what kind of trouble last occurred Trouble is on the link Trouble is on the Edge 6. Determining what VCO does the device belong too VCO 1, 2, 3 VCO 4 7. Determining if link name includes \"BYOB\" or \"Customer Provided\" Link name includes \"BYOB\" or \"Customer Provided\" Link name doesn't include \"BYOB\" or \"Customer Provided\" Event Descriptions BYOB IPA queue _attempt_ticket_creation","title":"IPA Event Logging"},{"location":"logging/events/2-BYOB-IPA-queue/#ipa-event-logging","text":"","title":"IPA Event Logging"},{"location":"logging/events/2-BYOB-IPA-queue/#process-workflows","text":"","title":"Process Workflows"},{"location":"logging/events/2-BYOB-IPA-queue/#list-of-decisions-made-by-the-ipa-system","text":"","title":"List of Decisions made by the IPA System"},{"location":"logging/events/2-BYOB-IPA-queue/#byob-ipa-queue","text":"","title":"BYOB IPA queue"},{"location":"logging/events/2-BYOB-IPA-queue/#start-of-byob-workflow","text":"1. Determining whether or not there is an ongoing trouble or not Trouble is detected Trouble stabilized","title":"Start of BYOB workflow"},{"location":"logging/events/2-BYOB-IPA-queue/#trouble-is-detected","text":"2. Determining what kind of trouble occurred Trouble is on the link Trouble is on the Edge 3. Determining what VCO does the troubled device belong too VCO 1, 2, 3 VCO 4 4. Determining if link name includes \"BYOB\" or \"Customer Provided\" Link name includes \"BYOB\" or \"Customer Provided\" Link name doesn't include \"BYOB\" or \"Customer Provided\"","title":"Trouble is detected"},{"location":"logging/events/2-BYOB-IPA-queue/#trouble-stabilized","text":"5. Determining what kind of trouble last occurred Trouble is on the link Trouble is on the Edge 6. Determining what VCO does the device belong too VCO 1, 2, 3 VCO 4 7. Determining if link name includes \"BYOB\" or \"Customer Provided\" Link name includes \"BYOB\" or \"Customer Provided\" Link name doesn't include \"BYOB\" or \"Customer Provided\"","title":"Trouble stabilized"},{"location":"logging/events/2-BYOB-IPA-queue/#event-descriptions","text":"","title":"Event Descriptions"},{"location":"logging/events/2-BYOB-IPA-queue/#byob-ipa-queue_1","text":"_attempt_ticket_creation","title":"BYOB IPA queue"},{"location":"logging/events/20-last-contact-report/","text":"Last Contact Report Event Logging Description The Last Contact Report service is responsible for running a job every first day of the month. The job makes sure to gather the edges across all VCOs, and send via e-mail a summary of the edges that have been last contacted by the VCO where they belong more than 30 days ago. Process Workflows List of Decisions made by the Last Contact Report service Overall workflow Condition Decision Decision 1 Check for edges successfully retrieved from the VCOs Edges are fetched from VCOs successfully An error happens while fetching all edges Process Edge workflow Condition Decision Decision 1 Check for the moment the edge was last contacted Edge was last contacted more than or exactly 30 days ago Edge was last contacted less than 30 days ago 2 Check for validity of edge state Edge state is invalid Edge state is valid 3 Check for activation state of edge Edge has been activated Edge has never been activated Event Descriptions Schedule Last Contact Report job start_alert_job Run Last Contact Report job _alert_job","title":"Last Contact Report Event Logging"},{"location":"logging/events/20-last-contact-report/#last-contact-report-event-logging","text":"","title":"Last Contact Report Event Logging"},{"location":"logging/events/20-last-contact-report/#description","text":"The Last Contact Report service is responsible for running a job every first day of the month. The job makes sure to gather the edges across all VCOs, and send via e-mail a summary of the edges that have been last contacted by the VCO where they belong more than 30 days ago.","title":"Description"},{"location":"logging/events/20-last-contact-report/#process-workflows","text":"","title":"Process Workflows"},{"location":"logging/events/20-last-contact-report/#list-of-decisions-made-by-the-last-contact-report-service","text":"","title":"List of Decisions made by the Last Contact Report service"},{"location":"logging/events/20-last-contact-report/#overall-workflow","text":"Condition Decision Decision 1 Check for edges successfully retrieved from the VCOs Edges are fetched from VCOs successfully An error happens while fetching all edges","title":"Overall workflow"},{"location":"logging/events/20-last-contact-report/#process-edge-workflow","text":"Condition Decision Decision 1 Check for the moment the edge was last contacted Edge was last contacted more than or exactly 30 days ago Edge was last contacted less than 30 days ago 2 Check for validity of edge state Edge state is invalid Edge state is valid 3 Check for activation state of edge Edge has been activated Edge has never been activated","title":"Process Edge workflow"},{"location":"logging/events/20-last-contact-report/#event-descriptions","text":"","title":"Event Descriptions"},{"location":"logging/events/20-last-contact-report/#schedule-last-contact-report-job","text":"start_alert_job","title":"Schedule Last Contact Report job"},{"location":"logging/events/20-last-contact-report/#run-last-contact-report-job","text":"_alert_job","title":"Run Last Contact Report job"},{"location":"logging/events/21-lumin-billing-report/","text":"Last Contact Report Event Logging Description The Lumin Billing Report service is responsible for running a job every first day of the month. The job makes sure to gather all the billable events registered during the past month in the LuminAI system, and send a summary of those events via e-mail. Process Workflows List of Decisions made by the Lumin Billing Report service This service does not make any business decision Event Descriptions Schedule Lumin Billing Report job start_billing_report_job Run Lumin Billing Report job _billing_report_process","title":"Last Contact Report Event Logging"},{"location":"logging/events/21-lumin-billing-report/#last-contact-report-event-logging","text":"","title":"Last Contact Report Event Logging"},{"location":"logging/events/21-lumin-billing-report/#description","text":"The Lumin Billing Report service is responsible for running a job every first day of the month. The job makes sure to gather all the billable events registered during the past month in the LuminAI system, and send a summary of those events via e-mail.","title":"Description"},{"location":"logging/events/21-lumin-billing-report/#process-workflows","text":"","title":"Process Workflows"},{"location":"logging/events/21-lumin-billing-report/#list-of-decisions-made-by-the-lumin-billing-report-service","text":"This service does not make any business decision","title":"List of Decisions made by the Lumin Billing Report service"},{"location":"logging/events/21-lumin-billing-report/#event-descriptions","text":"","title":"Event Descriptions"},{"location":"logging/events/21-lumin-billing-report/#schedule-lumin-billing-report-job","text":"start_billing_report_job","title":"Schedule Lumin Billing Report job"},{"location":"logging/events/21-lumin-billing-report/#run-lumin-billing-report-job","text":"_billing_report_process","title":"Run Lumin Billing Report job"},{"location":"logging/events/22-digi-reboot-report/","text":"DiGi Reboot Report Event Logging Description The digi-reboot-report service creates a daily report based on the DiGi recovery logs from the last 3 days, and then emails it out. Process Workflows List of Decisions made by the Digi Reboot Report service This service does not make any business decision Event Descriptions Schedule Lumin Billing Report job start_digi_reboot_report_job Run Digi Reboot Report job _digi_reboot_report_process","title":"DiGi Reboot Report Event Logging"},{"location":"logging/events/22-digi-reboot-report/#digi-reboot-report-event-logging","text":"","title":"DiGi Reboot Report Event Logging"},{"location":"logging/events/22-digi-reboot-report/#description","text":"The digi-reboot-report service creates a daily report based on the DiGi recovery logs from the last 3 days, and then emails it out.","title":"Description"},{"location":"logging/events/22-digi-reboot-report/#process-workflows","text":"","title":"Process Workflows"},{"location":"logging/events/22-digi-reboot-report/#list-of-decisions-made-by-the-digi-reboot-report-service","text":"This service does not make any business decision","title":"List of Decisions made by the Digi Reboot Report service"},{"location":"logging/events/22-digi-reboot-report/#event-descriptions","text":"","title":"Event Descriptions"},{"location":"logging/events/22-digi-reboot-report/#schedule-lumin-billing-report-job","text":"start_digi_reboot_report_job","title":"Schedule Lumin Billing Report job"},{"location":"logging/events/22-digi-reboot-report/#run-digi-reboot-report-job","text":"_digi_reboot_report_process","title":"Run Digi Reboot Report job"},{"location":"logging/events/23-customer-cache/","text":"Customer Cache Event Logging Description The Customer Cache service has two responsibilities: * Run a periodic job that retrieves non-volatile data from VeloCloud and Bruin for all edges across VCOs, and then cross the data from both systems and store the resulting cache to a Redis instance. The cache will remain valid until the next successful execution of the job. * Serve the cache built from execution of the previously mentioned job to other services in the system. Process Workflows List of Decisions made by the Customer Cache service Bridge-like capabilities Subject: customer.cache.get Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for existence of the cache in Redis Cache exists for all VCOs Cache does NOT exist for any of the VCOs 3 Check for Last Contact filter in the request payload Last Contact filter was specified Last Contact filter was NOT specified 4 Check for emptiness of cache after filtering by Last Contact filter Resulting cache is NOT empty Resulting cache is empty Use case Overall workflow Condition Decision Decision 1 Check for edges successfully retrieved from the VCOs Edges are fetched from VCOs successfully An error happens while fetching all edges 1 Check if the threshold to retry fetching edges from the VCOs after a failure was maxed out Threshold to retry fetching edges from VCOs was reached Threshold to retry fetching edges from VCOs was NOT reached Workflow - Fetch edge data from VeloCloud Condition Decision Decision 1 Check for validity of edge state Edge state is invalid Edge state is valid 2 Check for activation state of edge Edge has been activated Edge has never been activated 3 Check if the edge is blacklisted from IPA System's monitoring Edge is NOT blacklisted from IPA system's monitoring Edge is blacklisted from IPA system's monitoring Workflow - Fetch edge data from Bruin Condition Decision Decision 1 Check for existence of client info in Bruin for the edge Client info was found in Bruin inventories No client info was found in Bruin inventories 2 Check if the management status of the edge is monitorable Management status is monitorable Management status is NOT monitorable 3 Check if the management status of the edge is set to Pending and is blacklisted for certain clients Management status is NOT Pending, or it is Pending and the client is NOT blacklisted for such status Management status is Pending and the client is blacklisted for such status Workflow - Cross VeloCloud and Bruin data & store cache Condition Decision Decision 1 Check if cache originated after crossing VeloCloud and Bruin data is empty Resulting cache is NOT empty Resulting cache is empty Event Descriptions Bridge-like capabilities Subject: customer.cache.get get_customers Use case Schedule Customer Cache Refresh job schedule_cache_refresh Run Customer Cache Refresh job _refresh_cache","title":"Customer Cache Event Logging"},{"location":"logging/events/23-customer-cache/#customer-cache-event-logging","text":"","title":"Customer Cache Event Logging"},{"location":"logging/events/23-customer-cache/#description","text":"The Customer Cache service has two responsibilities: * Run a periodic job that retrieves non-volatile data from VeloCloud and Bruin for all edges across VCOs, and then cross the data from both systems and store the resulting cache to a Redis instance. The cache will remain valid until the next successful execution of the job. * Serve the cache built from execution of the previously mentioned job to other services in the system.","title":"Description"},{"location":"logging/events/23-customer-cache/#process-workflows","text":"","title":"Process Workflows"},{"location":"logging/events/23-customer-cache/#list-of-decisions-made-by-the-customer-cache-service","text":"","title":"List of Decisions made by the Customer Cache service"},{"location":"logging/events/23-customer-cache/#bridge-like-capabilities","text":"","title":"Bridge-like capabilities"},{"location":"logging/events/23-customer-cache/#subject-customercacheget","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for existence of the cache in Redis Cache exists for all VCOs Cache does NOT exist for any of the VCOs 3 Check for Last Contact filter in the request payload Last Contact filter was specified Last Contact filter was NOT specified 4 Check for emptiness of cache after filtering by Last Contact filter Resulting cache is NOT empty Resulting cache is empty","title":"Subject: customer.cache.get"},{"location":"logging/events/23-customer-cache/#use-case","text":"","title":"Use case"},{"location":"logging/events/23-customer-cache/#overall-workflow","text":"Condition Decision Decision 1 Check for edges successfully retrieved from the VCOs Edges are fetched from VCOs successfully An error happens while fetching all edges 1 Check if the threshold to retry fetching edges from the VCOs after a failure was maxed out Threshold to retry fetching edges from VCOs was reached Threshold to retry fetching edges from VCOs was NOT reached","title":"Overall workflow"},{"location":"logging/events/23-customer-cache/#workflow-fetch-edge-data-from-velocloud","text":"Condition Decision Decision 1 Check for validity of edge state Edge state is invalid Edge state is valid 2 Check for activation state of edge Edge has been activated Edge has never been activated 3 Check if the edge is blacklisted from IPA System's monitoring Edge is NOT blacklisted from IPA system's monitoring Edge is blacklisted from IPA system's monitoring","title":"Workflow - Fetch edge data from VeloCloud"},{"location":"logging/events/23-customer-cache/#workflow-fetch-edge-data-from-bruin","text":"Condition Decision Decision 1 Check for existence of client info in Bruin for the edge Client info was found in Bruin inventories No client info was found in Bruin inventories 2 Check if the management status of the edge is monitorable Management status is monitorable Management status is NOT monitorable 3 Check if the management status of the edge is set to Pending and is blacklisted for certain clients Management status is NOT Pending, or it is Pending and the client is NOT blacklisted for such status Management status is Pending and the client is blacklisted for such status","title":"Workflow - Fetch edge data from Bruin"},{"location":"logging/events/23-customer-cache/#workflow-cross-velocloud-and-bruin-data-store-cache","text":"Condition Decision Decision 1 Check if cache originated after crossing VeloCloud and Bruin data is empty Resulting cache is NOT empty Resulting cache is empty","title":"Workflow - Cross VeloCloud and Bruin data &amp; store cache"},{"location":"logging/events/23-customer-cache/#event-descriptions","text":"","title":"Event Descriptions"},{"location":"logging/events/23-customer-cache/#bridge-like-capabilities_1","text":"","title":"Bridge-like capabilities"},{"location":"logging/events/23-customer-cache/#subject-customercacheget_1","text":"get_customers","title":"Subject: customer.cache.get"},{"location":"logging/events/23-customer-cache/#use-case_1","text":"","title":"Use case"},{"location":"logging/events/23-customer-cache/#schedule-customer-cache-refresh-job","text":"schedule_cache_refresh","title":"Schedule Customer Cache Refresh job"},{"location":"logging/events/23-customer-cache/#run-customer-cache-refresh-job","text":"_refresh_cache","title":"Run Customer Cache Refresh job"},{"location":"logging/events/24-hawkeye-customer-cache/","text":"Hawkeye Customer Cache Event Logging Description The Hawkeye Customer Cache service has two responsibilities: Run a periodic job that retrieves non-volatile data from Hawkeye / Ixia and Bruin for all devices, and then cross the data from both systems and store the resulting cache to a Redis instance. The cache will remain valid until the next successful execution of the job. Serve the cache built from execution of the previously mentioned job to other services in the system. Process Workflows List of Decisions made by the Hawkeye Customer Cache service Bridge-like capabilities Subject: hawkeye.customer.cache.get Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for Last Contact filter in the request payload Last Contact filter was specified Last Contact filter was NOT specified 3 Check for emptiness of cache after filtering by Last Contact filter Resulting cache is NOT empty Resulting cache is empty Use case Overall workflow Condition Decision Decision 1 Check for devices successfully retrieved from Ixia Devices are fetched from VCOs successfully An error happens while fetching all devices 1 Check if the threshold to retry fetching devices from Ixia after a failure was maxed out Threshold to retry fetching devices from VCOs was reached Threshold to retry fetching devices from VCOs was NOT reached Workflow - Fetch device data from Bruin Condition Decision Decision 1 Check if the device has ever been contacted Device has been contacted at least once Device has never been contacted 2 Check for existence of client info in Bruin for the device Client info was found in Bruin inventories No client info was found in Bruin inventories 3 Check if the management status of the device is monitorable Management status is monitorable Management status is NOT monitorable Event Descriptions Bridge-like capabilities Subject: customer.cache.get get_customers Use case Schedule Hawkeye Customer Cache Refresh job schedule_cache_refresh Run Hawkeye Customer Cache Refresh job _refresh_cache","title":"Hawkeye Customer Cache Event Logging"},{"location":"logging/events/24-hawkeye-customer-cache/#hawkeye-customer-cache-event-logging","text":"","title":"Hawkeye Customer Cache Event Logging"},{"location":"logging/events/24-hawkeye-customer-cache/#description","text":"The Hawkeye Customer Cache service has two responsibilities: Run a periodic job that retrieves non-volatile data from Hawkeye / Ixia and Bruin for all devices, and then cross the data from both systems and store the resulting cache to a Redis instance. The cache will remain valid until the next successful execution of the job. Serve the cache built from execution of the previously mentioned job to other services in the system.","title":"Description"},{"location":"logging/events/24-hawkeye-customer-cache/#process-workflows","text":"","title":"Process Workflows"},{"location":"logging/events/24-hawkeye-customer-cache/#list-of-decisions-made-by-the-hawkeye-customer-cache-service","text":"","title":"List of Decisions made by the Hawkeye Customer Cache service"},{"location":"logging/events/24-hawkeye-customer-cache/#bridge-like-capabilities","text":"","title":"Bridge-like capabilities"},{"location":"logging/events/24-hawkeye-customer-cache/#subject-hawkeyecustomercacheget","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for Last Contact filter in the request payload Last Contact filter was specified Last Contact filter was NOT specified 3 Check for emptiness of cache after filtering by Last Contact filter Resulting cache is NOT empty Resulting cache is empty","title":"Subject: hawkeye.customer.cache.get"},{"location":"logging/events/24-hawkeye-customer-cache/#use-case","text":"","title":"Use case"},{"location":"logging/events/24-hawkeye-customer-cache/#overall-workflow","text":"Condition Decision Decision 1 Check for devices successfully retrieved from Ixia Devices are fetched from VCOs successfully An error happens while fetching all devices 1 Check if the threshold to retry fetching devices from Ixia after a failure was maxed out Threshold to retry fetching devices from VCOs was reached Threshold to retry fetching devices from VCOs was NOT reached","title":"Overall workflow"},{"location":"logging/events/24-hawkeye-customer-cache/#workflow-fetch-device-data-from-bruin","text":"Condition Decision Decision 1 Check if the device has ever been contacted Device has been contacted at least once Device has never been contacted 2 Check for existence of client info in Bruin for the device Client info was found in Bruin inventories No client info was found in Bruin inventories 3 Check if the management status of the device is monitorable Management status is monitorable Management status is NOT monitorable","title":"Workflow - Fetch device data from Bruin"},{"location":"logging/events/24-hawkeye-customer-cache/#event-descriptions","text":"","title":"Event Descriptions"},{"location":"logging/events/24-hawkeye-customer-cache/#bridge-like-capabilities_1","text":"","title":"Bridge-like capabilities"},{"location":"logging/events/24-hawkeye-customer-cache/#subject-customercacheget","text":"get_customers","title":"Subject: customer.cache.get"},{"location":"logging/events/24-hawkeye-customer-cache/#use-case_1","text":"","title":"Use case"},{"location":"logging/events/24-hawkeye-customer-cache/#schedule-hawkeye-customer-cache-refresh-job","text":"schedule_cache_refresh","title":"Schedule Hawkeye Customer Cache Refresh job"},{"location":"logging/events/24-hawkeye-customer-cache/#run-hawkeye-customer-cache-refresh-job","text":"_refresh_cache","title":"Run Hawkeye Customer Cache Refresh job"},{"location":"logging/events/25-hawkeye-bridge/","text":"Hawkeye Bridge Event Logging Description Hawkeye Bridge is used to make calls to the Hawkeye API. Process Workflows List of Decisions made by the Hawkeye Bridge Subject: hawkeye.probe.request (aims at endpoint [GET /probes]) Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from GET /probes HTTP response has status 200 HTTP response has NOT status 200 Subject: hawkeye.test.request (aims at endpoint [GET /testsresults]) Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from GET /testsresults HTTP response has status 200 HTTP response has NOT status 200 Event Descriptions Subject: hawkeye.probe.request get_probes Subject: hawkeye.test.request get_test_results","title":"Hawkeye Bridge Event Logging"},{"location":"logging/events/25-hawkeye-bridge/#hawkeye-bridge-event-logging","text":"","title":"Hawkeye Bridge Event Logging"},{"location":"logging/events/25-hawkeye-bridge/#description","text":"Hawkeye Bridge is used to make calls to the Hawkeye API.","title":"Description"},{"location":"logging/events/25-hawkeye-bridge/#process-workflows","text":"","title":"Process Workflows"},{"location":"logging/events/25-hawkeye-bridge/#list-of-decisions-made-by-the-hawkeye-bridge","text":"","title":"List of Decisions made by the Hawkeye Bridge"},{"location":"logging/events/25-hawkeye-bridge/#subject-hawkeyeproberequest-aims-at-endpoint-get-probes","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from GET /probes HTTP response has status 200 HTTP response has NOT status 200","title":"Subject: hawkeye.probe.request (aims at endpoint [GET /probes])"},{"location":"logging/events/25-hawkeye-bridge/#subject-hawkeyetestrequest-aims-at-endpoint-get-testsresults","text":"Condition Decision Decision 1 Check for shape and content of incoming request Request has valid format Request has invalid format 2 Check for status of response from GET /testsresults HTTP response has status 200 HTTP response has NOT status 200","title":"Subject: hawkeye.test.request (aims at endpoint [GET /testsresults])"},{"location":"logging/events/25-hawkeye-bridge/#event-descriptions","text":"","title":"Event Descriptions"},{"location":"logging/events/25-hawkeye-bridge/#subject-hawkeyeproberequest","text":"get_probes","title":"Subject: hawkeye.probe.request"},{"location":"logging/events/25-hawkeye-bridge/#subject-hawkeyetestrequest","text":"get_test_results","title":"Subject: hawkeye.test.request"},{"location":"logging/events/3-HNOC-forwarding/","text":"HNOC Forwarding Event Logging Process Workflows List of Decisions made by the HNOC forwarding System HNOC forwarding queue Start of HNOC forwarding workflow (SO) 1. Service outage detected 2. Attempt to create ticket outage Create new SO ticket Reopen exist ticket 3. If exist ticket and have more than 60 min Forward HNOC END 4. New ticket created Append triage note 5. If edge outage Forward to HNOC END 6. If link outage Check if more than 60 minutes Start of HNOC forwarding workflow (SA) 1. Service affecting trouble detected Not SA ticket for device SA ticket for device 2. Not SA ticket Create new SA ticket and append note 3. SA ticket exist Reopen SA ticket and append note 4 Wait 60 seconds and forward to HNOC Event Descriptions HNOC forwarding outage queue _attempt_ticket_creation Event Descriptions HNOC forwarding affecting queue _attempt_ticket_creation","title":"HNOC Forwarding Event Logging"},{"location":"logging/events/3-HNOC-forwarding/#hnoc-forwarding-event-logging","text":"","title":"HNOC Forwarding Event Logging"},{"location":"logging/events/3-HNOC-forwarding/#process-workflows","text":"","title":"Process Workflows"},{"location":"logging/events/3-HNOC-forwarding/#list-of-decisions-made-by-the-hnoc-forwarding-system","text":"","title":"List of Decisions made by the HNOC forwarding System"},{"location":"logging/events/3-HNOC-forwarding/#hnoc-forwarding-queue","text":"","title":"HNOC forwarding queue"},{"location":"logging/events/3-HNOC-forwarding/#start-of-hnoc-forwarding-workflow-so","text":"1. Service outage detected 2. Attempt to create ticket outage Create new SO ticket Reopen exist ticket 3. If exist ticket and have more than 60 min Forward HNOC END 4. New ticket created Append triage note 5. If edge outage Forward to HNOC END 6. If link outage Check if more than 60 minutes","title":"Start of  HNOC forwarding workflow (SO)"},{"location":"logging/events/3-HNOC-forwarding/#start-of-hnoc-forwarding-workflow-sa","text":"1. Service affecting trouble detected Not SA ticket for device SA ticket for device 2. Not SA ticket Create new SA ticket and append note 3. SA ticket exist Reopen SA ticket and append note 4 Wait 60 seconds and forward to HNOC","title":"Start of  HNOC forwarding workflow (SA)"},{"location":"logging/events/3-HNOC-forwarding/#event-descriptions","text":"","title":"Event Descriptions"},{"location":"logging/events/3-HNOC-forwarding/#hnoc-forwarding-outage-queue","text":"_attempt_ticket_creation","title":"HNOC forwarding outage queue"},{"location":"logging/events/3-HNOC-forwarding/#event-descriptions_1","text":"","title":"Event Descriptions"},{"location":"logging/events/3-HNOC-forwarding/#hnoc-forwarding-affecting-queue","text":"_attempt_ticket_creation","title":"HNOC forwarding affecting queue"},{"location":"logging/events/4-SA-forward-to-ASR/","text":"IPA Event Logging Process Workflows List of Decisions made by the IPA System Service Affecting Circuit Instability 1. Check for existing SA ticket for SD-WAN SA ticket does not exist for SD-WAN Resolved SA ticket exists for SD-WAN Open/In progress SA ticket exist for SD-WAN 2. Check for other troubles on the ticket Other trouble is documented on ticket. (Jitter, Latency, Packet Loss, Bandwidth) Only Circuit Instability is the only documented trouble on the ticket 3. Checking what kind of link the instability was detected on Instability was detected for Wireless Link Instability was detected for Wired Link 4. Checking wired link's name for BYOB or Customer Owned Wired Link name contains BYOB or Customer Owned Wired Link name does NOT contain BYOB or Customer Owned 5. Checking if the wired link name is an IP Wired link name is an IP Wired link name is NOT an IP Event Descriptions Service Affecting Bouncing check","title":"IPA Event Logging"},{"location":"logging/events/4-SA-forward-to-ASR/#ipa-event-logging","text":"","title":"IPA Event Logging"},{"location":"logging/events/4-SA-forward-to-ASR/#process-workflows","text":"","title":"Process Workflows"},{"location":"logging/events/4-SA-forward-to-ASR/#list-of-decisions-made-by-the-ipa-system","text":"","title":"List of Decisions made by the IPA System"},{"location":"logging/events/4-SA-forward-to-ASR/#service-affecting","text":"","title":"Service Affecting"},{"location":"logging/events/4-SA-forward-to-ASR/#circuit-instability","text":"1. Check for existing SA ticket for SD-WAN SA ticket does not exist for SD-WAN Resolved SA ticket exists for SD-WAN Open/In progress SA ticket exist for SD-WAN 2. Check for other troubles on the ticket Other trouble is documented on ticket. (Jitter, Latency, Packet Loss, Bandwidth) Only Circuit Instability is the only documented trouble on the ticket 3. Checking what kind of link the instability was detected on Instability was detected for Wireless Link Instability was detected for Wired Link 4. Checking wired link's name for BYOB or Customer Owned Wired Link name contains BYOB or Customer Owned Wired Link name does NOT contain BYOB or Customer Owned 5. Checking if the wired link name is an IP Wired link name is an IP Wired link name is NOT an IP","title":"Circuit Instability"},{"location":"logging/events/4-SA-forward-to-ASR/#event-descriptions","text":"","title":"Event Descriptions"},{"location":"logging/events/4-SA-forward-to-ASR/#service-affecting_1","text":"Bouncing check","title":"Service Affecting"},{"location":"logging/events/5-TNBA-monitor/","text":"1. <G ent Logging Process Workflows List of Decisions made by the TNBA Monitor 1. Get TNBA prediction for SD-WAN task Prediction not repair request complete Prediction repair request complete Ticket is not outage Ticket is outage Ticket is not created by IPA Ticket created by IPA Confidence level is < 80 Confidence level is > 80 2. Append prediction note SD-WAN - - 3. Check status SD-WAN Edge or link not online Edge and links online 4. TBD - - 5. Autoresolve SD-WAN task - - 6. Append A.I. resolve note - - Start of TNBA Monitor Event description Start TNBA automated process","title":"5 TNBA monitor"},{"location":"logging/events/5-TNBA-monitor/#process-workflows","text":"","title":"Process Workflows"},{"location":"logging/events/5-TNBA-monitor/#list-of-decisions-made-by-the-tnba-monitor","text":"1. Get TNBA prediction for SD-WAN task Prediction not repair request complete Prediction repair request complete Ticket is not outage Ticket is outage Ticket is not created by IPA Ticket created by IPA Confidence level is < 80 Confidence level is > 80 2. Append prediction note SD-WAN - - 3. Check status SD-WAN Edge or link not online Edge and links online 4. TBD - - 5. Autoresolve SD-WAN task - - 6. Append A.I. resolve note - -","title":"List of Decisions made by the TNBA Monitor"},{"location":"logging/events/5-TNBA-monitor/#start-of-tnba-monitor","text":"","title":"Start of TNBA Monitor"},{"location":"logging/events/5-TNBA-monitor/#event-description","text":"Start TNBA automated process","title":"Event description"},{"location":"logging/events/6-ticket-severity/","text":"Ticket severity Process Workflows List of Decisions made by ticket severity Ticket Severity Start of change ticket severity 1. Outage condition is detected Edge DOWN Link DOWN Edge Down 1. Attempt to create a service Outage bruin ticket Status 200, 409, 473, 472, 471 2. Set ticket severity 2 END Link Down 1. Attempt to create a service Outage bruin ticket Status 200 or 473 Status 409, 472 or 471 2. For status 200 or 473 Set ticket severity 3 - 3. For status 409, 472 or 471 Ticket with only 1 Task set severity 3 If ticket have more than 1 task end Autoresolution Event Descriptions Attempt ticket creation","title":"Ticket severity"},{"location":"logging/events/6-ticket-severity/#ticket-severity","text":"","title":"Ticket severity"},{"location":"logging/events/6-ticket-severity/#process-workflows","text":"","title":"Process Workflows"},{"location":"logging/events/6-ticket-severity/#list-of-decisions-made-by-ticket-severity","text":"","title":"List of Decisions made by ticket severity"},{"location":"logging/events/6-ticket-severity/#ticket-severity_1","text":"","title":"Ticket Severity"},{"location":"logging/events/6-ticket-severity/#start-of-change-ticket-severity","text":"1. Outage condition is detected Edge DOWN Link DOWN","title":"Start of change ticket severity"},{"location":"logging/events/6-ticket-severity/#edge-down","text":"1. Attempt to create a service Outage bruin ticket Status 200, 409, 473, 472, 471 2. Set ticket severity 2 END","title":"Edge Down"},{"location":"logging/events/6-ticket-severity/#link-down","text":"1. Attempt to create a service Outage bruin ticket Status 200 or 473 Status 409, 472 or 471 2. For status 200 or 473 Set ticket severity 3 - 3. For status 409, 472 or 471 Ticket with only 1 Task set severity 3 If ticket have more than 1 task end","title":"Link Down"},{"location":"logging/events/6-ticket-severity/#autoresolution","text":"","title":"Autoresolution"},{"location":"logging/events/6-ticket-severity/#event-descriptions","text":"Attempt ticket creation","title":"Event Descriptions"},{"location":"logging/events/7-ticket-creation-outcome/","text":"","title":"7 ticket creation outcome"},{"location":"logging/events/8-service-affecting/","text":"Service affecting Event Logging Process Workflows List of Decisions made by the service affecting System Service affecting queue Start of service affecting workflow 1. Detected service trouble SD-WAN 2. Check if exist ticket No new, in progress or resolved ticket created Exist a resolve ticket New or in progress exist 3. If no exist ticket Create ticket and append note for trouble 4. If resolved ticket exist Reopen ticket and append note for trouble 5. If exist in progress ticket Check if is the same problem, if is the same end process If not the same trouble append new note Event Descriptions Service affecting queue _attempt_ticket_creation","title":"Service affecting Event Logging"},{"location":"logging/events/8-service-affecting/#service-affecting-event-logging","text":"","title":"Service affecting Event Logging"},{"location":"logging/events/8-service-affecting/#process-workflows","text":"","title":"Process Workflows"},{"location":"logging/events/8-service-affecting/#list-of-decisions-made-by-the-service-affecting-system","text":"","title":"List of Decisions made by the service affecting System"},{"location":"logging/events/8-service-affecting/#service-affecting-queue","text":"","title":"Service affecting queue"},{"location":"logging/events/8-service-affecting/#start-of-service-affecting-workflow","text":"1. Detected service trouble SD-WAN 2. Check if exist ticket No new, in progress or resolved ticket created Exist a resolve ticket New or in progress exist 3. If no exist ticket Create ticket and append note for trouble 4. If resolved ticket exist Reopen ticket and append note for trouble 5. If exist in progress ticket Check if is the same problem, if is the same end process If not the same trouble append new note","title":"Start of  service affecting workflow"},{"location":"logging/events/8-service-affecting/#event-descriptions","text":"","title":"Event Descriptions"},{"location":"logging/events/8-service-affecting/#service-affecting-queue_1","text":"_attempt_ticket_creation","title":"Service affecting queue"},{"location":"logging/events/9-intermapper-monitor/","text":"Intermapper Event Logging Description The mission of this service is to analyze InterMapper events sent by one or more InterMapper instances via e-mail, where each event refers to a device. The outcome of the analysis will determine whether: * A new Bruin ticket is created, if the device is down. * An existing Bruin ticket is re-opened, if the device is down and the ticket is resolved. * An existing Bruin ticket is auto-resolved, if the device is up and the ticket is open. When any of these cases take place, the event information is added to the ticket as a note. In some cases, this note can be enriched with information from the DRI system. Whatever the outcome of the analysis is, the event is finally marked as processed. Process Workflows List of Decisions made by the Intermapper Monitor Process E-mail Batch workflow Condition Decision Decision 1 Check for Circuit ID existence in e-mail Circuit ID is defined Circuit ID is undefined 2 Check for Circuit ID being an SD-WAN Circuit ID is not SD-WAN Circuit ID is SD-WAN Process E-mail workflow Condition Decision Decision Decision 1 Check for Event Type Event type is Alarm, Critical, Warning, Down or Link Warning Event type is Up or OK Event Type is any other Ticket Creation workflow Condition Decision Decision 1 Check for Probe Type Probe Type is Data Remote Probe Type is NOT Data Remote 2 Check to see if we can retrieve data from DRI Successfully retrieved data from DRI for Inventory Could not retrieve any data for inventory from DRI 3 Check to see if another DOWN event note with the same Condition has already been appended since the latest re-open Note with same Condition has already been appended since the latest re-open Note with same Condition has NOT been appended since the latest re-open 4 Check Probe Type and Condition of event Probe Type is Data Remote Probe AND Condition is Device Lost Power - Battery is in use Probe Type is NOT Data Remote Probe or Condition is NOT Device Lost Power - Battery is in use Auto-Resolution workflow Condition Decision Decision 1 Check to see if another UP event note with the same Condition has already been appended since the latest re-open Note with same Condition has already been appended since the latest re-open Note with same Condition has NOT been appended since the latest re-open 2 Check to see if ticket's product category is in the whitelist Ticket's product category is whitelisted Ticket's product category is NOT whitelisted 3 Check for time at impacted site Time at impacted site is between 12am and 6am (NIGHT) Time at impacted site is between 6am and 12am (DAY) 4 Check if time passed is more or less than 3 hrs (NIGHT) Less than 3 hrs have passed since an outage has been documented More than 3 hrs have passed since an outage has been documented 5 Check if time passed is more or less than 90 min (DAY) Less than 90 min have passed since an outage has been documented More than 90 min have passed since an outage has been documented 6 Check if max auto-resolves threshold has been exceeded Ticket has been auto-resolved less than 3 times Ticket has been auto-resolved 3+ times already 7 Check if ticket is resolved Ticket is resolved already Ticket is not resolved Event Descriptions Start InterMapper Outage Monitoring start_intermapper_outage_monitoring Process E-mail Batch _process_email_batch Process E-mail _process_email Ticket Creation _create_outage_ticket Auto-Resolution _autoresolve_ticket","title":"Intermapper Event Logging"},{"location":"logging/events/9-intermapper-monitor/#intermapper-event-logging","text":"","title":"Intermapper Event Logging"},{"location":"logging/events/9-intermapper-monitor/#description","text":"The mission of this service is to analyze InterMapper events sent by one or more InterMapper instances via e-mail, where each event refers to a device. The outcome of the analysis will determine whether: * A new Bruin ticket is created, if the device is down. * An existing Bruin ticket is re-opened, if the device is down and the ticket is resolved. * An existing Bruin ticket is auto-resolved, if the device is up and the ticket is open. When any of these cases take place, the event information is added to the ticket as a note. In some cases, this note can be enriched with information from the DRI system. Whatever the outcome of the analysis is, the event is finally marked as processed.","title":"Description"},{"location":"logging/events/9-intermapper-monitor/#process-workflows","text":"","title":"Process Workflows"},{"location":"logging/events/9-intermapper-monitor/#list-of-decisions-made-by-the-intermapper-monitor","text":"","title":"List of Decisions made by the Intermapper Monitor"},{"location":"logging/events/9-intermapper-monitor/#process-e-mail-batch-workflow","text":"Condition Decision Decision 1 Check for Circuit ID existence in e-mail Circuit ID is defined Circuit ID is undefined 2 Check for Circuit ID being an SD-WAN Circuit ID is not SD-WAN Circuit ID is SD-WAN","title":"Process E-mail Batch workflow"},{"location":"logging/events/9-intermapper-monitor/#process-e-mail-workflow","text":"Condition Decision Decision Decision 1 Check for Event Type Event type is Alarm, Critical, Warning, Down or Link Warning Event type is Up or OK Event Type is any other","title":"Process E-mail workflow"},{"location":"logging/events/9-intermapper-monitor/#ticket-creation-workflow","text":"Condition Decision Decision 1 Check for Probe Type Probe Type is Data Remote Probe Type is NOT Data Remote 2 Check to see if we can retrieve data from DRI Successfully retrieved data from DRI for Inventory Could not retrieve any data for inventory from DRI 3 Check to see if another DOWN event note with the same Condition has already been appended since the latest re-open Note with same Condition has already been appended since the latest re-open Note with same Condition has NOT been appended since the latest re-open 4 Check Probe Type and Condition of event Probe Type is Data Remote Probe AND Condition is Device Lost Power - Battery is in use Probe Type is NOT Data Remote Probe or Condition is NOT Device Lost Power - Battery is in use","title":"Ticket Creation workflow"},{"location":"logging/events/9-intermapper-monitor/#auto-resolution-workflow","text":"Condition Decision Decision 1 Check to see if another UP event note with the same Condition has already been appended since the latest re-open Note with same Condition has already been appended since the latest re-open Note with same Condition has NOT been appended since the latest re-open 2 Check to see if ticket's product category is in the whitelist Ticket's product category is whitelisted Ticket's product category is NOT whitelisted 3 Check for time at impacted site Time at impacted site is between 12am and 6am (NIGHT) Time at impacted site is between 6am and 12am (DAY) 4 Check if time passed is more or less than 3 hrs (NIGHT) Less than 3 hrs have passed since an outage has been documented More than 3 hrs have passed since an outage has been documented 5 Check if time passed is more or less than 90 min (DAY) Less than 90 min have passed since an outage has been documented More than 90 min have passed since an outage has been documented 6 Check if max auto-resolves threshold has been exceeded Ticket has been auto-resolved less than 3 times Ticket has been auto-resolved 3+ times already 7 Check if ticket is resolved Ticket is resolved already Ticket is not resolved","title":"Auto-Resolution workflow"},{"location":"logging/events/9-intermapper-monitor/#event-descriptions","text":"","title":"Event Descriptions"},{"location":"logging/events/9-intermapper-monitor/#start-intermapper-outage-monitoring","text":"start_intermapper_outage_monitoring","title":"Start InterMapper Outage Monitoring"},{"location":"logging/events/9-intermapper-monitor/#process-e-mail-batch","text":"_process_email_batch","title":"Process E-mail Batch"},{"location":"logging/events/9-intermapper-monitor/#process-e-mail","text":"_process_email","title":"Process E-mail"},{"location":"logging/events/9-intermapper-monitor/#ticket-creation","text":"_create_outage_ticket","title":"Ticket Creation"},{"location":"logging/events/9-intermapper-monitor/#auto-resolution","text":"_autoresolve_ticket","title":"Auto-Resolution"},{"location":"logging/services/TNBA-monitor/actions/_append_tnba_notes/","text":"Append tnba notes for ticket id in notes ticket id: self._logger.info(f\"Appending {len(notes)} TNBA notes to ticket {ticket_id}...\") append_multiple_notes_to_ticket If append multiple notes status is not OK: self._logger.warning(f\"Bad status calling append multiple notes to ticket id: {ticket_id}.\" f\" Skipping ...\")","title":" append tnba notes"},{"location":"logging/services/TNBA-monitor/actions/_append_tnba_notes/#append-tnba-notes","text":"for ticket id in notes ticket id: self._logger.info(f\"Appending {len(notes)} TNBA notes to ticket {ticket_id}...\") append_multiple_notes_to_ticket If append multiple notes status is not OK: self._logger.warning(f\"Bad status calling append multiple notes to ticket id: {ticket_id}.\" f\" Skipping ...\")","title":"Append tnba notes"},{"location":"logging/services/TNBA-monitor/actions/_autoresolve_ticket_detail/","text":"Autoresolve ticket detail self._logger.info(f\"Running autoresolve for serial {serial_number} of ticket {ticket_id}...\") * If ticket created by automation engine: self._logger.info( f\"Ticket {ticket_id}, where serial {serial_number} is, was not created by Automation Engine. \" \"Skipping autoresolve...\" ) * If is detail in outage ticket: self._logger.info( f\"Serial {serial_number} of ticket {ticket_id} is in outage state. Skipping autoresolve...\" ) * If is detail in affecting ticket and are all metrics within thresholds: self._logger.info( f\"At least one metric from serial {serial_number} of ticket {ticket_id} is not within the threshold.\" f\" Skipping autoresolve...\" ) * If prediction is not confident enough: self._logger.info( f\"The confidence of the best prediction found for ticket {ticket_id}, where serial {serial_number} is, \" f\"did not exceed the minimum threshold. Skipping autoresolve...\" ) * If environment is not PRODUCTION: self._logger.info( f\"Detail related to serial {serial_number} of ticket {ticket_id} was about to be resolved, but the \" f\"current environment is {self._config.CURRENT_ENVIRONMENT.upper()}. Skipping autoresolve...\" ) * unpause_ticket_detail * resolve_ticket_detail * If resolve ticket detail status is not Ok: self._logger.warning(f\"Bad status calling resolve ticket detail for ticket id: {ticket_id} \" f\"and ticket detail id: {ticket_detail_id} . Skipping resolve ticket detail\")","title":" autoresolve ticket detail"},{"location":"logging/services/TNBA-monitor/actions/_autoresolve_ticket_detail/#autoresolve-ticket-detail","text":"self._logger.info(f\"Running autoresolve for serial {serial_number} of ticket {ticket_id}...\") * If ticket created by automation engine: self._logger.info( f\"Ticket {ticket_id}, where serial {serial_number} is, was not created by Automation Engine. \" \"Skipping autoresolve...\" ) * If is detail in outage ticket: self._logger.info( f\"Serial {serial_number} of ticket {ticket_id} is in outage state. Skipping autoresolve...\" ) * If is detail in affecting ticket and are all metrics within thresholds: self._logger.info( f\"At least one metric from serial {serial_number} of ticket {ticket_id} is not within the threshold.\" f\" Skipping autoresolve...\" ) * If prediction is not confident enough: self._logger.info( f\"The confidence of the best prediction found for ticket {ticket_id}, where serial {serial_number} is, \" f\"did not exceed the minimum threshold. Skipping autoresolve...\" ) * If environment is not PRODUCTION: self._logger.info( f\"Detail related to serial {serial_number} of ticket {ticket_id} was about to be resolved, but the \" f\"current environment is {self._config.CURRENT_ENVIRONMENT.upper()}. Skipping autoresolve...\" ) * unpause_ticket_detail * resolve_ticket_detail * If resolve ticket detail status is not Ok: self._logger.warning(f\"Bad status calling resolve ticket detail for ticket id: {ticket_id} \" f\"and ticket detail id: {ticket_detail_id} . Skipping resolve ticket detail\")","title":"Autoresolve ticket detail"},{"location":"logging/services/TNBA-monitor/actions/_filter_outage_ticket_details_based_on_last_outage/","text":"Filter outage ticket details based on last outage for ticket detail in tickets details: If is outage ticket and last outage detected recently: self._logger.info( f\"Last outage detected for serial {serial_number} in Service Outage ticket {ticket_id} is \" \"too recent. Skipping...\" )","title":" filter outage ticket details based on last outage"},{"location":"logging/services/TNBA-monitor/actions/_filter_outage_ticket_details_based_on_last_outage/#filter-outage-ticket-details-based-on-last-outage","text":"for ticket detail in tickets details: If is outage ticket and last outage detected recently: self._logger.info( f\"Last outage detected for serial {serial_number} in Service Outage ticket {ticket_id} is \" \"too recent. Skipping...\" )","title":"Filter outage ticket details based on last outage"},{"location":"logging/services/TNBA-monitor/actions/_filter_tickets_and_details_related_to_edges_under_monitoring/","text":"Filter tickets and details related to edges under monitoring for ticket in tickets If not relevant ticket: self._logger.warning(f\"Don't found relevant tickets. Skipping ticket ...\")","title":" filter tickets and details related to edges under monitoring"},{"location":"logging/services/TNBA-monitor/actions/_filter_tickets_and_details_related_to_edges_under_monitoring/#filter-tickets-and-details-related-to-edges-under-monitoring","text":"for ticket in tickets If not relevant ticket: self._logger.warning(f\"Don't found relevant tickets. Skipping ticket ...\")","title":"Filter tickets and details related to edges under monitoring"},{"location":"logging/services/TNBA-monitor/actions/_get_all_open_tickets_with_details_for_monitored_companies/","text":"Get all open tickets with details for monitored companies _get_open_tickets_with_details_by_client_id","title":" get all open tickets with details for monitored companies"},{"location":"logging/services/TNBA-monitor/actions/_get_all_open_tickets_with_details_for_monitored_companies/#get-all-open-tickets-with-details-for-monitored-companies","text":"_get_open_tickets_with_details_by_client_id","title":"Get all open tickets with details for monitored companies"},{"location":"logging/services/TNBA-monitor/actions/_get_open_tickets_with_details_by_client_id/","text":"Get open tickets with details by client id get_open_outage_tickets If bad status calling to get outage tickets: self._logger.warning(f\"Bad status calling to get outage tickets. Return empty list ...\") get_open_affecting_tickets self._logger.warning(f\"Bad status calling to get affecting tickets. Return empty list ...\") self._logger.info(f\"Getting all opened tickets for Bruin customer {client_id}...\") For ticket in all tickets: get_ticket_details.md self._logger.warning(f\"Bad status calling to get tickets details with id: {ticket_id}.\" f\"Skipping ticket ...\") If not ticket details: self._logger.info( f\"Ticket {ticket_id} doesn't have any detail under ticketDetails key. \" f\"Skipping...\" ) self._logger.info(f\"Got details for ticket {ticket_id} of Bruin customer {client_id}!\") self._logger.info(f\"Finished getting all opened tickets for Bruin customer {client_id}!\") If Exception: self._logger.error( f\"An error occurred while trying to get open tickets with details for Bruin client {client_id} -> {e}\" )","title":" get open tickets with details by client id"},{"location":"logging/services/TNBA-monitor/actions/_get_open_tickets_with_details_by_client_id/#get-open-tickets-with-details-by-client-id","text":"get_open_outage_tickets If bad status calling to get outage tickets: self._logger.warning(f\"Bad status calling to get outage tickets. Return empty list ...\") get_open_affecting_tickets self._logger.warning(f\"Bad status calling to get affecting tickets. Return empty list ...\") self._logger.info(f\"Getting all opened tickets for Bruin customer {client_id}...\") For ticket in all tickets: get_ticket_details.md self._logger.warning(f\"Bad status calling to get tickets details with id: {ticket_id}.\" f\"Skipping ticket ...\") If not ticket details: self._logger.info( f\"Ticket {ticket_id} doesn't have any detail under ticketDetails key. \" f\"Skipping...\" ) self._logger.info(f\"Got details for ticket {ticket_id} of Bruin customer {client_id}!\") self._logger.info(f\"Finished getting all opened tickets for Bruin customer {client_id}!\") If Exception: self._logger.error( f\"An error occurred while trying to get open tickets with details for Bruin client {client_id} -> {e}\" )","title":"Get open tickets with details by client id"},{"location":"logging/services/TNBA-monitor/actions/_get_predictions_by_ticket_id/","text":"Get predictions by ticket id for ticket in tickets: self._logger.info(f\"Claiming T7 predictions for ticket {ticket_id}...\") get_ticket_task_history self._logger.warning(f\"Bad status calling to get ticket history. \" f\"Skipping for ticket id: {ticket_id} ...\") If any ticket row has asset: self._logger.info(f\"Task history of ticket {ticket_id} doesn't have any asset. Skipping...\") get_prediction self._logger.warning(f\"Bad status calling to t7 predictions. \" f\"Skipping predictions for ticket id: {ticket_id}\") If not predictions: self._logger.info(f\"There are no predictions for ticket {ticket_id}. Skipping...\") self._logger.info(f\"T7 predictions found for ticket {ticket_id}!\")","title":" get predictions by ticket id"},{"location":"logging/services/TNBA-monitor/actions/_get_predictions_by_ticket_id/#get-predictions-by-ticket-id","text":"for ticket in tickets: self._logger.info(f\"Claiming T7 predictions for ticket {ticket_id}...\") get_ticket_task_history self._logger.warning(f\"Bad status calling to get ticket history. \" f\"Skipping for ticket id: {ticket_id} ...\") If any ticket row has asset: self._logger.info(f\"Task history of ticket {ticket_id} doesn't have any asset. Skipping...\") get_prediction self._logger.warning(f\"Bad status calling to t7 predictions. \" f\"Skipping predictions for ticket id: {ticket_id}\") If not predictions: self._logger.info(f\"There are no predictions for ticket {ticket_id}. Skipping...\") self._logger.info(f\"T7 predictions found for ticket {ticket_id}!\")","title":"Get predictions by ticket id"},{"location":"logging/services/TNBA-monitor/actions/_map_ticket_details_with_predictions/","text":"Map ticket details with predictions for detail obj in detail ticket details: If not predictions for ticket: self._logger.info( f\"Ticket {ticket_id} does not have any prediction associated. Skipping serial \" f\"{serial_number}...\" ) If not prediction object for related serial: self._logger.info( f\"No predictions were found for ticket {ticket_id} and serial {serial_number}. Skipping...\" )","title":" map ticket details with predictions"},{"location":"logging/services/TNBA-monitor/actions/_map_ticket_details_with_predictions/#map-ticket-details-with-predictions","text":"for detail obj in detail ticket details: If not predictions for ticket: self._logger.info( f\"Ticket {ticket_id} does not have any prediction associated. Skipping serial \" f\"{serial_number}...\" ) If not prediction object for related serial: self._logger.info( f\"No predictions were found for ticket {ticket_id} and serial {serial_number}. Skipping...\" )","title":"Map ticket details with predictions"},{"location":"logging/services/TNBA-monitor/actions/_process_ticket_detail/","text":"Process ticket detail self._logger.info( f\"Processing detail {ticket_detail_id} (serial: {serial_number}) of ticket {ticket_id}...\" ) If is a tnba note and tnba note is not old enough: self._logger.info( f\"TNBA note found for ticket {ticket_id} and detail {ticket_detail_id} is too recent. \" f\"Skipping detail...\" ) get_next_results_for_ticket_detail If get next result for ticket detail status is not ok: self._logger.warning(f\"Bad status calling get next result for ticket details.\" f\"Skipping process ticket details for ticket id: {ticket_id} and\" f\"ticket detail id: {ticket_detail_id}\") self._logger.info( f\"Filtering predictions available in next results for ticket {ticket_id}, \" f\"detail {ticket_detail_id} and serial {serial_number}...\" ) If not relevant predictions: self._logger.info(f\"No predictions with name appearing in the next results were found for ticket {ticket_id}, \" f\"detail {ticket_detail_id} and serial {serial_number}!\") self._logger.info( f\"Predictions available in next results found for ticket {ticket_id}, detail {ticket_detail_id} \" f\"and serial {serial_number}: {relevant_predictions}\" ) If newest note: If best prediction different that the ticket note: self._logger.info( f\"Best prediction for ticket {ticket_id}, detail {ticket_detail_id} and serial {serial_number} \" f\"didn't change since the last TNBA note was appended. Skipping detail...\" ) self._logger.info( f\"Building TNBA note from prediction {best_prediction['name']} for ticket {ticket_id}, \" f\"detail {ticket_detail_id} and serial {serial_number}...\" ) If request or repair completed prediction: self._logger.info( f\"Best prediction found for serial {serial_number} of ticket {ticket_id} is \" f'{best_prediction[\"name\"]}. Running autoresolve...' ) _autoresolve_ticket_detail If autoresolve status is SUCCESS: post_live_automation_metrics If autoresolve status is SKIPPED: self._logger.info( f\"Autoresolve was triggered because the best prediction found for serial {serial_number} of \" f'ticket {ticket_id} was {best_prediction[\"name\"]}, but the process failed. A TNBA note with ' \"this prediction will be built and appended to the ticket later on.\" ) IF autoresolve status is BAD_PREDICTION: post_live_automation_metrics self._logger.info( f\"The prediction for serial {serial_number} of ticket {ticket_id} is considered wrong.\" ) If not TNBA note: self._logger.info(f\"No TNBA note will be appended for serial {serial_number} of ticket {ticket_id}.\") If environment DEV: self._logger.info(f\"TNBA note would have been appended to ticket {ticket_id} and detail {ticket_detail_id} \" f\"(serial: {serial_number}). Note: {tnba_note}. Details at app.bruin.com/t/{ticket_id}\") self._logger.info( f\"Finished processing detail {ticket_detail_id} (serial: {serial_number}) of ticket {ticket_id}!\" )","title":" process ticket detail"},{"location":"logging/services/TNBA-monitor/actions/_process_ticket_detail/#process-ticket-detail","text":"self._logger.info( f\"Processing detail {ticket_detail_id} (serial: {serial_number}) of ticket {ticket_id}...\" ) If is a tnba note and tnba note is not old enough: self._logger.info( f\"TNBA note found for ticket {ticket_id} and detail {ticket_detail_id} is too recent. \" f\"Skipping detail...\" ) get_next_results_for_ticket_detail If get next result for ticket detail status is not ok: self._logger.warning(f\"Bad status calling get next result for ticket details.\" f\"Skipping process ticket details for ticket id: {ticket_id} and\" f\"ticket detail id: {ticket_detail_id}\") self._logger.info( f\"Filtering predictions available in next results for ticket {ticket_id}, \" f\"detail {ticket_detail_id} and serial {serial_number}...\" ) If not relevant predictions: self._logger.info(f\"No predictions with name appearing in the next results were found for ticket {ticket_id}, \" f\"detail {ticket_detail_id} and serial {serial_number}!\") self._logger.info( f\"Predictions available in next results found for ticket {ticket_id}, detail {ticket_detail_id} \" f\"and serial {serial_number}: {relevant_predictions}\" ) If newest note: If best prediction different that the ticket note: self._logger.info( f\"Best prediction for ticket {ticket_id}, detail {ticket_detail_id} and serial {serial_number} \" f\"didn't change since the last TNBA note was appended. Skipping detail...\" ) self._logger.info( f\"Building TNBA note from prediction {best_prediction['name']} for ticket {ticket_id}, \" f\"detail {ticket_detail_id} and serial {serial_number}...\" ) If request or repair completed prediction: self._logger.info( f\"Best prediction found for serial {serial_number} of ticket {ticket_id} is \" f'{best_prediction[\"name\"]}. Running autoresolve...' ) _autoresolve_ticket_detail If autoresolve status is SUCCESS: post_live_automation_metrics If autoresolve status is SKIPPED: self._logger.info( f\"Autoresolve was triggered because the best prediction found for serial {serial_number} of \" f'ticket {ticket_id} was {best_prediction[\"name\"]}, but the process failed. A TNBA note with ' \"this prediction will be built and appended to the ticket later on.\" ) IF autoresolve status is BAD_PREDICTION: post_live_automation_metrics self._logger.info( f\"The prediction for serial {serial_number} of ticket {ticket_id} is considered wrong.\" ) If not TNBA note: self._logger.info(f\"No TNBA note will be appended for serial {serial_number} of ticket {ticket_id}.\") If environment DEV: self._logger.info(f\"TNBA note would have been appended to ticket {ticket_id} and detail {ticket_detail_id} \" f\"(serial: {serial_number}). Note: {tnba_note}. Details at app.bruin.com/t/{ticket_id}\") self._logger.info( f\"Finished processing detail {ticket_detail_id} (serial: {serial_number}) of ticket {ticket_id}!\" )","title":"Process ticket detail"},{"location":"logging/services/TNBA-monitor/actions/_remove_erroneous_predictions/","text":"Remove erroneous predictions for ticket in prediction tickets: for prediction in predictions: If error in prediction: self._logger.info( f\"Prediction for serial {serial_number} in ticket {ticket_id} was found but it contains an \" f\"error from T7 API -> {prediction_obj['error']}\" ) If not valid prediction: self._logger.info(f\"All predictions in ticket {ticket_id} were erroneous. Skipping ticket...\")","title":" remove erroneous predictions"},{"location":"logging/services/TNBA-monitor/actions/_remove_erroneous_predictions/#remove-erroneous-predictions","text":"for ticket in prediction tickets: for prediction in predictions: If error in prediction: self._logger.info( f\"Prediction for serial {serial_number} in ticket {ticket_id} was found but it contains an \" f\"error from T7 API -> {prediction_obj['error']}\" ) If not valid prediction: self._logger.info(f\"All predictions in ticket {ticket_id} were erroneous. Skipping ticket...\")","title":"Remove erroneous predictions"},{"location":"logging/services/TNBA-monitor/actions/_run_tickets_polling/","text":"Run tickets polling self._logger.info(\"Starting TNBA process...\") * get_cache_for_tnba_monitoring * If get cache status is not Ok: self._logger.warning(f\"Bad status calling to get cache. Skipping run ticket polling ...\") * get_edges_for_tnba_monitoring * If not edges statuses: self._logger.error(\"No edges statuses were received from VeloCloud. Aborting TNBA monitoring...\") self._logger.info(\"Keeping serials that exist in both the customer cache and the set of edges statuses...\") * get_links_metrics_for_autoresolve * If not link metrics: self._logger.info(\"List of links metrics arrived empty. Skipping...\") * get_events_by_serial_and_interface self._logger.info(\"Loading customer cache and edges statuses by serial into the monitor instance...\") self._logger.info(\"Getting all open tickets for all customers...\") * _get_all_open_tickets_with_details_for_monitored_companies self._logger.info( f\"Got {len(open_tickets)} open tickets for all customers. \" f\"Filtering them (and their details) to get only the ones under the device list\" ) * _filter_tickets_and_details_related_to_edges_under_monitoring self._logger.info( f\"Got {len(relevant_open_tickets)} relevant tickets for all customers. \" f\"Cleaning them up to exclude all invalid notes...\" ) self._logger.info(\"Getting T7 predictions for all relevant open tickets...\") * _get_predictions_by_ticket_id self._logger.info(\"Removing erroneous T7 predictions...\") * _remove_erroneous_predictions self._logger.info(\"Creating detail objects based on all tickets...\") self._logger.info(\"Discarding resolved ticket details...\") self._logger.info(\"Discarding ticket details of outage tickets whose last outage happened too recently...\") * _filter_outage_ticket_details_based_on_last_outage self._logger.info(\"Mapping all ticket details with their predictions...\") * _map_ticket_details_with_predictions self._logger.info( f\"{len(ticket_detail_objects)} ticket details were successfully mapped to predictions. \" \"Processing all details...\" ) * _process_ticket_detail self._logger.info(\"All ticket details were processed.\") * If not append notes TNBA: self._logger.info(\"No TNBA notes for append were built for any detail processed.\") * Else: self._logger.info(f\"{len(self._tnba_notes_to_append)} TNBA notes were built for append.\") * _append_tnba_notes self._logger.info(f\"TNBA process finished! Took {round((end_time - start_time) / 60, 2)} minutes.\")","title":" run tickets polling"},{"location":"logging/services/TNBA-monitor/actions/_run_tickets_polling/#run-tickets-polling","text":"self._logger.info(\"Starting TNBA process...\") * get_cache_for_tnba_monitoring * If get cache status is not Ok: self._logger.warning(f\"Bad status calling to get cache. Skipping run ticket polling ...\") * get_edges_for_tnba_monitoring * If not edges statuses: self._logger.error(\"No edges statuses were received from VeloCloud. Aborting TNBA monitoring...\") self._logger.info(\"Keeping serials that exist in both the customer cache and the set of edges statuses...\") * get_links_metrics_for_autoresolve * If not link metrics: self._logger.info(\"List of links metrics arrived empty. Skipping...\") * get_events_by_serial_and_interface self._logger.info(\"Loading customer cache and edges statuses by serial into the monitor instance...\") self._logger.info(\"Getting all open tickets for all customers...\") * _get_all_open_tickets_with_details_for_monitored_companies self._logger.info( f\"Got {len(open_tickets)} open tickets for all customers. \" f\"Filtering them (and their details) to get only the ones under the device list\" ) * _filter_tickets_and_details_related_to_edges_under_monitoring self._logger.info( f\"Got {len(relevant_open_tickets)} relevant tickets for all customers. \" f\"Cleaning them up to exclude all invalid notes...\" ) self._logger.info(\"Getting T7 predictions for all relevant open tickets...\") * _get_predictions_by_ticket_id self._logger.info(\"Removing erroneous T7 predictions...\") * _remove_erroneous_predictions self._logger.info(\"Creating detail objects based on all tickets...\") self._logger.info(\"Discarding resolved ticket details...\") self._logger.info(\"Discarding ticket details of outage tickets whose last outage happened too recently...\") * _filter_outage_ticket_details_based_on_last_outage self._logger.info(\"Mapping all ticket details with their predictions...\") * _map_ticket_details_with_predictions self._logger.info( f\"{len(ticket_detail_objects)} ticket details were successfully mapped to predictions. \" \"Processing all details...\" ) * _process_ticket_detail self._logger.info(\"All ticket details were processed.\") * If not append notes TNBA: self._logger.info(\"No TNBA notes for append were built for any detail processed.\") * Else: self._logger.info(f\"{len(self._tnba_notes_to_append)} TNBA notes were built for append.\") * _append_tnba_notes self._logger.info(f\"TNBA process finished! Took {round((end_time - start_time) / 60, 2)} minutes.\")","title":"Run tickets polling"},{"location":"logging/services/TNBA-monitor/actions/start_tnba_automated_process/","text":"Start tnba automated process (Start of service) self._logger.info(\"Scheduling TNBA automated process job...\") * If exec on start: self._logger.info(\"TNBA automated process job is going to be executed immediately\") * _run_tickets_polling * If ConflictingIdError: self._logger.info(f\"Skipping start of TNBA automated process job. Reason: {conflict}\")","title":"Start tnba automated process"},{"location":"logging/services/TNBA-monitor/actions/start_tnba_automated_process/#start-tnba-automated-process-start-of-service","text":"self._logger.info(\"Scheduling TNBA automated process job...\") * If exec on start: self._logger.info(\"TNBA automated process job is going to be executed immediately\") * _run_tickets_polling * If ConflictingIdError: self._logger.info(f\"Skipping start of TNBA automated process job. Reason: {conflict}\")","title":"Start tnba automated process (Start of service)"},{"location":"logging/services/TNBA-monitor/repositories/bruin_repository/append_multiple_notes_to_ticket/","text":"Append multiple notes to ticket self._logger.info(f\"Posting multiple notes for ticket {ticket_id}...\") * If Exception: self._logger.error(f\"An error occurred when appending multiple ticket notes to ticket {ticket_id}. \" f\"Notes: {notes}. Error: {e}\") self._logger.info(f\"Posted multiple notes for ticket {ticket_id}!\") * Else: self._logger.error(f\"Error while appending multiple notes to ticket {ticket_id} in \" f\"{self._config.ENVIRONMENT_NAME.upper()} environment. Notes were {notes}. \" f\"Error: Error {response_status} - {response_body}\")","title":"Append multiple notes to ticket"},{"location":"logging/services/TNBA-monitor/repositories/bruin_repository/append_multiple_notes_to_ticket/#append-multiple-notes-to-ticket","text":"self._logger.info(f\"Posting multiple notes for ticket {ticket_id}...\") * If Exception: self._logger.error(f\"An error occurred when appending multiple ticket notes to ticket {ticket_id}. \" f\"Notes: {notes}. Error: {e}\") self._logger.info(f\"Posted multiple notes for ticket {ticket_id}!\") * Else: self._logger.error(f\"Error while appending multiple notes to ticket {ticket_id} in \" f\"{self._config.ENVIRONMENT_NAME.upper()} environment. Notes were {notes}. \" f\"Error: Error {response_status} - {response_body}\")","title":"Append multiple notes to ticket"},{"location":"logging/services/TNBA-monitor/repositories/bruin_repository/get_next_results_for_ticket_detail/","text":"Get next results for ticket detail self._logger.info( f\"Claiming next results for ticket {ticket_id}, detail {detail_id} and \" f\"service number {service_number}...\" ) * If Exception: self._logger.error(f\"An error occurred when claiming next results for ticket {ticket_id}, detail {detail_id} and \" f\"service number {service_number} -> {e}\") self._logger.info( f\"Got next results for ticket {ticket_id}, detail {detail_id} and service number {service_number}!\" ) * If status not 200: self._logger.error(f\"Error while claiming next results for ticket {ticket_id}, detail {detail_id} and \" f\"service number {service_number} in {self._config.ENVIRONMENT_NAME.upper()} environment: \" f\"Error {response_status} - {response_body}\")","title":"Get next results for ticket detail"},{"location":"logging/services/TNBA-monitor/repositories/bruin_repository/get_next_results_for_ticket_detail/#get-next-results-for-ticket-detail","text":"self._logger.info( f\"Claiming next results for ticket {ticket_id}, detail {detail_id} and \" f\"service number {service_number}...\" ) * If Exception: self._logger.error(f\"An error occurred when claiming next results for ticket {ticket_id}, detail {detail_id} and \" f\"service number {service_number} -> {e}\") self._logger.info( f\"Got next results for ticket {ticket_id}, detail {detail_id} and service number {service_number}!\" ) * If status not 200: self._logger.error(f\"Error while claiming next results for ticket {ticket_id}, detail {detail_id} and \" f\"service number {service_number} in {self._config.ENVIRONMENT_NAME.upper()} environment: \" f\"Error {response_status} - {response_body}\")","title":"Get next results for ticket detail"},{"location":"logging/services/TNBA-monitor/repositories/bruin_repository/get_open_affecting_tickets/","text":"Get open affecting tickets get_tickets","title":"Get open affecting tickets"},{"location":"logging/services/TNBA-monitor/repositories/bruin_repository/get_open_affecting_tickets/#get-open-affecting-tickets","text":"get_tickets","title":"Get open affecting tickets"},{"location":"logging/services/TNBA-monitor/repositories/bruin_repository/get_open_outage_tickets/","text":"Get open outage tickets get_outage_tickets","title":"Get open outage tickets"},{"location":"logging/services/TNBA-monitor/repositories/bruin_repository/get_open_outage_tickets/#get-open-outage-tickets","text":"get_outage_tickets","title":"Get open outage tickets"},{"location":"logging/services/TNBA-monitor/repositories/bruin_repository/get_ticket_details/","text":"Get ticket details self._logger.info(f\"Getting details of ticket {ticket_id} from Bruin...\") * If Exception: self._logger.error(f\"An error occurred when requesting ticket details from Bruin API for ticket {ticket_id} -> {e}\") self._logger.info(f\"Got details of ticket {ticket_id} from Bruin!\") * If status not 200: self._logger.error(f\"Error while retrieving details of ticket {ticket_id} in {self._config.CURRENT_ENVIRONMENT.upper()} environment: Error {response_status} - {response_body}\")","title":"Get ticket details"},{"location":"logging/services/TNBA-monitor/repositories/bruin_repository/get_ticket_details/#get-ticket-details","text":"self._logger.info(f\"Getting details of ticket {ticket_id} from Bruin...\") * If Exception: self._logger.error(f\"An error occurred when requesting ticket details from Bruin API for ticket {ticket_id} -> {e}\") self._logger.info(f\"Got details of ticket {ticket_id} from Bruin!\") * If status not 200: self._logger.error(f\"Error while retrieving details of ticket {ticket_id} in {self._config.CURRENT_ENVIRONMENT.upper()} environment: Error {response_status} - {response_body}\")","title":"Get ticket details"},{"location":"logging/services/TNBA-monitor/repositories/bruin_repository/get_ticket_task_history/","text":"Get ticket task history self._logger.info(f\"Getting task history of ticket {ticket_id} from Bruin...\") * If Exception: self._logger.error(f\"An error occurred when requesting task history from Bruin API for ticket {ticket_id} -> {e}\") self._logger.info(f\"Got task history of ticket {ticket_id} from Bruin!\") * If status not 200: self._logger.error(f\"Error while retrieving task history of ticket {ticket_id} in \" f\"{self._config.ENVIRONMENT_NAME.upper()} environment: \" f\"Error {response_status} - {response_body}\")","title":"Get ticket task history"},{"location":"logging/services/TNBA-monitor/repositories/bruin_repository/get_ticket_task_history/#get-ticket-task-history","text":"self._logger.info(f\"Getting task history of ticket {ticket_id} from Bruin...\") * If Exception: self._logger.error(f\"An error occurred when requesting task history from Bruin API for ticket {ticket_id} -> {e}\") self._logger.info(f\"Got task history of ticket {ticket_id} from Bruin!\") * If status not 200: self._logger.error(f\"Error while retrieving task history of ticket {ticket_id} in \" f\"{self._config.ENVIRONMENT_NAME.upper()} environment: \" f\"Error {response_status} - {response_body}\")","title":"Get ticket task history"},{"location":"logging/services/TNBA-monitor/repositories/bruin_repository/get_tickets/","text":"Get ticket self._logger.info(f'Getting all tickets with parameters of {request[\"body\"]} from Bruin...') * If Exception: self._logger.error(f'An error occurred when requesting tickets from Bruin API with parameters of {request[\"body\"]} -> {e}') * If status ok: self._logger.info(f'Got all tickets with parameters of {request[\"body\"]} from Bruin!') * Else: self._logger.error(f'Error while retrieving tickets with parameters of {request[\"body\"]} in ' f\"{self._config.CURRENT_ENVIRONMENT.upper()} environment: \" f\"Error {response_status} - {response_body}\")","title":"Get tickets"},{"location":"logging/services/TNBA-monitor/repositories/bruin_repository/get_tickets/#get-ticket","text":"self._logger.info(f'Getting all tickets with parameters of {request[\"body\"]} from Bruin...') * If Exception: self._logger.error(f'An error occurred when requesting tickets from Bruin API with parameters of {request[\"body\"]} -> {e}') * If status ok: self._logger.info(f'Got all tickets with parameters of {request[\"body\"]} from Bruin!') * Else: self._logger.error(f'Error while retrieving tickets with parameters of {request[\"body\"]} in ' f\"{self._config.CURRENT_ENVIRONMENT.upper()} environment: \" f\"Error {response_status} - {response_body}\")","title":"Get ticket"},{"location":"logging/services/TNBA-monitor/repositories/bruin_repository/resolve_ticket_detail/","text":"Resolve ticket detail self._logger.info(f\"Resolving detail {detail_id} of ticket {ticket_id}...\") * If Exception: self._logger.error(f\"An error occurred when resolving detail {detail_id} of affecting ticket {ticket_id} -> {e}\") self._logger.info(f\"Ticket {ticket_id} resolved!\") * If status not ok: self._logger.error(f\"Error while resolving detail {detail_id} of ticket {ticket_id} in \" f\"{self._config.ENVIRONMENT_NAME.upper()} environment: \" f\"Error {response_status} - {response_body}\") * Else: self._logger.info(f\"Detail {detail_id} of ticket {ticket_id} resolved successfully!\")","title":"Resolve ticket detail"},{"location":"logging/services/TNBA-monitor/repositories/bruin_repository/resolve_ticket_detail/#resolve-ticket-detail","text":"self._logger.info(f\"Resolving detail {detail_id} of ticket {ticket_id}...\") * If Exception: self._logger.error(f\"An error occurred when resolving detail {detail_id} of affecting ticket {ticket_id} -> {e}\") self._logger.info(f\"Ticket {ticket_id} resolved!\") * If status not ok: self._logger.error(f\"Error while resolving detail {detail_id} of ticket {ticket_id} in \" f\"{self._config.ENVIRONMENT_NAME.upper()} environment: \" f\"Error {response_status} - {response_body}\") * Else: self._logger.info(f\"Detail {detail_id} of ticket {ticket_id} resolved successfully!\")","title":"Resolve ticket detail"},{"location":"logging/services/TNBA-monitor/repositories/bruin_repository/unpause_ticket_detail/","text":"Unpause ticket detail self._logger.info(f\"Unpausing detail {detail_id} (serial {service_number}) of ticket {ticket_id}...\") * If Exception: self._logger.error(f\"An error occurred when unpausing detail {detail_id} (serial {service_number}) of ticket {ticket_id}. \" f\"Error: {e}\") * If status ok: self._logger.info(f\"Detail {detail_id} (serial {service_number}) of ticket {ticket_id} was unpaused!\") * Else: self._logger.error(f\"Error while unpausing detail {detail_id} (serial {service_number}) of ticket {ticket_id} in \" f\"{self._config.CURRENT_ENVIRONMENT.upper()} environment. \" f\"Error: Error {response_status} - {response_body}\")","title":"Unpause ticket detail"},{"location":"logging/services/TNBA-monitor/repositories/bruin_repository/unpause_ticket_detail/#unpause-ticket-detail","text":"self._logger.info(f\"Unpausing detail {detail_id} (serial {service_number}) of ticket {ticket_id}...\") * If Exception: self._logger.error(f\"An error occurred when unpausing detail {detail_id} (serial {service_number}) of ticket {ticket_id}. \" f\"Error: {e}\") * If status ok: self._logger.info(f\"Detail {detail_id} (serial {service_number}) of ticket {ticket_id} was unpaused!\") * Else: self._logger.error(f\"Error while unpausing detail {detail_id} (serial {service_number}) of ticket {ticket_id} in \" f\"{self._config.CURRENT_ENVIRONMENT.upper()} environment. \" f\"Error: Error {response_status} - {response_body}\")","title":"Unpause ticket detail"},{"location":"logging/services/TNBA-monitor/repositories/customer_cache/get_cache/","text":"get cache Documentation If velo_filter self._logger.info(f\"Getting customer cache for Velocloud host(s) {', '.join(velo_filter.keys())}...\") 2. Else: self._logger.info(f\"Getting customer cache for all Velocloud hosts...\") 3. If Exception : self._logger.error(f\"An error occurred when requesting customer cache -> {e}\") If response status == 202: self._logger.error(response_body) Else: If velo_filter: self._logger.info(f\"Got customer cache for Velocloud host(s) {', '.join(velo_filter.keys())}!\") * Else self._logger.info(f\"Got customer cache for all Velocloud hosts!\")","title":"Get cache"},{"location":"logging/services/TNBA-monitor/repositories/customer_cache/get_cache/#get-cache-documentation","text":"If velo_filter self._logger.info(f\"Getting customer cache for Velocloud host(s) {', '.join(velo_filter.keys())}...\") 2. Else: self._logger.info(f\"Getting customer cache for all Velocloud hosts...\") 3. If Exception : self._logger.error(f\"An error occurred when requesting customer cache -> {e}\") If response status == 202: self._logger.error(response_body) Else: If velo_filter: self._logger.info(f\"Got customer cache for Velocloud host(s) {', '.join(velo_filter.keys())}!\") * Else self._logger.info(f\"Got customer cache for all Velocloud hosts!\")","title":"get cache Documentation"},{"location":"logging/services/TNBA-monitor/repositories/customer_cache/get_cache_for_tnba_monitoring/","text":"Get cache for tnba monitoring get_cache","title":"Get cache for tnba monitoring"},{"location":"logging/services/TNBA-monitor/repositories/customer_cache/get_cache_for_tnba_monitoring/#get-cache-for-tnba-monitoring","text":"get_cache","title":"Get cache for tnba monitoring"},{"location":"logging/services/TNBA-monitor/repositories/t7_repository/get_prediction/","text":"Get prediction self._logger.info(f\"Claiming T7 prediction for ticket {ticket_id}...\") * If Exception: self._logger.error(f\"An error occurred when claiming T7 prediction for ticket {ticket_id}. Error: {e}\") self._logger.info(f\"Got T7 prediction for ticket {ticket_id}!\") * If status not 200: self._logger.error(f\"Error while claiming T7 prediction for ticket {ticket_id} in \" f\"{self._config.ENVIRONMENT_NAME.upper()} environment. \" f\"Error: Error {response_status} - {response_body}\")","title":"Get prediction"},{"location":"logging/services/TNBA-monitor/repositories/t7_repository/get_prediction/#get-prediction","text":"self._logger.info(f\"Claiming T7 prediction for ticket {ticket_id}...\") * If Exception: self._logger.error(f\"An error occurred when claiming T7 prediction for ticket {ticket_id}. Error: {e}\") self._logger.info(f\"Got T7 prediction for ticket {ticket_id}!\") * If status not 200: self._logger.error(f\"Error while claiming T7 prediction for ticket {ticket_id} in \" f\"{self._config.ENVIRONMENT_NAME.upper()} environment. \" f\"Error: Error {response_status} - {response_body}\")","title":"Get prediction"},{"location":"logging/services/TNBA-monitor/repositories/t7_repository/post_live_automation_metrics/","text":"Post live automation metrics self._logger.info(f\"Posting live metric for ticket {ticket_id} to T7...\") * If Exception: self._logger.error(f\"An error occurred when posting live metrics for ticket {ticket_id} to T7. Error: {e}\") * If status is OK: self._logger.info(f\"Live metrics posted for ticket {ticket_id}!\") * If status not 200: self._logger.error(f\"Error when posting live metrics for ticket {ticket_id} to T7 in \" f\"{self._config.ENVIRONMENT_NAME.upper()} \" f\"environment. Error: Error {response_status} - {response_body}\")","title":"Post live automation metrics"},{"location":"logging/services/TNBA-monitor/repositories/t7_repository/post_live_automation_metrics/#post-live-automation-metrics","text":"self._logger.info(f\"Posting live metric for ticket {ticket_id} to T7...\") * If Exception: self._logger.error(f\"An error occurred when posting live metrics for ticket {ticket_id} to T7. Error: {e}\") * If status is OK: self._logger.info(f\"Live metrics posted for ticket {ticket_id}!\") * If status not 200: self._logger.error(f\"Error when posting live metrics for ticket {ticket_id} to T7 in \" f\"{self._config.ENVIRONMENT_NAME.upper()} \" f\"environment. Error: Error {response_status} - {response_body}\")","title":"Post live automation metrics"},{"location":"logging/services/TNBA-monitor/repositories/velocloud_repository/get_all_links_metrics/","text":"Get all links metrics For host in hosts: get_links_metrics_by_host If status is not Ok: self._logger.info(f\"Error: could not retrieve links metrics from Velocloud host {host}\")","title":"Get all links metrics"},{"location":"logging/services/TNBA-monitor/repositories/velocloud_repository/get_all_links_metrics/#get-all-links-metrics","text":"For host in hosts: get_links_metrics_by_host If status is not Ok: self._logger.info(f\"Error: could not retrieve links metrics from Velocloud host {host}\")","title":"Get all links metrics"},{"location":"logging/services/TNBA-monitor/repositories/velocloud_repository/get_edges_for_tnba_monitoring/","text":"Get edges for tnba monitoring For host in host: get_links_with_edge_info If status is Ok: self._logger.info(f\"Error: could not retrieve edges links by host: {host}\") group_links_by_serial","title":"Get edges for tnba monitoring"},{"location":"logging/services/TNBA-monitor/repositories/velocloud_repository/get_edges_for_tnba_monitoring/#get-edges-for-tnba-monitoring","text":"For host in host: get_links_with_edge_info If status is Ok: self._logger.info(f\"Error: could not retrieve edges links by host: {host}\") group_links_by_serial","title":"Get edges for tnba monitoring"},{"location":"logging/services/TNBA-monitor/repositories/velocloud_repository/get_enterprise_events/","text":"Get enterprise events self._logger.info( f\"Getting events of host {host} and enterprise id {enterprise_id} having any type of {event_types} \" f\"that took place between {past_moment} and {now} from Velocloud...\" ) If Exception self._logger.error(f\"An error occurred when requesting edge events from Velocloud for host {host} \" f\"and enterprise id {enterprise_id} -> {e}\") If status is Ok: self._logger.info( f\"Got events of host {host} and enterprise id {enterprise_id} having any type in {event_types} \" f\"that took place between {past_moment} and {now} from Velocloud!\" ) Else: self._logger.error(f\"Error while retrieving events of host {host} and enterprise id {enterprise_id} having any type \" f\"in {event_types} that took place between {past_moment} and {now} \" f\"in {self._config.ENVIRONMENT_NAME.upper()}\" f\"environment: Error {response_status} - {response_body}\")","title":"Get enterprise events"},{"location":"logging/services/TNBA-monitor/repositories/velocloud_repository/get_enterprise_events/#get-enterprise-events","text":"self._logger.info( f\"Getting events of host {host} and enterprise id {enterprise_id} having any type of {event_types} \" f\"that took place between {past_moment} and {now} from Velocloud...\" ) If Exception self._logger.error(f\"An error occurred when requesting edge events from Velocloud for host {host} \" f\"and enterprise id {enterprise_id} -> {e}\") If status is Ok: self._logger.info( f\"Got events of host {host} and enterprise id {enterprise_id} having any type in {event_types} \" f\"that took place between {past_moment} and {now} from Velocloud!\" ) Else: self._logger.error(f\"Error while retrieving events of host {host} and enterprise id {enterprise_id} having any type \" f\"in {event_types} that took place between {past_moment} and {now} \" f\"in {self._config.ENVIRONMENT_NAME.upper()}\" f\"environment: Error {response_status} - {response_body}\")","title":"Get enterprise events"},{"location":"logging/services/TNBA-monitor/repositories/velocloud_repository/get_events_by_serial_and_interface/","text":"Get events by serial and interface for host in hosts: for enterprise id in enterprises ids: get_enterprise_events self._logger.warning(f\" Bad status calling get enterprise events for host: {host} and enterprise\" f\"{enterprise_id}. Skipping enterprise events ...\") For events in enterprise events: If not match edge: self._logger.info( f'No edge in the customer cache had edge name {event[\"edgeName\"]}. Skipping...' ) self._logger.info( f'Event with edge name {event[\"edgeName\"]} matches edge from customer cache with' f\"serial number {serial}\" )","title":"Get events by serial and interface"},{"location":"logging/services/TNBA-monitor/repositories/velocloud_repository/get_events_by_serial_and_interface/#get-events-by-serial-and-interface","text":"for host in hosts: for enterprise id in enterprises ids: get_enterprise_events self._logger.warning(f\" Bad status calling get enterprise events for host: {host} and enterprise\" f\"{enterprise_id}. Skipping enterprise events ...\") For events in enterprise events: If not match edge: self._logger.info( f'No edge in the customer cache had edge name {event[\"edgeName\"]}. Skipping...' ) self._logger.info( f'Event with edge name {event[\"edgeName\"]} matches edge from customer cache with' f\"serial number {serial}\" )","title":"Get events by serial and interface"},{"location":"logging/services/TNBA-monitor/repositories/velocloud_repository/get_links_metrics_by_host/","text":"Get links metrics by host self._logger.info( f\"Getting links metrics between {interval['start']} and {interval['end']} \" f\"from Velocloud host {host}...\" ) If Exception f\"An error occurred when requesting links metrics from Velocloud -> {e}\" self._logger.info(f\"Got links metrics from Velocloud host {host}!\") Else: self._logger.error(f\"Error while retrieving links metrics in {self._config.ENVIRONMENT_NAME.upper()} \" f\"environment: Error {response_status} - {response_body}\")","title":"Get links metrics by host"},{"location":"logging/services/TNBA-monitor/repositories/velocloud_repository/get_links_metrics_by_host/#get-links-metrics-by-host","text":"self._logger.info( f\"Getting links metrics between {interval['start']} and {interval['end']} \" f\"from Velocloud host {host}...\" ) If Exception f\"An error occurred when requesting links metrics from Velocloud -> {e}\" self._logger.info(f\"Got links metrics from Velocloud host {host}!\") Else: self._logger.error(f\"Error while retrieving links metrics in {self._config.ENVIRONMENT_NAME.upper()} \" f\"environment: Error {response_status} - {response_body}\")","title":"Get links metrics by host"},{"location":"logging/services/TNBA-monitor/repositories/velocloud_repository/get_links_metrics_for_autoresolve/","text":"Get links metrics for autoresolve get_all_links_metrics If not link metrics: self._logger.info(\"List of links metrics arrived empty. Skipping...\") get_events_by_serial_and_interface","title":"Get links metrics for autoresolve"},{"location":"logging/services/TNBA-monitor/repositories/velocloud_repository/get_links_metrics_for_autoresolve/#get-links-metrics-for-autoresolve","text":"get_all_links_metrics If not link metrics: self._logger.info(\"List of links metrics arrived empty. Skipping...\") get_events_by_serial_and_interface","title":"Get links metrics for autoresolve"},{"location":"logging/services/TNBA-monitor/repositories/velocloud_repository/get_links_with_edge_info/","text":"Get Links with edge info Documentation self._logger.info(f\"Getting links with edge info from Velocloud for host {velocloud_host}...\") If Exception self._logger.error(f\"An error occurred when requesting edge list from Velocloud -> {e}\") * If status OK: self._logger.info(f\"Got links with edge info from Velocloud for host {velocloud_host}!\") * Else: self._logger.error(f\"Error while retrieving links with edge info in {self._config.ENVIRONMENT_NAME.upper()} \" f\"environment: Error {response_status} - {response_body}\")","title":"Get links with edge info"},{"location":"logging/services/TNBA-monitor/repositories/velocloud_repository/get_links_with_edge_info/#get-links-with-edge-info-documentation","text":"self._logger.info(f\"Getting links with edge info from Velocloud for host {velocloud_host}...\") If Exception self._logger.error(f\"An error occurred when requesting edge list from Velocloud -> {e}\") * If status OK: self._logger.info(f\"Got links with edge info from Velocloud for host {velocloud_host}!\") * Else: self._logger.error(f\"Error while retrieving links with edge info in {self._config.ENVIRONMENT_NAME.upper()} \" f\"environment: Error {response_status} - {response_body}\")","title":"Get Links with edge info Documentation"},{"location":"logging/services/TNBA-monitor/repositories/velocloud_repository/group_links_by_serial/","text":"Group links by serial For link in links: If not edge state: self._logger.info( f\"Edge in host {velocloud_host} and enterprise {enterprise_name} (ID: {enterprise_id}) \" f\"has an invalid state. Skipping...\" ) If never activated: self._logger.info( f\"Edge {edge_name} in host {velocloud_host} and enterprise {enterprise_name} (ID: {enterprise_id}) \" f\"has never been activated. Skipping...\" )","title":"Group links by serial"},{"location":"logging/services/TNBA-monitor/repositories/velocloud_repository/group_links_by_serial/#group-links-by-serial","text":"For link in links: If not edge state: self._logger.info( f\"Edge in host {velocloud_host} and enterprise {enterprise_name} (ID: {enterprise_id}) \" f\"has an invalid state. Skipping...\" ) If never activated: self._logger.info( f\"Edge {edge_name} in host {velocloud_host} and enterprise {enterprise_name} (ID: {enterprise_id}) \" f\"has never been activated. Skipping...\" )","title":"Group links by serial"},{"location":"logging/services/bruin-bridge/actions/change_detail_work_queue/","text":"Subject: bruin.ticket.change.work Message arrives at subject If message doesn't have a body: self . _logger . error ( f \"Cannot change detail work queue using { json . dumps ( msg ) } . JSON malformed\" ) END If message body doesn't have ticket_id , queue_name or doesn't have service_number or detail_id : self . _logger . error ( f \"Cannot change detail work queue using { json . dumps ( msg_body ) } . \" f 'Need all these parameters: \"service_number\" or \"detail_id\", \"ticket_id\", \"queue_name\"' ) END self . _logger . info ( f \"Changing work queue of ticket { ticket_id } with filters: { json . dumps ( msg_body ) } \" ) change_detail_work_queue self . _logger . info ( f \"Result of changing work queue of ticket { ticket_id } with filters { json . dumps ( msg_body ) } \" \"published in event bus!\" )","title":"Change detail work queue"},{"location":"logging/services/bruin-bridge/actions/change_detail_work_queue/#subject-bruinticketchangework","text":"Message arrives at subject If message doesn't have a body: self . _logger . error ( f \"Cannot change detail work queue using { json . dumps ( msg ) } . JSON malformed\" ) END If message body doesn't have ticket_id , queue_name or doesn't have service_number or detail_id : self . _logger . error ( f \"Cannot change detail work queue using { json . dumps ( msg_body ) } . \" f 'Need all these parameters: \"service_number\" or \"detail_id\", \"ticket_id\", \"queue_name\"' ) END self . _logger . info ( f \"Changing work queue of ticket { ticket_id } with filters: { json . dumps ( msg_body ) } \" ) change_detail_work_queue self . _logger . info ( f \"Result of changing work queue of ticket { ticket_id } with filters { json . dumps ( msg_body ) } \" \"published in event bus!\" )","title":"Subject: bruin.ticket.change.work"},{"location":"logging/services/bruin-bridge/actions/change_ticket_severity/","text":"Subject: bruin.change.ticket.severity Message arrives at subject If message doesn't have a body: self . _logger . error ( f \"Cannot change ticket severity level using { json . dumps ( msg ) } . JSON malformed\" ) END If message body doesn't have ticket_id , severity and reason filters: self . _logger . error ( f \"Cannot change ticket severity level using { json . dumps ( msg ) } . \" 'Need fields \"ticket_id\", \"severity\" and \"reason\".' ) END self . _logger . info ( f \"Changing ticket severity level using parameters { json . dumps ( payload ) } ...\" ) change_ticket_severity self . _logger . info ( f \"Publishing result of changing severity level of ticket { ticket_id } using payload { json . dumps ( payload ) } \" \"to the event bus...\" )","title":"Change ticket severity"},{"location":"logging/services/bruin-bridge/actions/change_ticket_severity/#subject-bruinchangeticketseverity","text":"Message arrives at subject If message doesn't have a body: self . _logger . error ( f \"Cannot change ticket severity level using { json . dumps ( msg ) } . JSON malformed\" ) END If message body doesn't have ticket_id , severity and reason filters: self . _logger . error ( f \"Cannot change ticket severity level using { json . dumps ( msg ) } . \" 'Need fields \"ticket_id\", \"severity\" and \"reason\".' ) END self . _logger . info ( f \"Changing ticket severity level using parameters { json . dumps ( payload ) } ...\" ) change_ticket_severity self . _logger . info ( f \"Publishing result of changing severity level of ticket { ticket_id } using payload { json . dumps ( payload ) } \" \"to the event bus...\" )","title":"Subject: bruin.change.ticket.severity"},{"location":"logging/services/bruin-bridge/actions/get_asset_topics/","text":"Subject: bruin.get.asset.topics Message arrives at subject If message body doesn't have client_id or service_number : self . _logger . error ( f \"Cannot get asset topics using { json . dumps ( msg ) } . \" f \"JSON malformed\" ) END Try converting message body.client_id into an int If ValueError is caught: self . _logger . error ( f \"body.client_id { payload . get ( 'client_id' ) } should be an int.\" ) END Getting service_number from message body If message body doesnt have a value for service_number : self . _logger . error ( f \"body.service_number can't be empty\" ) END self . _logger . info ( f \"Getting asset topics for client ' { client_id } ', service number ' { service_number } '\" ) get_asset_topics","title":"Get asset topics"},{"location":"logging/services/bruin-bridge/actions/get_asset_topics/#subject-bruingetassettopics","text":"Message arrives at subject If message body doesn't have client_id or service_number : self . _logger . error ( f \"Cannot get asset topics using { json . dumps ( msg ) } . \" f \"JSON malformed\" ) END Try converting message body.client_id into an int If ValueError is caught: self . _logger . error ( f \"body.client_id { payload . get ( 'client_id' ) } should be an int.\" ) END Getting service_number from message body If message body doesnt have a value for service_number : self . _logger . error ( f \"body.service_number can't be empty\" ) END self . _logger . info ( f \"Getting asset topics for client ' { client_id } ', service number ' { service_number } '\" ) get_asset_topics","title":"Subject: bruin.get.asset.topics"},{"location":"logging/services/bruin-bridge/actions/get_attributes_serial/","text":"Subject: bruin.inventory.attributes.serial Message arrives at subject If message doesn't have a body: self . _logger . error ( f \"Cannot get attribute's serial number using { json . dumps ( msg ) } . JSON malformed\" ) END If message body doesn't have client_id , status or service_number : self . _logger . info ( f \"Cannot get attribute's serial number using { json . dumps ( filters ) } . \" f 'Need \"client_id\", \"status\", \"service_number\"' ) END self . _logger . info ( f \"'Getting attribute's serial number with filters: { json . dumps ( filters ) } '\" ) get_attributes_serial self . _logger . info ( f \"'Attribute's serial number published in event bus for request { json . dumps ( msg ) } . '\" f \"Message published was { response } \" )","title":"Get attributes serial"},{"location":"logging/services/bruin-bridge/actions/get_attributes_serial/#subject-bruininventoryattributesserial","text":"Message arrives at subject If message doesn't have a body: self . _logger . error ( f \"Cannot get attribute's serial number using { json . dumps ( msg ) } . JSON malformed\" ) END If message body doesn't have client_id , status or service_number : self . _logger . info ( f \"Cannot get attribute's serial number using { json . dumps ( filters ) } . \" f 'Need \"client_id\", \"status\", \"service_number\"' ) END self . _logger . info ( f \"'Getting attribute's serial number with filters: { json . dumps ( filters ) } '\" ) get_attributes_serial self . _logger . info ( f \"'Attribute's serial number published in event bus for request { json . dumps ( msg ) } . '\" f \"Message published was { response } \" )","title":"Subject: bruin.inventory.attributes.serial"},{"location":"logging/services/bruin-bridge/actions/get_circuit_id/","text":"Subject: bruin.get.circuit.id Message arrives at subject If message doesn't have a body: self . _logger . error ( f \"Cannot get bruin circuit id using { json . dumps ( msg ) } . JSON malformed\" ) END If message body doesn't have circuit_id : self . _logger . error ( f 'Cannot get bruin circuit id using { json . dumps ( params ) } . Need \"circuit_id\"' ) END self . _logger . info ( f \"Getting Bruin circuit ID with filters: { json . dumps ( params ) } \" ) get_circuit_id self . _logger . info ( f \"Bruin circuit ID published in event bus for request { json . dumps ( msg ) } . \" f \"Message published was { response } \" )","title":"Get circuit id"},{"location":"logging/services/bruin-bridge/actions/get_circuit_id/#subject-bruingetcircuitid","text":"Message arrives at subject If message doesn't have a body: self . _logger . error ( f \"Cannot get bruin circuit id using { json . dumps ( msg ) } . JSON malformed\" ) END If message body doesn't have circuit_id : self . _logger . error ( f 'Cannot get bruin circuit id using { json . dumps ( params ) } . Need \"circuit_id\"' ) END self . _logger . info ( f \"Getting Bruin circuit ID with filters: { json . dumps ( params ) } \" ) get_circuit_id self . _logger . info ( f \"Bruin circuit ID published in event bus for request { json . dumps ( msg ) } . \" f \"Message published was { response } \" )","title":"Subject: bruin.get.circuit.id"},{"location":"logging/services/bruin-bridge/actions/get_client_info/","text":"Subject: bruin.customer.get.info Message arrives at subject If message doesn't have a body: self . _logger . error ( f \"Cannot get bruin client info using { json . dumps ( msg ) } . JSON malformed\" ) END If message body doesn't have service_number : self . _logger . error ( f 'Cannot get bruin client info using { json . dumps ( filters ) } . Need \"service_number\"' ) END self . _logger . info ( f \"Getting Bruin client ID with filters: { json . dumps ( filters ) } \" ) get_client_info self . _logger . info ( f \"Bruin client_info published in event bus for request { json . dumps ( msg ) } . \" f \"Message published was { response } \" )","title":"Get client info"},{"location":"logging/services/bruin-bridge/actions/get_client_info/#subject-bruincustomergetinfo","text":"Message arrives at subject If message doesn't have a body: self . _logger . error ( f \"Cannot get bruin client info using { json . dumps ( msg ) } . JSON malformed\" ) END If message body doesn't have service_number : self . _logger . error ( f 'Cannot get bruin client info using { json . dumps ( filters ) } . Need \"service_number\"' ) END self . _logger . info ( f \"Getting Bruin client ID with filters: { json . dumps ( filters ) } \" ) get_client_info self . _logger . info ( f \"Bruin client_info published in event bus for request { json . dumps ( msg ) } . \" f \"Message published was { response } \" )","title":"Subject: bruin.customer.get.info"},{"location":"logging/services/bruin-bridge/actions/get_client_info_by_did/","text":"Subject: bruin.customer.get.info_by_did Message arrives at subject If message doesn't have a body: self . _logger . error ( f \"Cannot get Bruin client info by DID using { json . dumps ( msg ) } . JSON malformed\" ) END If message body doesn't have did : self . _logger . error ( f 'Cannot get Bruin client info by DID using { json . dumps ( body ) } . Need \"did\"' ) END self . _logger . info ( f \"Getting Bruin client info by DID with body: { json . dumps ( body ) } \" ) get_client_info_by_did self . _logger . info ( f \"Bruin client_info_by_did published in event bus for request { json . dumps ( msg ) } . \" f \"Message published was { response } \" )","title":"Get client info by did"},{"location":"logging/services/bruin-bridge/actions/get_client_info_by_did/#subject-bruincustomergetinfo_by_did","text":"Message arrives at subject If message doesn't have a body: self . _logger . error ( f \"Cannot get Bruin client info by DID using { json . dumps ( msg ) } . JSON malformed\" ) END If message body doesn't have did : self . _logger . error ( f 'Cannot get Bruin client info by DID using { json . dumps ( body ) } . Need \"did\"' ) END self . _logger . info ( f \"Getting Bruin client info by DID with body: { json . dumps ( body ) } \" ) get_client_info_by_did self . _logger . info ( f \"Bruin client_info_by_did published in event bus for request { json . dumps ( msg ) } . \" f \"Message published was { response } \" )","title":"Subject: bruin.customer.get.info_by_did"},{"location":"logging/services/bruin-bridge/actions/get_management_status/","text":"Subject: bruin.inventory.management.status Message arrives at subject If message doesn't have a body: self . _logger . error ( f \"Cannot get management status using { json . dumps ( msg ) } . JSON malformed\" ) END If message body doesn't have client_id , status , or service_number : self . _logger . info ( f \"Cannot get management status using { json . dumps ( filters ) } . \" f 'Need \"client_id\", \"status\", \"service_number\"' ) END self . _logger . info ( f \"Getting management status with filters: { json . dumps ( filters ) } \" ) get_management_status self . _logger . info ( f \"Management status published in event bus for request { json . dumps ( msg ) } . \" f \"Message published was { response } \" )","title":"Get management status"},{"location":"logging/services/bruin-bridge/actions/get_management_status/#subject-bruininventorymanagementstatus","text":"Message arrives at subject If message doesn't have a body: self . _logger . error ( f \"Cannot get management status using { json . dumps ( msg ) } . JSON malformed\" ) END If message body doesn't have client_id , status , or service_number : self . _logger . info ( f \"Cannot get management status using { json . dumps ( filters ) } . \" f 'Need \"client_id\", \"status\", \"service_number\"' ) END self . _logger . info ( f \"Getting management status with filters: { json . dumps ( filters ) } \" ) get_management_status self . _logger . info ( f \"Management status published in event bus for request { json . dumps ( msg ) } . \" f \"Message published was { response } \" )","title":"Subject: bruin.inventory.management.status"},{"location":"logging/services/bruin-bridge/actions/get_next_results_for_ticket_detail/","text":"Subject: bruin.ticket.detail.get.next.results Message arrives at subject If message doesn't have a body: self . _logger . error ( f \"Cannot get next results for ticket detail using { json . dumps ( msg ) } . JSON malformed\" ) END If message body doesn't have ticket_id , detail_id , or service_number : self . _logger . info ( f \"Cannot get next results for ticket detail using { json . dumps ( request_body ) } . \" f 'Need \"ticket_id\", \"detail_id\", \"service_number\"' ) END self . _logger . info ( f \"Claiming all available next results for ticket { ticket_id } and detail { detail_id } ...\" ) get_next_results_for_ticket_detail self . _logger . info ( f \"Next results for ticket { ticket_id } and detail { detail_id } published in event bus!\" )","title":"Get next results for ticket detail"},{"location":"logging/services/bruin-bridge/actions/get_next_results_for_ticket_detail/#subject-bruinticketdetailgetnextresults","text":"Message arrives at subject If message doesn't have a body: self . _logger . error ( f \"Cannot get next results for ticket detail using { json . dumps ( msg ) } . JSON malformed\" ) END If message body doesn't have ticket_id , detail_id , or service_number : self . _logger . info ( f \"Cannot get next results for ticket detail using { json . dumps ( request_body ) } . \" f 'Need \"ticket_id\", \"detail_id\", \"service_number\"' ) END self . _logger . info ( f \"Claiming all available next results for ticket { ticket_id } and detail { detail_id } ...\" ) get_next_results_for_ticket_detail self . _logger . info ( f \"Next results for ticket { ticket_id } and detail { detail_id } published in event bus!\" )","title":"Subject: bruin.ticket.detail.get.next.results"},{"location":"logging/services/bruin-bridge/actions/get_single_ticket_basic_info/","text":"Subject: bruin.single_ticket.basic.request Message arrives at subject If message doesn't have a body: self . _logger . error ( f \"Cannot get tickets basic info using { json . dumps ( msg ) } . JSON malformed\" ) END If message body doesn't have ticket_id : self . _logger . error ( f \"Cannot get tickets basic info using { json . dumps ( msg ) } . Need a TicketId to keep going.\" ) END self . _logger . info ( f \"Fetching basic info for ticket { ticket_id } \" ) get_single_ticket_basic_info self . _logger . info ( f \"Publishing ticket data to the event bus...\" )","title":"Get single ticket basic info"},{"location":"logging/services/bruin-bridge/actions/get_single_ticket_basic_info/#subject-bruinsingle_ticketbasicrequest","text":"Message arrives at subject If message doesn't have a body: self . _logger . error ( f \"Cannot get tickets basic info using { json . dumps ( msg ) } . JSON malformed\" ) END If message body doesn't have ticket_id : self . _logger . error ( f \"Cannot get tickets basic info using { json . dumps ( msg ) } . Need a TicketId to keep going.\" ) END self . _logger . info ( f \"Fetching basic info for ticket { ticket_id } \" ) get_single_ticket_basic_info self . _logger . info ( f \"Publishing ticket data to the event bus...\" )","title":"Subject: bruin.single_ticket.basic.request"},{"location":"logging/services/bruin-bridge/actions/get_site/","text":"Subject: bruin.get.site Message arrives at subject If message doesn't have a body: self . _logger . error ( f \"Cannot get bruin site using { json . dumps ( msg ) } . JSON malformed\" ) END If message body doesn't have client_id filter: self . _logger . error ( f 'Cannot get bruin site using { json . dumps ( filters ) } . Need \"client_id\"' ) END If message body doesn't have site_id filter: self . _logger . error ( f 'Cannot get bruin site using { json . dumps ( filters ) } . Need \"site_id\"' ) END self . _logger . info ( f \"Getting Bruin site with filters: { json . dumps ( filters ) } \" ) get_site self . _logger . info ( f \"Bruin get_site published in event bus for request { json . dumps ( msg ) } . Message published was { response } \" )","title":"Get site"},{"location":"logging/services/bruin-bridge/actions/get_site/#subject-bruingetsite","text":"Message arrives at subject If message doesn't have a body: self . _logger . error ( f \"Cannot get bruin site using { json . dumps ( msg ) } . JSON malformed\" ) END If message body doesn't have client_id filter: self . _logger . error ( f 'Cannot get bruin site using { json . dumps ( filters ) } . Need \"client_id\"' ) END If message body doesn't have site_id filter: self . _logger . error ( f 'Cannot get bruin site using { json . dumps ( filters ) } . Need \"site_id\"' ) END self . _logger . info ( f \"Getting Bruin site with filters: { json . dumps ( filters ) } \" ) get_site self . _logger . info ( f \"Bruin get_site published in event bus for request { json . dumps ( msg ) } . Message published was { response } \" )","title":"Subject: bruin.get.site"},{"location":"logging/services/bruin-bridge/actions/get_ticket_details/","text":"Subject: bruin.ticket.details.request Message arrives at subject If message body doesn't have ticket_id : self . _logger . error ( f \"Cannot get ticket_details using { json . dumps ( msg ) } . JSON malformed\" ) END self . _logger . info ( f \"Collecting ticket details for ticket id: { ticket_id } ...\" ) get_ticket_details self . _logger . info ( f \"Ticket details for ticket id: { ticket_id } sent!\" )","title":"Get ticket details"},{"location":"logging/services/bruin-bridge/actions/get_ticket_details/#subject-bruinticketdetailsrequest","text":"Message arrives at subject If message body doesn't have ticket_id : self . _logger . error ( f \"Cannot get ticket_details using { json . dumps ( msg ) } . JSON malformed\" ) END self . _logger . info ( f \"Collecting ticket details for ticket id: { ticket_id } ...\" ) get_ticket_details self . _logger . info ( f \"Ticket details for ticket id: { ticket_id } sent!\" )","title":"Subject: bruin.ticket.details.request"},{"location":"logging/services/bruin-bridge/actions/get_ticket_overview/","text":"Subject: bruin.ticket.overview.request self . _logger . info ( f \"Getting ticket for ticket_id: { ticket_id } ...\" ) get_ticket_overview self . _logger . info ( f \"Got ticket overview for ticket id: { ticket_id } ...\" )","title":"Get ticket overview"},{"location":"logging/services/bruin-bridge/actions/get_ticket_overview/#subject-bruinticketoverviewrequest","text":"self . _logger . info ( f \"Getting ticket for ticket_id: { ticket_id } ...\" ) get_ticket_overview self . _logger . info ( f \"Got ticket overview for ticket id: { ticket_id } ...\" )","title":"Subject: bruin.ticket.overview.request"},{"location":"logging/services/bruin-bridge/actions/get_ticket_task_history/","text":"Subject: bruin.ticket.get.task.history Message arrives at subject If message doesn't have a body: self . _logger . error ( f \"Cannot get ticket task history using { json . dumps ( msg ) } . JSON malformed\" ) END If message body doesn't have ticket_id : self . _logger . info ( f \"Cannot get get ticket task history using { json . dumps ( filters ) } . Need 'ticket_id'\" ) END self . _logger . info ( f \"Getting ticket task history with filters: { json . dumps ( filters ) } \" ) get_ticket_task_history self . _logger . info ( f \"get ticket task history published in event bus for request { json . dumps ( msg ) } . \" f \"Message published was { response } \" )","title":"Get ticket task history"},{"location":"logging/services/bruin-bridge/actions/get_ticket_task_history/#subject-bruinticketgettaskhistory","text":"Message arrives at subject If message doesn't have a body: self . _logger . error ( f \"Cannot get ticket task history using { json . dumps ( msg ) } . JSON malformed\" ) END If message body doesn't have ticket_id : self . _logger . info ( f \"Cannot get get ticket task history using { json . dumps ( filters ) } . Need 'ticket_id'\" ) END self . _logger . info ( f \"Getting ticket task history with filters: { json . dumps ( filters ) } \" ) get_ticket_task_history self . _logger . info ( f \"get ticket task history published in event bus for request { json . dumps ( msg ) } . \" f \"Message published was { response } \" )","title":"Subject: bruin.ticket.get.task.history"},{"location":"logging/services/bruin-bridge/actions/get_tickets/","text":"Subject: bruin.ticket.request self . _logger . info ( f 'Collecting all tickets for client id: { params [ \"client_id\" ] } ...' ) get_all_filtered_tickets self . _logger . info ( f 'All tickets for client id: { params [ \"client_id\" ] } sent' )","title":"Get tickets"},{"location":"logging/services/bruin-bridge/actions/get_tickets/#subject-bruinticketrequest","text":"self . _logger . info ( f 'Collecting all tickets for client id: { params [ \"client_id\" ] } ...' ) get_all_filtered_tickets self . _logger . info ( f 'All tickets for client id: { params [ \"client_id\" ] } sent' )","title":"Subject: bruin.ticket.request"},{"location":"logging/services/bruin-bridge/actions/get_tickets_basic_info/","text":"Subject: bruin.ticket.basic.request Message arrives at subject If message doesn't have a body: self . _logger . error ( f \"Cannot get tickets basic info using { json . dumps ( msg ) } . JSON malformed\" ) END If message body doesn't have ticket_statuses filter: self . _logger . error ( f \"Cannot get tickets basic info using { json . dumps ( msg ) } . Need a list of ticket statuses to keep going.\" ) END self . _logger . info ( f 'Fetching basic info of all tickets with statuses { \", \" . join ( ticket_statuses ) } and matching filters ' f \" { json . dumps ( bruin_payload ) } ...\" ) get_tickets_basic_info self . _logger . info ( f 'Publishing { len ( response_msg [ \"body\" ]) } tickets to the event bus...' )","title":"Get tickets basic info"},{"location":"logging/services/bruin-bridge/actions/get_tickets_basic_info/#subject-bruinticketbasicrequest","text":"Message arrives at subject If message doesn't have a body: self . _logger . error ( f \"Cannot get tickets basic info using { json . dumps ( msg ) } . JSON malformed\" ) END If message body doesn't have ticket_statuses filter: self . _logger . error ( f \"Cannot get tickets basic info using { json . dumps ( msg ) } . Need a list of ticket statuses to keep going.\" ) END self . _logger . info ( f 'Fetching basic info of all tickets with statuses { \", \" . join ( ticket_statuses ) } and matching filters ' f \" { json . dumps ( bruin_payload ) } ...\" ) get_tickets_basic_info self . _logger . info ( f 'Publishing { len ( response_msg [ \"body\" ]) } tickets to the event bus...' )","title":"Subject: bruin.ticket.basic.request"},{"location":"logging/services/bruin-bridge/actions/link_ticket_to_email/","text":"Subject: bruin.link.ticket.email Message arrives at subject If message body doesn't have ticket_id or email_id : self . _logger . error ( f \"Cannot link ticket to email using { json . dumps ( msg ) } . JSON malformed\" ) END self . _logger . info ( f \"Linking ticket { ticket_id } to email { email_id } ...\" ) link_ticket_to_email self . _logger . info ( f \"Ticket { ticket_id } successfully posted to email_id: { email_id } \" )","title":"Link ticket to email"},{"location":"logging/services/bruin-bridge/actions/link_ticket_to_email/#subject-bruinlinkticketemail","text":"Message arrives at subject If message body doesn't have ticket_id or email_id : self . _logger . error ( f \"Cannot link ticket to email using { json . dumps ( msg ) } . JSON malformed\" ) END self . _logger . info ( f \"Linking ticket { ticket_id } to email { email_id } ...\" ) link_ticket_to_email self . _logger . info ( f \"Ticket { ticket_id } successfully posted to email_id: { email_id } \" )","title":"Subject: bruin.link.ticket.email"},{"location":"logging/services/bruin-bridge/actions/mark_email_as_done/","text":"Subject: bruin.mark.email.done Message arrives at subject If message body has email_id : self . _logger . info ( f \"Marking email: { email_id } as Done\" ) mark_email_as_done else self . _logger . error ( f \"Cannot mark emails as done using { json . dumps ( msg ) } . JSON malformed\" ) END","title":"Mark email as done"},{"location":"logging/services/bruin-bridge/actions/mark_email_as_done/#subject-bruinmarkemaildone","text":"Message arrives at subject If message body has email_id : self . _logger . info ( f \"Marking email: { email_id } as Done\" ) mark_email_as_done else self . _logger . error ( f \"Cannot mark emails as done using { json . dumps ( msg ) } . JSON malformed\" ) END","title":"Subject: bruin.mark.email.done"},{"location":"logging/services/bruin-bridge/actions/open_ticket/","text":"Subject: bruin.ticket.status.open Message arrives at subject If message body doesn't have ticket_id or detail_id : self . _logger . error ( f \"Cannot open a ticket using { json . dumps ( msg ) } . JSON malformed\" ) END self . _logger . info ( f \"Updating the ticket status for ticket id: { ticket_id } to OPEN\" ) open_ticket","title":"Open ticket"},{"location":"logging/services/bruin-bridge/actions/open_ticket/#subject-bruinticketstatusopen","text":"Message arrives at subject If message body doesn't have ticket_id or detail_id : self . _logger . error ( f \"Cannot open a ticket using { json . dumps ( msg ) } . JSON malformed\" ) END self . _logger . info ( f \"Updating the ticket status for ticket id: { ticket_id } to OPEN\" ) open_ticket","title":"Subject: bruin.ticket.status.open"},{"location":"logging/services/bruin-bridge/actions/post_email_reply/","text":"Subject: bruin.email.reply Message arrives at subject Try to use parse_obj on Message body ValidationError caught: self . logger . warning ( f \"Wrong request message: msg= { msg } , validation_error= { e } \" ) END self . logger . info ( f \"Sending email { message_body . parent_email_id } an auto-reply\" ) post if response.status from calling post is HTTPStatus.UNAUTHORIZED self . logger . error ( f \"Got 401 from Bruin. Re-logging in...\" ) END","title":"Post email reply"},{"location":"logging/services/bruin-bridge/actions/post_email_reply/#subject-bruinemailreply","text":"Message arrives at subject Try to use parse_obj on Message body ValidationError caught: self . logger . warning ( f \"Wrong request message: msg= { msg } , validation_error= { e } \" ) END self . logger . info ( f \"Sending email { message_body . parent_email_id } an auto-reply\" ) post if response.status from calling post is HTTPStatus.UNAUTHORIZED self . logger . error ( f \"Got 401 from Bruin. Re-logging in...\" ) END","title":"Subject: bruin.email.reply"},{"location":"logging/services/bruin-bridge/actions/post_email_status/","text":"Subject: bruin.email.status Message arrives at subject Try to use parse_obj on Message body ValidationError caught: self . logger . warning ( f \"Wrong request message: msg= { msg } , validation_error= { e } \" ) END self . logger . info ( f \"Setting email status: post_request= { post_request } \" ) post if response.status from calling post is HTTPStatus.UNAUTHORIZED self . logger . error ( f \"Got 401 from Bruin. Re-logging in...\" ) END","title":"Post email status"},{"location":"logging/services/bruin-bridge/actions/post_email_status/#subject-bruinemailstatus","text":"Message arrives at subject Try to use parse_obj on Message body ValidationError caught: self . logger . warning ( f \"Wrong request message: msg= { msg } , validation_error= { e } \" ) END self . logger . info ( f \"Setting email status: post_request= { post_request } \" ) post if response.status from calling post is HTTPStatus.UNAUTHORIZED self . logger . error ( f \"Got 401 from Bruin. Re-logging in...\" ) END","title":"Subject: bruin.email.status"},{"location":"logging/services/bruin-bridge/actions/post_email_tag/","text":"Subject: bruin.email.tag.request Message arrives at subject If message body doesn't have email_id or tag_id : self . _logger . error ( f \"Cannot add a tag to email using { json . dumps ( msg ) } . JSON malformed\" ) END self . _logger . info ( f 'Adding tag_id \" { tag_id } \" to email_id \" { email_id } \"...' ) post_email_tag If status from post_email_tag is in range of 200 - 300: self . _logger . info ( f \"Tags successfully added to email_id: { email_id } \" ) Else self . _logger . error ( f \"Error adding tags to email: Status: { response [ 'status' ] } body: { response [ 'body' ] } \" ) END","title":"Post email tag"},{"location":"logging/services/bruin-bridge/actions/post_email_tag/#subject-bruinemailtagrequest","text":"Message arrives at subject If message body doesn't have email_id or tag_id : self . _logger . error ( f \"Cannot add a tag to email using { json . dumps ( msg ) } . JSON malformed\" ) END self . _logger . info ( f 'Adding tag_id \" { tag_id } \" to email_id \" { email_id } \"...' ) post_email_tag If status from post_email_tag is in range of 200 - 300: self . _logger . info ( f \"Tags successfully added to email_id: { email_id } \" ) Else self . _logger . error ( f \"Error adding tags to email: Status: { response [ 'status' ] } body: { response [ 'body' ] } \" ) END","title":"Subject: bruin.email.tag.request"},{"location":"logging/services/bruin-bridge/actions/post_multiple_notes/","text":"Subject: bruin.ticket.multiple.notes.append.request Message arrives at subject If message doesn't have a body: self . _logger . error ( f \"Cannot post a note to ticket using { json . dumps ( msg ) } . JSON malformed\" ) END self . _logger . info ( f \"Posting multiple notes for ticket { ticket_id } ...\" ) post_multiple_ticket_notes","title":"Post multiple notes"},{"location":"logging/services/bruin-bridge/actions/post_multiple_notes/#subject-bruinticketmultiplenotesappendrequest","text":"Message arrives at subject If message doesn't have a body: self . _logger . error ( f \"Cannot post a note to ticket using { json . dumps ( msg ) } . JSON malformed\" ) END self . _logger . info ( f \"Posting multiple notes for ticket { ticket_id } ...\" ) post_multiple_ticket_notes","title":"Subject: bruin.ticket.multiple.notes.append.request"},{"location":"logging/services/bruin-bridge/actions/post_note/","text":"Subject: bruin.ticket.note.append.request Message arrives at subject If message body doesn't have ticket_id or note : self . _logger . error ( f \"Cannot post a note to ticket using { json . dumps ( msg ) } . JSON malformed\" ) END self . _logger . info ( f \"Putting note in: { ticket_id } ...\" ) post_ticket_note self . _logger . info ( f \"Note successfully posted to ticketID: { ticket_id } \" )","title":"Post note"},{"location":"logging/services/bruin-bridge/actions/post_note/#subject-bruinticketnoteappendrequest","text":"Message arrives at subject If message body doesn't have ticket_id or note : self . _logger . error ( f \"Cannot post a note to ticket using { json . dumps ( msg ) } . JSON malformed\" ) END self . _logger . info ( f \"Putting note in: { ticket_id } ...\" ) post_ticket_note self . _logger . info ( f \"Note successfully posted to ticketID: { ticket_id } \" )","title":"Subject: bruin.ticket.note.append.request"},{"location":"logging/services/bruin-bridge/actions/post_notification_email_milestone/","text":"Subject: bruin.notification.email.milestone Message arrives at subject If message body doesn't have ticket_id , notification_type , or service_number : self . _logger . error ( f \"Cannot send milestone email using { json . dumps ( msg ) } . \" f \"JSON malformed\" ) END self . _logger . info ( f 'Sending milestone email for ticket \" { ticket_id } \", service number \" { service_number } \"' f ' and notification type \" { notification_type } \"...' ) post_notification_email_milestone If status from post_notification_email_milestone is in range of 200 - 300: self . _logger . info ( f \"Milestone email notification successfully sent for ticket { ticket_id } , service number\" f \" { service_number } and notification type { notification_type } \" ) Else self . _logger . error ( f \"Error sending milestone email notification for ticket { ticket_id } , service number\" f \" { service_number } and notification type { notification_type } : Status:\" f ' { response [ \"status\" ] } body: { response [ \"body\" ] } ' ) END","title":"Post notification email milestone"},{"location":"logging/services/bruin-bridge/actions/post_notification_email_milestone/#subject-bruinnotificationemailmilestone","text":"Message arrives at subject If message body doesn't have ticket_id , notification_type , or service_number : self . _logger . error ( f \"Cannot send milestone email using { json . dumps ( msg ) } . \" f \"JSON malformed\" ) END self . _logger . info ( f 'Sending milestone email for ticket \" { ticket_id } \", service number \" { service_number } \"' f ' and notification type \" { notification_type } \"...' ) post_notification_email_milestone If status from post_notification_email_milestone is in range of 200 - 300: self . _logger . info ( f \"Milestone email notification successfully sent for ticket { ticket_id } , service number\" f \" { service_number } and notification type { notification_type } \" ) Else self . _logger . error ( f \"Error sending milestone email notification for ticket { ticket_id } , service number\" f \" { service_number } and notification type { notification_type } : Status:\" f ' { response [ \"status\" ] } body: { response [ \"body\" ] } ' ) END","title":"Subject: bruin.notification.email.milestone"},{"location":"logging/services/bruin-bridge/actions/post_outage_ticket/","text":"Subject: bruin.ticket.creation.outage.request Message arrives at subject If message body doesn't have service_number or client_id : self . _logger . error ( f \"Cannot post ticket using payload { json . dumps ( msg ) } . \" 'Need \"client_id\" and \"service_number\"' ) END If client_id is None or service_number is None: self . _logger . error ( f \"Cannot post ticket using payload { json . dumps ( msg ) } .\" f '\"client_id\" and \"service_number\" must have non-null values.' ) self . _logger . info ( f \"Posting outage ticket with payload: { json . dumps ( msg ) } \" ) post_outage_ticket self . _logger . info ( f \"Outage ticket posted using parameters { json . dumps ( msg ) } \" ) self . _logger . info ( f \"Outage ticket published in event bus for request { json . dumps ( msg ) } \" )","title":"Post outage ticket"},{"location":"logging/services/bruin-bridge/actions/post_outage_ticket/#subject-bruinticketcreationoutagerequest","text":"Message arrives at subject If message body doesn't have service_number or client_id : self . _logger . error ( f \"Cannot post ticket using payload { json . dumps ( msg ) } . \" 'Need \"client_id\" and \"service_number\"' ) END If client_id is None or service_number is None: self . _logger . error ( f \"Cannot post ticket using payload { json . dumps ( msg ) } .\" f '\"client_id\" and \"service_number\" must have non-null values.' ) self . _logger . info ( f \"Posting outage ticket with payload: { json . dumps ( msg ) } \" ) post_outage_ticket self . _logger . info ( f \"Outage ticket posted using parameters { json . dumps ( msg ) } \" ) self . _logger . info ( f \"Outage ticket published in event bus for request { json . dumps ( msg ) } \" )","title":"Subject: bruin.ticket.creation.outage.request"},{"location":"logging/services/bruin-bridge/actions/post_ticket/","text":"Subject: bruin.ticket.creation.request Message arrives at subject If message doesn't have a body: self . _logger . error ( f \"Cannot create a ticket using { json . dumps ( msg ) } . JSON malformed\" ) END If message body doesn't have clientId , category , services , contacts : self . _logger . info ( f \"Cannot create ticket using { json . dumps ( payload ) } . \" f 'Need \"clientId\", \"category\", \"services\", \"contacts\"' ) END self . _logger . info ( f 'Creating ticket for client id: { payload [ \"clientId\" ] } ...' ) post_ticket If status from post_ticket is in range 200 - 300: self . _logger . info ( f 'Ticket created for client id: { payload [ \"clientId\" ] } with ticket id:' f ' { result [ \"body\" ][ \"ticketIds\" ][ 0 ] } ' ) Else self . _logger . error ( response [ \"body\" ]) END","title":"Post ticket"},{"location":"logging/services/bruin-bridge/actions/post_ticket/#subject-bruinticketcreationrequest","text":"Message arrives at subject If message doesn't have a body: self . _logger . error ( f \"Cannot create a ticket using { json . dumps ( msg ) } . JSON malformed\" ) END If message body doesn't have clientId , category , services , contacts : self . _logger . info ( f \"Cannot create ticket using { json . dumps ( payload ) } . \" f 'Need \"clientId\", \"category\", \"services\", \"contacts\"' ) END self . _logger . info ( f 'Creating ticket for client id: { payload [ \"clientId\" ] } ...' ) post_ticket If status from post_ticket is in range 200 - 300: self . _logger . info ( f 'Ticket created for client id: { payload [ \"clientId\" ] } with ticket id:' f ' { result [ \"body\" ][ \"ticketIds\" ][ 0 ] } ' ) Else self . _logger . error ( response [ \"body\" ]) END","title":"Subject: bruin.ticket.creation.request"},{"location":"logging/services/bruin-bridge/actions/resolve_ticket/","text":"Subject: bruin.ticket.status.resolve Message arrives at subject If message body has ticket_id and detail_id : self . _logger . info ( f \"Updating the ticket status for ticket id: { ticket_id } to RESOLVED\" ) resolve_ticket Else self . _logger . error ( f \"Cannot resolve a ticket using { json . dumps ( msg ) } . JSON malformed\" ) END","title":"Resolve ticket"},{"location":"logging/services/bruin-bridge/actions/resolve_ticket/#subject-bruinticketstatusresolve","text":"Message arrives at subject If message body has ticket_id and detail_id : self . _logger . info ( f \"Updating the ticket status for ticket id: { ticket_id } to RESOLVED\" ) resolve_ticket Else self . _logger . error ( f \"Cannot resolve a ticket using { json . dumps ( msg ) } . JSON malformed\" ) END","title":"Subject: bruin.ticket.status.resolve"},{"location":"logging/services/bruin-bridge/actions/subscribe_user/","text":"Subject: bruin.subscribe.user Message arrives at subject Try to get Message body Catch ValidationError : self . logger . warning ( f \"Wrong request message: msg= { msg } , validation_error= { e } \" ) END self . logger . info ( f \"Subscribing user: post_request= { post_request } \" ) post If response.status from post is HTTPStatus.UNAUTHORIZED self . logger . error ( f \"Got 401 from Bruin. Re-logging in...\" ) END","title":"Subscribe user"},{"location":"logging/services/bruin-bridge/actions/subscribe_user/#subject-bruinsubscribeuser","text":"Message arrives at subject Try to get Message body Catch ValidationError : self . logger . warning ( f \"Wrong request message: msg= { msg } , validation_error= { e } \" ) END self . logger . info ( f \"Subscribing user: post_request= { post_request } \" ) post If response.status from post is HTTPStatus.UNAUTHORIZED self . logger . error ( f \"Got 401 from Bruin. Re-logging in...\" ) END","title":"Subject: bruin.subscribe.user"},{"location":"logging/services/bruin-bridge/actions/unpause_ticket/","text":"Subject: bruin.ticket.unpause Message arrives at subject If message body doesn't have service_number or detail_id : self . _logger . error ( f \"Cannot unpause a ticket using { json . dumps ( msg ) } . JSON malformed\" ) END self . _logger . info ( f \"Unpause the ticket for ticket id: { ticket_id } , \" f \"serial number: { serial_number } and detail id: { detail_id } \" ) unpause_ticket self . _logger . info ( f \"Response from unpause: { response } to the ticket with ticket id: { ticket_id } , \" f \"serial number: { serial_number } and detail id { detail_id } \" )","title":"Unpause ticket"},{"location":"logging/services/bruin-bridge/actions/unpause_ticket/#subject-bruinticketunpause","text":"Message arrives at subject If message body doesn't have service_number or detail_id : self . _logger . error ( f \"Cannot unpause a ticket using { json . dumps ( msg ) } . JSON malformed\" ) END self . _logger . info ( f \"Unpause the ticket for ticket id: { ticket_id } , \" f \"serial number: { serial_number } and detail id: { detail_id } \" ) unpause_ticket self . _logger . info ( f \"Response from unpause: { response } to the ticket with ticket id: { ticket_id } , \" f \"serial number: { serial_number } and detail id { detail_id } \" )","title":"Subject: bruin.ticket.unpause"},{"location":"logging/services/bruin-bridge/app_entrypoint/app/","text":"App entrypoint self . _logger . info ( \"Bruin bridge starting...\" )","title":"App"},{"location":"logging/services/bruin-bridge/app_entrypoint/app/#app-entrypoint","text":"self . _logger . info ( \"Bruin bridge starting...\" )","title":"App entrypoint"},{"location":"logging/services/bruin-bridge/clients/bruin_client/_get_request_headers/","text":"Get request headers If there is no bearer token: raise Exception ( \"Missing BEARER token\" )","title":"Get request headers"},{"location":"logging/services/bruin-bridge/clients/bruin_client/_get_request_headers/#get-request-headers","text":"If there is no bearer token: raise Exception ( \"Missing BEARER token\" )","title":"Get request headers"},{"location":"logging/services/bruin-bridge/clients/bruin_client/change_detail_work_queue/","text":"Change detail work queue self . _logger . info ( f \"Changing work queue for ticket detail: { filters } and ticket id : { ticket_id } \" ) Call Bruin API endpoint PUT /api/Ticket/{ticket_id}/details/work with the desired payload. If the status of the HTTP response is in range 200 - 299 : self . _logger . info ( f \"Work queue changed for ticket detail: { filters } \" ) END If the status of the HTTP response is 400 : self . _logger . error ( f \"Got error from Bruin { response_json } \" ) END If the status of the HTTP response is 401 : self . _logger . error ( f \"Got 401 from Bruin. Re-logging in...\" ) login END If the status of the HTTP response is in range 500 - 513 : self . _logger . error ( f \"Got { response . status } .\" ) END","title":"Change detail work queue"},{"location":"logging/services/bruin-bridge/clients/bruin_client/change_detail_work_queue/#change-detail-work-queue","text":"self . _logger . info ( f \"Changing work queue for ticket detail: { filters } and ticket id : { ticket_id } \" ) Call Bruin API endpoint PUT /api/Ticket/{ticket_id}/details/work with the desired payload. If the status of the HTTP response is in range 200 - 299 : self . _logger . info ( f \"Work queue changed for ticket detail: { filters } \" ) END If the status of the HTTP response is 400 : self . _logger . error ( f \"Got error from Bruin { response_json } \" ) END If the status of the HTTP response is 401 : self . _logger . error ( f \"Got 401 from Bruin. Re-logging in...\" ) login END If the status of the HTTP response is in range 500 - 513 : self . _logger . error ( f \"Got { response . status } .\" ) END","title":"Change detail work queue"},{"location":"logging/services/bruin-bridge/clients/bruin_client/change_ticket_severity/","text":"Change ticket severity self . _logger . info ( f \"Changing severity of ticket { ticket_id } using payload { payload } ...\" ) Call Bruin API endpoint PUT /api/Ticket/{ticket_id}/severity with the desired payload. If there's an error while connecting to Bruin API: self . _logger . error ( f \"A connection error happened while trying to connect to Bruin API -> { e } \" ) END If the status of the HTTP response is 200 : self . _logger . info ( f \"Severity of ticket { ticket_id } changed successfully! Payload used was { payload } \" ) END If the status of the HTTP response is 400 : self . _logger . error ( f \"Got HTTP 400 from Bruin -> { response_json } \" ) END If the status of the HTTP response is 401 : self . _logger . error ( f \"Got HTTP 401 from Bruin. Re-logging in...\" ) login END If the status of the HTTP response is 403 : self . _logger . error ( f \"Got HTTP 403 from Bruin\" ) END If the status of the HTTP response is 404 : self . _logger . error ( f \"Got HTTP 404 from Bruin\" ) END If the status of the HTTP response is between 500 and 512 (both inclusive): self . _logger . error ( f \"Got HTTP { response . status } from Bruin\" ) END","title":"Change ticket severity"},{"location":"logging/services/bruin-bridge/clients/bruin_client/change_ticket_severity/#change-ticket-severity","text":"self . _logger . info ( f \"Changing severity of ticket { ticket_id } using payload { payload } ...\" ) Call Bruin API endpoint PUT /api/Ticket/{ticket_id}/severity with the desired payload. If there's an error while connecting to Bruin API: self . _logger . error ( f \"A connection error happened while trying to connect to Bruin API -> { e } \" ) END If the status of the HTTP response is 200 : self . _logger . info ( f \"Severity of ticket { ticket_id } changed successfully! Payload used was { payload } \" ) END If the status of the HTTP response is 400 : self . _logger . error ( f \"Got HTTP 400 from Bruin -> { response_json } \" ) END If the status of the HTTP response is 401 : self . _logger . error ( f \"Got HTTP 401 from Bruin. Re-logging in...\" ) login END If the status of the HTTP response is 403 : self . _logger . error ( f \"Got HTTP 403 from Bruin\" ) END If the status of the HTTP response is 404 : self . _logger . error ( f \"Got HTTP 404 from Bruin\" ) END If the status of the HTTP response is between 500 and 512 (both inclusive): self . _logger . error ( f \"Got HTTP { response . status } from Bruin\" ) END","title":"Change ticket severity"},{"location":"logging/services/bruin-bridge/clients/bruin_client/get_all_tickets/","text":"Get all tickets self . _logger . info ( f \"Getting ticket(s) using params { json . dumps ( parsed_params ) } \" ) Call Bruin API endpoint GET /api/Ticket with the desired payload. If the status of the HTTP response is 400 : self . _logger . error ( f \"Got error from Bruin { response_json } \" ) END If the status of the HTTP response is 401 : self . _logger . error ( f \"Got 401 from Bruin. Re-logging in...\" ) login END If the status of the HTTP response is 403 : self . _logger . error ( f \"Forbidden error from Bruin { response_json } \" ) END If the status of the HTTP response is 404 : self . _logger . error ( f \"Got 404 from Bruin, resource not found for params { request_params } \" ) END If the status of the HTTP response is between 500 and 512 (both inclusive): self . _logger . error ( f \"Got { response . status } .\" ) END","title":"Get all tickets"},{"location":"logging/services/bruin-bridge/clients/bruin_client/get_all_tickets/#get-all-tickets","text":"self . _logger . info ( f \"Getting ticket(s) using params { json . dumps ( parsed_params ) } \" ) Call Bruin API endpoint GET /api/Ticket with the desired payload. If the status of the HTTP response is 400 : self . _logger . error ( f \"Got error from Bruin { response_json } \" ) END If the status of the HTTP response is 401 : self . _logger . error ( f \"Got 401 from Bruin. Re-logging in...\" ) login END If the status of the HTTP response is 403 : self . _logger . error ( f \"Forbidden error from Bruin { response_json } \" ) END If the status of the HTTP response is 404 : self . _logger . error ( f \"Got 404 from Bruin, resource not found for params { request_params } \" ) END If the status of the HTTP response is between 500 and 512 (both inclusive): self . _logger . error ( f \"Got { response . status } .\" ) END","title":"Get all tickets"},{"location":"logging/services/bruin-bridge/clients/bruin_client/get_asset_topics/","text":"Get asset topics self . _logger . info ( f \"Getting asset topics for: { params } \" ) Call Bruin API endpoint GET /api/Ticket/topics with the desired payload. If the status of the HTTP response is HTTPStatus.UNAUTHORIZED : self . _logger . error ( f \"Got 401 from Bruin. Re-logging in...\" ) login END","title":"Get asset topics"},{"location":"logging/services/bruin-bridge/clients/bruin_client/get_asset_topics/#get-asset-topics","text":"self . _logger . info ( f \"Getting asset topics for: { params } \" ) Call Bruin API endpoint GET /api/Ticket/topics with the desired payload. If the status of the HTTP response is HTTPStatus.UNAUTHORIZED : self . _logger . error ( f \"Got 401 from Bruin. Re-logging in...\" ) login END","title":"Get asset topics"},{"location":"logging/services/bruin-bridge/clients/bruin_client/get_circuit_id/","text":"Get circuit id self . _logger . info ( f \"Getting the circuit id from bruin with params { parsed_params } \" ) Call Bruin API endpoint GET /api/Inventory/circuit with the desired payload. If there's an error while connecting to Bruin API: self . _logger . error ( f \"A connection error happened while trying to connect to Bruin API -> { e } \" ) END If the status of the HTTP response is in range 200 - 300 : self . _logger . info ( f \"Got circuit id from bruin with params: { parsed_params } \" ) END If the status of the HTTP response is 204 : self . _logger . error ( \"Got status 204 from Bruin\" ) END If the status of the HTTP response is 400 : self . _logger . error ( f \"Got error 400 from Bruin { response_json } \" ) END If the status of the HTTP response is 401 : self . _logger . error ( f \"Got 401 from Bruin. Re-logging in...\" ) login END If the status of the HTTP response is 403 : self . _logger . error ( f \"Forbidden error from Bruin { response_json } \" ) END If the status of the HTTP response is in range 500 - 513 : self . _logger . error ( f \"Got { response . status } .\" ) END","title":"Get circuit id"},{"location":"logging/services/bruin-bridge/clients/bruin_client/get_circuit_id/#get-circuit-id","text":"self . _logger . info ( f \"Getting the circuit id from bruin with params { parsed_params } \" ) Call Bruin API endpoint GET /api/Inventory/circuit with the desired payload. If there's an error while connecting to Bruin API: self . _logger . error ( f \"A connection error happened while trying to connect to Bruin API -> { e } \" ) END If the status of the HTTP response is in range 200 - 300 : self . _logger . info ( f \"Got circuit id from bruin with params: { parsed_params } \" ) END If the status of the HTTP response is 204 : self . _logger . error ( \"Got status 204 from Bruin\" ) END If the status of the HTTP response is 400 : self . _logger . error ( f \"Got error 400 from Bruin { response_json } \" ) END If the status of the HTTP response is 401 : self . _logger . error ( f \"Got 401 from Bruin. Re-logging in...\" ) login END If the status of the HTTP response is 403 : self . _logger . error ( f \"Forbidden error from Bruin { response_json } \" ) END If the status of the HTTP response is in range 500 - 513 : self . _logger . error ( f \"Got { response . status } .\" ) END","title":"Get circuit id"},{"location":"logging/services/bruin-bridge/clients/bruin_client/get_client_info/","text":"Get client info self . _logger . info ( f \"Getting Bruin client ID for filters: { filters } \" ) Call Bruin API endpoint GET /api/Inventory with the desired payload. If there's an error while connecting to Bruin API: self . _logger . error ( f \"A connection error happened while trying to connect to Bruin API -> { e } \" ) END If the status of the HTTP response is 400 : self . _logger . error ( f \"Got error from Bruin { response_json } \" ) END If the status of the HTTP response is 401 : self . _logger . error ( f \"Got 401 from Bruin. Re-logging in...\" ) login END","title":"Get client info"},{"location":"logging/services/bruin-bridge/clients/bruin_client/get_client_info/#get-client-info","text":"self . _logger . info ( f \"Getting Bruin client ID for filters: { filters } \" ) Call Bruin API endpoint GET /api/Inventory with the desired payload. If there's an error while connecting to Bruin API: self . _logger . error ( f \"A connection error happened while trying to connect to Bruin API -> { e } \" ) END If the status of the HTTP response is 400 : self . _logger . error ( f \"Got error from Bruin { response_json } \" ) END If the status of the HTTP response is 401 : self . _logger . error ( f \"Got 401 from Bruin. Re-logging in...\" ) login END","title":"Get client info"},{"location":"logging/services/bruin-bridge/clients/bruin_client/get_client_info_by_did/","text":"Get client info by did self . _logger . info ( f \"Getting Bruin client info by DID: { did } \" ) Call Bruin API endpoint GET /api/Inventory/phoneNumber/Lines with the desired payload. If there's an error while connecting to Bruin API: self . _logger . error ( f \"A connection error happened while trying to connect to Bruin API -> { e } \" ) END If the status of the HTTP response is 400 : self . _logger . error ( f \"Got error from Bruin { response_json } \" ) END If the status of the HTTP response is 401 : self . _logger . error ( f \"Got 401 from Bruin. Re-logging in...\" ) login END","title":"Get client info by did"},{"location":"logging/services/bruin-bridge/clients/bruin_client/get_client_info_by_did/#get-client-info-by-did","text":"self . _logger . info ( f \"Getting Bruin client info by DID: { did } \" ) Call Bruin API endpoint GET /api/Inventory/phoneNumber/Lines with the desired payload. If there's an error while connecting to Bruin API: self . _logger . error ( f \"A connection error happened while trying to connect to Bruin API -> { e } \" ) END If the status of the HTTP response is 400 : self . _logger . error ( f \"Got error from Bruin { response_json } \" ) END If the status of the HTTP response is 401 : self . _logger . error ( f \"Got 401 from Bruin. Re-logging in...\" ) login END","title":"Get client info by did"},{"location":"logging/services/bruin-bridge/clients/bruin_client/get_inventory_attributes/","text":"Get inventory attributes self . _logger . info ( f 'Getting inventory_attributes for client ID: { filters [ \"client_id\" ] } ' ) self . _logger . info ( f \"Filters that will be applied (parsed to PascalCase): { json . dumps ( parsed_filters ) } \" ) Call Bruin API endpoint GET /api/Inventory/Attribute with the desired payload. If there's an error while connecting to Bruin API: self . _logger . error ( f \"A connection error happened while trying to connect to Bruin API -> { e } \" ) END If the status of the HTTP response is 400 : self . _logger . error ( f \"Got error from Bruin { response_json } \" ) END If the status of the HTTP response is 401 : self . _logger . error ( f \"Got 401 from Bruin. Re-logging in...\" ) login END If the status of the HTTP response is 403 : self . _logger . error ( f \"Forbidden error from Bruin { response_json } \" ) END If the status of the HTTP response is between 500 and 512 (both inclusive): self . _logger . error ( f \"Got { response . status } .\" ) END","title":"Get inventory attributes"},{"location":"logging/services/bruin-bridge/clients/bruin_client/get_inventory_attributes/#get-inventory-attributes","text":"self . _logger . info ( f 'Getting inventory_attributes for client ID: { filters [ \"client_id\" ] } ' ) self . _logger . info ( f \"Filters that will be applied (parsed to PascalCase): { json . dumps ( parsed_filters ) } \" ) Call Bruin API endpoint GET /api/Inventory/Attribute with the desired payload. If there's an error while connecting to Bruin API: self . _logger . error ( f \"A connection error happened while trying to connect to Bruin API -> { e } \" ) END If the status of the HTTP response is 400 : self . _logger . error ( f \"Got error from Bruin { response_json } \" ) END If the status of the HTTP response is 401 : self . _logger . error ( f \"Got 401 from Bruin. Re-logging in...\" ) login END If the status of the HTTP response is 403 : self . _logger . error ( f \"Forbidden error from Bruin { response_json } \" ) END If the status of the HTTP response is between 500 and 512 (both inclusive): self . _logger . error ( f \"Got { response . status } .\" ) END","title":"Get inventory attributes"},{"location":"logging/services/bruin-bridge/clients/bruin_client/get_possible_detail_next_result/","text":"Get possible detail next result self . _logger . info ( f \"Getting work queues for ticket detail: { filters } \" ) Call Bruin API endpoint GET /api/Ticket/{ticket_id}/nextresult with the desired payload. If the status of the HTTP response is in range 200 - 299 : self . _logger . info ( f \"Got possible next work queue results for : { filters } \" ) END If the status of the HTTP response is 400 : self . _logger . error ( f \"Got error 400 from Bruin { response_json } \" ) END If the status of the HTTP response is 401 : self . _logger . error ( f \"Got 401 from Bruin. Re-logging in...\" ) login END If the status of the HTTP response is in range 500 - 513 : self . _logger . error ( f \"Got { response . status } .\" ) END","title":"Get possible detail next result"},{"location":"logging/services/bruin-bridge/clients/bruin_client/get_possible_detail_next_result/#get-possible-detail-next-result","text":"self . _logger . info ( f \"Getting work queues for ticket detail: { filters } \" ) Call Bruin API endpoint GET /api/Ticket/{ticket_id}/nextresult with the desired payload. If the status of the HTTP response is in range 200 - 299 : self . _logger . info ( f \"Got possible next work queue results for : { filters } \" ) END If the status of the HTTP response is 400 : self . _logger . error ( f \"Got error 400 from Bruin { response_json } \" ) END If the status of the HTTP response is 401 : self . _logger . error ( f \"Got 401 from Bruin. Re-logging in...\" ) login END If the status of the HTTP response is in range 500 - 513 : self . _logger . error ( f \"Got { response . status } .\" ) END","title":"Get possible detail next result"},{"location":"logging/services/bruin-bridge/clients/bruin_client/get_site/","text":"Get site self . _logger . info ( f \"Getting Bruin Site for params: { params } \" ) Call Bruin API endpoint GET /api/Site with the set of desired query parameters. If there's an error while connecting to Bruin API: self . _logger . error ( f \"A connection error happened while trying to connect to Bruin API. { e } \" ) END If the status of the HTTP response is 200 : self . _logger . info ( f \"Got HTTP 200 from GET /api/Site for params { json . dumps ( params ) } \" ) END If the status of the HTTP response is 400 : self . _logger . error ( f \"Got error from Bruin { response_json } \" ) END If the status of the HTTP response is 401 : self . _logger . error ( f \"Got 401 from Bruin. Re-logging in...\" ) login END If the status of the HTTP response is 403 : self . _logger . error ( f \"Got HTTP 403 from Bruin\" ) END If the status of the HTTP response is 404 : self . _logger . error ( f \"Got HTTP 404 from Bruin\" ) END If the status of the HTTP response is between 500 and 512 (both inclusive): self . _logger . error ( f \"Got HTTP { response . status } from Bruin\" ) END","title":"Get site"},{"location":"logging/services/bruin-bridge/clients/bruin_client/get_site/#get-site","text":"self . _logger . info ( f \"Getting Bruin Site for params: { params } \" ) Call Bruin API endpoint GET /api/Site with the set of desired query parameters. If there's an error while connecting to Bruin API: self . _logger . error ( f \"A connection error happened while trying to connect to Bruin API. { e } \" ) END If the status of the HTTP response is 200 : self . _logger . info ( f \"Got HTTP 200 from GET /api/Site for params { json . dumps ( params ) } \" ) END If the status of the HTTP response is 400 : self . _logger . error ( f \"Got error from Bruin { response_json } \" ) END If the status of the HTTP response is 401 : self . _logger . error ( f \"Got 401 from Bruin. Re-logging in...\" ) login END If the status of the HTTP response is 403 : self . _logger . error ( f \"Got HTTP 403 from Bruin\" ) END If the status of the HTTP response is 404 : self . _logger . error ( f \"Got HTTP 404 from Bruin\" ) END If the status of the HTTP response is between 500 and 512 (both inclusive): self . _logger . error ( f \"Got HTTP { response . status } from Bruin\" ) END","title":"Get site"},{"location":"logging/services/bruin-bridge/clients/bruin_client/get_ticket_details/","text":"Get ticket details self . _logger . info ( f \"Getting ticket details for ticket id: { ticket_id } \" ) Call Bruin API endpoint GET /api/Ticket/{ticket_id}/details with the desired payload. If the status of the HTTP response is 400 : self . _logger . error ( f \"Got error from Bruin { response_json } \" ) END If the status of the HTTP response is 401 : self . _logger . error ( f \"Got 401 from Bruin. Re-logging in...\" ) login END If the status of the HTTP response is 403 : self . _logger . error ( f \"Forbidden error from Bruin { response_json } \" ) END If the status of the HTTP response is 404 : self . _logger . error ( f \"Got 404 from Bruin, resource not found for ticket id { ticket_id } \" ) END If the status of the HTTP response is between 500 and 512 (both inclusive): self . _logger . error ( f \"Got { response . status } .\" ) END","title":"Get ticket details"},{"location":"logging/services/bruin-bridge/clients/bruin_client/get_ticket_details/#get-ticket-details","text":"self . _logger . info ( f \"Getting ticket details for ticket id: { ticket_id } \" ) Call Bruin API endpoint GET /api/Ticket/{ticket_id}/details with the desired payload. If the status of the HTTP response is 400 : self . _logger . error ( f \"Got error from Bruin { response_json } \" ) END If the status of the HTTP response is 401 : self . _logger . error ( f \"Got 401 from Bruin. Re-logging in...\" ) login END If the status of the HTTP response is 403 : self . _logger . error ( f \"Forbidden error from Bruin { response_json } \" ) END If the status of the HTTP response is 404 : self . _logger . error ( f \"Got 404 from Bruin, resource not found for ticket id { ticket_id } \" ) END If the status of the HTTP response is between 500 and 512 (both inclusive): self . _logger . error ( f \"Got { response . status } .\" ) END","title":"Get ticket details"},{"location":"logging/services/bruin-bridge/clients/bruin_client/get_ticket_task_history/","text":"Get ticket task history self . _logger . info ( f \"Getting ticket task history for ticket: { filters } \" ) Call Bruin API endpoint GET /api/Ticket/AITicketData?ticketId={filters[\"ticket_id\"]} with the desired payload. If there's an error while connecting to Bruin API: self . _logger . error ( f \"A connection error happened while trying to connect to Bruin API -> { e } \" ) END If the status of the HTTP response is in range 200 - 300 : self . _logger . info ( f \"Got ticket task history for : { filters } \" ) END If the status of the HTTP response is 400 : self . _logger . error ( f \"Got error 400 from Bruin { response_json } \" ) END If the status of the HTTP response is 401 : self . _logger . error ( f \"Got 401 from Bruin. Re-logging in...\" ) login END If the status of the HTTP response is in range 500 - 513 : self . _logger . error ( f \"Got { response . status } .\" ) END","title":"Get ticket task history"},{"location":"logging/services/bruin-bridge/clients/bruin_client/get_ticket_task_history/#get-ticket-task-history","text":"self . _logger . info ( f \"Getting ticket task history for ticket: { filters } \" ) Call Bruin API endpoint GET /api/Ticket/AITicketData?ticketId={filters[\"ticket_id\"]} with the desired payload. If there's an error while connecting to Bruin API: self . _logger . error ( f \"A connection error happened while trying to connect to Bruin API -> { e } \" ) END If the status of the HTTP response is in range 200 - 300 : self . _logger . info ( f \"Got ticket task history for : { filters } \" ) END If the status of the HTTP response is 400 : self . _logger . error ( f \"Got error 400 from Bruin { response_json } \" ) END If the status of the HTTP response is 401 : self . _logger . error ( f \"Got 401 from Bruin. Re-logging in...\" ) login END If the status of the HTTP response is in range 500 - 513 : self . _logger . error ( f \"Got { response . status } .\" ) END","title":"Get ticket task history"},{"location":"logging/services/bruin-bridge/clients/bruin_client/get_tickets_basic_info/","text":"Get tickets basic info self . _logger . info ( f \"Getting tickets basic info using params { json . dumps ( request_params ) } ...\" ) Call Bruin API endpoint GET /api/Ticket/basic with the set of desired query parameters. If there's an error while connecting to Bruin API: self . _logger . error ( f \"A connection error happened while trying to connect to Bruin API: { e } \" ) END If the status of the HTTP response is 200 : self . _logger . info ( f \"Got HTTP 200 from GET /api/Ticket/basic for params { json . dumps ( request_params ) } \" ) END If the status of the HTTP response is 400 : self . _logger . error ( f \"Got error from Bruin { response_json } \" ) END If the status of the HTTP response is 401 : self . _logger . error ( f \"Got 401 from Bruin. Re-logging in...\" ) login END If the status of the HTTP response is 403 : self . _logger . error ( f \"Forbidden error from Bruin { response_json } \" ) END If the status of the HTTP response is 404 : self . _logger . error ( f \"Got 404 from Bruin, resource not found for params { request_params } \" ) END If the status of the HTTP response is between 500 and 512 (both inclusive): self . _logger . error ( f \"Got { response . status } .\" ) END","title":"Get tickets basic info"},{"location":"logging/services/bruin-bridge/clients/bruin_client/get_tickets_basic_info/#get-tickets-basic-info","text":"self . _logger . info ( f \"Getting tickets basic info using params { json . dumps ( request_params ) } ...\" ) Call Bruin API endpoint GET /api/Ticket/basic with the set of desired query parameters. If there's an error while connecting to Bruin API: self . _logger . error ( f \"A connection error happened while trying to connect to Bruin API: { e } \" ) END If the status of the HTTP response is 200 : self . _logger . info ( f \"Got HTTP 200 from GET /api/Ticket/basic for params { json . dumps ( request_params ) } \" ) END If the status of the HTTP response is 400 : self . _logger . error ( f \"Got error from Bruin { response_json } \" ) END If the status of the HTTP response is 401 : self . _logger . error ( f \"Got 401 from Bruin. Re-logging in...\" ) login END If the status of the HTTP response is 403 : self . _logger . error ( f \"Forbidden error from Bruin { response_json } \" ) END If the status of the HTTP response is 404 : self . _logger . error ( f \"Got 404 from Bruin, resource not found for params { request_params } \" ) END If the status of the HTTP response is between 500 and 512 (both inclusive): self . _logger . error ( f \"Got { response . status } .\" ) END","title":"Get tickets basic info"},{"location":"logging/services/bruin-bridge/clients/bruin_client/link_ticket_to_email/","text":"Link ticket to email self . _logger . info ( f \"Linking ticket { ticket_id } with email { email_id } \" ) Call Bruin API endpoint POST /api/Email/{email_id}/link/ticket/{ticket_id} with the desired payload. If there's an error while connecting to Bruin API: self . _logger . error ( f \"A connection error happened while trying to connect to Bruin API -> { e } \" ) END If the status of the HTTP response is 401 : self . _logger . error ( f \"Got 401 from Bruin. Re-logging in...\" ) login END If the status of the HTTP response is in range 500 - 513 : self . _logger . error ( f \"Got HTTP { response . status } from Bruin\" ) END","title":"Link ticket to email"},{"location":"logging/services/bruin-bridge/clients/bruin_client/link_ticket_to_email/#link-ticket-to-email","text":"self . _logger . info ( f \"Linking ticket { ticket_id } with email { email_id } \" ) Call Bruin API endpoint POST /api/Email/{email_id}/link/ticket/{ticket_id} with the desired payload. If there's an error while connecting to Bruin API: self . _logger . error ( f \"A connection error happened while trying to connect to Bruin API -> { e } \" ) END If the status of the HTTP response is 401 : self . _logger . error ( f \"Got 401 from Bruin. Re-logging in...\" ) login END If the status of the HTTP response is in range 500 - 513 : self . _logger . error ( f \"Got HTTP { response . status } from Bruin\" ) END","title":"Link ticket to email"},{"location":"logging/services/bruin-bridge/clients/bruin_client/login/","text":"Login self . _logger . info ( \"Logging into Bruin...\" ) Call Bruin Identity Server endpoint POST /identity/connect/token using authentication credentials. If no errors arise while calling the endpoint: self . _logger . info ( \"Logged into Bruin!\" ) Otherwise: self . _logger . error ( f \"An error occurred while trying to login to Bruin: { err } \" )","title":"Login"},{"location":"logging/services/bruin-bridge/clients/bruin_client/login/#login","text":"self . _logger . info ( \"Logging into Bruin...\" ) Call Bruin Identity Server endpoint POST /identity/connect/token using authentication credentials. If no errors arise while calling the endpoint: self . _logger . info ( \"Logged into Bruin!\" ) Otherwise: self . _logger . error ( f \"An error occurred while trying to login to Bruin: { err } \" )","title":"Login"},{"location":"logging/services/bruin-bridge/clients/bruin_client/mark_email_as_done/","text":"Mark email as done self . _logger . info ( f \"Marking email as done: { email_id } \" ) Call Bruin API endpoint POST /api/Email/status with the desired payload. If there's an error while connecting to Bruin API: self . _logger . error ( f \"A connection error happened while trying to connect to Bruin API -> { e } \" ) END If the status of the HTTP response is 400 : self . _logger . error ( f \"Got error 400 from Bruin { response_json } \" ) END If the status of the HTTP response is 401 : self . _logger . error ( f \"Got 401 from Bruin. Re-logging in...\" ) login END If the status of the HTTP response is in range 500 - 513 : self . _logger . error ( f \"Got HTTP { response . status } from Bruin\" ) END","title":"Mark email as done"},{"location":"logging/services/bruin-bridge/clients/bruin_client/mark_email_as_done/#mark-email-as-done","text":"self . _logger . info ( f \"Marking email as done: { email_id } \" ) Call Bruin API endpoint POST /api/Email/status with the desired payload. If there's an error while connecting to Bruin API: self . _logger . error ( f \"A connection error happened while trying to connect to Bruin API -> { e } \" ) END If the status of the HTTP response is 400 : self . _logger . error ( f \"Got error 400 from Bruin { response_json } \" ) END If the status of the HTTP response is 401 : self . _logger . error ( f \"Got 401 from Bruin. Re-logging in...\" ) login END If the status of the HTTP response is in range 500 - 513 : self . _logger . error ( f \"Got HTTP { response . status } from Bruin\" ) END","title":"Mark email as done"},{"location":"logging/services/bruin-bridge/clients/bruin_client/post_email_tag/","text":"Post email tag try self . _logger . info ( f \"Sending request to /api/Email/ { email_id } /tag/ { tag_id } \" ) Call Bruin API endpoint POST /api/Email/{email_id}/tag/{tag_id} with the desired payload. self . _logger . info ( f \"Got response from Bruin. Status: { response . status } Response: { response } .\" ) If the status of the HTTP response is 400 : self . _logger . error ( f \"Got error 400 from Bruin { response_json } \" ) END If the status of the HTTP response is 401 : self . _logger . error ( f \"Got 401 from Bruin. Re-logging in...\" ) login END If the status of the HTTP response is 403 : self . _logger . error ( f \"Forbidden error from Bruin { response_json } \" ) END If the status of the HTTP response is 404 : self . _logger . error ( f \"Got 404 from Bruin, resource not posted for email_id { email_id } with tag_id { tag_id } \" ) END If the status of the HTTP response is 409 : self . _logger . error ( f \"Got 409 from Bruin, resource not posted for email_id { email_id } with tag_id { tag_id } \" ) END If the status of the HTTP response is in range 500 - 513 : self . _logger . error ( f \"Got { response . status } .\" ) END catch Exception self . _logger . error ( f \"Exception during call to post_email_tag. Error: { e } .\" )","title":"Post email tag"},{"location":"logging/services/bruin-bridge/clients/bruin_client/post_email_tag/#post-email-tag","text":"try self . _logger . info ( f \"Sending request to /api/Email/ { email_id } /tag/ { tag_id } \" ) Call Bruin API endpoint POST /api/Email/{email_id}/tag/{tag_id} with the desired payload. self . _logger . info ( f \"Got response from Bruin. Status: { response . status } Response: { response } .\" ) If the status of the HTTP response is 400 : self . _logger . error ( f \"Got error 400 from Bruin { response_json } \" ) END If the status of the HTTP response is 401 : self . _logger . error ( f \"Got 401 from Bruin. Re-logging in...\" ) login END If the status of the HTTP response is 403 : self . _logger . error ( f \"Forbidden error from Bruin { response_json } \" ) END If the status of the HTTP response is 404 : self . _logger . error ( f \"Got 404 from Bruin, resource not posted for email_id { email_id } with tag_id { tag_id } \" ) END If the status of the HTTP response is 409 : self . _logger . error ( f \"Got 409 from Bruin, resource not posted for email_id { email_id } with tag_id { tag_id } \" ) END If the status of the HTTP response is in range 500 - 513 : self . _logger . error ( f \"Got { response . status } .\" ) END catch Exception self . _logger . error ( f \"Exception during call to post_email_tag. Error: { e } .\" )","title":"Post email tag"},{"location":"logging/services/bruin-bridge/clients/bruin_client/post_multiple_ticket_notes/","text":"Post multiple ticket notes self . _logger . info ( f \"Posting multiple notes for ticket id: { ticket_id } . Payload { json . dumps ( payload ) } \" ) Call Bruin API endpoint POST /api/Ticket/{ticket_id}/notes/advanced with the desired payload. If there's an error while connecting to Bruin API: self . _logger . error ( f \"A connection error happened while trying to connect to Bruin API -> { e } \" ) END If the status of the HTTP response is 400 : self . _logger . error ( f \"Got error from Bruin { response_json } \" ) END If the status of the HTTP response is 401 : self . _logger . error ( f \"Got 401 from Bruin. Re-logging in...\" ) login END If the status of the HTTP response is 403 : self . _logger . error ( f \"Forbidden error from Bruin { response_json } \" ) END If the status of the HTTP response is 404 : self . _logger . error ( f \"Got 404 from Bruin, resources not posted for ticket_id { ticket_id } with payload { payload } \" ) END If the status of the HTTP response is between 500 and 512 (both inclusive): self . _logger . error ( f \"Got { response . status } .\" ) END","title":"Post multiple ticket notes"},{"location":"logging/services/bruin-bridge/clients/bruin_client/post_multiple_ticket_notes/#post-multiple-ticket-notes","text":"self . _logger . info ( f \"Posting multiple notes for ticket id: { ticket_id } . Payload { json . dumps ( payload ) } \" ) Call Bruin API endpoint POST /api/Ticket/{ticket_id}/notes/advanced with the desired payload. If there's an error while connecting to Bruin API: self . _logger . error ( f \"A connection error happened while trying to connect to Bruin API -> { e } \" ) END If the status of the HTTP response is 400 : self . _logger . error ( f \"Got error from Bruin { response_json } \" ) END If the status of the HTTP response is 401 : self . _logger . error ( f \"Got 401 from Bruin. Re-logging in...\" ) login END If the status of the HTTP response is 403 : self . _logger . error ( f \"Forbidden error from Bruin { response_json } \" ) END If the status of the HTTP response is 404 : self . _logger . error ( f \"Got 404 from Bruin, resources not posted for ticket_id { ticket_id } with payload { payload } \" ) END If the status of the HTTP response is between 500 and 512 (both inclusive): self . _logger . error ( f \"Got { response . status } .\" ) END","title":"Post multiple ticket notes"},{"location":"logging/services/bruin-bridge/clients/bruin_client/post_notification_email_milestone/","text":"Post notification email milestone self . _logger . info ( f 'Sending milestone email for ticket id { payload [ \"ticket_id\" ] } , service number' f ' { payload [ \"detail\" ][ \"service_number\" ] } and notification type' f ' { payload [ \"notification_type\" ] } ' ) self . _logger . info ( f \"Payload that will be applied : { json . dumps ( payload , indent = 2 ) } \" ) Call Bruin API endpoint POST /api/Notification/email/milestone with the desired payload. If the status of the HTTP response is 400 : self . _logger . error ( f \"Got error from Bruin { response_json } \" ) END If the status of the HTTP response is 401 : self . _logger . error ( f \"Got 401 from Bruin. Re-logging in...\" ) login END If the status of the HTTP response is 403 : self . _logger . error ( f \"Forbidden error from Bruin { response_json } \" ) END If the status of the HTTP response is 404 : self . _logger . error ( f \"Got 404 from Bruin, resource not posted for payload of { payload } \" ) END If the status of the HTTP response is in range 500 - 513 : self . _logger . error ( f \"Got { response . status } .\" ) END","title":"Post notification email milestone"},{"location":"logging/services/bruin-bridge/clients/bruin_client/post_notification_email_milestone/#post-notification-email-milestone","text":"self . _logger . info ( f 'Sending milestone email for ticket id { payload [ \"ticket_id\" ] } , service number' f ' { payload [ \"detail\" ][ \"service_number\" ] } and notification type' f ' { payload [ \"notification_type\" ] } ' ) self . _logger . info ( f \"Payload that will be applied : { json . dumps ( payload , indent = 2 ) } \" ) Call Bruin API endpoint POST /api/Notification/email/milestone with the desired payload. If the status of the HTTP response is 400 : self . _logger . error ( f \"Got error from Bruin { response_json } \" ) END If the status of the HTTP response is 401 : self . _logger . error ( f \"Got 401 from Bruin. Re-logging in...\" ) login END If the status of the HTTP response is 403 : self . _logger . error ( f \"Forbidden error from Bruin { response_json } \" ) END If the status of the HTTP response is 404 : self . _logger . error ( f \"Got 404 from Bruin, resource not posted for payload of { payload } \" ) END If the status of the HTTP response is in range 500 - 513 : self . _logger . error ( f \"Got { response . status } .\" ) END","title":"Post notification email milestone"},{"location":"logging/services/bruin-bridge/clients/bruin_client/post_outage_ticket/","text":"Post outage ticket self . _logger . info ( f \"Posting outage ticket for client with ID { client_id } and for service number { service_number } \" ) self . _logger . info ( f \"Posting payload { json . dumps ( payload ) } to create new outage ticket...\" ) Call Bruin API endpoint POST /api/Ticket/repair with the desired payload. If there's an error while connecting to Bruin API: self . _logger . error ( f \"A connection error happened while trying to connect to Bruin API. Cause: { err } \" ) END If the status of the HTTP response is in range of 200 - 300 : If errorCode field from HTTP response is 409 self . _logger . info ( f \"Got HTTP 409 from Bruin when posting outage ticket with payload { json . dumps ( payload ) } . \" f \"There's no need to create a new ticket as there is an existing one with In-Progress status\" ) If errorCode field from HTTP response is 471 self . _logger . info ( f \"Got HTTP 471 from Bruin when posting outage ticket with payload { json . dumps ( payload ) } . \" f \"There's no need to create a new ticket as there is an existing one with Resolved status\" ) If errorCode field from HTTP response is 472 self . _logger . info ( f \"Got HTTP 472 from Bruin when posting outage ticket with payload { json . dumps ( payload ) } . \" f \"There's no need to create a new ticket as there is an existing one with Resolved status. \" f \"The existing ticket has been unresolved and it's now In-Progress.\" ) If errorCode field from HTTP response is 473 self . _logger . info ( f \"Got HTTP 473 from Bruin when posting outage ticket with payload { json . dumps ( payload ) } . \" f \"There's no need to create a new ticket as there is an existing one with Resolved status for \" f \"the same location of the service number. The existing ticket has been unresolved and it's \" f \"now In-Progress, and a new ticket detail has been added for the specified service number.\" ) END If the status of the HTTP response is 400 : self . _logger . error ( f \"Got HTTP 400 from Bruin when posting outage ticket with payload { json . dumps ( payload ) } . \" f \"Reason: { response_json } \" ) END If the status of the HTTP response is 401 : self . _logger . error ( f \"Got 401 from Bruin. Re-logging in...\" ) login END If the status of the HTTP response is 403 : self . _logger . error ( \"Got HTTP 403 from Bruin. Bruin client doesn't have permissions to post a new outage ticket with \" f \"payload { json . dumps ( payload ) } \" ) END If the status of the HTTP response is 404 : self . _logger . error ( f \"Got HTTP 404 from Bruin when posting outage ticket. Payload: { json . dumps ( payload ) } \" ) END If the status of the HTTP response is between 500 and 513 (both inclusive): self . _logger . error ( f \"Got HTTP { status_code } from Bruin when posting outage ticket with payload { json . dumps ( payload ) } . \" ) END","title":"Post outage ticket"},{"location":"logging/services/bruin-bridge/clients/bruin_client/post_outage_ticket/#post-outage-ticket","text":"self . _logger . info ( f \"Posting outage ticket for client with ID { client_id } and for service number { service_number } \" ) self . _logger . info ( f \"Posting payload { json . dumps ( payload ) } to create new outage ticket...\" ) Call Bruin API endpoint POST /api/Ticket/repair with the desired payload. If there's an error while connecting to Bruin API: self . _logger . error ( f \"A connection error happened while trying to connect to Bruin API. Cause: { err } \" ) END If the status of the HTTP response is in range of 200 - 300 : If errorCode field from HTTP response is 409 self . _logger . info ( f \"Got HTTP 409 from Bruin when posting outage ticket with payload { json . dumps ( payload ) } . \" f \"There's no need to create a new ticket as there is an existing one with In-Progress status\" ) If errorCode field from HTTP response is 471 self . _logger . info ( f \"Got HTTP 471 from Bruin when posting outage ticket with payload { json . dumps ( payload ) } . \" f \"There's no need to create a new ticket as there is an existing one with Resolved status\" ) If errorCode field from HTTP response is 472 self . _logger . info ( f \"Got HTTP 472 from Bruin when posting outage ticket with payload { json . dumps ( payload ) } . \" f \"There's no need to create a new ticket as there is an existing one with Resolved status. \" f \"The existing ticket has been unresolved and it's now In-Progress.\" ) If errorCode field from HTTP response is 473 self . _logger . info ( f \"Got HTTP 473 from Bruin when posting outage ticket with payload { json . dumps ( payload ) } . \" f \"There's no need to create a new ticket as there is an existing one with Resolved status for \" f \"the same location of the service number. The existing ticket has been unresolved and it's \" f \"now In-Progress, and a new ticket detail has been added for the specified service number.\" ) END If the status of the HTTP response is 400 : self . _logger . error ( f \"Got HTTP 400 from Bruin when posting outage ticket with payload { json . dumps ( payload ) } . \" f \"Reason: { response_json } \" ) END If the status of the HTTP response is 401 : self . _logger . error ( f \"Got 401 from Bruin. Re-logging in...\" ) login END If the status of the HTTP response is 403 : self . _logger . error ( \"Got HTTP 403 from Bruin. Bruin client doesn't have permissions to post a new outage ticket with \" f \"payload { json . dumps ( payload ) } \" ) END If the status of the HTTP response is 404 : self . _logger . error ( f \"Got HTTP 404 from Bruin when posting outage ticket. Payload: { json . dumps ( payload ) } \" ) END If the status of the HTTP response is between 500 and 513 (both inclusive): self . _logger . error ( f \"Got HTTP { status_code } from Bruin when posting outage ticket with payload { json . dumps ( payload ) } . \" ) END","title":"Post outage ticket"},{"location":"logging/services/bruin-bridge/clients/bruin_client/post_ticket/","text":"Post ticket self . _logger . info ( f 'Posting ticket for client id: { payload [ \"clientId\" ] } ' ) self . _logger . info ( f \"Payload that will be applied : { json . dumps ( payload , indent = 2 ) } \" ) Call Bruin API endpoint POST /api/Ticket/ with the desired payload. If the status of the HTTP response is 400 : self . _logger . error ( f \"Got error from Bruin { response_json } \" ) END If the status of the HTTP response is 401 : self . _logger . error ( f \"Got 401 from Bruin. Re-logging in...\" ) login END If the status of the HTTP response is 403 : self . _logger . error ( f \"Forbidden error from Bruin { response_json } \" ) END If the status of the HTTP response is 404 : self . _logger . error ( f \"Got 404 from Bruin, resource not posted for payload of { payload } \" ) END If the status of the HTTP response is between 500 and 512 (both inclusive): self . _logger . error ( f \"Got { response . status } .\" ) END","title":"Post ticket"},{"location":"logging/services/bruin-bridge/clients/bruin_client/post_ticket/#post-ticket","text":"self . _logger . info ( f 'Posting ticket for client id: { payload [ \"clientId\" ] } ' ) self . _logger . info ( f \"Payload that will be applied : { json . dumps ( payload , indent = 2 ) } \" ) Call Bruin API endpoint POST /api/Ticket/ with the desired payload. If the status of the HTTP response is 400 : self . _logger . error ( f \"Got error from Bruin { response_json } \" ) END If the status of the HTTP response is 401 : self . _logger . error ( f \"Got 401 from Bruin. Re-logging in...\" ) login END If the status of the HTTP response is 403 : self . _logger . error ( f \"Forbidden error from Bruin { response_json } \" ) END If the status of the HTTP response is 404 : self . _logger . error ( f \"Got 404 from Bruin, resource not posted for payload of { payload } \" ) END If the status of the HTTP response is between 500 and 512 (both inclusive): self . _logger . error ( f \"Got { response . status } .\" ) END","title":"Post ticket"},{"location":"logging/services/bruin-bridge/clients/bruin_client/post_ticket_note/","text":"Post ticket notes self . _logger . info ( f \"Getting posting notes for ticket id: { ticket_id } \" ) self . _logger . info ( f \"Payload that will be applied: { json . dumps ( payload ) } \" ) Call Bruin API endpoint POST /api/Ticket/{ticket_id}/notes with the desired payload. If the status of the HTTP response is 400 : self . _logger . error ( f \"Got error from Bruin { response_json } \" ) END If the status of the HTTP response is 401 : self . _logger . error ( f \"Got 401 from Bruin. Re-logging in...\" ) login END If the status of the HTTP response is 403 : self . _logger . error ( f \"Forbidden error from Bruin { response_json } \" ) END If the status of the HTTP response is 404 : self . _logger . error ( f \"Got 404 from Bruin, resource not posted for ticket_id { ticket_id } with payload { payload } \" ) END If the status of the HTTP response is between 500 and 512 (both inclusive): self . _logger . error ( f \"Got { response . status } .\" ) END","title":"Post ticket notes"},{"location":"logging/services/bruin-bridge/clients/bruin_client/post_ticket_note/#post-ticket-notes","text":"self . _logger . info ( f \"Getting posting notes for ticket id: { ticket_id } \" ) self . _logger . info ( f \"Payload that will be applied: { json . dumps ( payload ) } \" ) Call Bruin API endpoint POST /api/Ticket/{ticket_id}/notes with the desired payload. If the status of the HTTP response is 400 : self . _logger . error ( f \"Got error from Bruin { response_json } \" ) END If the status of the HTTP response is 401 : self . _logger . error ( f \"Got 401 from Bruin. Re-logging in...\" ) login END If the status of the HTTP response is 403 : self . _logger . error ( f \"Forbidden error from Bruin { response_json } \" ) END If the status of the HTTP response is 404 : self . _logger . error ( f \"Got 404 from Bruin, resource not posted for ticket_id { ticket_id } with payload { payload } \" ) END If the status of the HTTP response is between 500 and 512 (both inclusive): self . _logger . error ( f \"Got { response . status } .\" ) END","title":"Post ticket notes"},{"location":"logging/services/bruin-bridge/clients/bruin_client/unpause_ticket/","text":"Unpause ticket self . _logger . info ( f \"Unpause ticket for ticket id: { ticket_id } with filters { filters } \" ) Call Bruin API endpoint POST /api/Ticket/{ticket_id}/detail/unpause with the desired payload. If there's an error while connecting to Bruin API: self . _logger . error ( f \"A connection error happened while trying to connect to Bruin API -> { e } \" ) END If the status of the HTTP response is in range 200 - 300 : self . _logger . info ( f \"Correct unpause ticket for ticket id: { ticket_id } with filters { filters } \" ) END If the status of the HTTP response is 400 : self . _logger . error ( f \"Got error 400 from Bruin { response_json } \" ) END If the status of the HTTP response is 401 : self . _logger . error ( f \"Got 401 from Bruin. Re-logging in...\" ) login END If the status of the HTTP response is 403 : self . _logger . error ( f \"Forbidden error from Bruin { response_json } \" ) END If the status of the HTTP response is in range 500 - 513 : self . _logger . error ( f \"Got { response . status } .\" ) END","title":"Unpause ticket"},{"location":"logging/services/bruin-bridge/clients/bruin_client/unpause_ticket/#unpause-ticket","text":"self . _logger . info ( f \"Unpause ticket for ticket id: { ticket_id } with filters { filters } \" ) Call Bruin API endpoint POST /api/Ticket/{ticket_id}/detail/unpause with the desired payload. If there's an error while connecting to Bruin API: self . _logger . error ( f \"A connection error happened while trying to connect to Bruin API -> { e } \" ) END If the status of the HTTP response is in range 200 - 300 : self . _logger . info ( f \"Correct unpause ticket for ticket id: { ticket_id } with filters { filters } \" ) END If the status of the HTTP response is 400 : self . _logger . error ( f \"Got error 400 from Bruin { response_json } \" ) END If the status of the HTTP response is 401 : self . _logger . error ( f \"Got 401 from Bruin. Re-logging in...\" ) login END If the status of the HTTP response is 403 : self . _logger . error ( f \"Forbidden error from Bruin { response_json } \" ) END If the status of the HTTP response is in range 500 - 513 : self . _logger . error ( f \"Got { response . status } .\" ) END","title":"Unpause ticket"},{"location":"logging/services/bruin-bridge/clients/bruin_client/update_ticket_status/","text":"Update ticket status self . _logger . info ( f \"Updating ticket status for ticket id: { ticket_id } \" ) self . _logger . info ( f \"Payload that will be applied (parsed to PascalCase): { json . dumps ( payload ) } \" ) Call Bruin API endpoint PUT /api/Ticket/{ticket_id}/details/{detail_id}/status with the desired payload. If the status of the HTTP response is 400 : self . _logger . error ( f \"Got error from Bruin { response_json } \" ) END If the status of the HTTP response is 401 : self . _logger . error ( f \"Got 401 from Bruin. Re-logging in...\" ) login END If the status of the HTTP response is 403 : self . _logger . error ( f \"Forbidden error from Bruin { response_json } \" ) END If the status of the HTTP response is 404 : self . _logger . error ( f \"Got 404 from Bruin, resource not posted for payload of { payload } \" ) END If the status of the HTTP response is between 500 and 512 (both inclusive): self . _logger . error ( f \"Got { response . status } .\" ) END","title":"Update ticket status"},{"location":"logging/services/bruin-bridge/clients/bruin_client/update_ticket_status/#update-ticket-status","text":"self . _logger . info ( f \"Updating ticket status for ticket id: { ticket_id } \" ) self . _logger . info ( f \"Payload that will be applied (parsed to PascalCase): { json . dumps ( payload ) } \" ) Call Bruin API endpoint PUT /api/Ticket/{ticket_id}/details/{detail_id}/status with the desired payload. If the status of the HTTP response is 400 : self . _logger . error ( f \"Got error from Bruin { response_json } \" ) END If the status of the HTTP response is 401 : self . _logger . error ( f \"Got 401 from Bruin. Re-logging in...\" ) login END If the status of the HTTP response is 403 : self . _logger . error ( f \"Forbidden error from Bruin { response_json } \" ) END If the status of the HTTP response is 404 : self . _logger . error ( f \"Got 404 from Bruin, resource not posted for payload of { payload } \" ) END If the status of the HTTP response is between 500 and 512 (both inclusive): self . _logger . error ( f \"Got { response . status } .\" ) END","title":"Update ticket status"},{"location":"logging/services/bruin-bridge/clients/bruin_session/__post_init__/","text":"Post init self . logger . info ( f \"Started Bruin session\" )","title":"Post init"},{"location":"logging/services/bruin-bridge/clients/bruin_session/__post_init__/#post-init","text":"self . logger . info ( f \"Started Bruin session\" )","title":"Post init"},{"location":"logging/services/bruin-bridge/clients/bruin_session/get/","text":"Get self . logger . debug ( f \"get(request= { request } )\" ) Try Get response from Bruin If response is not ok self . logger . warning ( f \"get(request= { request } ) => response= { response } \" ) END If there's an error while connecting to Bruin API: self . logger . error ( f \"get(request= { request } ) => ClientConnectionError: { e } \" ) END Catch general exception: self . logger . error ( f \"get(request= { request } ) => UnexpectedError: { e } \" ) END","title":"Get"},{"location":"logging/services/bruin-bridge/clients/bruin_session/get/#get","text":"self . logger . debug ( f \"get(request= { request } )\" ) Try Get response from Bruin If response is not ok self . logger . warning ( f \"get(request= { request } ) => response= { response } \" ) END If there's an error while connecting to Bruin API: self . logger . error ( f \"get(request= { request } ) => ClientConnectionError: { e } \" ) END Catch general exception: self . logger . error ( f \"get(request= { request } ) => UnexpectedError: { e } \" ) END","title":"Get"},{"location":"logging/services/bruin-bridge/clients/bruin_session/post/","text":"Post self . logger . debug ( f \"post(request= { request } \" ) Try Get response from Bruin If response is not ok self . logger . warning ( f \"post(request= { request } ) => response= { response } \" ) END If there's an error while connecting to Bruin API: self . logger . error ( f \"post(request= { request } ) => ClientConnectionError: { e } \" ) END Catch general exception: self . logger . error ( f \"post(request= { request } ) => UnexpectedError: { e } \" ) END","title":"Post"},{"location":"logging/services/bruin-bridge/clients/bruin_session/post/#post","text":"self . logger . debug ( f \"post(request= { request } \" ) Try Get response from Bruin If response is not ok self . logger . warning ( f \"post(request= { request } ) => response= { response } \" ) END If there's an error while connecting to Bruin API: self . logger . error ( f \"post(request= { request } ) => ClientConnectionError: { e } \" ) END Catch general exception: self . logger . error ( f \"post(request= { request } ) => UnexpectedError: { e } \" ) END","title":"Post"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/__make_paginated_request/","text":"Make paginated request to Bruin API self . _logger . info ( f \"Fetching all pages using { fn . __name__ } ...\" ) While there are pages to fetch: Make a call for the current page to Bruin API through the BruinClient If response status is not ok: self . _logger . warning ( f \"Call to { fn . __name__ } failed for page { current_page } . Checking if max retries threshold has been \" \"reached\" ) If the max attempts threshold hasn't been reached: self . _logger . info ( f \"Max retries threshold hasn't been reached yet. Retrying call to { fn . __name__ } for page \" f \" { current_page } ...\" ) Otherwise: self . _logger . error ( f \"There have been { max_retries } or more errors when calling { fn . __name__ } .\" ) END If there are no more pages to fetch: self . _logger . info ( f \"Finished fetching all pages for { fn . __name__ } .\" ) END","title":"  make paginated request"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/__make_paginated_request/#make-paginated-request-to-bruin-api","text":"self . _logger . info ( f \"Fetching all pages using { fn . __name__ } ...\" ) While there are pages to fetch: Make a call for the current page to Bruin API through the BruinClient If response status is not ok: self . _logger . warning ( f \"Call to { fn . __name__ } failed for page { current_page } . Checking if max retries threshold has been \" \"reached\" ) If the max attempts threshold hasn't been reached: self . _logger . info ( f \"Max retries threshold hasn't been reached yet. Retrying call to { fn . __name__ } for page \" f \" { current_page } ...\" ) Otherwise: self . _logger . error ( f \"There have been { max_retries } or more errors when calling { fn . __name__ } .\" ) END If there are no more pages to fetch: self . _logger . info ( f \"Finished fetching all pages for { fn . __name__ } .\" ) END","title":"Make paginated request to Bruin API"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/_get_attribute_from_inventory/","text":"Get attribute from inventory BruinClient::get_inventory_attributes","title":"Get attribute from inventory"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/_get_attribute_from_inventory/#get-attribute-from-inventory","text":"BruinClient::get_inventory_attributes","title":"Get attribute from inventory"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/_get_tickets_by_status/","text":"Get ticket by status BruinClient::get_all_tickets","title":"Get ticket by status"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/_get_tickets_by_status/#get-ticket-by-status","text":"BruinClient::get_all_tickets","title":"Get ticket by status"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/change_detail_work_queue/","text":"Change detail work queue BruinClient::get_possible_detail_next_result BruinClient::change_detail_work_queue","title":"Change detail work queue"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/change_detail_work_queue/#change-detail-work-queue","text":"BruinClient::get_possible_detail_next_result BruinClient::change_detail_work_queue","title":"Change detail work queue"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/change_ticket_severity/","text":"Change ticket severity BruinClient::change_ticket_severity","title":"Change ticket severity"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/change_ticket_severity/#change-ticket-severity","text":"BruinClient::change_ticket_severity","title":"Change ticket severity"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/get_all_filtered_tickets/","text":"Get all filtered tickets For all statues in ticket_status _get_tickets_by_status","title":"Get all filtered tickets"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/get_all_filtered_tickets/#get-all-filtered-tickets","text":"For all statues in ticket_status _get_tickets_by_status","title":"Get all filtered tickets"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/get_asset_topics/","text":"Get asset topics BruinClient::get_asset_topics","title":"Get asset topics"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/get_asset_topics/#get-asset-topics","text":"BruinClient::get_asset_topics","title":"Get asset topics"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/get_attributes_serial/","text":"Get attribute serial _get_attribute_from_inventory )","title":"Get attribute serial"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/get_attributes_serial/#get-attribute-serial","text":"_get_attribute_from_inventory )","title":"Get attribute serial"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/get_circuit_id/","text":"Get circuit id BruinClient::get_circuit_id","title":"Get circuit id"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/get_circuit_id/#get-circuit-id","text":"BruinClient::get_circuit_id","title":"Get circuit id"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/get_client_info/","text":"Get client info BruinClient::get_client_info","title":"Get client info"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/get_client_info/#get-client-info","text":"BruinClient::get_client_info","title":"Get client info"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/get_client_info_by_did/","text":"Get client info by did BruinClient::get_client_info_by_did","title":"Get client info by did"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/get_client_info_by_did/#get-client-info-by-did","text":"BruinClient::get_client_info_by_did","title":"Get client info by did"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/get_management_status/","text":"Get management status _get_attribute_from_inventory )","title":"Get management status"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/get_management_status/#get-management-status","text":"_get_attribute_from_inventory )","title":"Get management status"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/get_next_results_for_ticket_detail/","text":"Get next results for ticket detail BruinClient::get_possible_detail_next_result","title":"Get next results for ticket detail"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/get_next_results_for_ticket_detail/#get-next-results-for-ticket-detail","text":"BruinClient::get_possible_detail_next_result","title":"Get next results for ticket detail"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/get_single_ticket_basic_info/","text":"Get single ticket basic info BruinClient::get_tickets_basic_info If length of ticket list from get_tickets_basic_info is 0 self . _logger . error ( f \"Call to get_tickets_basic_info succeeded, but TicketID { ticket_id } not found.\" ) END","title":"Get single ticket basic info"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/get_single_ticket_basic_info/#get-single-ticket-basic-info","text":"BruinClient::get_tickets_basic_info If length of ticket list from get_tickets_basic_info is 0 self . _logger . error ( f \"Call to get_tickets_basic_info succeeded, but TicketID { ticket_id } not found.\" ) END","title":"Get single ticket basic info"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/get_site/","text":"Get site BruinClient::get_site If response is not ok: self . _logger . error ( f \"Got response with status { response [ 'status' ] } while getting site information for params { params } .\" ) END If site information is missing in response: msg = f \"No site information was found for site { params [ 'site_id' ] } and client { params [ 'client_id' ] } \" self . _logger . warning ( msg ) END","title":"Get site"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/get_site/#get-site","text":"BruinClient::get_site If response is not ok: self . _logger . error ( f \"Got response with status { response [ 'status' ] } while getting site information for params { params } .\" ) END If site information is missing in response: msg = f \"No site information was found for site { params [ 'site_id' ] } and client { params [ 'client_id' ] } \" self . _logger . warning ( msg ) END","title":"Get site"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/get_ticket_details/","text":"Get ticket details BruinClient::get_ticket_details","title":"Get ticket details"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/get_ticket_details/#get-ticket-details","text":"BruinClient::get_ticket_details","title":"Get ticket details"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/get_ticket_overview/","text":"Get ticket overview self . _logger . info ( f \"Getting ticket overview: { ticket_id } from Bruin...\" ) BruinClient::get_all_tickets","title":"Get ticket overview"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/get_ticket_overview/#get-ticket-overview","text":"self . _logger . info ( f \"Getting ticket overview: { ticket_id } from Bruin...\" ) BruinClient::get_all_tickets","title":"Get ticket overview"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/get_ticket_task_history/","text":"Get ticket task history BruinClient::get_ticket_task_history","title":"Get ticket task history"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/get_ticket_task_history/#get-ticket-task-history","text":"BruinClient::get_ticket_task_history","title":"Get ticket task history"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/get_tickets_basic_info/","text":"Get tickets basic info Call __make_paginated_request with BruinClient::get_tickets_basic_info to fetch all available pages for the desired set of filters.","title":"Get tickets basic info"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/get_tickets_basic_info/#get-tickets-basic-info","text":"Call __make_paginated_request with BruinClient::get_tickets_basic_info to fetch all available pages for the desired set of filters.","title":"Get tickets basic info"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/link_ticket_to_email/","text":"Link ticket to email BruinClient::link_ticket_to_email","title":"Link ticket to email"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/link_ticket_to_email/#link-ticket-to-email","text":"BruinClient::link_ticket_to_email","title":"Link ticket to email"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/mark_email_as_done/","text":"Mark email as done BruinClient::mark_email_as_done","title":"Mark email as done"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/mark_email_as_done/#mark-email-as-done","text":"BruinClient::mark_email_as_done","title":"Mark email as done"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/open_ticket/","text":"Open ticket BruinClient::open_ticket","title":"Open ticket"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/open_ticket/#open-ticket","text":"BruinClient::open_ticket","title":"Open ticket"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/post_email_tag/","text":"Post email tag BruinClient::post_email_tag","title":"Post email tag"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/post_email_tag/#post-email-tag","text":"BruinClient::post_email_tag","title":"Post email tag"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/post_multiple_ticket_notes/","text":"Post multiple ticket notes BruinClient::post_multiple_ticket_notes","title":"Post multiple ticket notes"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/post_multiple_ticket_notes/#post-multiple-ticket-notes","text":"BruinClient::post_multiple_ticket_notes","title":"Post multiple ticket notes"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/post_notification_email_milestone/","text":"Post notification email milestone BruinClient::post_notification_email_milestone","title":"Post notification email milestone"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/post_notification_email_milestone/#post-notification-email-milestone","text":"BruinClient::post_notification_email_milestone","title":"Post notification email milestone"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/post_outage_ticket/","text":"Post outage ticket BruinClient::post_outage_ticket","title":"Post outage ticket"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/post_outage_ticket/#post-outage-ticket","text":"BruinClient::post_outage_ticket","title":"Post outage ticket"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/post_ticket/","text":"Post ticket BruinClient::post_ticket","title":"Post ticket"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/post_ticket/#post-ticket","text":"BruinClient::post_ticket","title":"Post ticket"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/post_ticket_note/","text":"Post ticket note BruinClient::post_ticket_note","title":"Post ticket note"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/post_ticket_note/#post-ticket-note","text":"BruinClient::post_ticket_note","title":"Post ticket note"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/resolve_ticket/","text":"Resolve ticket BruinClient::resolve_ticket","title":"Resolve ticket"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/resolve_ticket/#resolve-ticket","text":"BruinClient::resolve_ticket","title":"Resolve ticket"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/unpause_ticket/","text":"Unpause ticket BruinClient::unpause_ticket","title":"Unpause ticket"},{"location":"logging/services/bruin-bridge/repositories/bruin_repository/unpause_ticket/#unpause-ticket","text":"BruinClient::unpause_ticket","title":"Unpause ticket"},{"location":"logging/services/customer-cache/actions/get_customers/get_customers/","text":"Subject: customer.cache.get Message arrives at subject If message doesn't have a body: logger . error ( f \"Cannot get customer cache using { json . dumps ( payload ) } . JSON malformed\" ) END If message body doesn't have filter filter with a list of VCOs to get caches for: logger . error ( f 'Cannot get customer cache info using { json . dumps ( body ) } . Need \"filter\"' ) END StorageRepository::get_host_cache If no cache could be found for the list of VCOs specified in the filter: logger . warning ( f 'Cache is still being built for host(s): { \", \" . join ( body [ \"filter\" ] . keys ()) } ' ) END If last_contact_filter was specified and no cached edges were last contacted before the last contact date: logger . warning ( f \"No edges were found for the specified filters: { body } \" ) END logger . info ( f \" { len ( filter_cache ) } edges were found for the specified filters: { body } \" ) logger . info ( f \"Get customer response published in event bus\" )","title":"Get customers"},{"location":"logging/services/customer-cache/actions/get_customers/get_customers/#subject-customercacheget","text":"Message arrives at subject If message doesn't have a body: logger . error ( f \"Cannot get customer cache using { json . dumps ( payload ) } . JSON malformed\" ) END If message body doesn't have filter filter with a list of VCOs to get caches for: logger . error ( f 'Cannot get customer cache info using { json . dumps ( body ) } . Need \"filter\"' ) END StorageRepository::get_host_cache If no cache could be found for the list of VCOs specified in the filter: logger . warning ( f 'Cache is still being built for host(s): { \", \" . join ( body [ \"filter\" ] . keys ()) } ' ) END If last_contact_filter was specified and no cached edges were last contacted before the last contact date: logger . warning ( f \"No edges were found for the specified filters: { body } \" ) END logger . info ( f \" { len ( filter_cache ) } edges were found for the specified filters: { body } \" ) logger . info ( f \"Get customer response published in event bus\" )","title":"Subject: customer.cache.get"},{"location":"logging/services/customer-cache/actions/refresh_cache/_add_ha_devices_to_cache/","text":"Extend cache with High Availability (HA) edges logger . info ( f \"Adding HA edges to the cache (current size: { len ( cache ) } edges)\" ) For each edge: If the edge doesn't have HA configured: logger . info ( f \"Edge { edge [ 'serial_number' ] } doesn't have a HA partner. Skipping...\" ) Continue with next edge logger . info ( f \" { len ( new_edges ) } HA edges added to the cache (current size: { len ( cache ) } edges)\" )","title":" add ha devices to cache"},{"location":"logging/services/customer-cache/actions/refresh_cache/_add_ha_devices_to_cache/#extend-cache-with-high-availability-ha-edges","text":"logger . info ( f \"Adding HA edges to the cache (current size: { len ( cache ) } edges)\" ) For each edge: If the edge doesn't have HA configured: logger . info ( f \"Edge { edge [ 'serial_number' ] } doesn't have a HA partner. Skipping...\" ) Continue with next edge logger . info ( f \" { len ( new_edges ) } HA edges added to the cache (current size: { len ( cache ) } edges)\" )","title":"Extend cache with High Availability (HA) edges"},{"location":"logging/services/customer-cache/actions/refresh_cache/_filter_edge_list/","text":"Fetch Bruin data for an edge, and cross it with VeloCloud's logger . info ( f \"Checking if edge { serial_number } should be monitored...\" ) BruinRepository::get_client_info If response status for get edge's client info in Bruin is not ok: logger . error ( f \"Error while fetching client info for edge { serial_number } : { client_info_response } \" ) END If the edge seems to be linked to multiple clients in Bruin: logger . info ( f \"Edge { serial_number } has { len ( client_info_response_body ) } inventories in Bruin\" ) Edge will be reported as having multiple inventories at the end of the caching process If the edge doesn't have any client info associated in Bruin: logger . warning ( f \"Edge with serial { serial_number } doesn't have any Bruin client info associated\" ) Edge will be excluded from the cache right before saving it END BruinRepository::get_management_status If response status for get edge's management status in Bruin is not ok: logger . error ( f \"Error while fetching management status for edge { serial_number } : { management_status_response } \" ) END If edge's management status is not monitorable: logger . warning ( f \"Management status is not active for { edge_identifier } . Skipping...\" ) Edge will be excluded from the cache right before saving it END If edge's management status is Pending and its owner (client) is blacklisted from monitoring for such status: logger . warning ( f \"Edge ( { serial_number } ) has management_status: Pending and has a blacklisted\" f \"client_id: { client_id } . Skipping...\" ) Edge will be excluded from the cache right before saving it END logger . info ( f \"Management status for { serial_number } seems active\" ) BruinRepository::get_site_details If response status for get edge's site details in Bruin is not ok: logger . error ( f \"Error while fetching site details for edge { serial_number } : { site_details_response } \" ) END VeloCloud and Bruin data for the edge are finally crossed If the whole crossing process fails for unexpected reasons: Run the crossing process again If the whole crossing process fails after multiple attempts: logger . error ( f \"An error occurred while checking if edge { serial_number } should be cached or not -> { e } \" )","title":" filter edge list"},{"location":"logging/services/customer-cache/actions/refresh_cache/_filter_edge_list/#fetch-bruin-data-for-an-edge-and-cross-it-with-veloclouds","text":"logger . info ( f \"Checking if edge { serial_number } should be monitored...\" ) BruinRepository::get_client_info If response status for get edge's client info in Bruin is not ok: logger . error ( f \"Error while fetching client info for edge { serial_number } : { client_info_response } \" ) END If the edge seems to be linked to multiple clients in Bruin: logger . info ( f \"Edge { serial_number } has { len ( client_info_response_body ) } inventories in Bruin\" ) Edge will be reported as having multiple inventories at the end of the caching process If the edge doesn't have any client info associated in Bruin: logger . warning ( f \"Edge with serial { serial_number } doesn't have any Bruin client info associated\" ) Edge will be excluded from the cache right before saving it END BruinRepository::get_management_status If response status for get edge's management status in Bruin is not ok: logger . error ( f \"Error while fetching management status for edge { serial_number } : { management_status_response } \" ) END If edge's management status is not monitorable: logger . warning ( f \"Management status is not active for { edge_identifier } . Skipping...\" ) Edge will be excluded from the cache right before saving it END If edge's management status is Pending and its owner (client) is blacklisted from monitoring for such status: logger . warning ( f \"Edge ( { serial_number } ) has management_status: Pending and has a blacklisted\" f \"client_id: { client_id } . Skipping...\" ) Edge will be excluded from the cache right before saving it END logger . info ( f \"Management status for { serial_number } seems active\" ) BruinRepository::get_site_details If response status for get edge's site details in Bruin is not ok: logger . error ( f \"Error while fetching site details for edge { serial_number } : { site_details_response } \" ) END VeloCloud and Bruin data for the edge are finally crossed If the whole crossing process fails for unexpected reasons: Run the crossing process again If the whole crossing process fails after multiple attempts: logger . error ( f \"An error occurred while checking if edge { serial_number } should be cached or not -> { e } \" )","title":"Fetch Bruin data for an edge, and cross it with VeloCloud's"},{"location":"logging/services/customer-cache/actions/refresh_cache/_need_to_refresh_cache/","text":"Check if it is time for a cache refresh logger . info ( \"Checking if it is time to refresh the cache...\" ) logger . info ( f \"Is time to refresh cache? { is_time } \" )","title":" need to refresh cache"},{"location":"logging/services/customer-cache/actions/refresh_cache/_need_to_refresh_cache/#check-if-it-is-time-for-a-cache-refresh","text":"logger . info ( \"Checking if it is time to refresh the cache...\" ) logger . info ( f \"Is time to refresh cache? { is_time } \" )","title":"Check if it is time for a cache refresh"},{"location":"logging/services/customer-cache/actions/refresh_cache/_partial_refresh_cache/","text":"Refresh customer cache for a VCO logger . info ( f \"Filtering the list of edges for host { host } \" ) For each edge in the VCO: _filter_edge_list logger . info ( f \"Finished filtering edges for host { host } \" ) logger . info ( f \"Adding { len ( ha_serials ) } HA edges as standalone edges to cache of host { host } ...\" ) _add_ha_devices_to_cache logger . info ( f \"Finished adding HA edges to cache of host { host } \" ) If resulting cache is empty after crossing VeloCloud and Bruin data for each edge: error_msg = ( f \"Cache for host { host } was empty after cross referencing with Bruin.\" f \" Check if Bruin is returning errors when asking for management statuses of the host\" ) logger . error ( error_msg ) END StorageRepository::get_cache logger . info ( f \"Crossing currently stored cache ( { len ( stored_cache ) } edges) with new one ( { len ( cache ) } edges)...\" ) Both caches are merged logger . info ( f \"Crossed cache of host { host } has { len ( crossed_cache ) } edges\" ) logger . info ( f \"Removing { len ( self . _invalid_edges [ host ]) } invalid edges from crossed cache of host { host } ...\" ) Edges whose data from Bruin could not be fetched are removed from the cache before saving it logger . info ( f \"Invalid edges removed from cache! Final cache has { len ( final_cache ) } edges\" ) logger . info ( f \"Storing cache of { len ( final_cache ) } edges to Redis for host { host } \" ) StorageRepository::set_cache _send_email_snapshot logger . info ( f \"Finished storing cache for host { host } \" )","title":" partial refresh cache"},{"location":"logging/services/customer-cache/actions/refresh_cache/_partial_refresh_cache/#refresh-customer-cache-for-a-vco","text":"logger . info ( f \"Filtering the list of edges for host { host } \" ) For each edge in the VCO: _filter_edge_list logger . info ( f \"Finished filtering edges for host { host } \" ) logger . info ( f \"Adding { len ( ha_serials ) } HA edges as standalone edges to cache of host { host } ...\" ) _add_ha_devices_to_cache logger . info ( f \"Finished adding HA edges to cache of host { host } \" ) If resulting cache is empty after crossing VeloCloud and Bruin data for each edge: error_msg = ( f \"Cache for host { host } was empty after cross referencing with Bruin.\" f \" Check if Bruin is returning errors when asking for management statuses of the host\" ) logger . error ( error_msg ) END StorageRepository::get_cache logger . info ( f \"Crossing currently stored cache ( { len ( stored_cache ) } edges) with new one ( { len ( cache ) } edges)...\" ) Both caches are merged logger . info ( f \"Crossed cache of host { host } has { len ( crossed_cache ) } edges\" ) logger . info ( f \"Removing { len ( self . _invalid_edges [ host ]) } invalid edges from crossed cache of host { host } ...\" ) Edges whose data from Bruin could not be fetched are removed from the cache before saving it logger . info ( f \"Invalid edges removed from cache! Final cache has { len ( final_cache ) } edges\" ) logger . info ( f \"Storing cache of { len ( final_cache ) } edges to Redis for host { host } \" ) StorageRepository::set_cache _send_email_snapshot logger . info ( f \"Finished storing cache for host { host } \" )","title":"Refresh customer cache for a VCO"},{"location":"logging/services/customer-cache/actions/refresh_cache/_refresh_cache/","text":"Run Customer Cache Refresh job _need_to_refresh_cache If the cache refresh is not due yet: logger . info ( \"Cache refresh is not due yet. Skipping refresh process...\" ) END logger . info ( \"Starting job to refresh the cache of edges...\" ) logger . info ( f \"Velocloud hosts that are going to be cached: { ', ' . join ( velocloud_hosts ) } \" ) logger . info ( \"Claiming edges for the hosts specified in the config...\" ) VelocloudRepository::get_all_velo_edges If no edges could be retrieved: logger . warning ( f \"Got an empty list of edges for hosts { ', ' . join ( velocloud_hosts ) } from VeloCloud. \" f \"Retrying to get edges...\" ) If the attempts' threshold to retry retrieving edges across VCOs has not been maxed out yet: logger . warning ( f \"Couldn't find any edge to refresh the cache. Re-trying job...\" ) The Customer Cache Refresh job triggers immediately again Otherwise: error_message = ( \"Too many consecutive failures happened while trying \" \"to claim the list of edges from Velocloud\" ) raise Exception ( error_message ) ... logger . error ( f \"An error occurred while refreshing the cache -> { e } \" ) END logger . info ( f \"Distinguishing { len ( edge_list ) } edges per Velocloud host...\" ) logger . info ( \"Refreshing cache for each of the hosts...\" ) For each VCO whose cache needs a refresh: _partial_refresh_cache StorageRepository::update_refresh_date _send_email_multiple_inventories logger . info ( \"Finished refreshing cache!\" )","title":"Run Customer Cache Refresh job"},{"location":"logging/services/customer-cache/actions/refresh_cache/_refresh_cache/#run-customer-cache-refresh-job","text":"_need_to_refresh_cache If the cache refresh is not due yet: logger . info ( \"Cache refresh is not due yet. Skipping refresh process...\" ) END logger . info ( \"Starting job to refresh the cache of edges...\" ) logger . info ( f \"Velocloud hosts that are going to be cached: { ', ' . join ( velocloud_hosts ) } \" ) logger . info ( \"Claiming edges for the hosts specified in the config...\" ) VelocloudRepository::get_all_velo_edges If no edges could be retrieved: logger . warning ( f \"Got an empty list of edges for hosts { ', ' . join ( velocloud_hosts ) } from VeloCloud. \" f \"Retrying to get edges...\" ) If the attempts' threshold to retry retrieving edges across VCOs has not been maxed out yet: logger . warning ( f \"Couldn't find any edge to refresh the cache. Re-trying job...\" ) The Customer Cache Refresh job triggers immediately again Otherwise: error_message = ( \"Too many consecutive failures happened while trying \" \"to claim the list of edges from Velocloud\" ) raise Exception ( error_message ) ... logger . error ( f \"An error occurred while refreshing the cache -> { e } \" ) END logger . info ( f \"Distinguishing { len ( edge_list ) } edges per Velocloud host...\" ) logger . info ( \"Refreshing cache for each of the hosts...\" ) For each VCO whose cache needs a refresh: _partial_refresh_cache StorageRepository::update_refresh_date _send_email_multiple_inventories logger . info ( \"Finished refreshing cache!\" )","title":"Run Customer Cache Refresh job"},{"location":"logging/services/customer-cache/actions/refresh_cache/_send_email_multiple_inventories/","text":"Send an e-mail with a summary of all edges having multiple inventories in Bruin If there are edges with multiple inventories in Bruin: message = f \"Alert. Detected some edges with more than one status. { self . _serials_with_multiple_inventories } \" [ ... ] logger . warning ( message ) logger . info ( f \"Sending mail with serials having multiples inventories to \" f \" { email_obj [ 'body' ][ 'email_data' ][ 'recipient' ] } \" ) E-mail is sent logger . info ( f \"Response from sending email with serials having multiple inventories: { json . dumps ( response ) } \" ) Otherwise: logger . info ( \"No edges with multiple Bruin inventories were detected\" )","title":" send email multiple inventories"},{"location":"logging/services/customer-cache/actions/refresh_cache/_send_email_multiple_inventories/#send-an-e-mail-with-a-summary-of-all-edges-having-multiple-inventories-in-bruin","text":"If there are edges with multiple inventories in Bruin: message = f \"Alert. Detected some edges with more than one status. { self . _serials_with_multiple_inventories } \" [ ... ] logger . warning ( message ) logger . info ( f \"Sending mail with serials having multiples inventories to \" f \" { email_obj [ 'body' ][ 'email_data' ][ 'recipient' ] } \" ) E-mail is sent logger . info ( f \"Response from sending email with serials having multiple inventories: { json . dumps ( response ) } \" ) Otherwise: logger . info ( \"No edges with multiple Bruin inventories were detected\" )","title":"Send an e-mail with a summary of all edges having multiple inventories in Bruin"},{"location":"logging/services/customer-cache/actions/refresh_cache/_send_email_snapshot/","text":"Send a snapshot of the already stored and new caches via e-mail logger . info ( \"Sending email with snapshots of cache...\" ) Both caches are sent via e-mail logger . info ( f \"Response from sending email: { json . dumps ( response ) } \" )","title":" send email snapshot"},{"location":"logging/services/customer-cache/actions/refresh_cache/_send_email_snapshot/#send-a-snapshot-of-the-already-stored-and-new-caches-via-e-mail","text":"logger . info ( \"Sending email with snapshots of cache...\" ) Both caches are sent via e-mail logger . info ( f \"Response from sending email: { json . dumps ( response ) } \" )","title":"Send a snapshot of the already stored and new caches via e-mail"},{"location":"logging/services/customer-cache/actions/refresh_cache/schedule_cache_refresh/","text":"Schedule Cache Refresh job logger . info ( f \"Scheduled to refresh cache every { self . _config . REFRESH_CONFIG [ 'refresh_map_minutes' ] // 60 } hours\" ) logger . info ( f \"Scheduled to check if refresh is needed every \" f \" { self . _config . REFRESH_CONFIG [ 'refresh_check_interval_minutes' ] } minutes\" ) _refresh_cache If there's a running job to refresh the customer caches already: logger . warning ( f \"There is a job scheduled for refreshing the cache already. No new job is going to be scheduled.\" )","title":"Schedule Cache Refresh job"},{"location":"logging/services/customer-cache/actions/refresh_cache/schedule_cache_refresh/#schedule-cache-refresh-job","text":"logger . info ( f \"Scheduled to refresh cache every { self . _config . REFRESH_CONFIG [ 'refresh_map_minutes' ] // 60 } hours\" ) logger . info ( f \"Scheduled to check if refresh is needed every \" f \" { self . _config . REFRESH_CONFIG [ 'refresh_check_interval_minutes' ] } minutes\" ) _refresh_cache If there's a running job to refresh the customer caches already: logger . warning ( f \"There is a job scheduled for refreshing the cache already. No new job is going to be scheduled.\" )","title":"Schedule Cache Refresh job"},{"location":"logging/services/customer-cache/repositories/bruin_repository/get_client_info/","text":"Get client info for edge logger . info ( f \"Claiming client info for service number { service_number } ...\" ) If there's an error while asking for the data to the bruin-bridge : err_msg = f \"An error occurred when claiming client info for service number { service_number } -> { e } \" [ ... ] logger . error ( err_msg ) END logger . info ( f \"Got client info for service number { service_number } !\" ) If response status for get client info for edge is not ok: err_msg = ( f \"Error while claiming client info for service number { service_number } in \" f \" { self . _config . ENVIRONMENT_NAME . upper () } environment: Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg )","title":"Get client info"},{"location":"logging/services/customer-cache/repositories/bruin_repository/get_client_info/#get-client-info-for-edge","text":"logger . info ( f \"Claiming client info for service number { service_number } ...\" ) If there's an error while asking for the data to the bruin-bridge : err_msg = f \"An error occurred when claiming client info for service number { service_number } -> { e } \" [ ... ] logger . error ( err_msg ) END logger . info ( f \"Got client info for service number { service_number } !\" ) If response status for get client info for edge is not ok: err_msg = ( f \"Error while claiming client info for service number { service_number } in \" f \" { self . _config . ENVIRONMENT_NAME . upper () } environment: Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg )","title":"Get client info for edge"},{"location":"logging/services/customer-cache/repositories/bruin_repository/get_management_status/","text":"Get management status for edge logger . info ( f \"Claiming management status for service number { service_number } and client { client_id } ...\" ) If there's an error while asking for the data to the bruin-bridge : err_msg = ( f \"An error occurred when claiming management status for service number { service_number } and \" f \"client { client_id } -> { e } \" ) [ ... ] logger . error ( err_msg ) END logger . info ( f \"Got management status for service number { service_number } and client { client_id } !\" ) If response status for get management status for edge is not ok: err_msg = ( f \"Error while claiming management status for service number { service_number } and \" f \"client { client_id } in { self . _config . ENVIRONMENT_NAME . upper () } environment: \" f \"Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg )","title":"Get management status"},{"location":"logging/services/customer-cache/repositories/bruin_repository/get_management_status/#get-management-status-for-edge","text":"logger . info ( f \"Claiming management status for service number { service_number } and client { client_id } ...\" ) If there's an error while asking for the data to the bruin-bridge : err_msg = ( f \"An error occurred when claiming management status for service number { service_number } and \" f \"client { client_id } -> { e } \" ) [ ... ] logger . error ( err_msg ) END logger . info ( f \"Got management status for service number { service_number } and client { client_id } !\" ) If response status for get management status for edge is not ok: err_msg = ( f \"Error while claiming management status for service number { service_number } and \" f \"client { client_id } in { self . _config . ENVIRONMENT_NAME . upper () } environment: \" f \"Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg )","title":"Get management status for edge"},{"location":"logging/services/customer-cache/repositories/bruin_repository/get_site_details/","text":"Get site details for edge logger . info ( f \"Getting site details of site { site_id } and client { client_id } ...\" ) If there's an error while asking for the data to the bruin-bridge : err_msg = f \"An error occurred while getting site details of site { site_id } and client { client_id } ... -> { e } \" [ ... ] logger . error ( err_msg ) END If response status for get site details for edge is ok: logger . info ( f \"Got site details of site { site_id } and client { client_id } successfully!\" ) Otherwise: err_msg = ( f \"Error while getting site details of site { site_id } and client { client_id } in \" f \" { self . _config . ENVIRONMENT_NAME . upper () } environment: Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg )","title":"Get site details"},{"location":"logging/services/customer-cache/repositories/bruin_repository/get_site_details/#get-site-details-for-edge","text":"logger . info ( f \"Getting site details of site { site_id } and client { client_id } ...\" ) If there's an error while asking for the data to the bruin-bridge : err_msg = f \"An error occurred while getting site details of site { site_id } and client { client_id } ... -> { e } \" [ ... ] logger . error ( err_msg ) END If response status for get site details for edge is ok: logger . info ( f \"Got site details of site { site_id } and client { client_id } successfully!\" ) Otherwise: err_msg = ( f \"Error while getting site details of site { site_id } and client { client_id } in \" f \" { self . _config . ENVIRONMENT_NAME . upper () } environment: Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg )","title":"Get site details for edge"},{"location":"logging/services/customer-cache/repositories/storage_repository/get_cache/","text":"Get customer cache for VeloCloud host (VCO) If cache exists: logger . info ( f \"Cache found for { key } \" ) Otherwise: logger . warning ( f \"No cache found for { key } \" )","title":"Get cache"},{"location":"logging/services/customer-cache/repositories/storage_repository/get_cache/#get-customer-cache-for-velocloud-host-vco","text":"If cache exists: logger . info ( f \"Cache found for { key } \" ) Otherwise: logger . warning ( f \"No cache found for { key } \" )","title":"Get customer cache for VeloCloud host (VCO)"},{"location":"logging/services/customer-cache/repositories/storage_repository/get_host_cache/","text":"Get customer caches for VeloCloud hosts (VCOs) If VeloCloud hosts' filter is empty: logger . info ( \"No VeloCloud hosts' filter was specified. Fetching caches for all hosts...\" ) Otherwise: logger . info ( f \"Fetching caches for VeloCloud hosts: { filters . keys () } ...\" ) For each VCO specified in the filter: get_cache If the filter specified a subset of enterprises from the VCO: logger . info ( f \"Filtering { host } cache of { len ( host_cache ) } edges for enterprises: { filters [ host ] } ...\" ) Cache is filtered logger . info ( f \"Cache for host { host } and filtered by enterprises has { len ( host_cache ) } edges\" )","title":"Get host cache"},{"location":"logging/services/customer-cache/repositories/storage_repository/get_host_cache/#get-customer-caches-for-velocloud-hosts-vcos","text":"If VeloCloud hosts' filter is empty: logger . info ( \"No VeloCloud hosts' filter was specified. Fetching caches for all hosts...\" ) Otherwise: logger . info ( f \"Fetching caches for VeloCloud hosts: { filters . keys () } ...\" ) For each VCO specified in the filter: get_cache If the filter specified a subset of enterprises from the VCO: logger . info ( f \"Filtering { host } cache of { len ( host_cache ) } edges for enterprises: { filters [ host ] } ...\" ) Cache is filtered logger . info ( f \"Cache for host { host } and filtered by enterprises has { len ( host_cache ) } edges\" )","title":"Get customer caches for VeloCloud hosts (VCOs)"},{"location":"logging/services/customer-cache/repositories/storage_repository/set_cache/","text":"Store customer cache for VeloCloud host (VCO) logger . info ( f \"Saving cache of { len ( cache ) } edges for { key } ...\" ) Cache is saved logger . info ( f \"Cache saved for { key } \" )","title":"Set cache"},{"location":"logging/services/customer-cache/repositories/storage_repository/set_cache/#store-customer-cache-for-velocloud-host-vco","text":"logger . info ( f \"Saving cache of { len ( cache ) } edges for { key } ...\" ) Cache is saved logger . info ( f \"Cache saved for { key } \" )","title":"Store customer cache for VeloCloud host (VCO)"},{"location":"logging/services/customer-cache/repositories/storage_repository/update_refresh_date/","text":"Update next cache refresh date logger . info ( \"Setting new refresh date in Redis...\" ) Next refresh date is updated logger . info ( f \"New refresh date: { date } set in Redis\" )","title":"Update refresh date"},{"location":"logging/services/customer-cache/repositories/storage_repository/update_refresh_date/#update-next-cache-refresh-date","text":"logger . info ( \"Setting new refresh date in Redis...\" ) Next refresh date is updated logger . info ( f \"New refresh date: { date } set in Redis\" )","title":"Update next cache refresh date"},{"location":"logging/services/customer-cache/repositories/velocloud_repository/_get_all_enterprise_edges/","text":"Get all edges belonging to an enterprise in a VCO logger . info ( f \"Getting all edges from Velocloud host { host } and enterprise ID { enterprise_id } ...\" ) If there's an error while asking for the data to the velocloud-bridge : err_msg = ( f \"An error occurred when requesting edge list from host { host } and enterprise \" f \"ID { enterprise_id } -> { e } \" ) [ ... ] logger . error ( err_msg ) END logger . info ( f \"Got all edges from Velocloud host { host } and enterprise ID { enterprise_id } !\" ) If response status for get all edges belonging to an enterprise is not ok: err_msg = ( f \"Error while retrieving edge list in { self . _config . ENVIRONMENT_NAME . upper () } \" f \"environment: Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg )","title":" get all enterprise edges"},{"location":"logging/services/customer-cache/repositories/velocloud_repository/_get_all_enterprise_edges/#get-all-edges-belonging-to-an-enterprise-in-a-vco","text":"logger . info ( f \"Getting all edges from Velocloud host { host } and enterprise ID { enterprise_id } ...\" ) If there's an error while asking for the data to the velocloud-bridge : err_msg = ( f \"An error occurred when requesting edge list from host { host } and enterprise \" f \"ID { enterprise_id } -> { e } \" ) [ ... ] logger . error ( err_msg ) END logger . info ( f \"Got all edges from Velocloud host { host } and enterprise ID { enterprise_id } !\" ) If response status for get all edges belonging to an enterprise is not ok: err_msg = ( f \"Error while retrieving edge list in { self . _config . ENVIRONMENT_NAME . upper () } \" f \"environment: Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg )","title":"Get all edges belonging to an enterprise in a VCO"},{"location":"logging/services/customer-cache/repositories/velocloud_repository/_get_all_serials/","text":"Map edges with their links' logical IDs data by serial number For each edge: logger . info ( f \"Mapping links' logical IDs to edge { edge } ...\" ) Links' logical IDs are mapped to the edge logger . info ( f \"Links' logical IDs mapped to edge { edge } \" )","title":" get all serials"},{"location":"logging/services/customer-cache/repositories/velocloud_repository/_get_all_serials/#map-edges-with-their-links-logical-ids-data-by-serial-number","text":"For each edge: logger . info ( f \"Mapping links' logical IDs to edge { edge } ...\" ) Links' logical IDs are mapped to the edge logger . info ( f \"Links' logical IDs mapped to edge { edge } \" )","title":"Map edges with their links' logical IDs data by serial number"},{"location":"logging/services/customer-cache/repositories/velocloud_repository/_get_logical_id_by_edge_list/","text":"Get logical ID for all links belonging to an edge For each VCO: For each enterprise within the VCO: _get_all_enterprise_edges If response status for get all edges in an enterprise is not ok: logger . error ( f \"Error could not get enterprise edges of enterprise { enterprise } \" ) Continue with next enterprise","title":" get logical id by edge list"},{"location":"logging/services/customer-cache/repositories/velocloud_repository/_get_logical_id_by_edge_list/#get-logical-id-for-all-links-belonging-to-an-edge","text":"For each VCO: For each enterprise within the VCO: _get_all_enterprise_edges If response status for get all edges in an enterprise is not ok: logger . error ( f \"Error could not get enterprise edges of enterprise { enterprise } \" ) Continue with next enterprise","title":"Get logical ID for all links belonging to an edge"},{"location":"logging/services/customer-cache/repositories/velocloud_repository/add_edge_config/","text":"Add links' configuration to edge logger . info ( f \"Adding links' configuration to edge { edge } ...\" ) get_links_configuration If response status for get links' configuration for the edge is not ok: logger . error ( f \"Error while getting links configuration for edge { edge_request } \" ) END logger . info ( f \"Links' configuration added to edge { edge } \" )","title":"Add edge config"},{"location":"logging/services/customer-cache/repositories/velocloud_repository/add_edge_config/#add-links-configuration-to-edge","text":"logger . info ( f \"Adding links' configuration to edge { edge } ...\" ) get_links_configuration If response status for get links' configuration for the edge is not ok: logger . error ( f \"Error while getting links configuration for edge { edge_request } \" ) END logger . info ( f \"Links' configuration added to edge { edge } \" )","title":"Add links' configuration to edge"},{"location":"logging/services/customer-cache/repositories/velocloud_repository/extract_edge_info/","text":"Extract edge info from links with edge info For link in links with edge info: If the state of the edge bound to the link is invalid: logger . info ( f \"Edge in host { velocloud_host } and enterprise { enterprise_name } (ID: { enterprise_id } ) \" f \"has an invalid state. Skipping...\" ) Continue with next link with edge info If the edge bound to the link has never been activated: logger . info ( f \"Edge { edge_name } in host { velocloud_host } and enterprise { enterprise_name } (ID: { enterprise_id } ) \" f \"has never been activated. Skipping...\" ) Continue with next link with edge info If the edge bound to the link is blacklisted from the IPA system's monitoring processes: logger . info ( f \"Edge { json . dumps ( edge_full_id ) } (serial: { serial_number } ) is in blacklist. Skipping...\" ) Continue with next link with edge info","title":"Extract edge info"},{"location":"logging/services/customer-cache/repositories/velocloud_repository/extract_edge_info/#extract-edge-info-from-links-with-edge-info","text":"For link in links with edge info: If the state of the edge bound to the link is invalid: logger . info ( f \"Edge in host { velocloud_host } and enterprise { enterprise_name } (ID: { enterprise_id } ) \" f \"has an invalid state. Skipping...\" ) Continue with next link with edge info If the edge bound to the link has never been activated: logger . info ( f \"Edge { edge_name } in host { velocloud_host } and enterprise { enterprise_name } (ID: { enterprise_id } ) \" f \"has never been activated. Skipping...\" ) Continue with next link with edge info If the edge bound to the link is blacklisted from the IPA system's monitoring processes: logger . info ( f \"Edge { json . dumps ( edge_full_id ) } (serial: { serial_number } ) is in blacklist. Skipping...\" ) Continue with next link with edge info","title":"Extract edge info from links with edge info"},{"location":"logging/services/customer-cache/repositories/velocloud_repository/get_all_edges_links/","text":"Get edges across all VCOs For every VCO: get_edges_links_by_host If an error occurred while fetching all edges in the VCO: logger . warning ( f \"Error: could not retrieve edges links by host: { host } \" ) Continue with next VCO","title":"Get all edges links"},{"location":"logging/services/customer-cache/repositories/velocloud_repository/get_all_edges_links/#get-edges-across-all-vcos","text":"For every VCO: get_edges_links_by_host If an error occurred while fetching all edges in the VCO: logger . warning ( f \"Error: could not retrieve edges links by host: { host } \" ) Continue with next VCO","title":"Get edges across all VCOs"},{"location":"logging/services/customer-cache/repositories/velocloud_repository/get_all_velo_edges/","text":"Get edges across VCOs logger . info ( \"Getting list of all velo edges\" ) get_edges logger . info ( f \"Got all edges from all velos. Took { ( time . time () - start_time ) // 60 } minutes\" ) logger . info ( \"Getting list of logical IDs by each velo edge\" ) _get_logical_id_by_edge_list logger . info ( f \"Got all logical IDs by each velo edge. Took { ( time . time () - start_time ) // 60 } minutes\" ) logger . info ( f \"Mapping edges to serials...\" ) _get_all_serials logger . info ( f \"Amount of edges: { len ( edges_with_serial ) } \" ) logger . info ( \"Adding links configuration to edges...\" ) add_edge_config logger . info ( \"Finished adding links configuration to edges. Took {(time.time() - start_time) // 60} minutes\" ) logger . info ( f \"Finished building velos + serials map. Took { ( time . time () - start_time ) // 60 } minutes\" )","title":"Get all velo edges"},{"location":"logging/services/customer-cache/repositories/velocloud_repository/get_all_velo_edges/#get-edges-across-vcos","text":"logger . info ( \"Getting list of all velo edges\" ) get_edges logger . info ( f \"Got all edges from all velos. Took { ( time . time () - start_time ) // 60 } minutes\" ) logger . info ( \"Getting list of logical IDs by each velo edge\" ) _get_logical_id_by_edge_list logger . info ( f \"Got all logical IDs by each velo edge. Took { ( time . time () - start_time ) // 60 } minutes\" ) logger . info ( f \"Mapping edges to serials...\" ) _get_all_serials logger . info ( f \"Amount of edges: { len ( edges_with_serial ) } \" ) logger . info ( \"Adding links configuration to edges...\" ) add_edge_config logger . info ( \"Finished adding links configuration to edges. Took {(time.time() - start_time) // 60} minutes\" ) logger . info ( f \"Finished building velos + serials map. Took { ( time . time () - start_time ) // 60 } minutes\" )","title":"Get edges across VCOs"},{"location":"logging/services/customer-cache/repositories/velocloud_repository/get_edges/","text":"Get edges get_all_edges_links extract_edge_info","title":"Get edges"},{"location":"logging/services/customer-cache/repositories/velocloud_repository/get_edges/#get-edges","text":"get_all_edges_links extract_edge_info","title":"Get edges"},{"location":"logging/services/customer-cache/repositories/velocloud_repository/get_edges_links_by_host/","text":"Get links with edge info by VCO logger . info ( f \"Getting edges links from Velocloud for host { host } ...\" ) If there's an error while asking for the data to the velocloud-bridge : err_msg = f \"An error occurred when requesting edge list from { host } -> { e } \" [ ... ] logger . error ( err_msg ) END logger . info ( \"Got edges links from Velocloud!\" ) If response status for get links with edge info is not ok: err_msg = ( f \"Error while retrieving edges links in { self . _config . ENVIRONMENT_NAME . upper () } \" f \"environment: Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg )","title":"Get edges links by host"},{"location":"logging/services/customer-cache/repositories/velocloud_repository/get_edges_links_by_host/#get-links-with-edge-info-by-vco","text":"logger . info ( f \"Getting edges links from Velocloud for host { host } ...\" ) If there's an error while asking for the data to the velocloud-bridge : err_msg = f \"An error occurred when requesting edge list from { host } -> { e } \" [ ... ] logger . error ( err_msg ) END logger . info ( \"Got edges links from Velocloud!\" ) If response status for get links with edge info is not ok: err_msg = ( f \"Error while retrieving edges links in { self . _config . ENVIRONMENT_NAME . upper () } \" f \"environment: Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg )","title":"Get links with edge info by VCO"},{"location":"logging/services/customer-cache/repositories/velocloud_repository/get_links_configuration/","text":"Get links' configuration for an edge logger . info ( f \"Getting links configuration for edge { edge } ...\" ) If there's an error while asking for the data to the velocloud-bridge : err_msg = f \"An error occurred when requesting links configuration for edge { edge } -> { e } \" [ ... ] logger . error ( err_msg ) END If response status for get links' configuration for the edge is not ok: err_msg = ( f \"Error while retrieving links configuration for edge { edge } in \" f \" { self . _config . ENVIRONMENT_NAME . upper () } environment: Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg ) END logger . info ( f \"Got links configuration for edge { edge } !\" )","title":"Get links configuration"},{"location":"logging/services/customer-cache/repositories/velocloud_repository/get_links_configuration/#get-links-configuration-for-an-edge","text":"logger . info ( f \"Getting links configuration for edge { edge } ...\" ) If there's an error while asking for the data to the velocloud-bridge : err_msg = f \"An error occurred when requesting links configuration for edge { edge } -> { e } \" [ ... ] logger . error ( err_msg ) END If response status for get links' configuration for the edge is not ok: err_msg = ( f \"Error while retrieving links configuration for edge { edge } in \" f \" { self . _config . ENVIRONMENT_NAME . upper () } environment: Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg ) END logger . info ( f \"Got links configuration for edge { edge } !\" )","title":"Get links' configuration for an edge"},{"location":"logging/services/digi-bridge/actions/digi_reboot/","text":"Subject: digi.reboot Message arrives at subject If message doesn't have body : logger . error ( f \"Cannot reboot DiGi client using { request_msg } . JSON malformed\" ) END If message body doesn't have velo_serial , ticket and MAC filters: logger . error ( f \"Cannot reboot DiGi client using { request_msg } . JSON malformed\" ) END logger . info ( f \"Attempting to reboot DiGi client with payload of: { request_filters } \" ) DiGiRepository::reboot logger . info ( f \"DiGi reboot process completed and publishing results in event bus for request { request_msg } . \" f \"Message published was { response } \" )","title":"Digi reboot"},{"location":"logging/services/digi-bridge/actions/digi_reboot/#subject-digireboot","text":"Message arrives at subject If message doesn't have body : logger . error ( f \"Cannot reboot DiGi client using { request_msg } . JSON malformed\" ) END If message body doesn't have velo_serial , ticket and MAC filters: logger . error ( f \"Cannot reboot DiGi client using { request_msg } . JSON malformed\" ) END logger . info ( f \"Attempting to reboot DiGi client with payload of: { request_filters } \" ) DiGiRepository::reboot logger . info ( f \"DiGi reboot process completed and publishing results in event bus for request { request_msg } . \" f \"Message published was { response } \" )","title":"Subject: digi.reboot"},{"location":"logging/services/digi-bridge/actions/get_digi_recovery_logs/","text":"Subject: get.digi.recovery.logs Message arrives at subject If message doesn't have body : logger . error ( f \"Cannot get DiGi recovery logs client using { request_msg } . JSON malformed\" ) END logger . info ( f \"Getting DiGi recovery logs\" ) DiGiRepository::get_digi_recovery_logs logger . info ( f \"DiGi recovery logs retrieved and publishing results in event bus for request { request_msg } . \" f \"Message published was { response } \" )","title":"Get digi recovery logs"},{"location":"logging/services/digi-bridge/actions/get_digi_recovery_logs/#subject-getdigirecoverylogs","text":"Message arrives at subject If message doesn't have body : logger . error ( f \"Cannot get DiGi recovery logs client using { request_msg } . JSON malformed\" ) END logger . info ( f \"Getting DiGi recovery logs\" ) DiGiRepository::get_digi_recovery_logs logger . info ( f \"DiGi recovery logs retrieved and publishing results in event bus for request { request_msg } . \" f \"Message published was { response } \" )","title":"Subject: get.digi.recovery.logs"},{"location":"logging/services/digi-bridge/clients/digi_client/check_if_token_is_created_and_valid/","text":"Check if token is created and valid If there isn't token logger . info ( f \"The token is not created yet\" ) If the token is expired logger . info ( f \"The token is not valid because it is expired\" )","title":"Check if token is created and valid"},{"location":"logging/services/digi-bridge/clients/digi_client/check_if_token_is_created_and_valid/#check-if-token-is-created-and-valid","text":"If there isn't token logger . info ( f \"The token is not created yet\" ) If the token is expired logger . info ( f \"The token is not valid because it is expired\" )","title":"Check if token is created and valid"},{"location":"logging/services/digi-bridge/clients/digi_client/get_digi_recovery_logs/","text":"Get DiGi recovery logs logger . info ( f \"Getting DiGi recovery logs with params { request_filters } \" ) check_if_token_is_created_and_valid Make a call to GET /DeviceManagement_API/rest/Recovery/Logs with the specified query parameters. If an error took place: logger . error ( f \"Got an error of { return_response [ 'body' ] } \" ) END If DiGi returned a response but the request couldn't succeed on their system: logger . error ( f \"Got { response . status } . Response returned { response_json } \" ) END","title":"Get digi recovery logs"},{"location":"logging/services/digi-bridge/clients/digi_client/get_digi_recovery_logs/#get-digi-recovery-logs","text":"logger . info ( f \"Getting DiGi recovery logs with params { request_filters } \" ) check_if_token_is_created_and_valid Make a call to GET /DeviceManagement_API/rest/Recovery/Logs with the specified query parameters. If an error took place: logger . error ( f \"Got an error of { return_response [ 'body' ] } \" ) END If DiGi returned a response but the request couldn't succeed on their system: logger . error ( f \"Got { response . status } . Response returned { response_json } \" ) END","title":"Get DiGi recovery logs"},{"location":"logging/services/digi-bridge/clients/digi_client/login/","text":"Login logger . info ( \"Scheduled task: logging in digi api\" ) Call DiGi Identity Server endpoint POST /Identity/rest/oauth/token using authentication credentials. If no errors arise while calling the endpoint: logger . info ( \"Logged into DiGi!\" ) Otherwise: logger . error ( \"An error occurred while trying to login to DiGi\" ) logger . error ( f \"Error: { err } \" )","title":"Login"},{"location":"logging/services/digi-bridge/clients/digi_client/login/#login","text":"logger . info ( \"Scheduled task: logging in digi api\" ) Call DiGi Identity Server endpoint POST /Identity/rest/oauth/token using authentication credentials. If no errors arise while calling the endpoint: logger . info ( \"Logged into DiGi!\" ) Otherwise: logger . error ( \"An error occurred while trying to login to DiGi\" ) logger . error ( f \"Error: { err } \" )","title":"Login"},{"location":"logging/services/digi-bridge/clients/digi_client/reboot/","text":"DiGi reboot logger . info ( f \"Rebooting DiGi device with params { request_filters } \" ) check_if_token_is_created_and_valid Make a call to POST /DeviceManagement_API/rest/Recovery/RecoverDevice with the specified query parameters. If an error took place: logger . error ( f \"Got an error of { response_error_list } \" ) END If DiGi aborted the request: logger . error ( f \"DiGi reboot aborted with message returning: { response_abort_messages_list } \" ) END If DiGi returned a response but the request couldn't succeed on their system: logger . error ( f \"Got { response . status } . Response returned { response_json } \" ) END","title":"Reboot"},{"location":"logging/services/digi-bridge/clients/digi_client/reboot/#digi-reboot","text":"logger . info ( f \"Rebooting DiGi device with params { request_filters } \" ) check_if_token_is_created_and_valid Make a call to POST /DeviceManagement_API/rest/Recovery/RecoverDevice with the specified query parameters. If an error took place: logger . error ( f \"Got an error of { response_error_list } \" ) END If DiGi aborted the request: logger . error ( f \"DiGi reboot aborted with message returning: { response_abort_messages_list } \" ) END If DiGi returned a response but the request couldn't succeed on their system: logger . error ( f \"Got { response . status } . Response returned { response_json } \" ) END","title":"DiGi reboot"},{"location":"logging/services/digi-bridge/repositories/digi_repository/get_digi_recovery_logs/","text":"Get DiGi recovery logs DiGiClient::get_digi_recovery_logs","title":"Get digi recovery logs"},{"location":"logging/services/digi-bridge/repositories/digi_repository/get_digi_recovery_logs/#get-digi-recovery-logs","text":"DiGiClient::get_digi_recovery_logs","title":"Get DiGi recovery logs"},{"location":"logging/services/digi-bridge/repositories/digi_repository/login_job/","text":"Login logger . info ( \"Scheduled task: logging in digi api\" ) DiGiClient::login_job","title":"Login job"},{"location":"logging/services/digi-bridge/repositories/digi_repository/login_job/#login","text":"logger . info ( \"Scheduled task: logging in digi api\" ) DiGiClient::login_job","title":"Login"},{"location":"logging/services/digi-bridge/repositories/digi_repository/reboot/","text":"DiGi reboot DiGiClient::reboot","title":"Reboot"},{"location":"logging/services/digi-bridge/repositories/digi_repository/reboot/#digi-reboot","text":"DiGiClient::reboot","title":"DiGi reboot"},{"location":"logging/services/digi-reboot-report/actions/_digi_reboot_report_process/","text":"Run Lumin Billing Report job logger . info ( \"Starting DiGi reboot report process\" ) logger . info ( \"Grabbing DiGi recovery logs\" ) The DiGi reboot report is called every 24 hours, and starts off by getting all the DiGi recovery logs from the past 3 days. It then takes all the ticket IDs from those logs and makes a list. From the list we get all the ticket task histories one by one. DiGiRebootReport::get_digi_recovery_logs _get_all_ticket_ids_from_digi_recovery_logs _get_ticket_task_histories _merge_recovery_logs Last step is take all the data from the ticket map to create a csv file that then is sent out through email. _generate_and_email_csv_file logger . info ( f \"DiGi reboot report process finished in { round (( stop - start ) / 60 , 2 ) } minutes\" )","title":" digi reboot report process"},{"location":"logging/services/digi-reboot-report/actions/_digi_reboot_report_process/#run-lumin-billing-report-job","text":"logger . info ( \"Starting DiGi reboot report process\" ) logger . info ( \"Grabbing DiGi recovery logs\" ) The DiGi reboot report is called every 24 hours, and starts off by getting all the DiGi recovery logs from the past 3 days. It then takes all the ticket IDs from those logs and makes a list. From the list we get all the ticket task histories one by one. DiGiRebootReport::get_digi_recovery_logs _get_all_ticket_ids_from_digi_recovery_logs _get_ticket_task_histories _merge_recovery_logs Last step is take all the data from the ticket map to create a csv file that then is sent out through email. _generate_and_email_csv_file logger . info ( f \"DiGi reboot report process finished in { round (( stop - start ) / 60 , 2 ) } minutes\" )","title":"Run Lumin Billing Report job"},{"location":"logging/services/digi-reboot-report/actions/_generate_and_email_csv_file/","text":"_generate_and_email_csv_file logger . info ( \"Generating a csv file from the ticket map of ticket IDs to ticket task histories\" ) Once the file is generated we proceed to send it logger.info(\"Sending csv file through email\") Report is sent via e-mail","title":" generate and email csv file"},{"location":"logging/services/digi-reboot-report/actions/_generate_and_email_csv_file/#_generate_and_email_csv_file","text":"logger . info ( \"Generating a csv file from the ticket map of ticket IDs to ticket task histories\" ) Once the file is generated we proceed to send it logger.info(\"Sending csv file through email\") Report is sent via e-mail","title":"_generate_and_email_csv_file"},{"location":"logging/services/digi-reboot-report/actions/_get_all_ticket_ids_from_digi_recovery_logs/","text":"_get_all_ticket_ids_from_digi_recovery_logs logger . info ( \"Creating a list of all ticket IDS from the DiGi recovery logs\" ) For each recovery log we create a list of all DiGi ticket IDs logger . info ( \"List of all DiGi ticket IDS created\" )","title":" get all ticket ids from digi recovery logs"},{"location":"logging/services/digi-reboot-report/actions/_get_all_ticket_ids_from_digi_recovery_logs/#_get_all_ticket_ids_from_digi_recovery_logs","text":"logger . info ( \"Creating a list of all ticket IDS from the DiGi recovery logs\" ) For each recovery log we create a list of all DiGi ticket IDs logger . info ( \"List of all DiGi ticket IDS created\" )","title":"_get_all_ticket_ids_from_digi_recovery_logs"},{"location":"logging/services/digi-reboot-report/actions/_get_ticket_task_histories/","text":"_get_ticket_task_histories logger . info ( \"Creating ticket map of ticket id to ticket task history\" ) Iterate over the ticket list logger . info ( f \"Grabbing the ticket task history for ticket { ticket_id } \" ) If ticket task history doesn't return 200 END logger . info ( f \"Parsing all data in the ticket task history for ticket { ticket_id } \" ) We parse tickets history and return them","title":" get ticket task histories"},{"location":"logging/services/digi-reboot-report/actions/_get_ticket_task_histories/#_get_ticket_task_histories","text":"logger . info ( \"Creating ticket map of ticket id to ticket task history\" ) Iterate over the ticket list logger . info ( f \"Grabbing the ticket task history for ticket { ticket_id } \" ) If ticket task history doesn't return 200 END logger . info ( f \"Parsing all data in the ticket task history for ticket { ticket_id } \" ) We parse tickets history and return them","title":"_get_ticket_task_histories"},{"location":"logging/services/digi-reboot-report/actions/_merge_recovery_logs/","text":"_merge_recovery_logs logger . info ( \"Merging recovery logs data into ticket map\" ) logger . info ( f \"Merging data from DiGi recovery logs of ticket id { ticket_id } \" \"into the ticket ID to ticket task history map\" ) We take all the recovery logs data and fill in the other values of each dictionary in the ticket map respectively based on matching ticket ids.","title":" merge recovery logs"},{"location":"logging/services/digi-reboot-report/actions/_merge_recovery_logs/#_merge_recovery_logs","text":"logger . info ( \"Merging recovery logs data into ticket map\" ) logger . info ( f \"Merging data from DiGi recovery logs of ticket id { ticket_id } \" \"into the ticket ID to ticket task history map\" ) We take all the recovery logs data and fill in the other values of each dictionary in the ticket map respectively based on matching ticket ids.","title":"_merge_recovery_logs"},{"location":"logging/services/digi-reboot-report/actions/start_digi_reboot_report_job/","text":"Schedule DiGi Reboot Report job logger . info ( \"Scheduled task: DiGi reboot report process configured to run every \" f \" { self . _config . DIGI_CONFIG [ 'digi_reboot_report_time' ] / 60 } hours\" ) If job should be executed on service start: logger . info ( f \"It will be executed now\" ) _digi_reboot_report_process","title":"Start digi reboot report job"},{"location":"logging/services/digi-reboot-report/actions/start_digi_reboot_report_job/#schedule-digi-reboot-report-job","text":"logger . info ( \"Scheduled task: DiGi reboot report process configured to run every \" f \" { self . _config . DIGI_CONFIG [ 'digi_reboot_report_time' ] / 60 } hours\" ) If job should be executed on service start: logger . info ( f \"It will be executed now\" ) _digi_reboot_report_process","title":"Schedule DiGi Reboot Report job"},{"location":"logging/services/digi-reboot-report/repositories/digi_repository/get_digi_recovery_logs/","text":"get_digi_recovery_logs logger . info ( f \"Getting DiGi recovery logs from \" f ' { self . _config . DIGI_CONFIG [ \"days_of_digi_recovery_log\" ] } ' f \"day(s) ago\" ) Request from nats DiGi recovery logs logger . info ( f 'Got DiGi recovery logs from { self . _config . DIGI_CONFIG [ \"days_of_digi_recovery_log\" ] } ' f \"day(s) ago\" ) If fails with an error logger . error ( f \"Error while attempting to get DiGi recovery logs in \" f \" { self . _config . ENVIRONMENT_NAME . upper () } environment: \" f \"Error { response_status } - { response_body } \" ) END If the connection with the bridge fails logger . error ( f \"An error occurred when attempting to get DiGi recovery logs -> { e } \" ) END","title":"Get digi recovery logs"},{"location":"logging/services/digi-reboot-report/repositories/digi_repository/get_digi_recovery_logs/#get_digi_recovery_logs","text":"logger . info ( f \"Getting DiGi recovery logs from \" f ' { self . _config . DIGI_CONFIG [ \"days_of_digi_recovery_log\" ] } ' f \"day(s) ago\" ) Request from nats DiGi recovery logs logger . info ( f 'Got DiGi recovery logs from { self . _config . DIGI_CONFIG [ \"days_of_digi_recovery_log\" ] } ' f \"day(s) ago\" ) If fails with an error logger . error ( f \"Error while attempting to get DiGi recovery logs in \" f \" { self . _config . ENVIRONMENT_NAME . upper () } environment: \" f \"Error { response_status } - { response_body } \" ) END If the connection with the bridge fails logger . error ( f \"An error occurred when attempting to get DiGi recovery logs -> { e } \" ) END","title":"get_digi_recovery_logs"},{"location":"logging/services/dri-bridge/actions/get_dri_parameters/","text":"Subject: dri.parameters.request Message arrives at subject If message doesn't have body : logger . error ( f \"Cannot get DRI parameters using { json . dumps ( payload ) } . JSON malformed\" ) END If message body doesn't have serial_number and parameter_set filters: logger . error ( f 'Cannot get DRI parameters using { json . dumps ( params ) } . Need \"serial_number\" and ' f '\"parameter_set\"' ) END logger . info ( f \"Getting DRI parameters for serial_number { serial_number } \" ) DRIRepository::get_dri_parameters logger . info ( f \"The DRI parameters response for serial { serial_number } was published in \" f \"event bus for request { json . dumps ( payload ) } . \" f \"Message published was { response } \" )","title":"Get dri parameters"},{"location":"logging/services/dri-bridge/actions/get_dri_parameters/#subject-driparametersrequest","text":"Message arrives at subject If message doesn't have body : logger . error ( f \"Cannot get DRI parameters using { json . dumps ( payload ) } . JSON malformed\" ) END If message body doesn't have serial_number and parameter_set filters: logger . error ( f 'Cannot get DRI parameters using { json . dumps ( params ) } . Need \"serial_number\" and ' f '\"parameter_set\"' ) END logger . info ( f \"Getting DRI parameters for serial_number { serial_number } \" ) DRIRepository::get_dri_parameters logger . info ( f \"The DRI parameters response for serial { serial_number } was published in \" f \"event bus for request { json . dumps ( payload ) } . \" f \"Message published was { response } \" )","title":"Subject: dri.parameters.request"},{"location":"logging/services/dri-bridge/clients/dri_client/get_pending_task_ids/","text":"Get pending tasks for serial number logger . info ( f \"Getting list of pending task ids for serial number { serial_number } ...\" ) Make a call to GET /acs/device/{serial_number}/taskpending . If there's an error while connecting to DRI API: logger . error ( f \"An error occurred while getting list of pending task ids for serial number { serial_number } \" ) logger . error ( f \"Error: { err } \" ) END If the status of the HTTP response is 401 : logger . error ( f \"Got 401 from DRI. Re-logging in...\" ) login END If the status of the HTTP response is any other and not a 2xx : logger . error ( f \"Got { response . status } . Response returned { response_json } \" )","title":"Get pending task ids"},{"location":"logging/services/dri-bridge/clients/dri_client/get_pending_task_ids/#get-pending-tasks-for-serial-number","text":"logger . info ( f \"Getting list of pending task ids for serial number { serial_number } ...\" ) Make a call to GET /acs/device/{serial_number}/taskpending . If there's an error while connecting to DRI API: logger . error ( f \"An error occurred while getting list of pending task ids for serial number { serial_number } \" ) logger . error ( f \"Error: { err } \" ) END If the status of the HTTP response is 401 : logger . error ( f \"Got 401 from DRI. Re-logging in...\" ) login END If the status of the HTTP response is any other and not a 2xx : logger . error ( f \"Got { response . status } . Response returned { response_json } \" )","title":"Get pending tasks for serial number"},{"location":"logging/services/dri-bridge/clients/dri_client/get_task_id/","text":"Create new task in DRI for serial number logger . info ( f \"Getting task id from serial { serial_number } with parameters { json_parameter_set } ...\" ) Make a call to GET /acs/device/{serial_number}/parameter_returnid?data={parameters} with the specified query parameters. If there's an error while connecting to DRI API: logger . error ( f \"An error occurred while trying to get the task id from serial { serial_number } \" ) logger . error ( f \"Error: { err } \" ) END If the status of the HTTP response is 401 : logger . error ( f \"Got 401 from DRI. Re-logging in...\" ) login END If the status of the HTTP response is 504 : logger . error ( f \"Got { response . status } . Getting task_id of { serial_number } timed out\" ) END If the status of the HTTP response is any other and not a 2xx : logger . error ( f \"Got { response . status } . Response returned { response_json } \" ) END","title":"Get task id"},{"location":"logging/services/dri-bridge/clients/dri_client/get_task_id/#create-new-task-in-dri-for-serial-number","text":"logger . info ( f \"Getting task id from serial { serial_number } with parameters { json_parameter_set } ...\" ) Make a call to GET /acs/device/{serial_number}/parameter_returnid?data={parameters} with the specified query parameters. If there's an error while connecting to DRI API: logger . error ( f \"An error occurred while trying to get the task id from serial { serial_number } \" ) logger . error ( f \"Error: { err } \" ) END If the status of the HTTP response is 401 : logger . error ( f \"Got 401 from DRI. Re-logging in...\" ) login END If the status of the HTTP response is 504 : logger . error ( f \"Got { response . status } . Getting task_id of { serial_number } timed out\" ) END If the status of the HTTP response is any other and not a 2xx : logger . error ( f \"Got { response . status } . Response returned { response_json } \" ) END","title":"Create new task in DRI for serial number"},{"location":"logging/services/dri-bridge/clients/dri_client/get_task_results/","text":"Get task results for serial number logger . info ( f \"Checking if { task_id } for serial { serial_number } is complete...\" ) Make a call to GET /acs/device/{serial_number}/parameter_tid?transactionid={task_id} with the specified query parameters. If there's an error while connecting to DRI API: logger . error ( f \"An error occurred while checking if { task_id } for serial { serial_number } is complete\" ) logger . error ( f \"Error: { err } \" ) END If the status of the HTTP response is 401 : logger . error ( f \"Got 401 from DRI. Re-logging in...\" ) login END If the status of the HTTP response is any other and not a 2xx : logger . error ( f \"Got { response . status } . Response returned { response_json } \" )","title":"Get task results"},{"location":"logging/services/dri-bridge/clients/dri_client/get_task_results/#get-task-results-for-serial-number","text":"logger . info ( f \"Checking if { task_id } for serial { serial_number } is complete...\" ) Make a call to GET /acs/device/{serial_number}/parameter_tid?transactionid={task_id} with the specified query parameters. If there's an error while connecting to DRI API: logger . error ( f \"An error occurred while checking if { task_id } for serial { serial_number } is complete\" ) logger . error ( f \"Error: { err } \" ) END If the status of the HTTP response is 401 : logger . error ( f \"Got 401 from DRI. Re-logging in...\" ) login END If the status of the HTTP response is any other and not a 2xx : logger . error ( f \"Got { response . status } . Response returned { response_json } \" )","title":"Get task results for serial number"},{"location":"logging/services/dri-bridge/clients/dri_client/login/","text":"Log in to DRI API logger . info ( \"Logging into DRI...\" ) Make a call to POST /auth/login using the set of credentials provided. If there's an error while connecting to DRI API: logger . error ( \"An error occurred while trying to login to DRI\" ) logger . error ( f \"Error: { err } \" ) END logger . info ( \"Logged into DRI!\" )","title":"Log in to DRI API"},{"location":"logging/services/dri-bridge/clients/dri_client/login/#log-in-to-dri-api","text":"logger . info ( \"Logging into DRI...\" ) Make a call to POST /auth/login using the set of credentials provided. If there's an error while connecting to DRI API: logger . error ( \"An error occurred while trying to login to DRI\" ) logger . error ( f \"Error: { err } \" ) END logger . info ( \"Logged into DRI!\" )","title":"Log in to DRI API"},{"location":"logging/services/dri-bridge/repositories/dri_repository/_get_pending_task_ids/","text":"Get pending tasks for serial number DRIClient::get_pending_task_ids If an error took place while looking for pending tasks linked to the serial number: logger . error ( f \"Failed to get pending task ids list from DRI for serial { serial_number } \" ) END If DRI returned a response but the request couldn't succeed on their system: logger . error ( f \"Getting list of pending tasks for serial { serial_number } failed.\" f \"Response returned { pending_task_ids_response [ 'body' ] } \" ) END logger . info ( f \"Pending task ids list from DRI for serial { serial_number } found: { pending_task_ids } \" )","title":" get pending task ids"},{"location":"logging/services/dri-bridge/repositories/dri_repository/_get_pending_task_ids/#get-pending-tasks-for-serial-number","text":"DRIClient::get_pending_task_ids If an error took place while looking for pending tasks linked to the serial number: logger . error ( f \"Failed to get pending task ids list from DRI for serial { serial_number } \" ) END If DRI returned a response but the request couldn't succeed on their system: logger . error ( f \"Getting list of pending tasks for serial { serial_number } failed.\" f \"Response returned { pending_task_ids_response [ 'body' ] } \" ) END logger . info ( f \"Pending task ids list from DRI for serial { serial_number } found: { pending_task_ids } \" )","title":"Get pending tasks for serial number"},{"location":"logging/services/dri-bridge/repositories/dri_repository/_get_task_id/","text":"Get task ID for serial number logger . info ( f \"Checking redis for task id from DRI for serial_number { serial_number } \" ) If no task ID linked to the serial number was found: logger . info ( f \"No task ids found from redis for serial_number { serial_number } . Checking \" f \"if any task_ids are currently in the pending task queue...\" ) _get_pending_task_ids If an error took place while looking for pending tasks linked to the serial number: logger . error ( f \"An error occurred while looking for pending tasks for serial number { serial_number } : \" f \" { pending_task_ids } \" ) END If pending tasks were found for serial number: logger . info ( f \"Found { len ( pending_task_ids [ 'body' ]) } pending tasks for serial number { serial_number } : \" f \" { pending_task_ids } \" ) Most recent task ID is linked to the serial number in Redis Otherwise: logger . info ( f \"No task ids found from the pending task queue for serial_number { serial_number } . \" f \"Getting task_id from DRI...\" ) _get_task_id_from_dri","title":" get task id"},{"location":"logging/services/dri-bridge/repositories/dri_repository/_get_task_id/#get-task-id-for-serial-number","text":"logger . info ( f \"Checking redis for task id from DRI for serial_number { serial_number } \" ) If no task ID linked to the serial number was found: logger . info ( f \"No task ids found from redis for serial_number { serial_number } . Checking \" f \"if any task_ids are currently in the pending task queue...\" ) _get_pending_task_ids If an error took place while looking for pending tasks linked to the serial number: logger . error ( f \"An error occurred while looking for pending tasks for serial number { serial_number } : \" f \" { pending_task_ids } \" ) END If pending tasks were found for serial number: logger . info ( f \"Found { len ( pending_task_ids [ 'body' ]) } pending tasks for serial number { serial_number } : \" f \" { pending_task_ids } \" ) Most recent task ID is linked to the serial number in Redis Otherwise: logger . info ( f \"No task ids found from the pending task queue for serial_number { serial_number } . \" f \"Getting task_id from DRI...\" ) _get_task_id_from_dri","title":"Get task ID for serial number"},{"location":"logging/services/dri-bridge/repositories/dri_repository/_get_task_id_from_dri/","text":"Create new task in DRI for serial number DRIClient::get_task_id If an error took place while creating a new task in DRI for the serial number: logger . error ( f \"An error occurred when getting task_id from DRI for serial { serial_number } : { task_id_response } \" ) END If DRI returned a response but the request couldn't succeed on their system: logger . error ( f \"Getting task_id of { serial_number } failed. Response returned { task_id_response [ 'body' ] } \" ) END Task ID is linked to the serial number in Redis logger . info ( f \"Got task id { dri_task_id } from DRI for serial { serial_number } \" )","title":" get task id from dri"},{"location":"logging/services/dri-bridge/repositories/dri_repository/_get_task_id_from_dri/#create-new-task-in-dri-for-serial-number","text":"DRIClient::get_task_id If an error took place while creating a new task in DRI for the serial number: logger . error ( f \"An error occurred when getting task_id from DRI for serial { serial_number } : { task_id_response } \" ) END If DRI returned a response but the request couldn't succeed on their system: logger . error ( f \"Getting task_id of { serial_number } failed. Response returned { task_id_response [ 'body' ] } \" ) END Task ID is linked to the serial number in Redis logger . info ( f \"Got task id { dri_task_id } from DRI for serial { serial_number } \" )","title":"Create new task in DRI for serial number"},{"location":"logging/services/dri-bridge/repositories/dri_repository/_get_task_results/","text":"Get task results for serial number DRIClient::get_task_results If an authentication error took place while fetching the results of a task linked to the serial number from DRI: logger . warning ( f \"Got authentication error from DRI while looking for results of task { task_id } for \" f \"serial number { serial_number } \" ) END If some other error took place: logger . error ( f \"An error occurred while looking for results of task { task_id } for serial number \" f \" { serial_number } : { task_results_response } \" ) Task ID linked to the serial number is removed from Redis END If DRI returned a response but the request couldn't succeed on their system: logger . error ( f \"Checking if task_id { task_id } of { serial_number } is complete failed. \" f \"Response returned { task_results } \" ) Task ID linked to the serial number is removed from Redis END If DRI reported that the task linked to the serial number is still in progress: logger . info ( f \"Task { task_id } for serial number { serial_number } is still in progress\" ) END If DRI reported that the task linked to the serial number was rejected: logger . warning ( f \"Task { task_id } for serial number { serial_number } was rejected\" ) END","title":" get task results"},{"location":"logging/services/dri-bridge/repositories/dri_repository/_get_task_results/#get-task-results-for-serial-number","text":"DRIClient::get_task_results If an authentication error took place while fetching the results of a task linked to the serial number from DRI: logger . warning ( f \"Got authentication error from DRI while looking for results of task { task_id } for \" f \"serial number { serial_number } \" ) END If some other error took place: logger . error ( f \"An error occurred while looking for results of task { task_id } for serial number \" f \" { serial_number } : { task_results_response } \" ) Task ID linked to the serial number is removed from Redis END If DRI returned a response but the request couldn't succeed on their system: logger . error ( f \"Checking if task_id { task_id } of { serial_number } is complete failed. \" f \"Response returned { task_results } \" ) Task ID linked to the serial number is removed from Redis END If DRI reported that the task linked to the serial number is still in progress: logger . info ( f \"Task { task_id } for serial number { serial_number } is still in progress\" ) END If DRI reported that the task linked to the serial number was rejected: logger . warning ( f \"Task { task_id } for serial number { serial_number } was rejected\" ) END","title":"Get task results for serial number"},{"location":"logging/services/dri-bridge/repositories/dri_repository/get_dri_parameters/","text":"Get DRI parameters _get_task_id If an error took place while looking for a task ID linked to the serial number: logger . error ( f \"An error occurred while getting a task ID for serial number { serial_number } : { task_id_response } \" ) END logger . info ( f \"Checking task_id status for the task_id { task_id } of serial_number { serial_number } \" ) _get_task_results","title":"Get dri parameters"},{"location":"logging/services/dri-bridge/repositories/dri_repository/get_dri_parameters/#get-dri-parameters","text":"_get_task_id If an error took place while looking for a task ID linked to the serial number: logger . error ( f \"An error occurred while getting a task ID for serial number { serial_number } : { task_id_response } \" ) END logger . info ( f \"Checking task_id status for the task_id { task_id } of serial_number { serial_number } \" ) _get_task_results","title":"Get DRI parameters"},{"location":"logging/services/email-bridge/actions/get_emails/","text":"Subject: get.email.request Message arrives at subject If message doesn't have a body: logger . error ( f \"Cannot get unread emails with { json . dumps ( payload ) } . Must include body in request\" ) END If message body doesn't have email_account , email_filter , lookup_days fields: logger . error ( f \"Cannot get unread emails with { json . dumps ( payload ) } . JSON malformed\" ) END logger . info ( f \"Attempting to get all unread messages from email account { email_account } from the past { lookup_days } \" f \"days coming from { email_filter } \" ) get_unread_emails logger . info ( f \"Received the following from the gmail account { email_account } : { response [ 'body' ] } \" )","title":"Get emails"},{"location":"logging/services/email-bridge/actions/get_emails/#subject-getemailrequest","text":"Message arrives at subject If message doesn't have a body: logger . error ( f \"Cannot get unread emails with { json . dumps ( payload ) } . Must include body in request\" ) END If message body doesn't have email_account , email_filter , lookup_days fields: logger . error ( f \"Cannot get unread emails with { json . dumps ( payload ) } . JSON malformed\" ) END logger . info ( f \"Attempting to get all unread messages from email account { email_account } from the past { lookup_days } \" f \"days coming from { email_filter } \" ) get_unread_emails logger . info ( f \"Received the following from the gmail account { email_account } : { response [ 'body' ] } \" )","title":"Subject: get.email.request"},{"location":"logging/services/email-bridge/actions/mark_email_as_read/","text":"Subject: mark.email.read.request Message arrives at subject If message doesn't have a body: logger . error ( f \"Cannot mark email as read using { json . dumps ( payload ) } . Must include body in request\" ) END If message body doesn't have msg_uid , email_account fields: logger . error ( f \"Cannot mark email as read using { json . dumps ( payload ) } . JSON malformed\" ) END logger . info ( f \"Attempting to mark message { msg_uid } from email account { email_account } as read\" ) mark_as_read logger . info ( f \"Received the following from attempting to mark message { msg_uid } as read: \" f ' { json . dumps ( response [ \"body\" ], indent = 2 ) } ' )","title":"Mark email as read"},{"location":"logging/services/email-bridge/actions/mark_email_as_read/#subject-markemailreadrequest","text":"Message arrives at subject If message doesn't have a body: logger . error ( f \"Cannot mark email as read using { json . dumps ( payload ) } . Must include body in request\" ) END If message body doesn't have msg_uid , email_account fields: logger . error ( f \"Cannot mark email as read using { json . dumps ( payload ) } . JSON malformed\" ) END logger . info ( f \"Attempting to mark message { msg_uid } from email account { email_account } as read\" ) mark_as_read logger . info ( f \"Received the following from attempting to mark message { msg_uid } as read: \" f ' { json . dumps ( response [ \"body\" ], indent = 2 ) } ' )","title":"Subject: mark.email.read.request"},{"location":"logging/services/email-bridge/actions/send_to_email/","text":"Subject: notification.email.request Message arrives at subject If message doesn't have a body: logger . error ( f \"Cannot send to email with { json . dumps ( payload ) } . Must include body in request\" ) END If message body does not contain email_data : logger . error ( f 'Cannot send to email with { json . dumps ( payload ) } . JSON malformed\"' ) END send_to_email","title":"Send to email"},{"location":"logging/services/email-bridge/actions/send_to_email/#subject-notificationemailrequest","text":"Message arrives at subject If message doesn't have a body: logger . error ( f \"Cannot send to email with { json . dumps ( payload ) } . Must include body in request\" ) END If message body does not contain email_data : logger . error ( f 'Cannot send to email with { json . dumps ( payload ) } . JSON malformed\"' ) END send_to_email","title":"Subject: notification.email.request"},{"location":"logging/services/email-bridge/clients/email_client/email_login/","text":"Email login Login into the mail server given the account and password in our settings","title":"Email login"},{"location":"logging/services/email-bridge/clients/email_client/email_login/#email-login","text":"Login into the mail server given the account and password in our settings","title":"Email login"},{"location":"logging/services/email-bridge/clients/email_client/send_to_email/","text":"Send to email email_login Call email server endpoint to send email with the set of desired query parameters. If there's an error while connecting to email server: logger . exception ( \"Error: Email not sent\" ) END If the status of the HTTP response is 200 : logger . info ( \"Success: Email sent!\" ) Close the email server connection","title":"Send to email"},{"location":"logging/services/email-bridge/clients/email_client/send_to_email/#send-to-email","text":"email_login Call email server endpoint to send email with the set of desired query parameters. If there's an error while connecting to email server: logger . exception ( \"Error: Email not sent\" ) END If the status of the HTTP response is 200 : logger . info ( \"Success: Email sent!\" ) Close the email server connection","title":"Send to email"},{"location":"logging/services/email-bridge/clients/email_reader_client/create_connection/","text":"Create connection Given the email server imaplib.IMAP4_SSL(\"imap.gmail.com\") try to create a connection If there is an error while fetching the emails: logger . error ( f \"There was an error trying to create the connection to the inbox: { err } \" ) END","title":"Create connection"},{"location":"logging/services/email-bridge/clients/email_reader_client/create_connection/#create-connection","text":"Given the email server imaplib.IMAP4_SSL(\"imap.gmail.com\") try to create a connection If there is an error while fetching the emails: logger . error ( f \"There was an error trying to create the connection to the inbox: { err } \" ) END","title":"Create connection"},{"location":"logging/services/email-bridge/clients/email_reader_client/get_body/","text":"Get body Get email body from the email receipt If there is an error while building the email's body from the email receipt: logger . error ( f \"Error getting body from message { msg } due to { err } \" ) END","title":"Get body"},{"location":"logging/services/email-bridge/clients/email_reader_client/get_body/#get-body","text":"Get email body from the email receipt If there is an error while building the email's body from the email receipt: logger . error ( f \"Error getting body from message { msg } due to { err } \" ) END","title":"Get body"},{"location":"logging/services/email-bridge/clients/email_reader_client/get_unread_messages/","text":"Get unread messages login If there is an error while connecting to the email server: logger . error ( f \"Cannot obtain unread messages due to current email server being None. \" f \"Returning empty list of unread messages\" ) END If there are not any new emails: logger . info ( \"No unread messages found\" ) END search_messages Fetch all the emails from the email server given the constraints If there is an error while fetching the emails: logger . error ( f \"Error while getting unread messages: FETCH response code is not OK\" ) END Build response with emails get_body logout","title":"Get unread messages"},{"location":"logging/services/email-bridge/clients/email_reader_client/get_unread_messages/#get-unread-messages","text":"login If there is an error while connecting to the email server: logger . error ( f \"Cannot obtain unread messages due to current email server being None. \" f \"Returning empty list of unread messages\" ) END If there are not any new emails: logger . info ( \"No unread messages found\" ) END search_messages Fetch all the emails from the email server given the constraints If there is an error while fetching the emails: logger . error ( f \"Error while getting unread messages: FETCH response code is not OK\" ) END Build response with emails get_body logout","title":"Get unread messages"},{"location":"logging/services/email-bridge/clients/email_reader_client/login/","text":"Login create connection If failed to create server connection: logger . error ( f \"There was an error trying to create the connection to the inbox: { err } \" ) END Call Email Server login endpoint using authentication credentials. If there is an error while trying to open the inbox: logger . error ( f \"Unable to open the { recipient_folder } folder\" ) END If there is an error while trying to log in to the inbox: logger . error ( f \"There was an error trying to login into the inbox: { err } \" ) END logger . info ( f \"Logged in to Gmail mailbox!\" )","title":"Login"},{"location":"logging/services/email-bridge/clients/email_reader_client/login/#login","text":"create connection If failed to create server connection: logger . error ( f \"There was an error trying to create the connection to the inbox: { err } \" ) END Call Email Server login endpoint using authentication credentials. If there is an error while trying to open the inbox: logger . error ( f \"Unable to open the { recipient_folder } folder\" ) END If there is an error while trying to log in to the inbox: logger . error ( f \"There was an error trying to login into the inbox: { err } \" ) END logger . info ( f \"Logged in to Gmail mailbox!\" )","title":"Login"},{"location":"logging/services/email-bridge/clients/email_reader_client/logout/","text":"Logout If there is not a server connection: logger . error ( f \"Cannot log out due to current email server being None\" ) END If there is an error while trying to log out: f \"Cannot close connection due to { err } of type { type ( err ) . __name__ } . Proceeding to logout...\" END logger . info ( \"Logged out from Gmail!\" )","title":"Logout"},{"location":"logging/services/email-bridge/clients/email_reader_client/logout/#logout","text":"If there is not a server connection: logger . error ( f \"Cannot log out due to current email server being None\" ) END If there is an error while trying to log out: f \"Cannot close connection due to { err } of type { type ( err ) . __name__ } . Proceeding to logout...\" END logger . info ( \"Logged out from Gmail!\" )","title":"Logout"},{"location":"logging/services/email-bridge/clients/email_reader_client/mark_as_read/","text":"Mark as read login If there is an error while connecting to the email server: logger . error ( f \"Cannot mark email { msg_uid } as read due to email server being None\" ) END Mark email related to the given identifier msg_uid as read If there is an error while marking the email as read: logger . error ( f \"Error marking message { msg_uid } as read due to { err } \" ) END logout","title":"Mark as read"},{"location":"logging/services/email-bridge/clients/email_reader_client/mark_as_read/#mark-as-read","text":"login If there is an error while connecting to the email server: logger . error ( f \"Cannot mark email { msg_uid } as read due to email server being None\" ) END Mark email related to the given identifier msg_uid as read If there is an error while marking the email as read: logger . error ( f \"Error marking message { msg_uid } as read due to { err } \" ) END logout","title":"Mark as read"},{"location":"logging/services/email-bridge/clients/email_reader_client/search_messages/","text":"Search messages Search unread messages with the given constraints If there is an error while connecting to the email server: logger . error ( f \"Unable to access the unread mails due to { err } \" ) END If it fails to get any emails: logger . error ( f \"Unable to access the unread mails\" ) END logger . info ( f \"Search resp code: { search_resp_code } . Number of unseen messages: { len ( messages ) } \" ) logger . info ( f \"Messages to process in next batch: { len ( messages ) } \" )","title":"Search messages"},{"location":"logging/services/email-bridge/clients/email_reader_client/search_messages/#search-messages","text":"Search unread messages with the given constraints If there is an error while connecting to the email server: logger . error ( f \"Unable to access the unread mails due to { err } \" ) END If it fails to get any emails: logger . error ( f \"Unable to access the unread mails\" ) END logger . info ( f \"Search resp code: { search_resp_code } . Number of unseen messages: { len ( messages ) } \" ) logger . info ( f \"Messages to process in next batch: { len ( messages ) } \" )","title":"Search messages"},{"location":"logging/services/email-bridge/repositories/email_reader_repository/get_unread_emails/","text":"Get unread emails If there is not a password for the given email account: unread_emails = f \"Email account { email_account } 's password is not in our MONITORABLE_EMAIL_ACCOUNTS dict\" logger . error ( unread_emails ) END EmailReaderClient::get_unread_messages to fetch all available emails for the desired set of filters.","title":"Get unread emails"},{"location":"logging/services/email-bridge/repositories/email_reader_repository/get_unread_emails/#get-unread-emails","text":"If there is not a password for the given email account: unread_emails = f \"Email account { email_account } 's password is not in our MONITORABLE_EMAIL_ACCOUNTS dict\" logger . error ( unread_emails ) END EmailReaderClient::get_unread_messages to fetch all available emails for the desired set of filters.","title":"Get unread emails"},{"location":"logging/services/email-bridge/repositories/email_reader_repository/mark_as_read/","text":"Mark as read If there is not a matching password for the given email account: unread_emails = f \"Email account { email_account } 's password is not in our MONITORABLE_EMAIL_ACCOUNTS dict\" logger . error ( unread_emails ) END EmailReaderClient::mark_as_read","title":"Mark as read"},{"location":"logging/services/email-bridge/repositories/email_reader_repository/mark_as_read/#mark-as-read","text":"If there is not a matching password for the given email account: unread_emails = f \"Email account { email_account } 's password is not in our MONITORABLE_EMAIL_ACCOUNTS dict\" logger . error ( unread_emails ) END EmailReaderClient::mark_as_read","title":"Mark as read"},{"location":"logging/services/email-bridge/repositories/email_repository/send_to_email/","text":"Send to email EmailClient::send_to_email","title":"Send to email"},{"location":"logging/services/email-bridge/repositories/email_repository/send_to_email/#send-to-email","text":"EmailClient::send_to_email","title":"Send to email"},{"location":"logging/services/fraud-monitor/actions/_append_note_to_ticket/","text":"Append note to ticket self._logger.info(f\"Appending Fraud note to ticket {ticket_id}\") * If note existe: self._logger.info( f\"No Fraud trouble note will be appended to ticket {ticket_id}. \" f\"A note for this email was already appended to the ticket after the latest re-open or ticket creation.\" ) * If not PRODUCTION: self._logger.info( f\"No Fraud note will be appended to ticket {ticket_id} since the current environment is not production\" ) * append_note_to_ticket * If status is not Ok: self._logger.warning(f\"Bad status calling to append note to ticket id: {ticket_id}. \" f\"Skipping append note ...\") self._logger.info(f\"Fraud note was successfully appended to ticket {ticket_id}!\")","title":" append note to ticket"},{"location":"logging/services/fraud-monitor/actions/_append_note_to_ticket/#append-note-to-ticket","text":"self._logger.info(f\"Appending Fraud note to ticket {ticket_id}\") * If note existe: self._logger.info( f\"No Fraud trouble note will be appended to ticket {ticket_id}. \" f\"A note for this email was already appended to the ticket after the latest re-open or ticket creation.\" ) * If not PRODUCTION: self._logger.info( f\"No Fraud note will be appended to ticket {ticket_id} since the current environment is not production\" ) * append_note_to_ticket * If status is not Ok: self._logger.warning(f\"Bad status calling to append note to ticket id: {ticket_id}. \" f\"Skipping append note ...\") self._logger.info(f\"Fraud note was successfully appended to ticket {ticket_id}!\")","title":"Append note to ticket"},{"location":"logging/services/fraud-monitor/actions/_create_fraud_ticket/","text":"Create fraud ticket self._logger.info(f\"Creating Fraud ticket for client {client_id} and service number {service_number}\") * If not contacts: self._logger.warning(f\"Not found contacts to create the fraud ticket\") * If environment is not PRODUCTION: self._logger.info(f\"No Fraud ticket will be created since the current environment is not production\") * create_fraud_ticket * If status is not Ok: self._logger.warning(f\"Bad status calling to create fraud ticket with client id: {client_id} and\" f\"service number: {service_number}. Create fraud ticket return FALSE ...\") self._logger.info(f\"Fraud ticket was successfully created! Ticket ID is {ticket_id}\") * append_note_to_ticket * If status is not Ok: self._logger.warning(f\"Bad status calling to append note to ticket id: {ticket_id} and service number:\" f\"{service_number}. Create fraud ticket return FALSE ...\") self._logger.info(f\"Fraud note was successfully appended to ticket {ticket_id}!\") self._logger.info(f\"Forwarding ticket {ticket_id} to HNOC\") * change_detail_work_queue_to_hnoc","title":" create fraud ticket"},{"location":"logging/services/fraud-monitor/actions/_create_fraud_ticket/#create-fraud-ticket","text":"self._logger.info(f\"Creating Fraud ticket for client {client_id} and service number {service_number}\") * If not contacts: self._logger.warning(f\"Not found contacts to create the fraud ticket\") * If environment is not PRODUCTION: self._logger.info(f\"No Fraud ticket will be created since the current environment is not production\") * create_fraud_ticket * If status is not Ok: self._logger.warning(f\"Bad status calling to create fraud ticket with client id: {client_id} and\" f\"service number: {service_number}. Create fraud ticket return FALSE ...\") self._logger.info(f\"Fraud ticket was successfully created! Ticket ID is {ticket_id}\") * append_note_to_ticket * If status is not Ok: self._logger.warning(f\"Bad status calling to append note to ticket id: {ticket_id} and service number:\" f\"{service_number}. Create fraud ticket return FALSE ...\") self._logger.info(f\"Fraud note was successfully appended to ticket {ticket_id}!\") self._logger.info(f\"Forwarding ticket {ticket_id} to HNOC\") * change_detail_work_queue_to_hnoc","title":"Create fraud ticket"},{"location":"logging/services/fraud-monitor/actions/_fraud_monitoring_process/","text":"Fraud monitoring process self._logger.info(f'Processing all unread email from {self._config.FRAUD_CONFIG[\"inbox_email\"]}') * get_unread_emails * If status is no Ok: self._logger.warning(f\"Bad status calling to get unread emails. Skipping fraud monitor process\") * for email in emails: * If message is none or uid -1: self._logger.error(f\"Invalid message: {email}\") * If not email regex: self._logger.info(f\"Email with msg_uid {msg_uid} is not a fraud warning. Skipping...\") * If not found body: self._logger.error(f\"Email with msg_uid {msg_uid} has an unexpected body\") self._logger.info(f\"Processing email with msg_uid {msg_uid}\") * _process_fraud * If processed and PRODUCTION: * If mark email as read status is Ok: self._logger.error(f\"Could not mark email with msg_uid {msg_uid} as read\") * If processed: self._logger.info(f\"Processed email with msg_uid {msg_uid}\") * Else: self._logger.info(f\"Failed to process email with msg_uid {msg_uid}\") self._logger.info( f'Finished processing all unread email from {self._config.FRAUD_CONFIG[\"inbox_email\"]}. ' f\"Elapsed time: {round((stop - start) / 60, 2)} minutes\" )","title":" fraud monitoring process"},{"location":"logging/services/fraud-monitor/actions/_fraud_monitoring_process/#fraud-monitoring-process","text":"self._logger.info(f'Processing all unread email from {self._config.FRAUD_CONFIG[\"inbox_email\"]}') * get_unread_emails * If status is no Ok: self._logger.warning(f\"Bad status calling to get unread emails. Skipping fraud monitor process\") * for email in emails: * If message is none or uid -1: self._logger.error(f\"Invalid message: {email}\") * If not email regex: self._logger.info(f\"Email with msg_uid {msg_uid} is not a fraud warning. Skipping...\") * If not found body: self._logger.error(f\"Email with msg_uid {msg_uid} has an unexpected body\") self._logger.info(f\"Processing email with msg_uid {msg_uid}\") * _process_fraud * If processed and PRODUCTION: * If mark email as read status is Ok: self._logger.error(f\"Could not mark email with msg_uid {msg_uid} as read\") * If processed: self._logger.info(f\"Processed email with msg_uid {msg_uid}\") * Else: self._logger.info(f\"Failed to process email with msg_uid {msg_uid}\") self._logger.info( f'Finished processing all unread email from {self._config.FRAUD_CONFIG[\"inbox_email\"]}. ' f\"Elapsed time: {round((stop - start) / 60, 2)} minutes\" )","title":"Fraud monitoring process"},{"location":"logging/services/fraud-monitor/actions/_get_oldest_fraud_ticket/","text":"Get oldest fraud ticket For ticket in tickets: get_ticket_details If status is not Ok: self._logger.warning(f\"Bad status calling to get ticket details for ticket id: {ticket_id}.\" f\"Skipping get oldest fraud ticket ...\")","title":" get oldest fraud ticket"},{"location":"logging/services/fraud-monitor/actions/_get_oldest_fraud_ticket/#get-oldest-fraud-ticket","text":"For ticket in tickets: get_ticket_details If status is not Ok: self._logger.warning(f\"Bad status calling to get ticket details for ticket id: {ticket_id}.\" f\"Skipping get oldest fraud ticket ...\")","title":"Get oldest fraud ticket"},{"location":"logging/services/fraud-monitor/actions/_process_fraud/","text":"Process fraud get_client_info_by_did If status not Ok: self._logger.warning(f\"Failed to get client info by DID {did}, using default client info\") get_open_fraud_tickets self._logger.warning(f\"fBad status calling to get open fraud tickets for client id: {client_id} and \" f\"service number: {service_number}. Process fraud FALSE ...\") _get_oldest_fraud_ticket If open fraud ticket: self._logger.info(f\"An open Fraud ticket was found for {service_number}. Ticket ID: {ticket_id}\") If is a task resolved: self._logger.info( f\"Fraud ticket with ID {ticket_id} is open, but the task related to {service_number} is resolved. \" f\"Therefore, the ticket will be considered as Resolved.\" ) Else: _append_note_to_ticket Else: self._logger.info(f\"No open Fraud ticket was found for {service_number}\") get_resolved_fraud_tickets If status is not Ok: self._logger.warning(f\"bad status calling to get resolved fraud tickets for client id: {client_id} \" f\"and service number: {service_number}. Skipping process fraud ...\") _get_oldest_fraud_ticket If resolved fraud ticket: self._logger.info(f\"A resolved Fraud ticket was found for {service_number}. Ticket ID: {ticket_id}\") _unresolve_task_for_ticket self._logger.info(f\"No open or resolved Fraud ticket was found for {service_number}\") _create_fraud_ticket","title":" process fraud"},{"location":"logging/services/fraud-monitor/actions/_process_fraud/#process-fraud","text":"get_client_info_by_did If status not Ok: self._logger.warning(f\"Failed to get client info by DID {did}, using default client info\") get_open_fraud_tickets self._logger.warning(f\"fBad status calling to get open fraud tickets for client id: {client_id} and \" f\"service number: {service_number}. Process fraud FALSE ...\") _get_oldest_fraud_ticket If open fraud ticket: self._logger.info(f\"An open Fraud ticket was found for {service_number}. Ticket ID: {ticket_id}\") If is a task resolved: self._logger.info( f\"Fraud ticket with ID {ticket_id} is open, but the task related to {service_number} is resolved. \" f\"Therefore, the ticket will be considered as Resolved.\" ) Else: _append_note_to_ticket Else: self._logger.info(f\"No open Fraud ticket was found for {service_number}\") get_resolved_fraud_tickets If status is not Ok: self._logger.warning(f\"bad status calling to get resolved fraud tickets for client id: {client_id} \" f\"and service number: {service_number}. Skipping process fraud ...\") _get_oldest_fraud_ticket If resolved fraud ticket: self._logger.info(f\"A resolved Fraud ticket was found for {service_number}. Ticket ID: {ticket_id}\") _unresolve_task_for_ticket self._logger.info(f\"No open or resolved Fraud ticket was found for {service_number}\") _create_fraud_ticket","title":"Process fraud"},{"location":"logging/services/fraud-monitor/actions/_unresolve_task_for_ticket/","text":"Unresolve task for ticket self._logger.info(f\"Unresolving task related to {service_number} of Fraud ticket {ticket_id}...\") * If environment not PRODUCTION: self._logger.info( f\"Task related to {service_number} of Fraud ticket {ticket_id} will not be unresolved \" f\"since the current environment is not production\" ) * open_ticket self._logger.warning(f\"Bad status calling to open ticket with ticket id: {ticket_id}. \" f\"Unresolve task for ticket return FALSE\") self._logger.info(f\"Task related to {service_number} of Fraud ticket {ticket_id} was successfully unresolved!\") * append_note_to_ticket self._logger.warning(f\"Bad status calling to append note to ticket id: {ticket_id} and service number:\" f\"{service_number}. Unresolve task for ticket return FALSE\") self._logger.info(f\"Fraud note was successfully appended to ticket {ticket_id}!\")","title":" unresolve task for ticket"},{"location":"logging/services/fraud-monitor/actions/_unresolve_task_for_ticket/#unresolve-task-for-ticket","text":"self._logger.info(f\"Unresolving task related to {service_number} of Fraud ticket {ticket_id}...\") * If environment not PRODUCTION: self._logger.info( f\"Task related to {service_number} of Fraud ticket {ticket_id} will not be unresolved \" f\"since the current environment is not production\" ) * open_ticket self._logger.warning(f\"Bad status calling to open ticket with ticket id: {ticket_id}. \" f\"Unresolve task for ticket return FALSE\") self._logger.info(f\"Task related to {service_number} of Fraud ticket {ticket_id} was successfully unresolved!\") * append_note_to_ticket self._logger.warning(f\"Bad status calling to append note to ticket id: {ticket_id} and service number:\" f\"{service_number}. Unresolve task for ticket return FALSE\") self._logger.info(f\"Fraud note was successfully appended to ticket {ticket_id}!\")","title":"Unresolve task for ticket"},{"location":"logging/services/fraud-monitor/actions/start_fraud_monitoring/","text":"Start fraud monitoring self._logger.info(\"Scheduling Fraud Monitor job...\") * If exec on start: self._logger.info(\"Fraud Monitor job is going to be executed immediately\") * _fraud_monitoring_process * If ConflictingIdError: self._logger.info(f\"Skipping start of Fraud Monitoring job. Reason: {conflict}\")","title":"Start fraud monitoring"},{"location":"logging/services/fraud-monitor/actions/start_fraud_monitoring/#start-fraud-monitoring","text":"self._logger.info(\"Scheduling Fraud Monitor job...\") * If exec on start: self._logger.info(\"Fraud Monitor job is going to be executed immediately\") * _fraud_monitoring_process * If ConflictingIdError: self._logger.info(f\"Skipping start of Fraud Monitoring job. Reason: {conflict}\")","title":"Start fraud monitoring"},{"location":"logging/services/fraud-monitor/repositories/bruin_repository/append_note_to_ticket/","text":"Append note to ticket If service number: self._logger.info(f'Appending note for service number(s) {\", \".join(service_numbers)} in ticket {ticket_id}...') Else: self._logger.info(f\"Appending note for all service number(s) in ticket {ticket_id}...\") If Exception: self._logger.error(f\"An error occurred when appending a ticket note to ticket {ticket_id}. \" f\"Ticket note: {note}. Error: {e}\") If status not ok: self._logger.error(f\"Error while appending note to ticket {ticket_id} in \" f\"{self._config.CURRENT_ENVIRONMENT.upper()} environment. Note was {note}. Error: \" f\"Error {response_status} - {response_body}\")","title":"Append note to ticket"},{"location":"logging/services/fraud-monitor/repositories/bruin_repository/append_note_to_ticket/#append-note-to-ticket","text":"If service number: self._logger.info(f'Appending note for service number(s) {\", \".join(service_numbers)} in ticket {ticket_id}...') Else: self._logger.info(f\"Appending note for all service number(s) in ticket {ticket_id}...\") If Exception: self._logger.error(f\"An error occurred when appending a ticket note to ticket {ticket_id}. \" f\"Ticket note: {note}. Error: {e}\") If status not ok: self._logger.error(f\"Error while appending note to ticket {ticket_id} in \" f\"{self._config.CURRENT_ENVIRONMENT.upper()} environment. Note was {note}. Error: \" f\"Error {response_status} - {response_body}\")","title":"Append note to ticket"},{"location":"logging/services/fraud-monitor/repositories/bruin_repository/change_detail_work_queue/","text":"Change detail work queue self._logger.info( f\"Changing task result of serial {service_number} in ticket {ticket_id} \" f\"to {task_result}...\" ) * If Exception: self._logger.error(f\"An error occurred when changing task result of serial {service_number} \" f\"in ticket {ticket_id} to {task_result} -> {e}\") * If status ok: self._logger.info(f\"Task result of detail serial {service_number} in ticket {ticket_id} \" f\"changed to {task_result} successfully!\") * Else: self._logger.error(f\"Error while changing task result of serial {service_number} in ticket \" f\"{ticket_id} to {task_result} in {self._config.ENVIRONMENT_NAME.upper()} \" f\"environment: Error {response_status} - {response_body}\")","title":"Change detail work queue"},{"location":"logging/services/fraud-monitor/repositories/bruin_repository/change_detail_work_queue/#change-detail-work-queue","text":"self._logger.info( f\"Changing task result of serial {service_number} in ticket {ticket_id} \" f\"to {task_result}...\" ) * If Exception: self._logger.error(f\"An error occurred when changing task result of serial {service_number} \" f\"in ticket {ticket_id} to {task_result} -> {e}\") * If status ok: self._logger.info(f\"Task result of detail serial {service_number} in ticket {ticket_id} \" f\"changed to {task_result} successfully!\") * Else: self._logger.error(f\"Error while changing task result of serial {service_number} in ticket \" f\"{ticket_id} to {task_result} in {self._config.ENVIRONMENT_NAME.upper()} \" f\"environment: Error {response_status} - {response_body}\")","title":"Change detail work queue"},{"location":"logging/services/fraud-monitor/repositories/bruin_repository/change_detail_work_queue_to_hnoc/","text":"Change detail work queue to hnoc change_detail_work_queue","title":"Change detail work queue to hnoc"},{"location":"logging/services/fraud-monitor/repositories/bruin_repository/change_detail_work_queue_to_hnoc/#change-detail-work-queue-to-hnoc","text":"change_detail_work_queue","title":"Change detail work queue to hnoc"},{"location":"logging/services/fraud-monitor/repositories/bruin_repository/create_fraud_ticket/","text":"Create fraud ticket self._logger.info( f\"Creating fraud ticket for service number {service_number} that belongs to client {client_id}...\" ) * If Exception: f\"An error occurred when creating fraud ticket for service number {service_number} \" f\"that belongs to client {client_id} -> {e}\" * If status ok: self._logger.info(f\"Fraud ticket for service number {service_number} that belongs to client {client_id} created!\") * Else: self._logger.error(f\"Error while creating fraud ticket for service number {service_number} that belongs to client \" f\"{client_id} in {self._config.ENVIRONMENT_NAME.upper()} environment: \" f\"Error {response_status} - {response_body}\")","title":"Create fraud ticket"},{"location":"logging/services/fraud-monitor/repositories/bruin_repository/create_fraud_ticket/#create-fraud-ticket","text":"self._logger.info( f\"Creating fraud ticket for service number {service_number} that belongs to client {client_id}...\" ) * If Exception: f\"An error occurred when creating fraud ticket for service number {service_number} \" f\"that belongs to client {client_id} -> {e}\" * If status ok: self._logger.info(f\"Fraud ticket for service number {service_number} that belongs to client {client_id} created!\") * Else: self._logger.error(f\"Error while creating fraud ticket for service number {service_number} that belongs to client \" f\"{client_id} in {self._config.ENVIRONMENT_NAME.upper()} environment: \" f\"Error {response_status} - {response_body}\")","title":"Create fraud ticket"},{"location":"logging/services/fraud-monitor/repositories/bruin_repository/get_client_info_by_did/","text":"Get client info by did self._logger.info(f\"Getting client info by DID {did}...\") * If Exception: self._logger.error(f\"An error occurred when getting client info by DID {did} -> {e}\") * If status ok: self._logger.info(f\"Got client info by DID {did}!\") * Else: self._logger.error(f\"Error while getting client info by DID {did} in {self._config.ENVIRONMENT_NAME.upper()} \" f\"environment: Error {response_status} - {response_body}\")","title":"Get client info by did"},{"location":"logging/services/fraud-monitor/repositories/bruin_repository/get_client_info_by_did/#get-client-info-by-did","text":"self._logger.info(f\"Getting client info by DID {did}...\") * If Exception: self._logger.error(f\"An error occurred when getting client info by DID {did} -> {e}\") * If status ok: self._logger.info(f\"Got client info by DID {did}!\") * Else: self._logger.error(f\"Error while getting client info by DID {did} in {self._config.ENVIRONMENT_NAME.upper()} \" f\"environment: Error {response_status} - {response_body}\")","title":"Get client info by did"},{"location":"logging/services/fraud-monitor/repositories/bruin_repository/get_fraud_tickets/","text":"Get fraud tickets get_tickets","title":"Get fraud tickets"},{"location":"logging/services/fraud-monitor/repositories/bruin_repository/get_fraud_tickets/#get-fraud-tickets","text":"get_tickets","title":"Get fraud tickets"},{"location":"logging/services/fraud-monitor/repositories/bruin_repository/get_open_fraud_tickets/","text":"Get open fraud tickets get_fraud_tickets","title":"Get open fraud tickets"},{"location":"logging/services/fraud-monitor/repositories/bruin_repository/get_open_fraud_tickets/#get-open-fraud-tickets","text":"get_fraud_tickets","title":"Get open fraud tickets"},{"location":"logging/services/fraud-monitor/repositories/bruin_repository/get_resolved_fraud_tickets/","text":"Get resolved fraud tickets get_fraud_tickets","title":"Get resolved fraud tickets"},{"location":"logging/services/fraud-monitor/repositories/bruin_repository/get_resolved_fraud_tickets/#get-resolved-fraud-tickets","text":"get_fraud_tickets","title":"Get resolved fraud tickets"},{"location":"logging/services/fraud-monitor/repositories/bruin_repository/get_ticket_details/","text":"Get ticket details self._logger.info(f\"Getting details of ticket {ticket_id} from Bruin...\") * If Exception: self._logger.error(f\"An error occurred when requesting ticket details from Bruin API for ticket {ticket_id} -> {e}\") self._logger.info(f\"Got details of ticket {ticket_id} from Bruin!\") * If status not 200: self._logger.error(f\"Error while retrieving details of ticket {ticket_id} in {self._config.CURRENT_ENVIRONMENT.upper()} environment: Error {response_status} - {response_body}\")","title":"Get ticket details"},{"location":"logging/services/fraud-monitor/repositories/bruin_repository/get_ticket_details/#get-ticket-details","text":"self._logger.info(f\"Getting details of ticket {ticket_id} from Bruin...\") * If Exception: self._logger.error(f\"An error occurred when requesting ticket details from Bruin API for ticket {ticket_id} -> {e}\") self._logger.info(f\"Got details of ticket {ticket_id} from Bruin!\") * If status not 200: self._logger.error(f\"Error while retrieving details of ticket {ticket_id} in {self._config.CURRENT_ENVIRONMENT.upper()} environment: Error {response_status} - {response_body}\")","title":"Get ticket details"},{"location":"logging/services/fraud-monitor/repositories/bruin_repository/get_tickets/","text":"Get ticket self._logger.info(f'Getting all tickets with parameters of {request[\"body\"]} from Bruin...') * If Exception: self._logger.error(f'An error occurred when requesting tickets from Bruin API with parameters of {request[\"body\"]} -> {e}') * If status ok: self._logger.info(f'Got all tickets with parameters of {request[\"body\"]} from Bruin!') * Else: self._logger.error(f'Error while retrieving tickets with parameters of {request[\"body\"]} in ' f\"{self._config.CURRENT_ENVIRONMENT.upper()} environment: \" f\"Error {response_status} - {response_body}\")","title":"Get tickets"},{"location":"logging/services/fraud-monitor/repositories/bruin_repository/get_tickets/#get-ticket","text":"self._logger.info(f'Getting all tickets with parameters of {request[\"body\"]} from Bruin...') * If Exception: self._logger.error(f'An error occurred when requesting tickets from Bruin API with parameters of {request[\"body\"]} -> {e}') * If status ok: self._logger.info(f'Got all tickets with parameters of {request[\"body\"]} from Bruin!') * Else: self._logger.error(f'Error while retrieving tickets with parameters of {request[\"body\"]} in ' f\"{self._config.CURRENT_ENVIRONMENT.upper()} environment: \" f\"Error {response_status} - {response_body}\")","title":"Get ticket"},{"location":"logging/services/fraud-monitor/repositories/bruin_repository/open_ticket/","text":"Open ticket self._logger.info(f\"Opening ticket {ticket_id} (affected detail ID: {detail_id})...\") * If Exception: self._logger.error(f\"An error occurred when opening outage ticket {ticket_id} -> {e}\") self._logger.info(f\"Ticket {ticket_id} opened!\") * If status ok: self._logger.info(f\"Ticket {ticket_id} and serial {serial_number} task result changed to {task_result}\") * Else: self._logger.error(f\"Error while opening outage ticket {ticket_id} in \" f\"{self._config.CURRENT_ENVIRONMENT.upper()} environment: \" f\"Error {response_status} - {response_body}\")","title":"Open ticket"},{"location":"logging/services/fraud-monitor/repositories/bruin_repository/open_ticket/#open-ticket","text":"self._logger.info(f\"Opening ticket {ticket_id} (affected detail ID: {detail_id})...\") * If Exception: self._logger.error(f\"An error occurred when opening outage ticket {ticket_id} -> {e}\") self._logger.info(f\"Ticket {ticket_id} opened!\") * If status ok: self._logger.info(f\"Ticket {ticket_id} and serial {serial_number} task result changed to {task_result}\") * Else: self._logger.error(f\"Error while opening outage ticket {ticket_id} in \" f\"{self._config.CURRENT_ENVIRONMENT.upper()} environment: \" f\"Error {response_status} - {response_body}\")","title":"Open ticket"},{"location":"logging/services/fraud-monitor/repositories/notifications_repository/get_unread_emails/","text":"Get unread emails self._logger.info( f\"Getting the unread emails from the inbox of {email_account} sent from the users: \" f\"{email_filter}\" ) * If Exception: self._logger.error(f\"An error occurred while getting the unread emails from the inbox of {email_account} -> {e}\") * If status ok: self._logger.info(f\"Got the unread emails from the inbox of {email_account}\") * Else: self._logger.error(f\"Error getting the unread emails from the inbox of {email_account} in \" f\"{self._config.ENVIRONMENT_NAME.upper()} environment: Error {response_status} - {response_body}\")","title":"Get unread emails"},{"location":"logging/services/fraud-monitor/repositories/notifications_repository/get_unread_emails/#get-unread-emails","text":"self._logger.info( f\"Getting the unread emails from the inbox of {email_account} sent from the users: \" f\"{email_filter}\" ) * If Exception: self._logger.error(f\"An error occurred while getting the unread emails from the inbox of {email_account} -> {e}\") * If status ok: self._logger.info(f\"Got the unread emails from the inbox of {email_account}\") * Else: self._logger.error(f\"Error getting the unread emails from the inbox of {email_account} in \" f\"{self._config.ENVIRONMENT_NAME.upper()} environment: Error {response_status} - {response_body}\")","title":"Get unread emails"},{"location":"logging/services/gateway-monitor/actions/_get_unhealthy_gateways/","text":"Get unhealthy gateways For each gateway: If the gateway doesn't have metrics: self . _logger . warning ( f \"Gateway { gateway [ 'name' ] } from host { gateway [ 'host' ] } has missing metrics\" )","title":" get unhealthy gateways"},{"location":"logging/services/gateway-monitor/actions/_get_unhealthy_gateways/#get-unhealthy-gateways","text":"For each gateway: If the gateway doesn't have metrics: self . _logger . warning ( f \"Gateway { gateway [ 'name' ] } from host { gateway [ 'host' ] } has missing metrics\" )","title":"Get unhealthy gateways"},{"location":"logging/services/gateway-monitor/actions/_monitoring_process/","text":"Monitoring process self . _logger . info ( f \"Starting Gateway Monitoring process...\" ) For each VeloCloud host: _process_host If there's an exception: self . _logger . exception ( e ) self . _logger . info ( f \"Gateway Monitoring process finished! Elapsed time: { round (( stop - start ) / 60 , 2 ) } minutes\" )","title":" monitoring process"},{"location":"logging/services/gateway-monitor/actions/_monitoring_process/#monitoring-process","text":"self . _logger . info ( f \"Starting Gateway Monitoring process...\" ) For each VeloCloud host: _process_host If there's an exception: self . _logger . exception ( e ) self . _logger . info ( f \"Gateway Monitoring process finished! Elapsed time: { round (( stop - start ) / 60 , 2 ) } minutes\" )","title":"Monitoring process"},{"location":"logging/services/gateway-monitor/actions/_process_host/","text":"Process host self . _logger . info ( f \"Processing Velocloud host { host } ...\" ) For each gateway in the host: If there's an exception getting gateway metrics: self . _logger . exception ( e ) _get_unhealthy_gateways If there are any unhealthy gateways: self . _logger . info ( f \" { len ( unhealthy_gateways ) } unhealthy gateway(s) found for host { host } \" ) For each unhealthy gateway: _report_servicenow_incident If there's an exception: self . _logger . exception ( e ) Else: self . _logger . info ( f \"No unhealthy gateways were found for host { host } \" ) self . _logger . info ( f \"Finished processing Velocloud host { host } !\" )","title":" process host"},{"location":"logging/services/gateway-monitor/actions/_process_host/#process-host","text":"self . _logger . info ( f \"Processing Velocloud host { host } ...\" ) For each gateway in the host: If there's an exception getting gateway metrics: self . _logger . exception ( e ) _get_unhealthy_gateways If there are any unhealthy gateways: self . _logger . info ( f \" { len ( unhealthy_gateways ) } unhealthy gateway(s) found for host { host } \" ) For each unhealthy gateway: _report_servicenow_incident If there's an exception: self . _logger . exception ( e ) Else: self . _logger . info ( f \"No unhealthy gateways were found for host { host } \" ) self . _logger . info ( f \"Finished processing Velocloud host { host } !\" )","title":"Process host"},{"location":"logging/services/gateway-monitor/actions/_report_servicenow_incident/","text":"Report ServiceNow incident _servicenow_repository.report_incident If the result state is \"inserted\": self . _logger . info ( f \"A new incident with ID { result [ 'number' ] } was created in ServiceNow \" f \"for host { gateway [ 'host' ] } and gateway { gateway [ 'name' ] } \" ) If the result state is \"ignored\": self . _logger . info ( f \"An open incident with ID { result [ 'number' ] } already existed in ServiceNow \" f \"for host { gateway [ 'host' ] } and gateway { gateway [ 'name' ] } \" ) If the result state is \"reopened\": self . _logger . info ( f \"A resolved incident with ID { result [ 'number' ] } was reopened in ServiceNow \" f \"for host { gateway [ 'host' ] } and gateway { gateway [ 'name' ] } \" )","title":" report servicenow incident"},{"location":"logging/services/gateway-monitor/actions/_report_servicenow_incident/#report-servicenow-incident","text":"_servicenow_repository.report_incident If the result state is \"inserted\": self . _logger . info ( f \"A new incident with ID { result [ 'number' ] } was created in ServiceNow \" f \"for host { gateway [ 'host' ] } and gateway { gateway [ 'name' ] } \" ) If the result state is \"ignored\": self . _logger . info ( f \"An open incident with ID { result [ 'number' ] } already existed in ServiceNow \" f \"for host { gateway [ 'host' ] } and gateway { gateway [ 'name' ] } \" ) If the result state is \"reopened\": self . _logger . info ( f \"A resolved incident with ID { result [ 'number' ] } was reopened in ServiceNow \" f \"for host { gateway [ 'host' ] } and gateway { gateway [ 'name' ] } \" )","title":"Report ServiceNow incident"},{"location":"logging/services/gateway-monitor/actions/start_monitoring/","text":"Start monitoring self . _logger . info ( \"Scheduling Gateway Monitor job...\" ) If job should be executed on service start: self . _logger . info ( \"Gateway Monitor job is going to be executed immediately\" ) _monitoring_process If there's a running job to monitor gateways already: self . _logger . info ( f \"Skipping start of Gateway Monitoring job. Reason: { conflict } \" )","title":"Start monitoring"},{"location":"logging/services/gateway-monitor/actions/start_monitoring/#start-monitoring","text":"self . _logger . info ( \"Scheduling Gateway Monitor job...\" ) If job should be executed on service start: self . _logger . info ( \"Gateway Monitor job is going to be executed immediately\" ) _monitoring_process If there's a running job to monitor gateways already: self . _logger . info ( f \"Skipping start of Gateway Monitoring job. Reason: { conflict } \" )","title":"Start monitoring"},{"location":"logging/services/gateway-monitor/app_entrypoint/app/","text":"App entrypoint self . _logger . info ( f \"Gateway Monitor starting in { config . CURRENT_ENVIRONMENT } ...\" )","title":"App"},{"location":"logging/services/gateway-monitor/app_entrypoint/app/#app-entrypoint","text":"self . _logger . info ( f \"Gateway Monitor starting in { config . CURRENT_ENVIRONMENT } ...\" )","title":"App entrypoint"},{"location":"logging/services/gateway-monitor/repositories/servicenow_repository/report_incident/","text":"Report incident self . _logger . info ( f \"Reporting { gateway [ 'trouble' ] . value } incident to ServiceNow \" f \"for host { gateway [ 'host' ] } and gateway { gateway [ 'name' ] } ...\" ) If there's an exception: self . _logger . error ( f \"An error occurred when reporting incident to ServiceNow -> { e } \" ) If response status is not OK: self . _logger . error ( f \"Failed to report { gateway [ 'trouble' ] . value } incident to ServiceNow \" f \"for host { gateway [ 'host' ] } and gateway { gateway [ 'name' ] } in { environment } environment: \" f \"Error { response_status } - { response_body } \" ) Else: self . _logger . info ( f \"Reported { gateway [ 'trouble' ] . value } incident to ServiceNow \" f \"for host { gateway [ 'host' ] } and gateway { gateway [ 'name' ] } !\" )","title":"Report incident"},{"location":"logging/services/gateway-monitor/repositories/servicenow_repository/report_incident/#report-incident","text":"self . _logger . info ( f \"Reporting { gateway [ 'trouble' ] . value } incident to ServiceNow \" f \"for host { gateway [ 'host' ] } and gateway { gateway [ 'name' ] } ...\" ) If there's an exception: self . _logger . error ( f \"An error occurred when reporting incident to ServiceNow -> { e } \" ) If response status is not OK: self . _logger . error ( f \"Failed to report { gateway [ 'trouble' ] . value } incident to ServiceNow \" f \"for host { gateway [ 'host' ] } and gateway { gateway [ 'name' ] } in { environment } environment: \" f \"Error { response_status } - { response_body } \" ) Else: self . _logger . info ( f \"Reported { gateway [ 'trouble' ] . value } incident to ServiceNow \" f \"for host { gateway [ 'host' ] } and gateway { gateway [ 'name' ] } !\" )","title":"Report incident"},{"location":"logging/services/gateway-monitor/repositories/velocloud_repository/get_gateway_status_metrics/","text":"Get gateway status metrics self . _logger . info ( f \"Getting gateway status metrics from Velocloud host { gateway [ 'host' ] } \" f \"for gateway { gateway [ 'id' ] } for the past { lookup_interval // 60 } minutes...\" ) If there's an exception: self . _logger . error ( f \"An error occurred when requesting gateway status metrics from Velocloud -> { e } \" ) If response status is not OK: self . _logger . error ( f \"Error while retrieving gateway status metrics from Velocloud in { environment } \" f \"environment: Error { response_status } - { response_body } \" ) Else: self . _logger . info ( f \"Got gateway status metrics from Velocloud host { gateway [ 'host' ] } \" f \"for gateway { gateway [ 'id' ] } for the past { lookup_interval // 60 } minutes!\" )","title":"Get gateway status metrics"},{"location":"logging/services/gateway-monitor/repositories/velocloud_repository/get_gateway_status_metrics/#get-gateway-status-metrics","text":"self . _logger . info ( f \"Getting gateway status metrics from Velocloud host { gateway [ 'host' ] } \" f \"for gateway { gateway [ 'id' ] } for the past { lookup_interval // 60 } minutes...\" ) If there's an exception: self . _logger . error ( f \"An error occurred when requesting gateway status metrics from Velocloud -> { e } \" ) If response status is not OK: self . _logger . error ( f \"Error while retrieving gateway status metrics from Velocloud in { environment } \" f \"environment: Error { response_status } - { response_body } \" ) Else: self . _logger . info ( f \"Got gateway status metrics from Velocloud host { gateway [ 'host' ] } \" f \"for gateway { gateway [ 'id' ] } for the past { lookup_interval // 60 } minutes!\" )","title":"Get gateway status metrics"},{"location":"logging/services/gateway-monitor/repositories/velocloud_repository/get_network_gateway_list/","text":"Get network gateway list self . _logger . info ( f \"Getting network gateway list from Velocloud host { velocloud_host } ...\" ) If there's an exception: self . _logger . error ( f \"An error occurred when requesting network gateway list from Velocloud -> { e } \" ) If response status is not OK: self . _logger . error ( f \"Error while retrieving network gateway list from Velocloud in { environment } \" f \"environment: Error { response_status } - { response_body } \" ) Else: self . _logger . info ( f \"Got network gateway list from Velocloud host { velocloud_host } !\" )","title":"Get network gateway list"},{"location":"logging/services/gateway-monitor/repositories/velocloud_repository/get_network_gateway_list/#get-network-gateway-list","text":"self . _logger . info ( f \"Getting network gateway list from Velocloud host { velocloud_host } ...\" ) If there's an exception: self . _logger . error ( f \"An error occurred when requesting network gateway list from Velocloud -> { e } \" ) If response status is not OK: self . _logger . error ( f \"Error while retrieving network gateway list from Velocloud in { environment } \" f \"environment: Error { response_status } - { response_body } \" ) Else: self . _logger . info ( f \"Got network gateway list from Velocloud host { velocloud_host } !\" )","title":"Get network gateway list"},{"location":"logging/services/hawkeye-affecting-monitor/actions/_add_device_to_tickets_mapping/","text":"Add device to tickets mapping get_open_affecting_tickets If status is not Ok: self._logger.warning(f\"Bad status calling to get open affecting ticket to serial number \" f\"{serial_number}. Skipping add device to ticket mapping ...\") If not affecting ticket: self._logger.info( f\"No affecting tickets were found for device {serial_number} when building the mapping between \" f\"this serial and tickets.\" ) get_ticket_details self._logger.warning(f\"Bad status calling to get ticket details to ticket id: {ticket_id}.\" f\"Skipping add devices to ticket mapping ...\")","title":" add device to tickets mapping"},{"location":"logging/services/hawkeye-affecting-monitor/actions/_add_device_to_tickets_mapping/#add-device-to-tickets-mapping","text":"get_open_affecting_tickets If status is not Ok: self._logger.warning(f\"Bad status calling to get open affecting ticket to serial number \" f\"{serial_number}. Skipping add device to ticket mapping ...\") If not affecting ticket: self._logger.info( f\"No affecting tickets were found for device {serial_number} when building the mapping between \" f\"this serial and tickets.\" ) get_ticket_details self._logger.warning(f\"Bad status calling to get ticket details to ticket id: {ticket_id}.\" f\"Skipping add devices to ticket mapping ...\")","title":"Add device to tickets mapping"},{"location":"logging/services/hawkeye-affecting-monitor/actions/_affecting_monitoring_process/","text":"Affecting monitoring process self._logger.info(f\"Starting Hawkeye Affecting Monitor!\") * get_cache_for_affecting_monitoring * If status is not Ok: self._logger.warning(f\"Bad status calling to get cache. Skipping hawkeye affecting monitor process ...\") * get_tests_results_for_affecting_monitoring * If status is not Ok: self._logger.warning(f\"Bad request get test results for affectin monitor for probe uids: {probe_uids}.\" f\"Skipping hawkeye affecting monitor ...\") self._logger.info( f\"Looking for Service Affecting tickets for {len(cached_devices_mapped_to_tests_results)} devices...\" ) * _add_device_to_tickets_mapping self._logger.info(f\"Processing {len(cached_devices_mapped_to_tests_results)} devices...\") * _process_device self._logger.info(f\"Hawkeye Affecting Monitor process finished! Took {round((stop - start) / 60, 2)} minutes\")","title":" affecting monitoring process"},{"location":"logging/services/hawkeye-affecting-monitor/actions/_affecting_monitoring_process/#affecting-monitoring-process","text":"self._logger.info(f\"Starting Hawkeye Affecting Monitor!\") * get_cache_for_affecting_monitoring * If status is not Ok: self._logger.warning(f\"Bad status calling to get cache. Skipping hawkeye affecting monitor process ...\") * get_tests_results_for_affecting_monitoring * If status is not Ok: self._logger.warning(f\"Bad request get test results for affectin monitor for probe uids: {probe_uids}.\" f\"Skipping hawkeye affecting monitor ...\") self._logger.info( f\"Looking for Service Affecting tickets for {len(cached_devices_mapped_to_tests_results)} devices...\" ) * _add_device_to_tickets_mapping self._logger.info(f\"Processing {len(cached_devices_mapped_to_tests_results)} devices...\") * _process_device self._logger.info(f\"Hawkeye Affecting Monitor process finished! Took {round((stop - start) / 60, 2)} minutes\")","title":"Affecting monitoring process"},{"location":"logging/services/hawkeye-affecting-monitor/actions/_append_new_notes_for_device/","text":"Append new notes for device If serial not in ticket: self._logger.info( f\"Serial {serial_number} could not be added to the tickets mapping at the beginning of the \" f\"process, so no notes can be posted to any ticket. Skipping...\" ) If not notes to append: self._logger.info(f\"No notes to append for serial {serial_number} were found. Skipping...\") If environment is PRODUCTION: self._logger.info( f\"{len(notes_to_append)} affecting notes to append to ticket {ticket_id} were found, but the current \" \"environment is not PRODUCTION. Skipping...\" ) self._logger.info( f\"Posting {len(notes_to_append)} affecting notes to ticket {ticket_id} (serial: {serial_number})...\" )","title":" append new notes for device"},{"location":"logging/services/hawkeye-affecting-monitor/actions/_append_new_notes_for_device/#append-new-notes-for-device","text":"If serial not in ticket: self._logger.info( f\"Serial {serial_number} could not be added to the tickets mapping at the beginning of the \" f\"process, so no notes can be posted to any ticket. Skipping...\" ) If not notes to append: self._logger.info(f\"No notes to append for serial {serial_number} were found. Skipping...\") If environment is PRODUCTION: self._logger.info( f\"{len(notes_to_append)} affecting notes to append to ticket {ticket_id} were found, but the current \" \"environment is not PRODUCTION. Skipping...\" ) self._logger.info( f\"Posting {len(notes_to_append)} affecting notes to ticket {ticket_id} (serial: {serial_number})...\" )","title":"Append new notes for device"},{"location":"logging/services/hawkeye-affecting-monitor/actions/_process_device/","text":"Process device self._logger.info(f\"Processing device {serial_number}...\") * for test result in test results: * If test result passed: * _process_passed_test_result * If test result failed: * _process_failed_test_result * Else: self._logger.info( f'Test result {test_result[\"summary\"][\"id\"]} has state {test_result[\"summary\"][\"status\"].upper()}. ' \"Skipping...\" ) * _append_new_notes_for_device self._logger.info(f\"Finished processing device {serial_number}!\")","title":" process device"},{"location":"logging/services/hawkeye-affecting-monitor/actions/_process_device/#process-device","text":"self._logger.info(f\"Processing device {serial_number}...\") * for test result in test results: * If test result passed: * _process_passed_test_result * If test result failed: * _process_failed_test_result * Else: self._logger.info( f'Test result {test_result[\"summary\"][\"id\"]} has state {test_result[\"summary\"][\"status\"].upper()}. ' \"Skipping...\" ) * _append_new_notes_for_device self._logger.info(f\"Finished processing device {serial_number}!\")","title":"Process device"},{"location":"logging/services/hawkeye-affecting-monitor/actions/_process_failed_test_result/","text":"Process failed test result self._logger.info( f\"Processing FAILED test result {test_result_id} (type: {test_type}) that was run for serial \" f\"{serial_number}...\" ) * If serial not in tickets: self._logger.info( f\"Serial {serial_number} could not be added to the tickets mapping at the beginning of the \" f\"process, so the current FAILED state for test type {test_type} will be ignored. Skipping...\" ) * If not affecting ticket: * If working environment is not PRODUCTION: self._logger.info( f\"Serial {serial_number} is not under any affecting ticket and some troubles were spotted for \" f\"test type {test_type}, but the current environment is not PRODUCTION. Skipping ticket creation...\" ) self._logger.info( f\"Serial {serial_number} is not under any affecting ticket and some troubles were spotted for \" f\"test type {test_type}. Creating affecting ticket..\" ) * create_affecting_ticket * If status is not Ok: self._logger.warning(f\"Bad status calling create affecting ticket to serial: {serial_number}.\" f\"Skipping process test failed ...\") self._logger.info( f\"Affecting ticket created for serial {serial_number} (ID: {ticket_id}). A new note reporting the \" f\"current FAILED state for test type {test_type} will be built and appended to the ticket later on.\" ) * Else: self._logger.info( f\"Serial {serial_number} is under affecting ticket {ticket_id} and some troubles were spotted for \" f\"test type {test_type}.\" ) * If detail resolved ticket: self._logger.info( f\"Ticket detail of affecting ticket {ticket_id} that is related to serial {serial_number} is \" f\"currently unresolved and a FAILED state was spotted. Unresolving detail...\" ) * unresolve_ticket_detail * If status is not Ok: self._logger.info( f\"Ticket detail of affecting ticket {ticket_id} that is related to serial {serial_number} \" \"could not be unresolved. A note reporting the spotted FAILED state will be built and \" \"appended to the ticket later on.\" ) * Else: self._logger.info( f\"Ticket detail of affecting ticket {ticket_id} that is related to serial {serial_number} \" \"was unresolved successfully. A note reporting the spotted FAILED state will be built and \" \"appended to the ticket later on.\" ) * If not last note: self._logger.info( f\"No note was found for serial {serial_number} and test type {test_type} in ticket {ticket_id}. \" \"A new note reporting the current FAILED state for this test type will be built and appended \" \"to the ticket later on.\" ) * Else: * If passed note: self._logger.info( f\"Last note found for serial {serial_number} and test type {test_type} in ticket {ticket_id} \" f\"corresponds to a PASSED state. A new note reporting the current FAILED state for this test \" \"type will be built and appended to the ticket later on.\" ) * Else: self._logger.info( f\"Last note found for serial {serial_number} and test type {test_type} in ticket {ticket_id} \" \"corresponds to a previous FAILED state. No new notes will be built to report the current \" \"FAILED state.\" ) self._logger.info(f\"Finished processing FAILED test result {test_result_id}!\")","title":" process failed test result"},{"location":"logging/services/hawkeye-affecting-monitor/actions/_process_failed_test_result/#process-failed-test-result","text":"self._logger.info( f\"Processing FAILED test result {test_result_id} (type: {test_type}) that was run for serial \" f\"{serial_number}...\" ) * If serial not in tickets: self._logger.info( f\"Serial {serial_number} could not be added to the tickets mapping at the beginning of the \" f\"process, so the current FAILED state for test type {test_type} will be ignored. Skipping...\" ) * If not affecting ticket: * If working environment is not PRODUCTION: self._logger.info( f\"Serial {serial_number} is not under any affecting ticket and some troubles were spotted for \" f\"test type {test_type}, but the current environment is not PRODUCTION. Skipping ticket creation...\" ) self._logger.info( f\"Serial {serial_number} is not under any affecting ticket and some troubles were spotted for \" f\"test type {test_type}. Creating affecting ticket..\" ) * create_affecting_ticket * If status is not Ok: self._logger.warning(f\"Bad status calling create affecting ticket to serial: {serial_number}.\" f\"Skipping process test failed ...\") self._logger.info( f\"Affecting ticket created for serial {serial_number} (ID: {ticket_id}). A new note reporting the \" f\"current FAILED state for test type {test_type} will be built and appended to the ticket later on.\" ) * Else: self._logger.info( f\"Serial {serial_number} is under affecting ticket {ticket_id} and some troubles were spotted for \" f\"test type {test_type}.\" ) * If detail resolved ticket: self._logger.info( f\"Ticket detail of affecting ticket {ticket_id} that is related to serial {serial_number} is \" f\"currently unresolved and a FAILED state was spotted. Unresolving detail...\" ) * unresolve_ticket_detail * If status is not Ok: self._logger.info( f\"Ticket detail of affecting ticket {ticket_id} that is related to serial {serial_number} \" \"could not be unresolved. A note reporting the spotted FAILED state will be built and \" \"appended to the ticket later on.\" ) * Else: self._logger.info( f\"Ticket detail of affecting ticket {ticket_id} that is related to serial {serial_number} \" \"was unresolved successfully. A note reporting the spotted FAILED state will be built and \" \"appended to the ticket later on.\" ) * If not last note: self._logger.info( f\"No note was found for serial {serial_number} and test type {test_type} in ticket {ticket_id}. \" \"A new note reporting the current FAILED state for this test type will be built and appended \" \"to the ticket later on.\" ) * Else: * If passed note: self._logger.info( f\"Last note found for serial {serial_number} and test type {test_type} in ticket {ticket_id} \" f\"corresponds to a PASSED state. A new note reporting the current FAILED state for this test \" \"type will be built and appended to the ticket later on.\" ) * Else: self._logger.info( f\"Last note found for serial {serial_number} and test type {test_type} in ticket {ticket_id} \" \"corresponds to a previous FAILED state. No new notes will be built to report the current \" \"FAILED state.\" ) self._logger.info(f\"Finished processing FAILED test result {test_result_id}!\")","title":"Process failed test result"},{"location":"logging/services/hawkeye-affecting-monitor/actions/_process_passed_test_result/","text":"Process passed test result self._logger.info( f\"Processing PASSED test result {test_result_id} (type: {test_type}) that was run for serial \" f\"{serial_number}...\" ) * If serial not in tickets: self._logger.info( f\"Serial {serial_number} could not be added to the tickets mapping at the beginning of the \" f\"process, so the current PASSED state for test type {test_type} will be ignored. Skipping...\" ) * If affecting tickets: self._logger.info( f\"Serial {serial_number} is not under any affecting ticket and all thresholds are normal for \" f\"test type {test_type}. Skipping...\" ) * If affecting ticket detail is solved: self._logger.info( f\"Serial {serial_number} is under an affecting ticket (ID {ticket_id}) whose ticket detail is resolved \" f\"and all thresholds are normal for test type {test_type}, so the current PASSED state will not be \" \"reported. Skipping...\" ) * If not last note: self._logger.info( f\"No note was found for serial {serial_number} and test type {test_type} in ticket {ticket_id}. \" \"Skipping...\" ) * If is passed note: self._logger.info( f\"Last note found for serial {serial_number} and test type {test_type} in ticket {ticket_id} \" f\"corresponds to a PASSED state. Skipping...\" ) self._logger.info( f\"Last note found for serial {serial_number} and test type {test_type} in ticket {ticket_id} \" \"corresponds to a FAILED state. A new note reporting the current PASSED state will be built and appended \" \"to the ticket later on.\" ) self._logger.info(f\"Finished processing PASSED test result {test_result_id}!\")","title":" process passed test result"},{"location":"logging/services/hawkeye-affecting-monitor/actions/_process_passed_test_result/#process-passed-test-result","text":"self._logger.info( f\"Processing PASSED test result {test_result_id} (type: {test_type}) that was run for serial \" f\"{serial_number}...\" ) * If serial not in tickets: self._logger.info( f\"Serial {serial_number} could not be added to the tickets mapping at the beginning of the \" f\"process, so the current PASSED state for test type {test_type} will be ignored. Skipping...\" ) * If affecting tickets: self._logger.info( f\"Serial {serial_number} is not under any affecting ticket and all thresholds are normal for \" f\"test type {test_type}. Skipping...\" ) * If affecting ticket detail is solved: self._logger.info( f\"Serial {serial_number} is under an affecting ticket (ID {ticket_id}) whose ticket detail is resolved \" f\"and all thresholds are normal for test type {test_type}, so the current PASSED state will not be \" \"reported. Skipping...\" ) * If not last note: self._logger.info( f\"No note was found for serial {serial_number} and test type {test_type} in ticket {ticket_id}. \" \"Skipping...\" ) * If is passed note: self._logger.info( f\"Last note found for serial {serial_number} and test type {test_type} in ticket {ticket_id} \" f\"corresponds to a PASSED state. Skipping...\" ) self._logger.info( f\"Last note found for serial {serial_number} and test type {test_type} in ticket {ticket_id} \" \"corresponds to a FAILED state. A new note reporting the current PASSED state will be built and appended \" \"to the ticket later on.\" ) self._logger.info(f\"Finished processing PASSED test result {test_result_id}!\")","title":"Process passed test result"},{"location":"logging/services/hawkeye-affecting-monitor/actions/start_hawkeye_affecting_monitoring/","text":"Start hawkeye affecting monitoring (Start service) self._logger.info(\"Scheduling Hawkeye Affecting Monitor job...\") * If exec on start: self._logger.info(\"Hawkeye Affecting Monitor job is going to be executed immediately\") * _affecting_monitoring_process * If ConflictingIdError: self._logger.info(f\"Skipping start of Hawkeye Affecting Monitoring job. Reason: {conflict}\")","title":"Start hawkeye affecting monitoring"},{"location":"logging/services/hawkeye-affecting-monitor/actions/start_hawkeye_affecting_monitoring/#start-hawkeye-affecting-monitoring-start-service","text":"self._logger.info(\"Scheduling Hawkeye Affecting Monitor job...\") * If exec on start: self._logger.info(\"Hawkeye Affecting Monitor job is going to be executed immediately\") * _affecting_monitoring_process * If ConflictingIdError: self._logger.info(f\"Skipping start of Hawkeye Affecting Monitoring job. Reason: {conflict}\")","title":"Start hawkeye affecting monitoring (Start service)"},{"location":"logging/services/hawkeye-affecting-monitor/repositories/bruin_repository/append_multiple_notes_to_ticket/","text":"Append multiple notes to ticket self._logger.info(f\"Posting multiple notes to ticket {ticket_id}...\") * If Exception: self._logger.error(f\"An error occurred when appending multiple ticket notes to ticket {ticket_id}. \" f\"Notes: {notes}. Error: {e}\") * If status ok: self._logger.info(f\"Posted multiple notes to ticket {ticket_id}!\") * Else: self._logger.error(f\"Error while appending multiple notes to ticket {ticket_id} in \" f\"{self._config.CURRENT_ENVIRONMENT.upper()} environment. \" f\"Notes were {notes}. Error: Error {response_status} - {response_body}\")","title":"Append multiple notes to ticket"},{"location":"logging/services/hawkeye-affecting-monitor/repositories/bruin_repository/append_multiple_notes_to_ticket/#append-multiple-notes-to-ticket","text":"self._logger.info(f\"Posting multiple notes to ticket {ticket_id}...\") * If Exception: self._logger.error(f\"An error occurred when appending multiple ticket notes to ticket {ticket_id}. \" f\"Notes: {notes}. Error: {e}\") * If status ok: self._logger.info(f\"Posted multiple notes to ticket {ticket_id}!\") * Else: self._logger.error(f\"Error while appending multiple notes to ticket {ticket_id} in \" f\"{self._config.CURRENT_ENVIRONMENT.upper()} environment. \" f\"Notes were {notes}. Error: Error {response_status} - {response_body}\")","title":"Append multiple notes to ticket"},{"location":"logging/services/hawkeye-affecting-monitor/repositories/bruin_repository/create_affecting_ticket/","text":"Create Affecting ticket Documentation self._logger.info( f\"Creating affecting ticket for serial {service_number} belonging to client {client_id}...\" ) if Exception self._logger.error( f\"An error occurred while creating affecting ticket for client id {client_id} and serial \" f\"{service_number} -> {e}\" ) if response_status in range(200, 300) self._logger.info( f\"Affecting ticket for client {client_id} and serial {service_number} created successfully!\" ) else self._logger.error( f\"Error while opening affecting ticket for client {client_id} and serial {service_number} in \" f\"{self._config.ENVIRONMENT_NAME.upper()} environment: \" f\"Error {response_status} - {response_body}\" )","title":"Create affecting ticket"},{"location":"logging/services/hawkeye-affecting-monitor/repositories/bruin_repository/create_affecting_ticket/#create-affecting-ticket-documentation","text":"self._logger.info( f\"Creating affecting ticket for serial {service_number} belonging to client {client_id}...\" ) if Exception self._logger.error( f\"An error occurred while creating affecting ticket for client id {client_id} and serial \" f\"{service_number} -> {e}\" ) if response_status in range(200, 300) self._logger.info( f\"Affecting ticket for client {client_id} and serial {service_number} created successfully!\" ) else self._logger.error( f\"Error while opening affecting ticket for client {client_id} and serial {service_number} in \" f\"{self._config.ENVIRONMENT_NAME.upper()} environment: \" f\"Error {response_status} - {response_body}\" )","title":"Create Affecting ticket Documentation"},{"location":"logging/services/hawkeye-affecting-monitor/repositories/bruin_repository/get_affecting_tickets/","text":"Get affecting tickets Launch Get tickets","title":"Get affecting tickets"},{"location":"logging/services/hawkeye-affecting-monitor/repositories/bruin_repository/get_affecting_tickets/#get-affecting-tickets","text":"Launch Get tickets","title":"Get affecting tickets"},{"location":"logging/services/hawkeye-affecting-monitor/repositories/bruin_repository/get_open_affecting_tickets/","text":"Get open affecting tickets Launch Get affecting tickets","title":"Get open affecting tickets"},{"location":"logging/services/hawkeye-affecting-monitor/repositories/bruin_repository/get_open_affecting_tickets/#get-open-affecting-tickets","text":"Launch Get affecting tickets","title":"Get open affecting tickets"},{"location":"logging/services/hawkeye-affecting-monitor/repositories/bruin_repository/get_ticket_details/","text":"Get Ticket details Documentation self._logger.info(f\"Getting details of ticket {ticket_id} from Bruin...\" if Exception self._logger.error(f\"An error occurred when requesting ticket details from Bruin API for ticket {ticket_id} -> {e}\") if response_status not in range(200, 300) self._logger.error( f\"Error while retrieving details of ticket {ticket_id} in \" f\"{self._config.ENVIRONMENT_NAME.upper()} environment: \" f\"Error {response_status} - {response_body}\" ) else self._logger.info(f\"Got details of ticket {ticket_id} from Bruin!\")","title":"Get ticket details"},{"location":"logging/services/hawkeye-affecting-monitor/repositories/bruin_repository/get_ticket_details/#get-ticket-details-documentation","text":"self._logger.info(f\"Getting details of ticket {ticket_id} from Bruin...\" if Exception self._logger.error(f\"An error occurred when requesting ticket details from Bruin API for ticket {ticket_id} -> {e}\") if response_status not in range(200, 300) self._logger.error( f\"Error while retrieving details of ticket {ticket_id} in \" f\"{self._config.ENVIRONMENT_NAME.upper()} environment: \" f\"Error {response_status} - {response_body}\" ) else self._logger.info(f\"Got details of ticket {ticket_id} from Bruin!\")","title":"Get Ticket details Documentation"},{"location":"logging/services/hawkeye-affecting-monitor/repositories/bruin_repository/get_tickets/","text":"Get tickets Documentation if not service_number self._logger.info( f\"Getting all tickets with any status of {ticket_statuses}, with ticket topic \" f\"{ticket_topic} and belonging to client {client_id} from Bruin...\" ) else self._logger.info( f\"Getting all tickets with any status of {ticket_statuses}, with ticket topic \" f\"{ticket_topic}, service number {service_number} and belonging to client {client_id} from Bruin...\" ) if Exception self._logger.error( f\"An error occurred when requesting tickets from Bruin API with any status of {ticket_statuses}, \" f\"with ticket topic {ticket_topic} and belonging to client {client_id} -> {e}\" ) if response_status in range(200, 300): if not service_number: self._logger.info( f\"Got all tickets with any status of {ticket_statuses}, with ticket topic \" f\"{ticket_topic} and belonging to client {client_id} from Bruin!\" ) else self._logger.info( f\"Got all tickets with any status of {ticket_statuses}, with ticket topic \" f\"{ticket_topic}, service number {service_number} and belonging to client \" f\"{client_id} from Bruin!\" ) else if not service_number self._logger.error( f\"Error while retrieving tickets with any status of {ticket_statuses}, with ticket topic \" f\"{ticket_topic} and belonging to client {client_id} in \" f\"{self._config.ENVIRONMENT_NAME.upper()} environment: \" f\"Error {response_status} - {response_body}\" ) else self._logger.error( f\"Error while retrieving tickets with any status of {ticket_statuses}, with ticket topic \" f\"{ticket_topic}, service number {service_number} and belonging to client {client_id} in \" f\"{self._config.ENVIRONMENT_NAME.upper()} environment: \" f\"Error {response_status} - {response_body}\" )","title":"Get tickets"},{"location":"logging/services/hawkeye-affecting-monitor/repositories/bruin_repository/get_tickets/#get-tickets-documentation","text":"if not service_number self._logger.info( f\"Getting all tickets with any status of {ticket_statuses}, with ticket topic \" f\"{ticket_topic} and belonging to client {client_id} from Bruin...\" ) else self._logger.info( f\"Getting all tickets with any status of {ticket_statuses}, with ticket topic \" f\"{ticket_topic}, service number {service_number} and belonging to client {client_id} from Bruin...\" ) if Exception self._logger.error( f\"An error occurred when requesting tickets from Bruin API with any status of {ticket_statuses}, \" f\"with ticket topic {ticket_topic} and belonging to client {client_id} -> {e}\" ) if response_status in range(200, 300): if not service_number: self._logger.info( f\"Got all tickets with any status of {ticket_statuses}, with ticket topic \" f\"{ticket_topic} and belonging to client {client_id} from Bruin!\" ) else self._logger.info( f\"Got all tickets with any status of {ticket_statuses}, with ticket topic \" f\"{ticket_topic}, service number {service_number} and belonging to client \" f\"{client_id} from Bruin!\" ) else if not service_number self._logger.error( f\"Error while retrieving tickets with any status of {ticket_statuses}, with ticket topic \" f\"{ticket_topic} and belonging to client {client_id} in \" f\"{self._config.ENVIRONMENT_NAME.upper()} environment: \" f\"Error {response_status} - {response_body}\" ) else self._logger.error( f\"Error while retrieving tickets with any status of {ticket_statuses}, with ticket topic \" f\"{ticket_topic}, service number {service_number} and belonging to client {client_id} in \" f\"{self._config.ENVIRONMENT_NAME.upper()} environment: \" f\"Error {response_status} - {response_body}\" )","title":"Get tickets Documentation"},{"location":"logging/services/hawkeye-affecting-monitor/repositories/bruin_repository/unresolve_ticket_detail/","text":"Unesolve ticket detail self._logger.info(f\"Unresolving detail {detail_id} of ticket {ticket_id}...\") * If Exception: self._logger.error(f\"An error occurred when unresolving detail {detail_id} of affecting ticket {ticket_id} -> {e}\") * If status ok: self._logger.info(f\"Detail {detail_id} of ticket {ticket_id} unresolved successfully!\") * Else: self._logger.error(f\"Error while unresolving detail {detail_id} of affecting ticket {ticket_id} in \" f\"{self._config.CURRENT_ENVIRONMENT.upper()} environment: \" f\"Error {response_status} - {response_body}\")","title":"Unresolve ticket detail"},{"location":"logging/services/hawkeye-affecting-monitor/repositories/bruin_repository/unresolve_ticket_detail/#unesolve-ticket-detail","text":"self._logger.info(f\"Unresolving detail {detail_id} of ticket {ticket_id}...\") * If Exception: self._logger.error(f\"An error occurred when unresolving detail {detail_id} of affecting ticket {ticket_id} -> {e}\") * If status ok: self._logger.info(f\"Detail {detail_id} of ticket {ticket_id} unresolved successfully!\") * Else: self._logger.error(f\"Error while unresolving detail {detail_id} of affecting ticket {ticket_id} in \" f\"{self._config.CURRENT_ENVIRONMENT.upper()} environment: \" f\"Error {response_status} - {response_body}\")","title":"Unesolve ticket detail"},{"location":"logging/services/hawkeye-affecting-monitor/repositories/customer_cache_repository/get_cache/","text":"get cache Documentation If velo_filter self._logger.info(f\"Getting customer cache for Velocloud host(s) {', '.join(velo_filter.keys())}...\") 2. Else: self._logger.info(f\"Getting customer cache for all Velocloud hosts...\") 3. If Exception : self._logger.error(f\"An error occurred when requesting customer cache -> {e}\") If response status == 202: self._logger.error(response_body) Else: If velo_filter: self._logger.info(f\"Got customer cache for Velocloud host(s) {', '.join(velo_filter.keys())}!\") * Else self._logger.info(f\"Got customer cache for all Velocloud hosts!\")","title":"Get cache"},{"location":"logging/services/hawkeye-affecting-monitor/repositories/customer_cache_repository/get_cache/#get-cache-documentation","text":"If velo_filter self._logger.info(f\"Getting customer cache for Velocloud host(s) {', '.join(velo_filter.keys())}...\") 2. Else: self._logger.info(f\"Getting customer cache for all Velocloud hosts...\") 3. If Exception : self._logger.error(f\"An error occurred when requesting customer cache -> {e}\") If response status == 202: self._logger.error(response_body) Else: If velo_filter: self._logger.info(f\"Got customer cache for Velocloud host(s) {', '.join(velo_filter.keys())}!\") * Else self._logger.info(f\"Got customer cache for all Velocloud hosts!\")","title":"get cache Documentation"},{"location":"logging/services/hawkeye-affecting-monitor/repositories/customer_cache_repository/get_cache_for_affecting_monitoring/","text":"Get cache for affecting monitoring get_cache","title":"Get cache for affecting monitoring"},{"location":"logging/services/hawkeye-affecting-monitor/repositories/customer_cache_repository/get_cache_for_affecting_monitoring/#get-cache-for-affecting-monitoring","text":"get_cache","title":"Get cache for affecting monitoring"},{"location":"logging/services/hawkeye-affecting-monitor/repositories/hawkeye_repository/get_tests_results/","text":"Get tests results Get probes self._logger.info(f\"Getting tests results for {len(probe_uids)} probes from Hawkeye...\") * If Exception: self._logger.error(f\"An error occurred when requesting tests results from Hawkeye -> {e}\") * If status ok: self._logger.info(f\"Error while retrieving tests results: Error {response_status} - {response_body}\") * Else: self._logger.error(f\"Got all tests results for {len(probe_uids)} probes from Hawkeye!\")","title":"Get tests results"},{"location":"logging/services/hawkeye-affecting-monitor/repositories/hawkeye_repository/get_tests_results/#get-tests-results","text":"","title":"Get tests results"},{"location":"logging/services/hawkeye-affecting-monitor/repositories/hawkeye_repository/get_tests_results/#get-probes","text":"self._logger.info(f\"Getting tests results for {len(probe_uids)} probes from Hawkeye...\") * If Exception: self._logger.error(f\"An error occurred when requesting tests results from Hawkeye -> {e}\") * If status ok: self._logger.info(f\"Error while retrieving tests results: Error {response_status} - {response_body}\") * Else: self._logger.error(f\"Got all tests results for {len(probe_uids)} probes from Hawkeye!\")","title":"Get probes"},{"location":"logging/services/hawkeye-affecting-monitor/repositories/hawkeye_repository/get_tests_results_for_affecting_monitoring/","text":"Get tests results for affecting monitoring get_tests_results","title":"Get tests results for affecting monitoring"},{"location":"logging/services/hawkeye-affecting-monitor/repositories/hawkeye_repository/get_tests_results_for_affecting_monitoring/#get-tests-results-for-affecting-monitoring","text":"get_tests_results","title":"Get tests results for affecting monitoring"},{"location":"logging/services/hawkeye-bridge/actions/get_probes/","text":"Subject: hawkeye.probe.request Message arrives at subject If message doesn't have a body: logger . error ( f \"Cannot get probes site using { json . dumps ( payload ) } . JSON malformed\" ) END logger . info ( f \"Collecting all probes with filters: { json . dumps ( filters ) } ...\" ) get_probes","title":"Get probes"},{"location":"logging/services/hawkeye-bridge/actions/get_probes/#subject-hawkeyeproberequest","text":"Message arrives at subject If message doesn't have a body: logger . error ( f \"Cannot get probes site using { json . dumps ( payload ) } . JSON malformed\" ) END logger . info ( f \"Collecting all probes with filters: { json . dumps ( filters ) } ...\" ) get_probes","title":"Subject: hawkeye.probe.request"},{"location":"logging/services/hawkeye-bridge/actions/get_test_results/","text":"Subject: hawkeye.test.request Message arrives at subject If message doesn't have a body: logger . error ( f \"Cannot get probe's tests using { json . dumps ( payload ) } . JSON malformed\" ) END If message body doesn't have probe_uids filter: logger . error ( f \"Cannot get probe's tests using { json . dumps ( body ) } . \" f \"Must include 'probe_uids' in the body of the request\" ) END If message body doesn't have interval filter: logger . error ( f \"Cannot get probe's tests using { json . dumps ( body ) } . \" f \"Must include 'interval' in the body of the request\" ) END logger . info ( f \"Collecting all test results with filters: \" f \" { json . dumps ( body [ 'probe_uids' ]) } { json . dumps ( body [ 'interval' ]) } ...\" ) get_test_results","title":"Get test results"},{"location":"logging/services/hawkeye-bridge/actions/get_test_results/#subject-hawkeyetestrequest","text":"Message arrives at subject If message doesn't have a body: logger . error ( f \"Cannot get probe's tests using { json . dumps ( payload ) } . JSON malformed\" ) END If message body doesn't have probe_uids filter: logger . error ( f \"Cannot get probe's tests using { json . dumps ( body ) } . \" f \"Must include 'probe_uids' in the body of the request\" ) END If message body doesn't have interval filter: logger . error ( f \"Cannot get probe's tests using { json . dumps ( body ) } . \" f \"Must include 'interval' in the body of the request\" ) END logger . info ( f \"Collecting all test results with filters: \" f \" { json . dumps ( body [ 'probe_uids' ]) } { json . dumps ( body [ 'interval' ]) } ...\" ) get_test_results","title":"Subject: hawkeye.test.request"},{"location":"logging/services/hawkeye-bridge/app_entrypoint/app/","text":"App entrypoint self . _logger . info ( \"Hawkeye bridge starting...\" )","title":"App"},{"location":"logging/services/hawkeye-bridge/app_entrypoint/app/#app-entrypoint","text":"self . _logger . info ( \"Hawkeye bridge starting...\" )","title":"App entrypoint"},{"location":"logging/services/hawkeye-bridge/clients/hawkeye_client/__log_result/","text":"Log result If status is 400 logger . error ( f \"Got error from Hawkeye -> { body } \" ) If status is 401 logger . error ( f \"Authentication error -> { body } \" ) If status is between 500 and 513 logger . error ( f \"Got { status } from Hawkeye\" )","title":"  log result"},{"location":"logging/services/hawkeye-bridge/clients/hawkeye_client/__log_result/#log-result","text":"If status is 400 logger . error ( f \"Got error from Hawkeye -> { body } \" ) If status is 401 logger . error ( f \"Authentication error -> { body } \" ) If status is between 500 and 513 logger . error ( f \"Got { status } from Hawkeye\" )","title":"Log result"},{"location":"logging/services/hawkeye-bridge/clients/hawkeye_client/get_probes/","text":"Get probes logger . info ( f \"Getting probes using filters { filters } ...\" ) Call Hawkeye API endpoint GET /probes with the set of desired query parameters. If there's an error while connecting to Hawkeye API: __log_result END If the status of the HTTP response is 401 : login __log_result If max number of retries has been exceeded: logger . error ( f \"Maximum number of retries exceeded\" ) END Otherwise: get_probes If the status of the HTTP response is between 500 and 513 (both inclusive): __log_result END","title":"Get probes"},{"location":"logging/services/hawkeye-bridge/clients/hawkeye_client/get_probes/#get-probes","text":"logger . info ( f \"Getting probes using filters { filters } ...\" ) Call Hawkeye API endpoint GET /probes with the set of desired query parameters. If there's an error while connecting to Hawkeye API: __log_result END If the status of the HTTP response is 401 : login __log_result If max number of retries has been exceeded: logger . error ( f \"Maximum number of retries exceeded\" ) END Otherwise: get_probes If the status of the HTTP response is between 500 and 513 (both inclusive): __log_result END","title":"Get probes"},{"location":"logging/services/hawkeye-bridge/clients/hawkeye_client/get_test_result_details/","text":"Get test result details logger . info ( f \"Getting details of test result { test_result_id } ...\" ) Call Hawkeye API endpoint GET /testsresults/{test_result_id} with the set of desired query parameters. If there's an error while connecting to Hawkeye API: __log_result END If the status of the HTTP response is 401 : login __log_result If max number of retries has been exceeded: logger . error ( f \"Maximum number of retries exceeded\" ) END Otherwise: get_test_result_details If the status of the HTTP response is between 500 and 513 (both inclusive): __log_result END","title":"Get test result details"},{"location":"logging/services/hawkeye-bridge/clients/hawkeye_client/get_test_result_details/#get-test-result-details","text":"logger . info ( f \"Getting details of test result { test_result_id } ...\" ) Call Hawkeye API endpoint GET /testsresults/{test_result_id} with the set of desired query parameters. If there's an error while connecting to Hawkeye API: __log_result END If the status of the HTTP response is 401 : login __log_result If max number of retries has been exceeded: logger . error ( f \"Maximum number of retries exceeded\" ) END Otherwise: get_test_result_details If the status of the HTTP response is between 500 and 513 (both inclusive): __log_result END","title":"Get test result details"},{"location":"logging/services/hawkeye-bridge/clients/hawkeye_client/get_tests_results/","text":"Get tests results logger . info ( f \"Getting test results using filters { filters } ...\" ) Call Hawkeye API endpoint GET /testsresults with the set of desired query parameters. If there's an error while connecting to Hawkeye API: __log_result END If the status of the HTTP response is 401 : login __log_result If max number of retries has been exceeded: logger . error ( f \"Maximum number of retries exceeded\" ) END Otherwise: get_tests_results If the status of the HTTP response is between 500 and 513 (both inclusive): __log_result END","title":"Get tests results"},{"location":"logging/services/hawkeye-bridge/clients/hawkeye_client/get_tests_results/#get-tests-results","text":"logger . info ( f \"Getting test results using filters { filters } ...\" ) Call Hawkeye API endpoint GET /testsresults with the set of desired query parameters. If there's an error while connecting to Hawkeye API: __log_result END If the status of the HTTP response is 401 : login __log_result If max number of retries has been exceeded: logger . error ( f \"Maximum number of retries exceeded\" ) END Otherwise: get_tests_results If the status of the HTTP response is between 500 and 513 (both inclusive): __log_result END","title":"Get tests results"},{"location":"logging/services/hawkeye-bridge/clients/hawkeye_client/login/","text":"Login logger . info ( \"Logging into Hawkeye...\" ) Call Hawkeye endpoint POST /login using authentication credentials. If no errors arise while calling the endpoint: logger . info ( \"Logged into Hawkeye!\" ) logger . info ( \"Loading authentication cookie into the cookie jar...\" ) logger . info ( \"Loaded authentication cookie into the cookie jar!\" ) Otherwise: __log_result","title":"Login"},{"location":"logging/services/hawkeye-bridge/clients/hawkeye_client/login/#login","text":"logger . info ( \"Logging into Hawkeye...\" ) Call Hawkeye endpoint POST /login using authentication credentials. If no errors arise while calling the endpoint: logger . info ( \"Logged into Hawkeye!\" ) logger . info ( \"Loading authentication cookie into the cookie jar...\" ) logger . info ( \"Loaded authentication cookie into the cookie jar!\" ) Otherwise: __log_result","title":"Login"},{"location":"logging/services/hawkeye-bridge/repositories/hawkeye_repository/__make_paginated_request/","text":"Make paginated request to Hawkeye API logger . info ( f \"Check all pages\" ) logger . info ( f \"Fetching all pages using { fn . __name__ } ...\" ) While there are pages to fetch: Make a call for the current page to Hawkeye API through the HawkeyeClient If response status is not ok: logger . warning ( f \"Call to { fn . __name__ } failed. Checking if max retries threshold has been \" \"reached\" ) If the max attempts threshold has been reached: logger . error ( f \"There have been 5 or more errors when calling { fn . __name__ } . \" ) END If there are no more pages to fetch: logger . info ( f \"Finished fetching all pages for { fn . __name__ } .\" ) END","title":"  make paginated request"},{"location":"logging/services/hawkeye-bridge/repositories/hawkeye_repository/__make_paginated_request/#make-paginated-request-to-hawkeye-api","text":"logger . info ( f \"Check all pages\" ) logger . info ( f \"Fetching all pages using { fn . __name__ } ...\" ) While there are pages to fetch: Make a call for the current page to Hawkeye API through the HawkeyeClient If response status is not ok: logger . warning ( f \"Call to { fn . __name__ } failed. Checking if max retries threshold has been \" \"reached\" ) If the max attempts threshold has been reached: logger . error ( f \"There have been 5 or more errors when calling { fn . __name__ } . \" ) END If there are no more pages to fetch: logger . info ( f \"Finished fetching all pages for { fn . __name__ } .\" ) END","title":"Make paginated request to Hawkeye API"},{"location":"logging/services/hawkeye-bridge/repositories/hawkeye_repository/get_probes/","text":"Get probes Call __make_paginated_request with HawkeyeClient::get_probes to fetch all available pages for the desired set of filters.","title":"Get probes"},{"location":"logging/services/hawkeye-bridge/repositories/hawkeye_repository/get_probes/#get-probes","text":"Call __make_paginated_request with HawkeyeClient::get_probes to fetch all available pages for the desired set of filters.","title":"Get probes"},{"location":"logging/services/hawkeye-bridge/repositories/hawkeye_repository/get_test_results/","text":"Get test results Call __make_paginated_request with HawkeyeClient::get_tests_results to fetch all available pages for the desired set of filters. Once we have all the test results by probe uid we call HawkeyeClient::get_test_result_details If something fail when trying to get the details for a test result: logger . error ( f \"Error when calling get_tests_result_details using test result ID { test_result_id } )\" )","title":"Get test results"},{"location":"logging/services/hawkeye-bridge/repositories/hawkeye_repository/get_test_results/#get-test-results","text":"Call __make_paginated_request with HawkeyeClient::get_tests_results to fetch all available pages for the desired set of filters. Once we have all the test results by probe uid we call HawkeyeClient::get_test_result_details If something fail when trying to get the details for a test result: logger . error ( f \"Error when calling get_tests_result_details using test result ID { test_result_id } )\" )","title":"Get test results"},{"location":"logging/services/hawkeye-customer-cache/actions/get_customers/get_customers/","text":"Subject: hawkeye.customer.cache.get Message arrives at subject If message doesn't have a body: logger . error ( f \"Cannot get customer cache using { json . dumps ( payload ) } . JSON malformed\" ) END StorageRepository::get_hawkeye_cache If no cache could be found: logger . warning ( f \"Cache is still being built\" ) END If last_contact_filter was specified and no cached devices were last contacted before the last contact date: logger . warning ( f \"No devices were found for the specified filters: { body } \" ) END logger . info ( f \" { len ( filter_cache ) } devices were found for the specified filters: { body } \" ) logger . info ( f \"Get customer response published in event bus\" )","title":"Get customers"},{"location":"logging/services/hawkeye-customer-cache/actions/get_customers/get_customers/#subject-hawkeyecustomercacheget","text":"Message arrives at subject If message doesn't have a body: logger . error ( f \"Cannot get customer cache using { json . dumps ( payload ) } . JSON malformed\" ) END StorageRepository::get_hawkeye_cache If no cache could be found: logger . warning ( f \"Cache is still being built\" ) END If last_contact_filter was specified and no cached devices were last contacted before the last contact date: logger . warning ( f \"No devices were found for the specified filters: { body } \" ) END logger . info ( f \" { len ( filter_cache ) } devices were found for the specified filters: { body } \" ) logger . info ( f \"Get customer response published in event bus\" )","title":"Subject: hawkeye.customer.cache.get"},{"location":"logging/services/hawkeye-customer-cache/actions/refresh_cache/_refresh_cache/","text":"Run Hawkeye Customer Cache Refresh job logger . info ( \"Starting job to refresh the cache of hawkeye...\" ) logger . info ( \"Claiming all probes from Hawkeye...\" ) HawkeyeRepository::get_probes If no devices could be retrieved: logger . error ( f \"Bad status calling get_probes. Error: { probes_response [ 'status' ] } . Re-trying job...\" ) If the attempts' threshold to retry retrieving devices has not been maxed out yet: logger . warning ( \"Couldn't find any probe to refresh the cache. Re-trying job...\" ) The Hawkeye Customer Cache Refresh job triggers immediately again Otherwise: error_message = ( \"[hawkeye-customer-cache] Too many consecutive failures happened while trying \" \"to claim the list of probes of hawkeye\" ) raise Exception ( error_message ) ... logger . error ( f \"An error occurred while refreshing the hawkeye cache -> { e } \" ) END logger . info ( \"Got all probes from Hawkeye!\" ) logger . info ( f \"Got { len ( probes_list ) } probes from Hawkeye\" ) logger . info ( \"Refreshing cache for hawkeye\" ) For each device: If the device has never been contacted: logger . warning ( f \"Device { device [ 'serialNumber' ] } has never been contacted. Skipping...\" ) Continue with next device BruinRepository::filter_probe logger . info ( f \"Finished filtering probes for hawkeye\" ) logger . info ( f \"Storing cache of { len ( cache ) } devices to Redis for hawkeye\" ) StorageRepository::set_hawkeye_cache _send_email_multiple_inventories logger . info ( \"Finished refreshing hawkeye cache!\" )","title":"Run Hawkeye Customer Cache Refresh job"},{"location":"logging/services/hawkeye-customer-cache/actions/refresh_cache/_refresh_cache/#run-hawkeye-customer-cache-refresh-job","text":"logger . info ( \"Starting job to refresh the cache of hawkeye...\" ) logger . info ( \"Claiming all probes from Hawkeye...\" ) HawkeyeRepository::get_probes If no devices could be retrieved: logger . error ( f \"Bad status calling get_probes. Error: { probes_response [ 'status' ] } . Re-trying job...\" ) If the attempts' threshold to retry retrieving devices has not been maxed out yet: logger . warning ( \"Couldn't find any probe to refresh the cache. Re-trying job...\" ) The Hawkeye Customer Cache Refresh job triggers immediately again Otherwise: error_message = ( \"[hawkeye-customer-cache] Too many consecutive failures happened while trying \" \"to claim the list of probes of hawkeye\" ) raise Exception ( error_message ) ... logger . error ( f \"An error occurred while refreshing the hawkeye cache -> { e } \" ) END logger . info ( \"Got all probes from Hawkeye!\" ) logger . info ( f \"Got { len ( probes_list ) } probes from Hawkeye\" ) logger . info ( \"Refreshing cache for hawkeye\" ) For each device: If the device has never been contacted: logger . warning ( f \"Device { device [ 'serialNumber' ] } has never been contacted. Skipping...\" ) Continue with next device BruinRepository::filter_probe logger . info ( f \"Finished filtering probes for hawkeye\" ) logger . info ( f \"Storing cache of { len ( cache ) } devices to Redis for hawkeye\" ) StorageRepository::set_hawkeye_cache _send_email_multiple_inventories logger . info ( \"Finished refreshing hawkeye cache!\" )","title":"Run Hawkeye Customer Cache Refresh job"},{"location":"logging/services/hawkeye-customer-cache/actions/refresh_cache/_send_email_multiple_inventories/","text":"Send an e-mail with a summary of all devices having multiple inventories in Bruin If there are devices with multiple inventories in Bruin: message = ( f \"Alert. Detected some Ixia devices with more than one status. \" f \" { self . _bruin_repository . _serials_with_multiple_inventories } \" ) [ ... ] logger . warning ( message ) logger . info ( f \"Sending mail with serials having multiples inventories to \" f \" { email_obj [ 'body' ][ 'email_data' ][ 'recipient' ] } \" ) E-mail is sent logger . info ( f \"Response from sending email with serials having multiple inventories: { json . dumps ( response ) } \" ) Otherwise: logger . info ( \"No devices with multiple Bruin inventories were detected\" )","title":" send email multiple inventories"},{"location":"logging/services/hawkeye-customer-cache/actions/refresh_cache/_send_email_multiple_inventories/#send-an-e-mail-with-a-summary-of-all-devices-having-multiple-inventories-in-bruin","text":"If there are devices with multiple inventories in Bruin: message = ( f \"Alert. Detected some Ixia devices with more than one status. \" f \" { self . _bruin_repository . _serials_with_multiple_inventories } \" ) [ ... ] logger . warning ( message ) logger . info ( f \"Sending mail with serials having multiples inventories to \" f \" { email_obj [ 'body' ][ 'email_data' ][ 'recipient' ] } \" ) E-mail is sent logger . info ( f \"Response from sending email with serials having multiple inventories: { json . dumps ( response ) } \" ) Otherwise: logger . info ( \"No devices with multiple Bruin inventories were detected\" )","title":"Send an e-mail with a summary of all devices having multiple inventories in Bruin"},{"location":"logging/services/hawkeye-customer-cache/actions/refresh_cache/schedule_cache_refresh/","text":"Schedule Hawkeye Cache Refresh job logger . info ( f \"Scheduled to refresh cache every { self . _config . REFRESH_CONFIG [ 'refresh_map_minutes' ] // 60 } hours\" ) _refresh_cache If there's a running job to refresh the customer cache already: logger . warning ( \"There is a job scheduled for refreshing the cache already. No new job is going to be scheduled.\" )","title":"Schedule Hawkeye Cache Refresh job"},{"location":"logging/services/hawkeye-customer-cache/actions/refresh_cache/schedule_cache_refresh/#schedule-hawkeye-cache-refresh-job","text":"logger . info ( f \"Scheduled to refresh cache every { self . _config . REFRESH_CONFIG [ 'refresh_map_minutes' ] // 60 } hours\" ) _refresh_cache If there's a running job to refresh the customer cache already: logger . warning ( \"There is a job scheduled for refreshing the cache already. No new job is going to be scheduled.\" )","title":"Schedule Hawkeye Cache Refresh job"},{"location":"logging/services/hawkeye-customer-cache/repositories/bruin_repository/filter_probe/","text":"Fetch Bruin data for a device, and cross it with Ixia's logger . info ( f \"Checking if device with serial { serial_number } should be monitored...\" ) BruinRepository::get_client_info If response status for get device's client info in Bruin is not ok: logger . error ( f \"Error while fetching client info for device { serial_number } : { client_info_response } \" ) END If the device seems to be linked to multiple clients in Bruin: logger . info ( f \"Device { serial_number } has { len ( client_info_response_body ) } inventories in Bruin\" ) Device will be reported as having multiple inventories at the end of the caching process If the device doesn't have any client info associated in Bruin: logger . warning ( f \"Device with serial { serial_number } doesn't have any Bruin client info associated\" ) END BruinRepository::get_management_status If response status for get device's management status in Bruin is not ok: logger . error ( f \"Error while fetching management status for device { serial_number } : \" f \" { management_status_response } \" ) END If device's management status is not monitorable: logger . warning ( f \"Management status is not active for serial { serial_number } . Skipping...\" ) END logger . info ( f \"Management status for serial { serial_number } seems active\" ) Ixia and Bruin data for the device are finally crossed If the whole crossing process fails for unexpected reasons: Run the crossing process again If the whole crossing process fails after multiple attempts: logger . error ( f \"An error occurred while checking if probe { probe [ 'probeId' ] } should be cached or not -> { e } \" )","title":"Filter probe"},{"location":"logging/services/hawkeye-customer-cache/repositories/bruin_repository/filter_probe/#fetch-bruin-data-for-a-device-and-cross-it-with-ixias","text":"logger . info ( f \"Checking if device with serial { serial_number } should be monitored...\" ) BruinRepository::get_client_info If response status for get device's client info in Bruin is not ok: logger . error ( f \"Error while fetching client info for device { serial_number } : { client_info_response } \" ) END If the device seems to be linked to multiple clients in Bruin: logger . info ( f \"Device { serial_number } has { len ( client_info_response_body ) } inventories in Bruin\" ) Device will be reported as having multiple inventories at the end of the caching process If the device doesn't have any client info associated in Bruin: logger . warning ( f \"Device with serial { serial_number } doesn't have any Bruin client info associated\" ) END BruinRepository::get_management_status If response status for get device's management status in Bruin is not ok: logger . error ( f \"Error while fetching management status for device { serial_number } : \" f \" { management_status_response } \" ) END If device's management status is not monitorable: logger . warning ( f \"Management status is not active for serial { serial_number } . Skipping...\" ) END logger . info ( f \"Management status for serial { serial_number } seems active\" ) Ixia and Bruin data for the device are finally crossed If the whole crossing process fails for unexpected reasons: Run the crossing process again If the whole crossing process fails after multiple attempts: logger . error ( f \"An error occurred while checking if probe { probe [ 'probeId' ] } should be cached or not -> { e } \" )","title":"Fetch Bruin data for a device, and cross it with Ixia's"},{"location":"logging/services/hawkeye-customer-cache/repositories/bruin_repository/get_client_info/","text":"Get client info for device logger . info ( f \"Claiming client info for service number { service_number } ...\" ) If there's an error while asking for the data to the bruin-bridge : err_msg = f \"An error occurred when claiming client info for service number { service_number } -> { e } \" [ ... ] logger . error ( err_msg ) END logger . info ( f \"Got client info for service number { service_number } !\" ) If response status for get client info for device is not ok: err_msg = ( f \"Error while claiming client info for service number { service_number } in \" f \" { self . _config . ENVIRONMENT_NAME . upper () } environment: Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg )","title":"Get client info"},{"location":"logging/services/hawkeye-customer-cache/repositories/bruin_repository/get_client_info/#get-client-info-for-device","text":"logger . info ( f \"Claiming client info for service number { service_number } ...\" ) If there's an error while asking for the data to the bruin-bridge : err_msg = f \"An error occurred when claiming client info for service number { service_number } -> { e } \" [ ... ] logger . error ( err_msg ) END logger . info ( f \"Got client info for service number { service_number } !\" ) If response status for get client info for device is not ok: err_msg = ( f \"Error while claiming client info for service number { service_number } in \" f \" { self . _config . ENVIRONMENT_NAME . upper () } environment: Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg )","title":"Get client info for device"},{"location":"logging/services/hawkeye-customer-cache/repositories/bruin_repository/get_management_status/","text":"Get management status for device logger . info ( f \"Claiming management status for service number { service_number } and client { client_id } ...\" ) If there's an error while asking for the data to the bruin-bridge : err_msg = ( f \"An error occurred when claiming management status for service number { service_number } and \" f \"client { client_id } -> { e } \" ) [ ... ] logger . error ( err_msg ) END logger . info ( f \"Got management status for service number { service_number } and client { client_id } !\" ) If response status for get management status for device is not ok: err_msg = ( f \"Error while claiming management status for service number { service_number } and \" f \"client { client_id } in { self . _config . ENVIRONMENT_NAME . upper () } environment: \" f \"Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg )","title":"Get management status"},{"location":"logging/services/hawkeye-customer-cache/repositories/bruin_repository/get_management_status/#get-management-status-for-device","text":"logger . info ( f \"Claiming management status for service number { service_number } and client { client_id } ...\" ) If there's an error while asking for the data to the bruin-bridge : err_msg = ( f \"An error occurred when claiming management status for service number { service_number } and \" f \"client { client_id } -> { e } \" ) [ ... ] logger . error ( err_msg ) END logger . info ( f \"Got management status for service number { service_number } and client { client_id } !\" ) If response status for get management status for device is not ok: err_msg = ( f \"Error while claiming management status for service number { service_number } and \" f \"client { client_id } in { self . _config . ENVIRONMENT_NAME . upper () } environment: \" f \"Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg )","title":"Get management status for device"},{"location":"logging/services/hawkeye-customer-cache/repositories/hawkeye_repository/get_probes/","text":"Get all probes from Ixia logger . info ( f \"Getting all probes from Hawkeye...\" ) If there's an error while asking for the data to the hawkeye-bridge : err_msg = f \"An error occurred when requesting all probes from Hawkeye -> { e } \" [ ... ] logger . error ( err_msg ) END If response status for get probes is not ok: err_msg = f \"Error while retrieving probes: Error { response_status } - { response_body } \" [ ... ] logger . error ( err_msg ) END logger . info ( \"Got all probes from Hawkeye!\" )","title":"Get probes"},{"location":"logging/services/hawkeye-customer-cache/repositories/hawkeye_repository/get_probes/#get-all-probes-from-ixia","text":"logger . info ( f \"Getting all probes from Hawkeye...\" ) If there's an error while asking for the data to the hawkeye-bridge : err_msg = f \"An error occurred when requesting all probes from Hawkeye -> { e } \" [ ... ] logger . error ( err_msg ) END If response status for get probes is not ok: err_msg = f \"Error while retrieving probes: Error { response_status } - { response_body } \" [ ... ] logger . error ( err_msg ) END logger . info ( \"Got all probes from Hawkeye!\" )","title":"Get all probes from Ixia"},{"location":"logging/services/hawkeye-customer-cache/repositories/storage_repository/get_hawkeye_cache/","text":"Get customer cache for Ixia If cache exists: logger . info ( \"Ixia cache found\" ) Otherwise: logger . warning ( \"No Ixia cache found\" )","title":"Get hawkeye cache"},{"location":"logging/services/hawkeye-customer-cache/repositories/storage_repository/get_hawkeye_cache/#get-customer-cache-for-ixia","text":"If cache exists: logger . info ( \"Ixia cache found\" ) Otherwise: logger . warning ( \"No Ixia cache found\" )","title":"Get customer cache for Ixia"},{"location":"logging/services/hawkeye-customer-cache/repositories/storage_repository/set_hawkeye_cache/","text":"Store customer cache for Ixia logger . info ( f \"Saving cache of { len ( cache ) } devices for Ixia...\" ) Cache is saved logger . info ( f \"Cache saved\" )","title":"Set hawkeye cache"},{"location":"logging/services/hawkeye-customer-cache/repositories/storage_repository/set_hawkeye_cache/#store-customer-cache-for-ixia","text":"logger . info ( f \"Saving cache of { len ( cache ) } devices for Ixia...\" ) Cache is saved logger . info ( f \"Cache saved\" )","title":"Store customer cache for Ixia"},{"location":"logging/services/hawkeye-outage-monitor/actions/outage_monitoring/_append_triage_note_if_needed/","text":"Append triage note to ticket if there's not one already logger . info ( f \"Checking ticket { ticket_id } to see if device { serial_number } has a triage note already...\" ) BruinRepository::get_ticket_details If response status for get ticket details is not ok: logger . error ( f \"Error while getting details of ticket { ticket_id } : { ticket_details_response } . \" f \"Skipping append triage note...\" ) END If there is a Triage note appended to the ticket task linked to the Ixia device: logger . info ( f \"Triage note already exists in ticket { ticket_id } for serial { serial_number } , so no triage \" f \"note will be appended.\" ) END logger . info ( f \"No triage note was found for serial { serial_number } in ticket { ticket_id } . Appending triage note...\" ) BruinRepository::append_triage_note_to_ticket logger . info ( f \"Triage note for device { serial_number } appended to ticket { ticket_id } !\" )","title":" append triage note if needed"},{"location":"logging/services/hawkeye-outage-monitor/actions/outage_monitoring/_append_triage_note_if_needed/#append-triage-note-to-ticket-if-theres-not-one-already","text":"logger . info ( f \"Checking ticket { ticket_id } to see if device { serial_number } has a triage note already...\" ) BruinRepository::get_ticket_details If response status for get ticket details is not ok: logger . error ( f \"Error while getting details of ticket { ticket_id } : { ticket_details_response } . \" f \"Skipping append triage note...\" ) END If there is a Triage note appended to the ticket task linked to the Ixia device: logger . info ( f \"Triage note already exists in ticket { ticket_id } for serial { serial_number } , so no triage \" f \"note will be appended.\" ) END logger . info ( f \"No triage note was found for serial { serial_number } in ticket { ticket_id } . Appending triage note...\" ) BruinRepository::append_triage_note_to_ticket logger . info ( f \"Triage note for device { serial_number } appended to ticket { ticket_id } !\" )","title":"Append triage note to ticket if there's not one already"},{"location":"logging/services/hawkeye-outage-monitor/actions/outage_monitoring/_map_probes_info_with_customer_cache/","text":"Map Ixia devices' current state to their info stored in the cache For each Ixia device: If the Ixia device is not present in the cache of customers: logger . warning ( f \"No cached info was found for device { serial_number } . Skipping...\" ) Continue with next device","title":" map probes info with customer cache"},{"location":"logging/services/hawkeye-outage-monitor/actions/outage_monitoring/_map_probes_info_with_customer_cache/#map-ixia-devices-current-state-to-their-info-stored-in-the-cache","text":"For each Ixia device: If the Ixia device is not present in the cache of customers: logger . warning ( f \"No cached info was found for device { serial_number } . Skipping...\" ) Continue with next device","title":"Map Ixia devices' current state to their info stored in the cache"},{"location":"logging/services/hawkeye-outage-monitor/actions/outage_monitoring/_outage_monitoring_process/","text":"Run Hawkeye Outage Monitoring job logger . info ( f \"Starting Hawkeye Outage Monitor!\" ) CustomerCacheRepository::get_cache_for_outage_monitoring If response status for get Hawkeye's customer cache is not ok: logger . error ( f \"Error while getting Hawkeye's customer cache: { customer_cache_response } . \" f \"Skipping outage monitoring process...\" ) END HawkeyeRepository::get_probes If response status for get Hawkeye's devices is not ok: logger . error ( f \"Error while getting Hawkeye's probes: { probes_response } . Skipping outage monitoring process...\" ) END If there are no devices to monitor: logger . warning ( \"The list of probes arrived empty. Skipping outage monitoring process...\" ) END If there are no active devices to monitor: logger . warning ( \"All probes were detected as inactive. Skipping outage monitoring process...\" ) END _map_probes_info_with_customer_cache The list of devices is split to two different data sets: devices in outage state and devices online If there are devices in outage state: logger . info ( f \" { len ( outage_devices ) } devices were detected in outage state. \" \"Scheduling re-check job for all of them...\" ) _schedule_recheck_job_for_devices Otherwise: logger . info ( \"No devices were detected in outage state. Re-check job won't be scheduled\" ) If there are devices online: logger . info ( f \" { len ( healthy_devices ) } devices were detected in healthy state. Running autoresolve for all of them\" ) For each online device: _run_ticket_autoresolve Otherwise: logger . info ( \"No devices were detected in healthy state. Autoresolve won't be triggered\" ) logger . info ( f \"Hawkeye Outage Monitor process finished! Took { round (( stop - start ) / 60 , 2 ) } minutes\" )","title":" outage monitoring process"},{"location":"logging/services/hawkeye-outage-monitor/actions/outage_monitoring/_outage_monitoring_process/#run-hawkeye-outage-monitoring-job","text":"logger . info ( f \"Starting Hawkeye Outage Monitor!\" ) CustomerCacheRepository::get_cache_for_outage_monitoring If response status for get Hawkeye's customer cache is not ok: logger . error ( f \"Error while getting Hawkeye's customer cache: { customer_cache_response } . \" f \"Skipping outage monitoring process...\" ) END HawkeyeRepository::get_probes If response status for get Hawkeye's devices is not ok: logger . error ( f \"Error while getting Hawkeye's probes: { probes_response } . Skipping outage monitoring process...\" ) END If there are no devices to monitor: logger . warning ( \"The list of probes arrived empty. Skipping outage monitoring process...\" ) END If there are no active devices to monitor: logger . warning ( \"All probes were detected as inactive. Skipping outage monitoring process...\" ) END _map_probes_info_with_customer_cache The list of devices is split to two different data sets: devices in outage state and devices online If there are devices in outage state: logger . info ( f \" { len ( outage_devices ) } devices were detected in outage state. \" \"Scheduling re-check job for all of them...\" ) _schedule_recheck_job_for_devices Otherwise: logger . info ( \"No devices were detected in outage state. Re-check job won't be scheduled\" ) If there are devices online: logger . info ( f \" { len ( healthy_devices ) } devices were detected in healthy state. Running autoresolve for all of them\" ) For each online device: _run_ticket_autoresolve Otherwise: logger . info ( \"No devices were detected in healthy state. Autoresolve won't be triggered\" ) logger . info ( f \"Hawkeye Outage Monitor process finished! Took { round (( stop - start ) / 60 , 2 ) } minutes\" )","title":"Run Hawkeye Outage Monitoring job"},{"location":"logging/services/hawkeye-outage-monitor/actions/outage_monitoring/_recheck_devices_for_ticket_creation/","text":"Re-recheck devices sitting in the quarantine logger . info ( f \"Re-checking { len ( devices ) } devices in outage state prior to ticket creation...\" ) HawkeyeRepository::get_probes If response status for get Hawkeye's devices is not ok: logger . error ( f \"Error while getting Hawkeye's probes: { probes_response } . Skipping re-check process...\" ) END If there are no devices to re-check: logger . warning ( \"The list of probes arrived empty. Skipping re-check process...\" ) END If there are no active devices to re-check: logger . warning ( \"All probes were detected as inactive. Skipping re-check process...\" ) END _map_probes_info_with_customer_cache The list of devices is split to two different data sets: devices in outage state and devices online If there are devices still in outage state: logger . info ( f \" { len ( devices_still_in_outage ) } devices were detected as still in outage state after re-check.\" ) For each device in outage state: logger . info ( f \"Attempting outage ticket creation for faulty device { serial_number } ...\" ) BruinRepository::create_outage_ticket If response status for create outage ticket is 200 : logger . info ( f \"Outage ticket created for device { serial_number } ! Ticket ID: { ticket_id } \" ) logger . info ( f \"Appending triage note to outage ticket { ticket_id } ...\" ) BruinRepository::append_triage_note_to_ticket If response status for create outage ticket is 409 : logger . info ( f \"Faulty device { serial_number } already has an outage ticket in progress (ID = { ticket_id } ).\" ) _append_triage_note_if_needed If response status for create outage ticket is 471 : logger . info ( f \"Faulty device { serial_number } has a resolved outage ticket (ID = { ticket_id } ). \" \"Re-opening ticket...\" ) _reopen_outage_ticket If response status for create outage ticket is 472 : logger . info ( f \"[outage-recheck] Faulty device { serial_number } has a resolved outage ticket \" f \"(ID = { ticket_id } ). Its ticket detail was automatically unresolved \" f \"by Bruin. Appending reopen note to ticket...\" ) BruinRepository::append_note_to_ticket If response status for create outage ticket is 473 : logger . info ( f \"[outage-recheck] There is a resolve outage ticket for the same location of faulty device \" f \" { serial_number } (ticket ID = { ticket_id } ). The ticket was\" f \"automatically unresolved by Bruin and a new ticket detail for serial { serial_number } was \" f \"appended to it. Appending initial triage note for this service number...\" ) BruinRepository::append_triage_note_to_ticket Otherwise: logger . info ( \"No devices were detected in outage state after re-check. Outage tickets won't be created\" ) If there are devices online: logger . info ( f \" { len ( healthy_devices ) } devices were detected in healthy state after re-check.\" ) For each online device: _run_ticket_autoresolve Otherwise: logger . info ( \"No devices were detected in healthy state after re-check.\" ) logger . info ( f \"Finished re-checking { len ( devices ) } devices\" )","title":" recheck devices for ticket creation"},{"location":"logging/services/hawkeye-outage-monitor/actions/outage_monitoring/_recheck_devices_for_ticket_creation/#re-recheck-devices-sitting-in-the-quarantine","text":"logger . info ( f \"Re-checking { len ( devices ) } devices in outage state prior to ticket creation...\" ) HawkeyeRepository::get_probes If response status for get Hawkeye's devices is not ok: logger . error ( f \"Error while getting Hawkeye's probes: { probes_response } . Skipping re-check process...\" ) END If there are no devices to re-check: logger . warning ( \"The list of probes arrived empty. Skipping re-check process...\" ) END If there are no active devices to re-check: logger . warning ( \"All probes were detected as inactive. Skipping re-check process...\" ) END _map_probes_info_with_customer_cache The list of devices is split to two different data sets: devices in outage state and devices online If there are devices still in outage state: logger . info ( f \" { len ( devices_still_in_outage ) } devices were detected as still in outage state after re-check.\" ) For each device in outage state: logger . info ( f \"Attempting outage ticket creation for faulty device { serial_number } ...\" ) BruinRepository::create_outage_ticket If response status for create outage ticket is 200 : logger . info ( f \"Outage ticket created for device { serial_number } ! Ticket ID: { ticket_id } \" ) logger . info ( f \"Appending triage note to outage ticket { ticket_id } ...\" ) BruinRepository::append_triage_note_to_ticket If response status for create outage ticket is 409 : logger . info ( f \"Faulty device { serial_number } already has an outage ticket in progress (ID = { ticket_id } ).\" ) _append_triage_note_if_needed If response status for create outage ticket is 471 : logger . info ( f \"Faulty device { serial_number } has a resolved outage ticket (ID = { ticket_id } ). \" \"Re-opening ticket...\" ) _reopen_outage_ticket If response status for create outage ticket is 472 : logger . info ( f \"[outage-recheck] Faulty device { serial_number } has a resolved outage ticket \" f \"(ID = { ticket_id } ). Its ticket detail was automatically unresolved \" f \"by Bruin. Appending reopen note to ticket...\" ) BruinRepository::append_note_to_ticket If response status for create outage ticket is 473 : logger . info ( f \"[outage-recheck] There is a resolve outage ticket for the same location of faulty device \" f \" { serial_number } (ticket ID = { ticket_id } ). The ticket was\" f \"automatically unresolved by Bruin and a new ticket detail for serial { serial_number } was \" f \"appended to it. Appending initial triage note for this service number...\" ) BruinRepository::append_triage_note_to_ticket Otherwise: logger . info ( \"No devices were detected in outage state after re-check. Outage tickets won't be created\" ) If there are devices online: logger . info ( f \" { len ( healthy_devices ) } devices were detected in healthy state after re-check.\" ) For each online device: _run_ticket_autoresolve Otherwise: logger . info ( \"No devices were detected in healthy state after re-check.\" ) logger . info ( f \"Finished re-checking { len ( devices ) } devices\" )","title":"Re-recheck devices sitting in the quarantine"},{"location":"logging/services/hawkeye-outage-monitor/actions/outage_monitoring/_reopen_outage_ticket/","text":"Re-open task from Service Outage ticket logger . info ( f \"Reopening task from ticket { ticket_id } for device { device [ 'cached_info' ][ 'serial_number' ] } ...\" ) BruinRepository::get_ticket_details If response status for get ticket details is not ok: logger . error ( f \"Error while getting details of ticket { ticket_id } : { ticket_details_response } . \" f \"Skipping task re-open...\" ) END BruinRepository::open_ticket If response status for re-opening ticket task is ok: logger . info ( f \"Task from ticket { ticket_id } for device { device [ 'cached_info' ][ 'serial_number' ] } re-opened!\" ) BruinRepository::append_note_to_ticket is called to append a Re-Open note Otherwise: logger . error ( f \"Re-open failed for task from ticket { ticket_id } for device { device [ 'cached_info' ][ 'serial_number' ] } \" )","title":" reopen outage ticket"},{"location":"logging/services/hawkeye-outage-monitor/actions/outage_monitoring/_reopen_outage_ticket/#re-open-task-from-service-outage-ticket","text":"logger . info ( f \"Reopening task from ticket { ticket_id } for device { device [ 'cached_info' ][ 'serial_number' ] } ...\" ) BruinRepository::get_ticket_details If response status for get ticket details is not ok: logger . error ( f \"Error while getting details of ticket { ticket_id } : { ticket_details_response } . \" f \"Skipping task re-open...\" ) END BruinRepository::open_ticket If response status for re-opening ticket task is ok: logger . info ( f \"Task from ticket { ticket_id } for device { device [ 'cached_info' ][ 'serial_number' ] } re-opened!\" ) BruinRepository::append_note_to_ticket is called to append a Re-Open note Otherwise: logger . error ( f \"Re-open failed for task from ticket { ticket_id } for device { device [ 'cached_info' ][ 'serial_number' ] } \" )","title":"Re-open task from Service Outage ticket"},{"location":"logging/services/hawkeye-outage-monitor/actions/outage_monitoring/_run_ticket_autoresolve/","text":"Run ticket task auto-resolve for online Ixia device logger . info ( f \"Starting autoresolve for device { serial_number } ...\" ) BruinRepository::get_open_outage_tickets If response status for get open Service Outage tickets is not ok: logger . error ( f \"Error while getting open Service Outage tickets for device { serial_number } : \" f \" { outage_ticket_response } . Skipping autoresolve...\" ) END If there are no open tickets for the Ixia device: logger . warning ( f \"No open outage ticket found for device { serial_number } . Skipping autoresolve...\" ) END If the existing Service Outage ticket was not created by the IPA system: logger . warning ( f \"Ticket { outage_ticket_id } was not created by Automation Engine. Skipping autoresolve...\" ) END BruinRepository::get_ticket_details If response status for get ticket details is not ok: logger . error ( f \"Error while getting details of ticket { outage_ticket_id } : { ticket_details_response } . \" f \"Skipping autoresolve...\" ) END If the last outage documented in the ticket took place long time ago: logger . warning ( f \"Device { device } has been in outage state for a long time, so detail { client_id } \" f \"(serial { serial_number } ) of ticket { outage_ticket_id } will not be autoresolved. Skipping \" f \"autoresolve...\" ) END If the number of allowed auto-resolves has been maxed out for the task linked to the Ixia device: logger . warning ( f \"Limit to autoresolve ticket { outage_ticket_id } linked to device \" f \" { serial_number } has been maxed out already. Skipping autoresolve...\" ) END If the task linked to the Ixia device is already resolved: logger . warning ( f \"Task for { serial_number } of ticket { outage_ticket_id } is already resolved. \" f \"Skipping autoresolve...\" ) END logger . info ( f \"Autoresolving task for device { serial_number } of ticket { outage_ticket_id } ...\" ) BruinRepository::unpause_ticket_detail BruinRepository::resolve_ticket If response status for resolve ticket task is not ok: logger . error ( f \"Error while resolving task for device { device } of ticket { outage_ticket_id } . \" f \"Skipping autoresolve ...\" ) END BruinRepository::append_autoresolve_note_to_ticket logger . info ( f \"Task for device { serial_number } of ticket { outage_ticket_id } was autoresolved!\" )","title":" run ticket autoresolve"},{"location":"logging/services/hawkeye-outage-monitor/actions/outage_monitoring/_run_ticket_autoresolve/#run-ticket-task-auto-resolve-for-online-ixia-device","text":"logger . info ( f \"Starting autoresolve for device { serial_number } ...\" ) BruinRepository::get_open_outage_tickets If response status for get open Service Outage tickets is not ok: logger . error ( f \"Error while getting open Service Outage tickets for device { serial_number } : \" f \" { outage_ticket_response } . Skipping autoresolve...\" ) END If there are no open tickets for the Ixia device: logger . warning ( f \"No open outage ticket found for device { serial_number } . Skipping autoresolve...\" ) END If the existing Service Outage ticket was not created by the IPA system: logger . warning ( f \"Ticket { outage_ticket_id } was not created by Automation Engine. Skipping autoresolve...\" ) END BruinRepository::get_ticket_details If response status for get ticket details is not ok: logger . error ( f \"Error while getting details of ticket { outage_ticket_id } : { ticket_details_response } . \" f \"Skipping autoresolve...\" ) END If the last outage documented in the ticket took place long time ago: logger . warning ( f \"Device { device } has been in outage state for a long time, so detail { client_id } \" f \"(serial { serial_number } ) of ticket { outage_ticket_id } will not be autoresolved. Skipping \" f \"autoresolve...\" ) END If the number of allowed auto-resolves has been maxed out for the task linked to the Ixia device: logger . warning ( f \"Limit to autoresolve ticket { outage_ticket_id } linked to device \" f \" { serial_number } has been maxed out already. Skipping autoresolve...\" ) END If the task linked to the Ixia device is already resolved: logger . warning ( f \"Task for { serial_number } of ticket { outage_ticket_id } is already resolved. \" f \"Skipping autoresolve...\" ) END logger . info ( f \"Autoresolving task for device { serial_number } of ticket { outage_ticket_id } ...\" ) BruinRepository::unpause_ticket_detail BruinRepository::resolve_ticket If response status for resolve ticket task is not ok: logger . error ( f \"Error while resolving task for device { device } of ticket { outage_ticket_id } . \" f \"Skipping autoresolve ...\" ) END BruinRepository::append_autoresolve_note_to_ticket logger . info ( f \"Task for device { serial_number } of ticket { outage_ticket_id } was autoresolved!\" )","title":"Run ticket task auto-resolve for online Ixia device"},{"location":"logging/services/hawkeye-outage-monitor/actions/outage_monitoring/_schedule_recheck_job_for_devices/","text":"Schedule re-check job for devices sitting in the quarantine logger . info ( f \"Scheduling recheck job for { len ( devices ) } devices in outage state...\" ) _recheck_devices_for_ticket_creation is scheduled to run in 5 seconds logger . info ( f \"Devices scheduled for recheck successfully\" )","title":" schedule recheck job for devices"},{"location":"logging/services/hawkeye-outage-monitor/actions/outage_monitoring/_schedule_recheck_job_for_devices/#schedule-re-check-job-for-devices-sitting-in-the-quarantine","text":"logger . info ( f \"Scheduling recheck job for { len ( devices ) } devices in outage state...\" ) _recheck_devices_for_ticket_creation is scheduled to run in 5 seconds logger . info ( f \"Devices scheduled for recheck successfully\" )","title":"Schedule re-check job for devices sitting in the quarantine"},{"location":"logging/services/hawkeye-outage-monitor/actions/outage_monitoring/start_hawkeye_outage_monitoring/","text":"Schedule Hawkeye Outage Monitoring job logger . info ( \"Scheduling Hawkeye Outage Monitor job...\" ) If job should be executed on service start: logger . info ( \"Hawkeye Outage Monitor job is going to be executed immediately\" ) _outage_monitoring_process If there's a running job to monitor Ixia devices already: logger . warning ( f \"Skipping start of Hawkeye Outage Monitoring job. Reason: { conflict } \" )","title":"Start hawkeye outage monitoring"},{"location":"logging/services/hawkeye-outage-monitor/actions/outage_monitoring/start_hawkeye_outage_monitoring/#schedule-hawkeye-outage-monitoring-job","text":"logger . info ( \"Scheduling Hawkeye Outage Monitor job...\" ) If job should be executed on service start: logger . info ( \"Hawkeye Outage Monitor job is going to be executed immediately\" ) _outage_monitoring_process If there's a running job to monitor Ixia devices already: logger . warning ( f \"Skipping start of Hawkeye Outage Monitoring job. Reason: { conflict } \" )","title":"Schedule Hawkeye Outage Monitoring job"},{"location":"logging/services/hawkeye-outage-monitor/repositories/bruin_repository/append_autoresolve_note_to_ticket/","text":"Append auto-resolve note to ticket append_note_to_ticket is called with a note specifically built for an Auto-Resolve event","title":"Append autoresolve note to ticket"},{"location":"logging/services/hawkeye-outage-monitor/repositories/bruin_repository/append_autoresolve_note_to_ticket/#append-auto-resolve-note-to-ticket","text":"append_note_to_ticket is called with a note specifically built for an Auto-Resolve event","title":"Append auto-resolve note to ticket"},{"location":"logging/services/hawkeye-outage-monitor/repositories/bruin_repository/append_note_to_ticket/","text":"Append note to ticket If the note is meant to be appended to tasks linked to particular service numbers: logger . info ( f 'Appending note for service number(s) { \", \" . join ( service_numbers ) } in ticket { ticket_id } ...' ) Otherwise: logger . info ( f \"Appending note for all service number(s) in ticket { ticket_id } ...\" ) If there's an error while asking for the data to the bruin-bridge : err_msg = ( f \"An error occurred when appending a ticket note to ticket { ticket_id } . \" f \"Ticket note: { note } . Error: { e } \" ) [ ... ] logger . error ( err_msg ) END If response status for append note to ticket is not ok: err_msg = ( f \"Error while appending note to ticket { ticket_id } : Error: \" f \"Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg ) END If the note was successfully appended to tasks linked to particular service numbers: logger . info ( f 'Note for service number(s) { \", \" . join ( service_numbers ) } appended to ticket { ticket_id } !' ) Otherwise: logger . info ( f \"Note for all service number(s) appended to ticket { ticket_id } !\" )","title":"Append note to ticket"},{"location":"logging/services/hawkeye-outage-monitor/repositories/bruin_repository/append_note_to_ticket/#append-note-to-ticket","text":"If the note is meant to be appended to tasks linked to particular service numbers: logger . info ( f 'Appending note for service number(s) { \", \" . join ( service_numbers ) } in ticket { ticket_id } ...' ) Otherwise: logger . info ( f \"Appending note for all service number(s) in ticket { ticket_id } ...\" ) If there's an error while asking for the data to the bruin-bridge : err_msg = ( f \"An error occurred when appending a ticket note to ticket { ticket_id } . \" f \"Ticket note: { note } . Error: { e } \" ) [ ... ] logger . error ( err_msg ) END If response status for append note to ticket is not ok: err_msg = ( f \"Error while appending note to ticket { ticket_id } : Error: \" f \"Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg ) END If the note was successfully appended to tasks linked to particular service numbers: logger . info ( f 'Note for service number(s) { \", \" . join ( service_numbers ) } appended to ticket { ticket_id } !' ) Otherwise: logger . info ( f \"Note for all service number(s) appended to ticket { ticket_id } !\" )","title":"Append note to ticket"},{"location":"logging/services/hawkeye-outage-monitor/repositories/bruin_repository/append_triage_note_to_ticket/","text":"Append triage note to ticket If the note is not larger than 1500 characters: logger . info ( f \"Note for ticket { ticket_id } and { service_number } is { len ( note ) } characters large. \" f \"There's no need to split it.\" ) append_note_to_ticket Otherwise: logger . warning ( f \"Note for ticket { ticket_id } and { service_number } is { len ( note ) } characters large. \" f \"Splitting it to { total_notes } notes...\" ) For each chunk: logger . info ( f \"Appending Triage note ( { index } / { total_notes } ) to task linked to device { service_number } in \" f \"ticket { ticket_id } ...\" ) append_note_to_ticket If response status for append triage note to ticket is not ok: logger . error ( f \"Error while appending Triage note ( { index } / { total_notes } ) to task linked to device \" f \" { service_number } in ticket { ticket_id } . Remaining notes won't be appended\" ) END logger . info ( f \"Triage note ( { index } / { total_notes } ) appended to task linked to device \" f \" { service_number } in ticket { ticket_id } !\" )","title":"Append triage note to ticket"},{"location":"logging/services/hawkeye-outage-monitor/repositories/bruin_repository/append_triage_note_to_ticket/#append-triage-note-to-ticket","text":"If the note is not larger than 1500 characters: logger . info ( f \"Note for ticket { ticket_id } and { service_number } is { len ( note ) } characters large. \" f \"There's no need to split it.\" ) append_note_to_ticket Otherwise: logger . warning ( f \"Note for ticket { ticket_id } and { service_number } is { len ( note ) } characters large. \" f \"Splitting it to { total_notes } notes...\" ) For each chunk: logger . info ( f \"Appending Triage note ( { index } / { total_notes } ) to task linked to device { service_number } in \" f \"ticket { ticket_id } ...\" ) append_note_to_ticket If response status for append triage note to ticket is not ok: logger . error ( f \"Error while appending Triage note ( { index } / { total_notes } ) to task linked to device \" f \" { service_number } in ticket { ticket_id } . Remaining notes won't be appended\" ) END logger . info ( f \"Triage note ( { index } / { total_notes } ) appended to task linked to device \" f \" { service_number } in ticket { ticket_id } !\" )","title":"Append triage note to ticket"},{"location":"logging/services/hawkeye-outage-monitor/repositories/bruin_repository/create_outage_ticket/","text":"Create Service Outage ticket for Ixia device logger . info ( f \"Creating outage ticket for device { service_number } belonging to client { client_id } ...\" ) If there's an error while asking for the data to the bruin-bridge : err_msg = ( f \"An error occurred when creating outage ticket for device { service_number } belonging to client\" f \" { client_id } -> { e } \" ) [ ... ] logger . error ( err_msg ) END If response status for create outage ticket is not any of 200 , 409 , 471 , 472 or 473 : err_msg = ( f \"Error while creating outage ticket for device { service_number } that belongs to client \" f \" { client_id } : Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg ) END logger . info ( f \"Outage ticket for device { service_number } belonging to client { client_id } created!\" )","title":"Create outage ticket"},{"location":"logging/services/hawkeye-outage-monitor/repositories/bruin_repository/create_outage_ticket/#create-service-outage-ticket-for-ixia-device","text":"logger . info ( f \"Creating outage ticket for device { service_number } belonging to client { client_id } ...\" ) If there's an error while asking for the data to the bruin-bridge : err_msg = ( f \"An error occurred when creating outage ticket for device { service_number } belonging to client\" f \" { client_id } -> { e } \" ) [ ... ] logger . error ( err_msg ) END If response status for create outage ticket is not any of 200 , 409 , 471 , 472 or 473 : err_msg = ( f \"Error while creating outage ticket for device { service_number } that belongs to client \" f \" { client_id } : Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg ) END logger . info ( f \"Outage ticket for device { service_number } belonging to client { client_id } created!\" )","title":"Create Service Outage ticket for Ixia device"},{"location":"logging/services/hawkeye-outage-monitor/repositories/bruin_repository/get_open_outage_tickets/","text":"Get open Service Outage tickets for Ixia device get_outage_tickets is called to get any Service Outage ticket whose status is any of \"New\", \"InProgress\" or \"Draft\" for the Ixia device","title":"Get open outage tickets"},{"location":"logging/services/hawkeye-outage-monitor/repositories/bruin_repository/get_open_outage_tickets/#get-open-service-outage-tickets-for-ixia-device","text":"get_outage_tickets is called to get any Service Outage ticket whose status is any of \"New\", \"InProgress\" or \"Draft\" for the Ixia device","title":"Get open Service Outage tickets for Ixia device"},{"location":"logging/services/hawkeye-outage-monitor/repositories/bruin_repository/get_outage_tickets/","text":"Get Service Outage tickets for Ixia device get_tickets is called to get any ticket whose ticket topic is \"VOO\" for the Ixia device","title":"Get outage tickets"},{"location":"logging/services/hawkeye-outage-monitor/repositories/bruin_repository/get_outage_tickets/#get-service-outage-tickets-for-ixia-device","text":"get_tickets is called to get any ticket whose ticket topic is \"VOO\" for the Ixia device","title":"Get Service Outage tickets for Ixia device"},{"location":"logging/services/hawkeye-outage-monitor/repositories/bruin_repository/get_ticket_details/","text":"Get ticket details logger . info ( f \"Getting details of ticket { ticket_id } from Bruin...\" ) If there's an error while asking for the data to the bruin-bridge : err_msg = f \"An error occurred when requesting ticket details from Bruin API for ticket { ticket_id } -> { e } \" [ ... ] logger . error ( err_msg ) END logger . info ( f \"Got details of ticket { ticket_id } from Bruin!\" ) If response status for get Hawkeye's customer cache is not ok, or the cache is still building: err_msg = ( f \"Error while retrieving details of ticket { ticket_id } in \" f \" { self . _config . ENVIRONMENT_NAME . upper () } environment: \" f \"Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg ) END","title":"Get ticket details"},{"location":"logging/services/hawkeye-outage-monitor/repositories/bruin_repository/get_ticket_details/#get-ticket-details","text":"logger . info ( f \"Getting details of ticket { ticket_id } from Bruin...\" ) If there's an error while asking for the data to the bruin-bridge : err_msg = f \"An error occurred when requesting ticket details from Bruin API for ticket { ticket_id } -> { e } \" [ ... ] logger . error ( err_msg ) END logger . info ( f \"Got details of ticket { ticket_id } from Bruin!\" ) If response status for get Hawkeye's customer cache is not ok, or the cache is still building: err_msg = ( f \"Error while retrieving details of ticket { ticket_id } in \" f \" { self . _config . ENVIRONMENT_NAME . upper () } environment: \" f \"Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg ) END","title":"Get ticket details"},{"location":"logging/services/hawkeye-outage-monitor/repositories/bruin_repository/get_tickets/","text":"Get tickets If no service number was specified: logger . info ( f \"Getting all tickets with any status of { ticket_statuses } , with ticket topic \" f \" { ticket_topic } and belonging to client { client_id } from Bruin...\" ) Otherwise: logger . info ( f \"Getting all tickets with any status of { ticket_statuses } , with ticket topic \" f \" { ticket_topic } , service number { service_number } and belonging to client { client_id } from Bruin...\" ) If there's an error while asking for the data to the bruin-bridge : err_msg = ( f \"An error occurred when requesting tickets from Bruin API with any status of { ticket_statuses } , \" f \"with ticket topic { ticket_topic } and belonging to client { client_id } -> { e } \" ) [ ... ] logger . error ( err_msg ) END If response status for get tickets is not ok: If no service number was specified: err_msg = ( f \"Error while retrieving tickets with any status of { ticket_statuses } , with ticket topic \" f \" { ticket_topic } and belonging to client { client_id } in \" f \" { self . _config . ENVIRONMENT_NAME . upper () } environment: \" f \"Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg ) Otherwise: err_msg = ( f \"Error while retrieving tickets with any status of { ticket_statuses } , with ticket topic \" f \" { ticket_topic } , service number { service_number } and belonging to client { client_id } in \" f \" { self . _config . ENVIRONMENT_NAME . upper () } environment: \" f \"Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg ) END If no service number was specified: logger . info ( f \"Got all tickets with any status of { ticket_statuses } , with ticket topic \" f \" { ticket_topic } and belonging to client { client_id } from Bruin!\" ) Otherwise: logger . info ( f \"Got all tickets with any status of { ticket_statuses } , with ticket topic \" f \" { ticket_topic } , service number { service_number } and belonging to client \" f \" { client_id } from Bruin!\" )","title":"Get tickets"},{"location":"logging/services/hawkeye-outage-monitor/repositories/bruin_repository/get_tickets/#get-tickets","text":"If no service number was specified: logger . info ( f \"Getting all tickets with any status of { ticket_statuses } , with ticket topic \" f \" { ticket_topic } and belonging to client { client_id } from Bruin...\" ) Otherwise: logger . info ( f \"Getting all tickets with any status of { ticket_statuses } , with ticket topic \" f \" { ticket_topic } , service number { service_number } and belonging to client { client_id } from Bruin...\" ) If there's an error while asking for the data to the bruin-bridge : err_msg = ( f \"An error occurred when requesting tickets from Bruin API with any status of { ticket_statuses } , \" f \"with ticket topic { ticket_topic } and belonging to client { client_id } -> { e } \" ) [ ... ] logger . error ( err_msg ) END If response status for get tickets is not ok: If no service number was specified: err_msg = ( f \"Error while retrieving tickets with any status of { ticket_statuses } , with ticket topic \" f \" { ticket_topic } and belonging to client { client_id } in \" f \" { self . _config . ENVIRONMENT_NAME . upper () } environment: \" f \"Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg ) Otherwise: err_msg = ( f \"Error while retrieving tickets with any status of { ticket_statuses } , with ticket topic \" f \" { ticket_topic } , service number { service_number } and belonging to client { client_id } in \" f \" { self . _config . ENVIRONMENT_NAME . upper () } environment: \" f \"Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg ) END If no service number was specified: logger . info ( f \"Got all tickets with any status of { ticket_statuses } , with ticket topic \" f \" { ticket_topic } and belonging to client { client_id } from Bruin!\" ) Otherwise: logger . info ( f \"Got all tickets with any status of { ticket_statuses } , with ticket topic \" f \" { ticket_topic } , service number { service_number } and belonging to client \" f \" { client_id } from Bruin!\" )","title":"Get tickets"},{"location":"logging/services/hawkeye-outage-monitor/repositories/bruin_repository/open_ticket/","text":"Re-Open ticket task for Ixia device logger . info ( f \"Opening ticket { ticket_id } (affected detail ID: { detail_id } )...\" ) If there's an error while asking for the data to the bruin-bridge : err_msg = f \"An error occurred when opening outage ticket { ticket_id } -> { e } \" [ ... ] logger . error ( err_msg ) END logger . info ( f \"Ticket { ticket_id } opened!\" ) If response status for re-open task for Ixia device is not ok: err_msg = ( f \"Error while opening outage ticket { ticket_id } in \" f \" { self . _config . ENVIRONMENT_NAME . upper () } environment: \" f \"Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg ) END","title":"Open ticket"},{"location":"logging/services/hawkeye-outage-monitor/repositories/bruin_repository/open_ticket/#re-open-ticket-task-for-ixia-device","text":"logger . info ( f \"Opening ticket { ticket_id } (affected detail ID: { detail_id } )...\" ) If there's an error while asking for the data to the bruin-bridge : err_msg = f \"An error occurred when opening outage ticket { ticket_id } -> { e } \" [ ... ] logger . error ( err_msg ) END logger . info ( f \"Ticket { ticket_id } opened!\" ) If response status for re-open task for Ixia device is not ok: err_msg = ( f \"Error while opening outage ticket { ticket_id } in \" f \" { self . _config . ENVIRONMENT_NAME . upper () } environment: \" f \"Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg ) END","title":"Re-Open ticket task for Ixia device"},{"location":"logging/services/hawkeye-outage-monitor/repositories/bruin_repository/resolve_ticket/","text":"Resolve ticket task for Ixia device logger . info ( f \"Resolving ticket { ticket_id } (affected detail ID: { detail_id } )...\" ) If there's an error while asking for the data to the bruin-bridge : err_msg = f \"An error occurred when resolving ticket { ticket_id } -> { e } \" [ ... ] logger . error ( err_msg ) END logger . info ( f \"Ticket { ticket_id } resolved!\" ) If response status for unpause ticket task is not ok: err_msg = ( f \"Error while resolving ticket { ticket_id } in { self . _config . ENVIRONMENT_NAME . upper () } \" f \"environment: Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg )","title":"Resolve ticket"},{"location":"logging/services/hawkeye-outage-monitor/repositories/bruin_repository/resolve_ticket/#resolve-ticket-task-for-ixia-device","text":"logger . info ( f \"Resolving ticket { ticket_id } (affected detail ID: { detail_id } )...\" ) If there's an error while asking for the data to the bruin-bridge : err_msg = f \"An error occurred when resolving ticket { ticket_id } -> { e } \" [ ... ] logger . error ( err_msg ) END logger . info ( f \"Ticket { ticket_id } resolved!\" ) If response status for unpause ticket task is not ok: err_msg = ( f \"Error while resolving ticket { ticket_id } in { self . _config . ENVIRONMENT_NAME . upper () } \" f \"environment: Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg )","title":"Resolve ticket task for Ixia device"},{"location":"logging/services/hawkeye-outage-monitor/repositories/bruin_repository/unpause_ticket_detail/","text":"Unpause ticket task for Ixia device logger . info ( f \"Unpausing detail { detail_id } (serial { service_number } ) of ticket { ticket_id } ...\" ) If there's an error while asking for the data to the bruin-bridge : err_msg = ( f \"An error occurred when unpausing detail { detail_id } (serial { service_number } ) of ticket { ticket_id } . \" f \"Error: { e } \" ) [ ... ] logger . error ( err_msg ) END If response status for unpause ticket task is ok: logger . info ( f \"Detail { detail_id } (serial { service_number } ) of ticket { ticket_id } was unpaused!\" ) Otherwise: err_msg = ( f \"Error while unpausing detail { detail_id } (serial { service_number } ) of ticket { ticket_id } in \" f \" { self . _config . ENVIRONMENT_NAME . upper () } environment. \" f \"Error: Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg )","title":"Unpause ticket detail"},{"location":"logging/services/hawkeye-outage-monitor/repositories/bruin_repository/unpause_ticket_detail/#unpause-ticket-task-for-ixia-device","text":"logger . info ( f \"Unpausing detail { detail_id } (serial { service_number } ) of ticket { ticket_id } ...\" ) If there's an error while asking for the data to the bruin-bridge : err_msg = ( f \"An error occurred when unpausing detail { detail_id } (serial { service_number } ) of ticket { ticket_id } . \" f \"Error: { e } \" ) [ ... ] logger . error ( err_msg ) END If response status for unpause ticket task is ok: logger . info ( f \"Detail { detail_id } (serial { service_number } ) of ticket { ticket_id } was unpaused!\" ) Otherwise: err_msg = ( f \"Error while unpausing detail { detail_id } (serial { service_number } ) of ticket { ticket_id } in \" f \" { self . _config . ENVIRONMENT_NAME . upper () } environment. \" f \"Error: Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg )","title":"Unpause ticket task for Ixia device"},{"location":"logging/services/hawkeye-outage-monitor/repositories/customer_cache_repository/get_cache/","text":"Get Hawkeye's customer cache logger . info ( f \"Getting customer cache for Hawkeye...\" ) If there's an error while asking for the data to the hawkeye-customer-cache service: err_msg = f \"An error occurred when requesting customer cache -> { e } \" [ ... ] logger . error ( err_msg ) END If response status for get Hawkeye's customer cache is not ok, or the cache is still building: err_msg = response_body [ ... ] logger . error ( err_msg ) END logger . info ( f \"Got customer cache for Hawkeye!\" )","title":"Get cache"},{"location":"logging/services/hawkeye-outage-monitor/repositories/customer_cache_repository/get_cache/#get-hawkeyes-customer-cache","text":"logger . info ( f \"Getting customer cache for Hawkeye...\" ) If there's an error while asking for the data to the hawkeye-customer-cache service: err_msg = f \"An error occurred when requesting customer cache -> { e } \" [ ... ] logger . error ( err_msg ) END If response status for get Hawkeye's customer cache is not ok, or the cache is still building: err_msg = response_body [ ... ] logger . error ( err_msg ) END logger . info ( f \"Got customer cache for Hawkeye!\" )","title":"Get Hawkeye's customer cache"},{"location":"logging/services/hawkeye-outage-monitor/repositories/customer_cache_repository/get_cache_for_outage_monitoring/","text":"Get Hawkeye's customer cache for outage monitoring get_cache is called to get the set of Ixia devices contacted in the last 7 days","title":"Get cache for outage monitoring"},{"location":"logging/services/hawkeye-outage-monitor/repositories/customer_cache_repository/get_cache_for_outage_monitoring/#get-hawkeyes-customer-cache-for-outage-monitoring","text":"get_cache is called to get the set of Ixia devices contacted in the last 7 days","title":"Get Hawkeye's customer cache for outage monitoring"},{"location":"logging/services/hawkeye-outage-monitor/repositories/hawkeye_repository/get_probes/","text":"Get Ixia devices' current state logger . info ( f \"Getting all probes from Hawkeye...\" ) If there's an error while asking for the data to the hawkeye-bridge : err_msg = f \"An error occurred when requesting all probes from Hawkeye -> { e } \" [ ... ] logger . error ( err_msg ) END If response status for get Ixia devices' current state is not ok: err_msg = f \"Error while retrieving probes: Error { response_status } - { response_body } \" [ ... ] logger . error ( err_msg ) END logger . info ( \"Got all probes from Hawkeye!\" )","title":"Get probes"},{"location":"logging/services/hawkeye-outage-monitor/repositories/hawkeye_repository/get_probes/#get-ixia-devices-current-state","text":"logger . info ( f \"Getting all probes from Hawkeye...\" ) If there's an error while asking for the data to the hawkeye-bridge : err_msg = f \"An error occurred when requesting all probes from Hawkeye -> { e } \" [ ... ] logger . error ( err_msg ) END If response status for get Ixia devices' current state is not ok: err_msg = f \"Error while retrieving probes: Error { response_status } - { response_body } \" [ ... ] logger . error ( err_msg ) END logger . info ( \"Got all probes from Hawkeye!\" )","title":"Get Ixia devices' current state"},{"location":"logging/services/intermapper-outage-monitor/actions/_autoresolve_ticket/","text":"Autoresolve ticket logger . info ( \"Starting the autoresolve process\" ) get_ticket_basic_info If response status for get tickets basic info is not ok: logger . warning ( f \"Bad status calling to get ticket basic info for client id: { client_id } .\" f \"Skipping autoresolve ticket ...\" ) logger . info ( f \"Found { len ( tickets_body ) } tickets for service number { service_number } from bruin: { tickets_body } \" ) For ticket in tickets: If current condition has already been reported on the ticket: logger . info ( f \"Current condition has already been reported on ticket id { ticket_id } . \" f \"Skipping append note to ticket...\" ) Else: logger . info ( f \"Posting InterMapper UP note to task of ticket id { ticket_id } \" f \"related to service number { service_number } ...\" ) _append_intermapper_up_note If response status for append InterMapper UP note is not ok: logger . warning ( f \"Bad status calling to append intermapper note to ticket id: { ticket_id } .\" f \"Skipping autoresolve ticket ....\" ) END get_tickets If response status for get tickets is not ok: logger . warning ( f \"Bad status calling to get ticket for client id: { client_id } and \" f \"ticket id: { ticket_id } . Skipping autoresolve ticket ...\" ) END If there's no ticket data: logger . info ( f \"Ticket { ticket_id } couldn't be found in Bruin. Skipping autoresolve...\" ) Continue with next ticket logger . info ( f \"Product category of ticket { ticket_id } from bruin is { product_category } \" ) If ticket's product category is not whitelisted: logger . info ( f \"At least one product category of ticket { ticket_id } from the \" f \"following list is not one of the whitelisted categories for \" f \"auto-resolve: { product_category } . Skipping autoresolve ...\" ) Continue with next ticket logger . info ( f \"Checking to see if ticket { ticket_id } can be autoresolved\" ) get_ticket_details If response status for get ticket details is not ok: logger . warning ( f \"Bad status calling get ticket details to ticket id: { ticket_id } . Skipping autoresolve ...\" ) END If last outage hasn't been detected recently: logger . info ( f \"Edge has been in outage state for a long time, so detail { ticket_detail_id } \" f \"(service number { service_number } ) of ticket { ticket_id } will not be autoresolved. Skipping \" f \"autoresolve...\" ) Continue with next ticket If max auto-resolves threshold has been exceeded: logger . info ( f \"Limit to autoresolve detail { ticket_detail_id } (service number { service_number } ) \" f \"of ticket { ticket_id } has been maxed out already. \" \"Skipping autoresolve...\" ) Continue with next ticket If ticket task is resolved already: logger . info ( f \"Detail { ticket_detail_id } (service number { service_number } ) of ticket { ticket_id } is already \" \"resolved. Skipping autoresolve...\" ) Continue with next ticket If environment is not PRODUCTION : logger . info ( f \"Skipping autoresolve for service number { service_number } \" f \"since the current environment is not production\" ) Continue with next ticket unpause_ticket_detail resolve_ticket If response status for resolve ticket is not ok: logger . warning ( f \"Bad status calling to resolve ticket: { ticket_id } . Skipping autoresolve ...\" ) END logger . info ( f \"Outage ticket { ticket_id } for service_number { service_number } was autoresolved through InterMapper \" f \"emails. Ticket details at https://app.bruin.com/t/ { ticket_id } .\" ) append_autoresolve_note_to_ticket logger . info ( f \"Detail { ticket_detail_id } (service number { service_number } ) of ticket { ticket_id } was autoresolved!\" ) _remove_job_for_autoresolved_task ( HNOC Investigate queue) _remove_job_for_autoresolved_task ( IPA Investigate queue)","title":" autoresolve ticket"},{"location":"logging/services/intermapper-outage-monitor/actions/_autoresolve_ticket/#autoresolve-ticket","text":"logger . info ( \"Starting the autoresolve process\" ) get_ticket_basic_info If response status for get tickets basic info is not ok: logger . warning ( f \"Bad status calling to get ticket basic info for client id: { client_id } .\" f \"Skipping autoresolve ticket ...\" ) logger . info ( f \"Found { len ( tickets_body ) } tickets for service number { service_number } from bruin: { tickets_body } \" ) For ticket in tickets: If current condition has already been reported on the ticket: logger . info ( f \"Current condition has already been reported on ticket id { ticket_id } . \" f \"Skipping append note to ticket...\" ) Else: logger . info ( f \"Posting InterMapper UP note to task of ticket id { ticket_id } \" f \"related to service number { service_number } ...\" ) _append_intermapper_up_note If response status for append InterMapper UP note is not ok: logger . warning ( f \"Bad status calling to append intermapper note to ticket id: { ticket_id } .\" f \"Skipping autoresolve ticket ....\" ) END get_tickets If response status for get tickets is not ok: logger . warning ( f \"Bad status calling to get ticket for client id: { client_id } and \" f \"ticket id: { ticket_id } . Skipping autoresolve ticket ...\" ) END If there's no ticket data: logger . info ( f \"Ticket { ticket_id } couldn't be found in Bruin. Skipping autoresolve...\" ) Continue with next ticket logger . info ( f \"Product category of ticket { ticket_id } from bruin is { product_category } \" ) If ticket's product category is not whitelisted: logger . info ( f \"At least one product category of ticket { ticket_id } from the \" f \"following list is not one of the whitelisted categories for \" f \"auto-resolve: { product_category } . Skipping autoresolve ...\" ) Continue with next ticket logger . info ( f \"Checking to see if ticket { ticket_id } can be autoresolved\" ) get_ticket_details If response status for get ticket details is not ok: logger . warning ( f \"Bad status calling get ticket details to ticket id: { ticket_id } . Skipping autoresolve ...\" ) END If last outage hasn't been detected recently: logger . info ( f \"Edge has been in outage state for a long time, so detail { ticket_detail_id } \" f \"(service number { service_number } ) of ticket { ticket_id } will not be autoresolved. Skipping \" f \"autoresolve...\" ) Continue with next ticket If max auto-resolves threshold has been exceeded: logger . info ( f \"Limit to autoresolve detail { ticket_detail_id } (service number { service_number } ) \" f \"of ticket { ticket_id } has been maxed out already. \" \"Skipping autoresolve...\" ) Continue with next ticket If ticket task is resolved already: logger . info ( f \"Detail { ticket_detail_id } (service number { service_number } ) of ticket { ticket_id } is already \" \"resolved. Skipping autoresolve...\" ) Continue with next ticket If environment is not PRODUCTION : logger . info ( f \"Skipping autoresolve for service number { service_number } \" f \"since the current environment is not production\" ) Continue with next ticket unpause_ticket_detail resolve_ticket If response status for resolve ticket is not ok: logger . warning ( f \"Bad status calling to resolve ticket: { ticket_id } . Skipping autoresolve ...\" ) END logger . info ( f \"Outage ticket { ticket_id } for service_number { service_number } was autoresolved through InterMapper \" f \"emails. Ticket details at https://app.bruin.com/t/ { ticket_id } .\" ) append_autoresolve_note_to_ticket logger . info ( f \"Detail { ticket_detail_id } (service number { service_number } ) of ticket { ticket_id } was autoresolved!\" ) _remove_job_for_autoresolved_task ( HNOC Investigate queue) _remove_job_for_autoresolved_task ( IPA Investigate queue)","title":"Autoresolve ticket"},{"location":"logging/services/intermapper-outage-monitor/actions/_create_outage_ticket/","text":"Create outage ticket logger . info ( f \"Attempting outage ticket creation for client_id { client_id } and service_number { service_number } \" ) If environment is not PRODUCTION : logger . info ( f \"No outage ticket will be created for client_id { client_id } and circuit_id { circuit_id } \" f \"since the current environment is not production\" ) END create_outage_ticket logger . info ( f \"Bruin response for ticket creation for service number { service_number } : { outage_ticket_response } \" ) If response status for ticket creation is ok: logger . info ( f \"Successfully created outage ticket with ticket_id { ticket_id } \" ) If response status for ticket creation is a Bruin custom status ( 409 , 472 or 473 ): logger . info ( f \"Ticket for service number { service_number } already exists with ticket_id { ticket_id } .\" f \"Status returned was { outage_ticket_status } \" ) If response status for ticket creation is 409 : logger . info ( f \"In Progress ticket exists for location of service number { service_number } \" ) If response status for ticket creation is 472 : logger . info ( f \"Resolved ticket exists for service number { service_number } \" ) If response status for ticket creation is 473 : logger . info ( f \"Resolved ticket exists for location of service number { service_number \") If response status for get ticket details is not ok: logger . warning ( f \"Bad status calling get ticket details to ticket id: { ticket_id } . Skipping append note to ticket...\" ) If current condition has already been reported on the ticket: logger . info ( f \"Current condition has already been reported on ticket id { ticket_id } . \" f \"Skipping append note to ticket...\" ) If additional data exists in the DRI system for service number: logger . info ( f \"Appending InterMapper note to ticket id { ticket_id } with dri parameters: \" f \" { dri_parameters } \" ) append_dri_note If response status for append DRI note to ticket is not ok: logger . warning ( f \"Bad status calling append dri note. Skipping append note to ticket...\" ) Otherwise: END Otherwise: logger . info ( f \"Appending InterMapper note to ticket id { ticket_id } \" ) append_intermapper_note If response status of append InterMapper note is not ok: logger . warning ( f \"Bad status calling append intermapper note. Skipping append note to ticket...\" ) END If device should be forwarded to the IPA Investigate work queue: _schedule_forward_to_queue ( IPA Investigate queue) _schedule_forward_to_queue ( HNOC Investigate queue)","title":" create outage ticket"},{"location":"logging/services/intermapper-outage-monitor/actions/_create_outage_ticket/#create-outage-ticket","text":"logger . info ( f \"Attempting outage ticket creation for client_id { client_id } and service_number { service_number } \" ) If environment is not PRODUCTION : logger . info ( f \"No outage ticket will be created for client_id { client_id } and circuit_id { circuit_id } \" f \"since the current environment is not production\" ) END create_outage_ticket logger . info ( f \"Bruin response for ticket creation for service number { service_number } : { outage_ticket_response } \" ) If response status for ticket creation is ok: logger . info ( f \"Successfully created outage ticket with ticket_id { ticket_id } \" ) If response status for ticket creation is a Bruin custom status ( 409 , 472 or 473 ): logger . info ( f \"Ticket for service number { service_number } already exists with ticket_id { ticket_id } .\" f \"Status returned was { outage_ticket_status } \" ) If response status for ticket creation is 409 : logger . info ( f \"In Progress ticket exists for location of service number { service_number } \" ) If response status for ticket creation is 472 : logger . info ( f \"Resolved ticket exists for service number { service_number } \" ) If response status for ticket creation is 473 : logger . info ( f \"Resolved ticket exists for location of service number { service_number \") If response status for get ticket details is not ok: logger . warning ( f \"Bad status calling get ticket details to ticket id: { ticket_id } . Skipping append note to ticket...\" ) If current condition has already been reported on the ticket: logger . info ( f \"Current condition has already been reported on ticket id { ticket_id } . \" f \"Skipping append note to ticket...\" ) If additional data exists in the DRI system for service number: logger . info ( f \"Appending InterMapper note to ticket id { ticket_id } with dri parameters: \" f \" { dri_parameters } \" ) append_dri_note If response status for append DRI note to ticket is not ok: logger . warning ( f \"Bad status calling append dri note. Skipping append note to ticket...\" ) Otherwise: END Otherwise: logger . info ( f \"Appending InterMapper note to ticket id { ticket_id } \" ) append_intermapper_note If response status of append InterMapper note is not ok: logger . warning ( f \"Bad status calling append intermapper note. Skipping append note to ticket...\" ) END If device should be forwarded to the IPA Investigate work queue: _schedule_forward_to_queue ( IPA Investigate queue) _schedule_forward_to_queue ( HNOC Investigate queue)","title":"Create outage ticket"},{"location":"logging/services/intermapper-outage-monitor/actions/_get_dri_parameters/","text":"Get DRI parameters get_serial_attribute_from_inventory If response status for get serial attribute from inventory is not ok: logger . warning ( f \"Bad status while getting inventory attributes' serial number for service number { service_number } \" f \"and client ID { client_id } . Skipping get DRI parameters...\" ) END If inventory attributes' Serial Number field is undefined: logger . warning ( f \"No inventory attributes' found for service number { service_number } and client ID { client_id } . \" \"Skipping get DRI parameters...\" ) END get_dri_parameters If response status for get DRI parameters is not ok: logger . warning ( f \"Bad status while getting DRI parameters based on inventory attributes' serial number \" f \" { attributes_serial } for service number { service_number } and client ID { client_id } . \" f \"Skipping get DRI parameters...\" ) END","title":" get dri parameters"},{"location":"logging/services/intermapper-outage-monitor/actions/_get_dri_parameters/#get-dri-parameters","text":"get_serial_attribute_from_inventory If response status for get serial attribute from inventory is not ok: logger . warning ( f \"Bad status while getting inventory attributes' serial number for service number { service_number } \" f \"and client ID { client_id } . Skipping get DRI parameters...\" ) END If inventory attributes' Serial Number field is undefined: logger . warning ( f \"No inventory attributes' found for service number { service_number } and client ID { client_id } . \" \"Skipping get DRI parameters...\" ) END get_dri_parameters If response status for get DRI parameters is not ok: logger . warning ( f \"Bad status while getting DRI parameters based on inventory attributes' serial number \" f \" { attributes_serial } for service number { service_number } and client ID { client_id } . \" f \"Skipping get DRI parameters...\" ) END","title":"Get DRI parameters"},{"location":"logging/services/intermapper-outage-monitor/actions/_intermapper_monitoring_process/","text":"Intermapper monitoring process logger . info ( f 'Processing all unread email from { self . _config . INTERMAPPER_CONFIG [ \"inbox_email\" ] } ' ) get_unread_emails If response status of getting unread emails is not ok: logger . warning ( f \"Bad status calling to get unread emails. Skipping intermapper monitoring process...\" ) END Group e-mails by Circuit ID in batches. For every batch of e-mails: _process_email_batch logger . info ( f 'Finished processing unread emails from { self . _config . INTERMAPPER_CONFIG [ \"inbox_email\" ] } . ' f \"Elapsed time: { round (( stop - start ) / 60 , 2 ) } minutes\" )","title":" intermapper monitoring process"},{"location":"logging/services/intermapper-outage-monitor/actions/_intermapper_monitoring_process/#intermapper-monitoring-process","text":"logger . info ( f 'Processing all unread email from { self . _config . INTERMAPPER_CONFIG [ \"inbox_email\" ] } ' ) get_unread_emails If response status of getting unread emails is not ok: logger . warning ( f \"Bad status calling to get unread emails. Skipping intermapper monitoring process...\" ) END Group e-mails by Circuit ID in batches. For every batch of e-mails: _process_email_batch logger . info ( f 'Finished processing unread emails from { self . _config . INTERMAPPER_CONFIG [ \"inbox_email\" ] } . ' f \"Elapsed time: { round (( stop - start ) / 60 , 2 ) } minutes\" )","title":"Intermapper monitoring process"},{"location":"logging/services/intermapper-outage-monitor/actions/_mark_email_as_read/","text":"Mark email as read mark_email_as_read If response status for mark email as read is not ok: logger . error ( f \"Could not mark email with msg_uid: { msg_uid } as read\" )","title":" mark email as read"},{"location":"logging/services/intermapper-outage-monitor/actions/_mark_email_as_read/#mark-email-as-read","text":"mark_email_as_read If response status for mark email as read is not ok: logger . error ( f \"Could not mark email with msg_uid: { msg_uid } as read\" )","title":"Mark email as read"},{"location":"logging/services/intermapper-outage-monitor/actions/_process_email/","text":"Process E-mail If message is undefined or its UID is -1 : logger . error ( f \"Invalid message: { email } \" ) END logger . info ( f \"Processing email with msg_uid: { msg_uid } and subject: { subject } \" ) If e-mail represents an UP event: logger . info ( f 'Event from InterMapper was { parsed_email_dict [ \"event\" ] } , there is no need to create a new ticket\" ) _autoresolve_ticket If e-mail represents a DOWN event: logger . info ( f 'Event: { parsed_email_dict [ \"event\" ] } - ' f 'Condition: { parsed_email_dict [ \"condition\" ] } - ' f 'Document: { parsed_email_dict [ \"document\" ] } ' ) If device is a PIAB: logger . info ( f \"The probe type from Intermapper is { parsed_email_dict [ 'probe_type' ] } .\" f \"Attempting to get additional parameters from DRI...\" ) _get_dri_parameters _create_outage_ticket If e-mail represents any other kind of event: logger . info ( f 'Event from InterMapper was { parsed_email_dict [ \"event\" ] } , ' f \"so no further action is needs to be taken\" ) If e-mail was processed successfully and environment is PRODUCTION : _mark_email_as_read If event was processed successfully: logger . info ( f \"Processed email: { msg_uid } \" ) Otherwise: logger . error ( f \"Email with msg_uid: { msg_uid } and subject: { subject } \" f \"related to service number: { service_number } could not be processed\" )","title":" process email"},{"location":"logging/services/intermapper-outage-monitor/actions/_process_email/#process-e-mail","text":"If message is undefined or its UID is -1 : logger . error ( f \"Invalid message: { email } \" ) END logger . info ( f \"Processing email with msg_uid: { msg_uid } and subject: { subject } \" ) If e-mail represents an UP event: logger . info ( f 'Event from InterMapper was { parsed_email_dict [ \"event\" ] } , there is no need to create a new ticket\" ) _autoresolve_ticket If e-mail represents a DOWN event: logger . info ( f 'Event: { parsed_email_dict [ \"event\" ] } - ' f 'Condition: { parsed_email_dict [ \"condition\" ] } - ' f 'Document: { parsed_email_dict [ \"document\" ] } ' ) If device is a PIAB: logger . info ( f \"The probe type from Intermapper is { parsed_email_dict [ 'probe_type' ] } .\" f \"Attempting to get additional parameters from DRI...\" ) _get_dri_parameters _create_outage_ticket If e-mail represents any other kind of event: logger . info ( f 'Event from InterMapper was { parsed_email_dict [ \"event\" ] } , ' f \"so no further action is needs to be taken\" ) If e-mail was processed successfully and environment is PRODUCTION : _mark_email_as_read If event was processed successfully: logger . info ( f \"Processed email: { msg_uid } \" ) Otherwise: logger . error ( f \"Email with msg_uid: { msg_uid } and subject: { subject } \" f \"related to service number: { service_number } could not be processed\" )","title":"Process E-mail"},{"location":"logging/services/intermapper-outage-monitor/actions/_process_email_batch/","text":"Process E-mail batch logger . info ( f \"Processing { len ( emails ) } email(s) with circuit ID { circuit_id } ...\" ) If Circuit ID is undefined or Circuit ID is SD-WAN : For each email in batch: mark email as read logger . info ( f \"Invalid circuit_id. Skipping emails with circuit_id { circuit_id } ...\" ) END get_service_number_by_circuit_id If response status for call to get inventory by circuit ID is not ok: logger . error ( f \"Failed to get service number by circuit ID. Skipping emails with circuit_id { circuit_id } ...\" ) END If status = 204: logger . error ( f \"Bruin returned a 204 when getting the service number for circuit_id { circuit_id } . \" f \"Marking all emails with this circuit_id as read\" ) For each email in batch: If environment is PRODUCTION : mark email as read END For email in batch: _process_email logger . info ( f \"Finished processing all emails with circuit_id { circuit_id } !\" )","title":" process email batch"},{"location":"logging/services/intermapper-outage-monitor/actions/_process_email_batch/#process-e-mail-batch","text":"logger . info ( f \"Processing { len ( emails ) } email(s) with circuit ID { circuit_id } ...\" ) If Circuit ID is undefined or Circuit ID is SD-WAN : For each email in batch: mark email as read logger . info ( f \"Invalid circuit_id. Skipping emails with circuit_id { circuit_id } ...\" ) END get_service_number_by_circuit_id If response status for call to get inventory by circuit ID is not ok: logger . error ( f \"Failed to get service number by circuit ID. Skipping emails with circuit_id { circuit_id } ...\" ) END If status = 204: logger . error ( f \"Bruin returned a 204 when getting the service number for circuit_id { circuit_id } . \" f \"Marking all emails with this circuit_id as read\" ) For each email in batch: If environment is PRODUCTION : mark email as read END For email in batch: _process_email logger . info ( f \"Finished processing all emails with circuit_id { circuit_id } !\" )","title":"Process E-mail batch"},{"location":"logging/services/intermapper-outage-monitor/actions/_remove_job_for_autoresolved_task/","text":"Remove job for autoresolved task If there is a job scheduled for the work queue: logger . info ( f \"Found job to forward to { target_queue } scheduled for autoresolved ticket { ticket_id } \" f \" related to serial number { serial_number } ! Removing...\" )","title":" remove job for autoresolved task"},{"location":"logging/services/intermapper-outage-monitor/actions/_remove_job_for_autoresolved_task/#remove-job-for-autoresolved-task","text":"If there is a job scheduled for the work queue: logger . info ( f \"Found job to forward to { target_queue } scheduled for autoresolved ticket { ticket_id } \" f \" related to serial number { serial_number } ! Removing...\" )","title":"Remove job for autoresolved task"},{"location":"logging/services/intermapper-outage-monitor/actions/_schedule_forward_to_queue/","text":"Schedule forward to queue logger . info ( f \"Scheduling { target_queue } queue forwarding for ticket_id { ticket_id } and service number { serial_number } \" f \" to happen at timestamp: { forward_task_run_date } \" ) forward_ticket_to_queue","title":" schedule forward to queue"},{"location":"logging/services/intermapper-outage-monitor/actions/_schedule_forward_to_queue/#schedule-forward-to-queue","text":"logger . info ( f \"Scheduling { target_queue } queue forwarding for ticket_id { ticket_id } and service number { serial_number } \" f \" to happen at timestamp: { forward_task_run_date } \" ) forward_ticket_to_queue","title":"Schedule forward to queue"},{"location":"logging/services/intermapper-outage-monitor/actions/change_detail_work_queue/","text":"Change detail work queue change_detail_work_queue If response status for change detail work queue is ok: logger . info ( f \"Successfully forwarded ticket_id { ticket_id } and serial { serial_number } to { target_queue } queue.\" ) If target queue is HNOC Investigate : send_forward_email_milestone_notification If response for send forward email milestone notification is not ok: logger . error ( f \"Forward email related to service number { serial_number } could not be sent for ticket \" f \" { ticket_id } !\" ) Otherwise: logger . error ( f \"Failed to forward ticket_id { ticket_id } and \" f \"serial { serial_number } to { target_queue } queue due to bruin \" f \"returning { change_detail_work_queue_response } when attempting to forward to { target_queue } queue.\" )","title":"Change detail work queue"},{"location":"logging/services/intermapper-outage-monitor/actions/change_detail_work_queue/#change-detail-work-queue","text":"change_detail_work_queue If response status for change detail work queue is ok: logger . info ( f \"Successfully forwarded ticket_id { ticket_id } and serial { serial_number } to { target_queue } queue.\" ) If target queue is HNOC Investigate : send_forward_email_milestone_notification If response for send forward email milestone notification is not ok: logger . error ( f \"Forward email related to service number { serial_number } could not be sent for ticket \" f \" { ticket_id } !\" ) Otherwise: logger . error ( f \"Failed to forward ticket_id { ticket_id } and \" f \"serial { serial_number } to { target_queue } queue due to bruin \" f \"returning { change_detail_work_queue_response } when attempting to forward to { target_queue } queue.\" )","title":"Change detail work queue"},{"location":"logging/services/intermapper-outage-monitor/actions/forward_ticket_to_queue/","text":"Forward ticket to queue logger . info ( f \"Checking if ticket_id { ticket_id } for serial { serial_number } is resolved before \" f \"attempting to forward to { target_queue } queue...\" ) While there are retries left to try to forward to the work queue: change_detail_work_queue If the maximum number of retries was exceeded: logger . error ( f \"An error occurred while trying to forward ticket_id { ticket_id } for serial { serial_number } to\" f \" { target_queue } queue -> { e } \" )","title":"Forward ticket to queue"},{"location":"logging/services/intermapper-outage-monitor/actions/forward_ticket_to_queue/#forward-ticket-to-queue","text":"logger . info ( f \"Checking if ticket_id { ticket_id } for serial { serial_number } is resolved before \" f \"attempting to forward to { target_queue } queue...\" ) While there are retries left to try to forward to the work queue: change_detail_work_queue If the maximum number of retries was exceeded: logger . error ( f \"An error occurred while trying to forward ticket_id { ticket_id } for serial { serial_number } to\" f \" { target_queue } queue -> { e } \" )","title":"Forward ticket to queue"},{"location":"logging/services/intermapper-outage-monitor/actions/start_intermapper_outage_monitoring/","text":"Start InterMapper Outage Monitoring logger . info ( \"Scheduling InterMapper Monitor job...\" ) If job should be executed on service start: logger . info ( \"InterMapper Monitor job is going to be executed immediately\" ) _intermapper_monitoring_process If there's a running job to monitor InterMapper events already: logger . info ( f \"Skipping start of InterMapper Monitoring job. Reason: { conflict } \" )","title":"Start intermapper outage monitoring"},{"location":"logging/services/intermapper-outage-monitor/actions/start_intermapper_outage_monitoring/#start-intermapper-outage-monitoring","text":"logger . info ( \"Scheduling InterMapper Monitor job...\" ) If job should be executed on service start: logger . info ( \"InterMapper Monitor job is going to be executed immediately\" ) _intermapper_monitoring_process If there's a running job to monitor InterMapper events already: logger . info ( f \"Skipping start of InterMapper Monitoring job. Reason: { conflict } \" )","title":"Start InterMapper Outage Monitoring"},{"location":"logging/services/intermapper-outage-monitor/app_entrypoint/app/","text":"App entrypoint logger . info ( f \"InterMapper Outage Monitor starting in { config . CURRENT_ENVIRONMENT } ...\" )","title":"App"},{"location":"logging/services/intermapper-outage-monitor/app_entrypoint/app/#app-entrypoint","text":"logger . info ( f \"InterMapper Outage Monitor starting in { config . CURRENT_ENVIRONMENT } ...\" )","title":"App entrypoint"},{"location":"logging/services/intermapper-outage-monitor/repositories/bruin_repository/append_autoresolve_note_to_ticket/","text":"Append autoresolve note to ticket append_note_to_ticket","title":"Append autoresolve note to ticket"},{"location":"logging/services/intermapper-outage-monitor/repositories/bruin_repository/append_autoresolve_note_to_ticket/#append-autoresolve-note-to-ticket","text":"append_note_to_ticket","title":"Append autoresolve note to ticket"},{"location":"logging/services/intermapper-outage-monitor/repositories/bruin_repository/append_dri_note/","text":"Append dri note append_note_to_ticket","title":"Append dri note"},{"location":"logging/services/intermapper-outage-monitor/repositories/bruin_repository/append_dri_note/#append-dri-note","text":"append_note_to_ticket","title":"Append dri note"},{"location":"logging/services/intermapper-outage-monitor/repositories/bruin_repository/append_intermapper_note/","text":"Append intermapper note append_note_to_ticket","title":"Append intermapper note"},{"location":"logging/services/intermapper-outage-monitor/repositories/bruin_repository/append_intermapper_note/#append-intermapper-note","text":"append_note_to_ticket","title":"Append intermapper note"},{"location":"logging/services/intermapper-outage-monitor/repositories/bruin_repository/append_intermapper_up_note/","text":"Append intermapper up note append_note_to_ticket","title":"Append intermapper up note"},{"location":"logging/services/intermapper-outage-monitor/repositories/bruin_repository/append_intermapper_up_note/#append-intermapper-up-note","text":"append_note_to_ticket","title":"Append intermapper up note"},{"location":"logging/services/intermapper-outage-monitor/repositories/bruin_repository/append_note_to_ticket/","text":"Append note to ticket logger . info ( f \"Appending note to ticket { ticket_id } ... Note contents: { note } \" ) If there's an error while posting the data to the bruin-bridge : err_msg = ( f \"An error occurred when appending a ticket note to ticket { ticket_id } . \" f \"Ticket note: { note } . Error: { e } \" ) [ ... ] logger . error ( err_msg ) END If response status for append note to ticket is not ok: err_msg = ( f \"Error while appending note to ticket { ticket_id } in \" f \" { self . _config . ENVIRONMENT_NAME . upper () } environment. Note was { note } . Error: \" f \"Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg ) Otherwise: logger . info ( f \"Note appended to ticket { ticket_id } !\" )","title":"Append note to ticket"},{"location":"logging/services/intermapper-outage-monitor/repositories/bruin_repository/append_note_to_ticket/#append-note-to-ticket","text":"logger . info ( f \"Appending note to ticket { ticket_id } ... Note contents: { note } \" ) If there's an error while posting the data to the bruin-bridge : err_msg = ( f \"An error occurred when appending a ticket note to ticket { ticket_id } . \" f \"Ticket note: { note } . Error: { e } \" ) [ ... ] logger . error ( err_msg ) END If response status for append note to ticket is not ok: err_msg = ( f \"Error while appending note to ticket { ticket_id } in \" f \" { self . _config . ENVIRONMENT_NAME . upper () } environment. Note was { note } . Error: \" f \"Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg ) Otherwise: logger . info ( f \"Note appended to ticket { ticket_id } !\" )","title":"Append note to ticket"},{"location":"logging/services/intermapper-outage-monitor/repositories/bruin_repository/change_detail_work_queue/","text":"Change detail work queue logger . info ( f \"Changing task result for ticket { ticket_id } for device { serial_number } to { task_result } ...\" ) If there's an error while posting the data to the bruin-bridge : err_msg = f \"An error occurred when changing task result for ticket { ticket_id } and serial { serial_number } \" [ ... ] logger . error ( err_msg ) END If response status for change detail work queue is ok: logger . info ( f \"Ticket { ticket_id } and serial { serial_number } task result changed to { task_result } successfully!\" ) Otherwise: err_msg = ( f \"Error while changing task result for ticket { ticket_id } and serial { serial_number } in \" f \" { self . _config . CURRENT_ENVIRONMENT . upper () } environment: \" f \"Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg )","title":"Change detail work queue"},{"location":"logging/services/intermapper-outage-monitor/repositories/bruin_repository/change_detail_work_queue/#change-detail-work-queue","text":"logger . info ( f \"Changing task result for ticket { ticket_id } for device { serial_number } to { task_result } ...\" ) If there's an error while posting the data to the bruin-bridge : err_msg = f \"An error occurred when changing task result for ticket { ticket_id } and serial { serial_number } \" [ ... ] logger . error ( err_msg ) END If response status for change detail work queue is ok: logger . info ( f \"Ticket { ticket_id } and serial { serial_number } task result changed to { task_result } successfully!\" ) Otherwise: err_msg = ( f \"Error while changing task result for ticket { ticket_id } and serial { serial_number } in \" f \" { self . _config . CURRENT_ENVIRONMENT . upper () } environment: \" f \"Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg )","title":"Change detail work queue"},{"location":"logging/services/intermapper-outage-monitor/repositories/bruin_repository/create_outage_ticket/","text":"Create outage ticket logger . info ( f \"Creating outage ticket for device { service_number } that belongs to client { client_id } ...\" ) If there's an error while posting the data to the bruin-bridge : err_msg = ( f \"An error occurred when creating outage ticket for device { service_number } belong to client\" f \" { client_id } -> { e } \" ) [ ... ] logger . error ( err_msg ) END logger . info ( f \"Outage ticket for device { service_number } that belongs to client { client_id } created!\" ) If response status for get serial attribute from inventory is not ok, or is 409 , 471 , 472 or 473 : err_msg = ( f \"Error while creating outage ticket for device { service_number } that belongs to client \" f \" { client_id } in { self . _config . ENVIRONMENT_NAME . upper () } environment: \" f \"Error { response_status } - { response_body } \" )","title":"Create outage ticket"},{"location":"logging/services/intermapper-outage-monitor/repositories/bruin_repository/create_outage_ticket/#create-outage-ticket","text":"logger . info ( f \"Creating outage ticket for device { service_number } that belongs to client { client_id } ...\" ) If there's an error while posting the data to the bruin-bridge : err_msg = ( f \"An error occurred when creating outage ticket for device { service_number } belong to client\" f \" { client_id } -> { e } \" ) [ ... ] logger . error ( err_msg ) END logger . info ( f \"Outage ticket for device { service_number } that belongs to client { client_id } created!\" ) If response status for get serial attribute from inventory is not ok, or is 409 , 471 , 472 or 473 : err_msg = ( f \"Error while creating outage ticket for device { service_number } that belongs to client \" f \" { client_id } in { self . _config . ENVIRONMENT_NAME . upper () } environment: \" f \"Error { response_status } - { response_body } \" )","title":"Create outage ticket"},{"location":"logging/services/intermapper-outage-monitor/repositories/bruin_repository/get_serial_attribute_from_inventory/","text":"Get serial attribute from inventory logger . info ( f \"Getting inventory attributes' serial number for service number { service_number } and client ID\" f \" { client_id } \" ) If there's an error while asking for the data to the bruin-bridge : err_msg = ( f \"Error while getting inventory attributes' serial number for service number { service_number } and \" f \"client ID { client_id } : { e } \" ) [ ... ] logger . error ( err_msg ) END If response status for get serial attribute from inventory is not ok: err_msg = ( f \"Error while getting inventory attributes' serial number for service number { service_number } and \" f \"client ID { client_id } in { self . _config . ENVIRONMENT_NAME . upper () } environment. Error: \" f \"Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg ) Otherwise: logger . info ( f \"Got inventory attributes' serial number for service number { service_number } and client ID \" f \" { client_id } \" )","title":"Get serial attribute from inventory"},{"location":"logging/services/intermapper-outage-monitor/repositories/bruin_repository/get_serial_attribute_from_inventory/#get-serial-attribute-from-inventory","text":"logger . info ( f \"Getting inventory attributes' serial number for service number { service_number } and client ID\" f \" { client_id } \" ) If there's an error while asking for the data to the bruin-bridge : err_msg = ( f \"Error while getting inventory attributes' serial number for service number { service_number } and \" f \"client ID { client_id } : { e } \" ) [ ... ] logger . error ( err_msg ) END If response status for get serial attribute from inventory is not ok: err_msg = ( f \"Error while getting inventory attributes' serial number for service number { service_number } and \" f \"client ID { client_id } in { self . _config . ENVIRONMENT_NAME . upper () } environment. Error: \" f \"Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg ) Otherwise: logger . info ( f \"Got inventory attributes' serial number for service number { service_number } and client ID \" f \" { client_id } \" )","title":"Get serial attribute from inventory"},{"location":"logging/services/intermapper-outage-monitor/repositories/bruin_repository/get_service_number_by_circuit_id/","text":"Get service number by circuit ID logger . info ( f \"Getting the translation to service number for circuit_id { circuit_id } \" ) If there's an error while asking for the data to the bruin-bridge : err_msg = f \"Getting the translation to service number for circuit_id { circuit_id } Error: { e } \" [ ... ] logger . error ( err_msg ) END If response status for get service number by circuit ID is not ok or is 204 : err_msg = ( f \"Getting the translation to service number for circuit_id { circuit_id } in \" f \" { self . _config . ENVIRONMENT_NAME . upper () } environment. Error: \" f \"Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg )","title":"Get service number by circuit id"},{"location":"logging/services/intermapper-outage-monitor/repositories/bruin_repository/get_service_number_by_circuit_id/#get-service-number-by-circuit-id","text":"logger . info ( f \"Getting the translation to service number for circuit_id { circuit_id } \" ) If there's an error while asking for the data to the bruin-bridge : err_msg = f \"Getting the translation to service number for circuit_id { circuit_id } Error: { e } \" [ ... ] logger . error ( err_msg ) END If response status for get service number by circuit ID is not ok or is 204 : err_msg = ( f \"Getting the translation to service number for circuit_id { circuit_id } in \" f \" { self . _config . ENVIRONMENT_NAME . upper () } environment. Error: \" f \"Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg )","title":"Get service number by circuit ID"},{"location":"logging/services/intermapper-outage-monitor/repositories/bruin_repository/get_ticket_basic_info/","text":"Get ticket basic info logger . info ( f \"Getting all tickets basic info with any status of { ticket_statuses } , with ticket topic \" f \"VOO, service number { service_number } and belonging to client { client_id } from Bruin...\" ) If there's an error while asking for the data to the bruin-bridge : err_msg = ( f \"An error occurred when requesting tickets basic info from Bruin API with any status\" f \" of { ticket_statuses } , with ticket topic VOO and belonging to client { client_id } -> { e } \" ) [ ... ] logger . error ( err_msg ) END If response status for get ticket basic info is not ok: err_msg = ( f \"Error while retrieving tickets basic info with any status of { ticket_statuses } , \" f \"with ticket topic VOO, service number { service_number } and belonging to client { client_id } in \" f \" { self . _config . ENVIRONMENT_NAME . upper () } environment: \" f \"Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg ) Otherwise: logger . info ( f \"Got all tickets basic info with any status of { ticket_statuses } , with ticket topic \" f \"VOO, service number { service_number } and belonging to client \" f \" { client_id } from Bruin!\" )","title":"Get ticket basic info"},{"location":"logging/services/intermapper-outage-monitor/repositories/bruin_repository/get_ticket_basic_info/#get-ticket-basic-info","text":"logger . info ( f \"Getting all tickets basic info with any status of { ticket_statuses } , with ticket topic \" f \"VOO, service number { service_number } and belonging to client { client_id } from Bruin...\" ) If there's an error while asking for the data to the bruin-bridge : err_msg = ( f \"An error occurred when requesting tickets basic info from Bruin API with any status\" f \" of { ticket_statuses } , with ticket topic VOO and belonging to client { client_id } -> { e } \" ) [ ... ] logger . error ( err_msg ) END If response status for get ticket basic info is not ok: err_msg = ( f \"Error while retrieving tickets basic info with any status of { ticket_statuses } , \" f \"with ticket topic VOO, service number { service_number } and belonging to client { client_id } in \" f \" { self . _config . ENVIRONMENT_NAME . upper () } environment: \" f \"Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg ) Otherwise: logger . info ( f \"Got all tickets basic info with any status of { ticket_statuses } , with ticket topic \" f \"VOO, service number { service_number } and belonging to client \" f \" { client_id } from Bruin!\" )","title":"Get ticket basic info"},{"location":"logging/services/intermapper-outage-monitor/repositories/bruin_repository/get_ticket_details/","text":"Get ticket details logger . info ( f \"Getting details of ticket { ticket_id } from Bruin...\" ) If there's an error while asking for the data to the bruin-bridge : err_msg = f \"An error occurred when requesting ticket details from Bruin API for ticket { ticket_id } -> { e } \" [ ... ] logger . error ( err_msg ) END logger . info ( f \"Got details of ticket { ticket_id } from Bruin!\" ) If response status for get ticket details is not ok: err_msg = ( f \"Error while retrieving details of ticket { ticket_id } in \" f \" { self . _config . ENVIRONMENT_NAME . upper () } environment: \" f \"Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg )","title":"Get ticket details"},{"location":"logging/services/intermapper-outage-monitor/repositories/bruin_repository/get_ticket_details/#get-ticket-details","text":"logger . info ( f \"Getting details of ticket { ticket_id } from Bruin...\" ) If there's an error while asking for the data to the bruin-bridge : err_msg = f \"An error occurred when requesting ticket details from Bruin API for ticket { ticket_id } -> { e } \" [ ... ] logger . error ( err_msg ) END logger . info ( f \"Got details of ticket { ticket_id } from Bruin!\" ) If response status for get ticket details is not ok: err_msg = ( f \"Error while retrieving details of ticket { ticket_id } in \" f \" { self . _config . ENVIRONMENT_NAME . upper () } environment: \" f \"Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg )","title":"Get ticket details"},{"location":"logging/services/intermapper-outage-monitor/repositories/bruin_repository/get_tickets/","text":"Get tickets logger . info ( f \"Getting all tickets of ticket id { ticket_id } from Bruin...\" ) If there's an error while asking for the data to the bruin-bridge : err_msg = f \"An error occurred when requesting all tickets of ticket id { ticket_id } from Bruin API -> { e } \" [ ... ] logger . error ( err_msg ) END If response status for get tickets is not ok: err_msg = ( f \"Error while retrieving all tickets of ticket id { ticket_id } in \" f \" { self . _config . ENVIRONMENT_NAME . upper () } environment: \" f \"Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg ) Otherwise: logger . info ( f \"Got all tickets of ticket id { ticket_id } from Bruin\" )","title":"Get tickets"},{"location":"logging/services/intermapper-outage-monitor/repositories/bruin_repository/get_tickets/#get-tickets","text":"logger . info ( f \"Getting all tickets of ticket id { ticket_id } from Bruin...\" ) If there's an error while asking for the data to the bruin-bridge : err_msg = f \"An error occurred when requesting all tickets of ticket id { ticket_id } from Bruin API -> { e } \" [ ... ] logger . error ( err_msg ) END If response status for get tickets is not ok: err_msg = ( f \"Error while retrieving all tickets of ticket id { ticket_id } in \" f \" { self . _config . ENVIRONMENT_NAME . upper () } environment: \" f \"Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg ) Otherwise: logger . info ( f \"Got all tickets of ticket id { ticket_id } from Bruin\" )","title":"Get tickets"},{"location":"logging/services/intermapper-outage-monitor/repositories/bruin_repository/post_notification_email_milestone/","text":"Post notification email milestone logger . info ( f \"Sending email for ticket id { ticket_id } , \" f \"service_number { service_number } \" f \"and notification type { notification_type } ...\" ) If there's an error while posting the data to the bruin-bridge : err_msg = ( f \"An error occurred when sending email for ticket id { ticket_id } , \" f \"service_number { service_number } \" f \"and notification type { notification_type } ...-> { e } \" ) [ ... ] logger . error ( err_msg ) END If response status for post notification email milestone is ok: logger . info ( f \"Email sent for ticket { ticket_id } , service number { service_number } \" f \"and notification type { notification_type } !\" ) Otherwise: err_msg = ( f \"Error while sending email for ticket id { ticket_id } , service_number { service_number } \" f \"and notification type { notification_type } in \" f \" { self . _config . CURRENT_ENVIRONMENT . upper () } environment: \" f \"Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg )","title":"Post notification email milestone"},{"location":"logging/services/intermapper-outage-monitor/repositories/bruin_repository/post_notification_email_milestone/#post-notification-email-milestone","text":"logger . info ( f \"Sending email for ticket id { ticket_id } , \" f \"service_number { service_number } \" f \"and notification type { notification_type } ...\" ) If there's an error while posting the data to the bruin-bridge : err_msg = ( f \"An error occurred when sending email for ticket id { ticket_id } , \" f \"service_number { service_number } \" f \"and notification type { notification_type } ...-> { e } \" ) [ ... ] logger . error ( err_msg ) END If response status for post notification email milestone is ok: logger . info ( f \"Email sent for ticket { ticket_id } , service number { service_number } \" f \"and notification type { notification_type } !\" ) Otherwise: err_msg = ( f \"Error while sending email for ticket id { ticket_id } , service_number { service_number } \" f \"and notification type { notification_type } in \" f \" { self . _config . CURRENT_ENVIRONMENT . upper () } environment: \" f \"Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg )","title":"Post notification email milestone"},{"location":"logging/services/intermapper-outage-monitor/repositories/bruin_repository/resolve_ticket/","text":"Resolve ticket logger . info ( f \"Resolving ticket { ticket_id } (affected detail ID: { detail_id } )...\" ) If there's an error while posting the data to the bruin-bridge : err_msg = f \"An error occurred when resolving ticket { ticket_id } -> { e } \" [ ... ] logger . error ( err_msg ) END logger . info ( f \"Ticket { ticket_id } resolved!\" ) If response status for resolve ticket is not ok: err_msg = ( f \"Error while resolving ticket { ticket_id } in \" f \" { self . _config . ENVIRONMENT_NAME . upper () } \" f \"environment: Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg )","title":"Resolve ticket"},{"location":"logging/services/intermapper-outage-monitor/repositories/bruin_repository/resolve_ticket/#resolve-ticket","text":"logger . info ( f \"Resolving ticket { ticket_id } (affected detail ID: { detail_id } )...\" ) If there's an error while posting the data to the bruin-bridge : err_msg = f \"An error occurred when resolving ticket { ticket_id } -> { e } \" [ ... ] logger . error ( err_msg ) END logger . info ( f \"Ticket { ticket_id } resolved!\" ) If response status for resolve ticket is not ok: err_msg = ( f \"Error while resolving ticket { ticket_id } in \" f \" { self . _config . ENVIRONMENT_NAME . upper () } \" f \"environment: Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg )","title":"Resolve ticket"},{"location":"logging/services/intermapper-outage-monitor/repositories/bruin_repository/send_forward_email_milestone_notification/","text":"Send forward email milestone notification post_notification_email_milestone","title":"Send forward email milestone notification"},{"location":"logging/services/intermapper-outage-monitor/repositories/bruin_repository/send_forward_email_milestone_notification/#send-forward-email-milestone-notification","text":"post_notification_email_milestone","title":"Send forward email milestone notification"},{"location":"logging/services/intermapper-outage-monitor/repositories/bruin_repository/unpause_ticket_detail/","text":"Unpause ticket detail logger . info ( f \"Unpausing detail { detail_id } (serial { service_number } ) of ticket { ticket_id } ...\" ) If there's an error while posting the data to the bruin-bridge : err_msg = ( f \"An error occurred when unpausing detail { detail_id } (serial { service_number } ) of ticket { ticket_id } . \" f \"Error: { e } \" ) [ ... ] logger . error ( err_msg ) END If response status for unpause ticket detail is not ok: err_msg = ( f \"Error while unpausing detail { detail_id } (serial { service_number } ) of ticket { ticket_id } in \" f \" { self . _config . CURRENT_ENVIRONMENT . upper () } environment. \" f \"Error: Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg ) Otherwise: logger . info ( f \"Detail { detail_id } (serial { service_number } ) of ticket { ticket_id } was unpaused!\" )","title":"Unpause ticket detail"},{"location":"logging/services/intermapper-outage-monitor/repositories/bruin_repository/unpause_ticket_detail/#unpause-ticket-detail","text":"logger . info ( f \"Unpausing detail { detail_id } (serial { service_number } ) of ticket { ticket_id } ...\" ) If there's an error while posting the data to the bruin-bridge : err_msg = ( f \"An error occurred when unpausing detail { detail_id } (serial { service_number } ) of ticket { ticket_id } . \" f \"Error: { e } \" ) [ ... ] logger . error ( err_msg ) END If response status for unpause ticket detail is not ok: err_msg = ( f \"Error while unpausing detail { detail_id } (serial { service_number } ) of ticket { ticket_id } in \" f \" { self . _config . CURRENT_ENVIRONMENT . upper () } environment. \" f \"Error: Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg ) Otherwise: logger . info ( f \"Detail { detail_id } (serial { service_number } ) of ticket { ticket_id } was unpaused!\" )","title":"Unpause ticket detail"},{"location":"logging/services/intermapper-outage-monitor/repositories/dri_repository/get_dri_parameters/","text":"Get DRI parameters logger . info ( f \"Getting DRI parameters of serial number { serial_number } \" ) If there's an error while asking for the data to the dri-bridge : err_msg = f \"An error occurred while getting DRI parameter for serial number { serial_number } . Error: { e } \" [ ... ] logger . error ( err_msg ) END If response status for get DRI parameters is not ok: err_msg = ( f \"Error while getting DRI parameter of serial number { serial_number } in \" f \" { self . _config . ENVIRONMENT_NAME . upper () } environment. Error: \" f \"Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg ) Otherwise: logger . info ( f \"Got DRI parameter of serial number { serial_number } !\" )","title":"Get dri parameters"},{"location":"logging/services/intermapper-outage-monitor/repositories/dri_repository/get_dri_parameters/#get-dri-parameters","text":"logger . info ( f \"Getting DRI parameters of serial number { serial_number } \" ) If there's an error while asking for the data to the dri-bridge : err_msg = f \"An error occurred while getting DRI parameter for serial number { serial_number } . Error: { e } \" [ ... ] logger . error ( err_msg ) END If response status for get DRI parameters is not ok: err_msg = ( f \"Error while getting DRI parameter of serial number { serial_number } in \" f \" { self . _config . ENVIRONMENT_NAME . upper () } environment. Error: \" f \"Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg ) Otherwise: logger . info ( f \"Got DRI parameter of serial number { serial_number } !\" )","title":"Get DRI parameters"},{"location":"logging/services/intermapper-outage-monitor/repositories/email_repository/get_unread_emails/","text":"Get unread emails logger . info ( f \"Getting the unread emails from the inbox of { email_account } sent from the users: \" f \" { email_filter } in the last { lookup_days } days\" ) If there's an error while asking for the data to the email-bridge : err_msg = f \"An error occurred while getting the unread emails from the inbox of { email_account } -> { e } \" [ ... ] logger . error ( err_msg ) END If response status for get unread emails is not ok: err_msg = ( f \"Error getting the unread emails from the inbox of { email_account } in \" f \" { self . _config . ENVIRONMENT_NAME . upper () } environment: \" f \"Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg ) Otherwise: logger . info ( f \"Got the unread emails from the inbox of { email_account } \" )","title":"Get unread emails"},{"location":"logging/services/intermapper-outage-monitor/repositories/email_repository/get_unread_emails/#get-unread-emails","text":"logger . info ( f \"Getting the unread emails from the inbox of { email_account } sent from the users: \" f \" { email_filter } in the last { lookup_days } days\" ) If there's an error while asking for the data to the email-bridge : err_msg = f \"An error occurred while getting the unread emails from the inbox of { email_account } -> { e } \" [ ... ] logger . error ( err_msg ) END If response status for get unread emails is not ok: err_msg = ( f \"Error getting the unread emails from the inbox of { email_account } in \" f \" { self . _config . ENVIRONMENT_NAME . upper () } environment: \" f \"Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg ) Otherwise: logger . info ( f \"Got the unread emails from the inbox of { email_account } \" )","title":"Get unread emails"},{"location":"logging/services/intermapper-outage-monitor/repositories/email_repository/mark_email_as_read/","text":"Mark email as read logger . info ( f \"Marking message { msg_uid } from the inbox of { email_account } as read\" ) If there's an error while posting the data to the email-bridge : err_msg = f \"An error occurred while marking message { msg_uid } as read -> { e } \" [ ... ] logger . error ( err_msg ) END If response status for mark email as read is not ok: err_msg = ( f \"Error marking message { msg_uid } as read in \" f \" { self . _config . ENVIRONMENT_NAME . upper () } environment: \" f \"Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg ) Otherwise: logger . info ( f \"Marked message { msg_uid } as read\" )","title":"Mark email as read"},{"location":"logging/services/intermapper-outage-monitor/repositories/email_repository/mark_email_as_read/#mark-email-as-read","text":"logger . info ( f \"Marking message { msg_uid } from the inbox of { email_account } as read\" ) If there's an error while posting the data to the email-bridge : err_msg = f \"An error occurred while marking message { msg_uid } as read -> { e } \" [ ... ] logger . error ( err_msg ) END If response status for mark email as read is not ok: err_msg = ( f \"Error marking message { msg_uid } as read in \" f \" { self . _config . ENVIRONMENT_NAME . upper () } environment: \" f \"Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg ) Otherwise: logger . info ( f \"Marked message { msg_uid } as read\" )","title":"Mark email as read"},{"location":"logging/services/last-contact-report/actions/alert/_alert_job/","text":"Run Last Contact Report job logger . info ( \"Requesting all edges with details for alert report\" ) VelocloudRepository::get_edges If an error took place while fetching edges across all VCOs: logger . warning ( \"Couldn't retrieve any edge from any of the VCOs. Report won't be sent.\" ) END For every edge: If edge was last contacted less than 30 days ago: logger . info ( f \"Time elapsed is less than 30 days for { serial_number } \" ) Continue with next edge Compose e-mail with edges last contacted more than or exactly 30 days ago Deliver e-mail logger . info ( \"Last Contact Report sent\" )","title":" alert job"},{"location":"logging/services/last-contact-report/actions/alert/_alert_job/#run-last-contact-report-job","text":"logger . info ( \"Requesting all edges with details for alert report\" ) VelocloudRepository::get_edges If an error took place while fetching edges across all VCOs: logger . warning ( \"Couldn't retrieve any edge from any of the VCOs. Report won't be sent.\" ) END For every edge: If edge was last contacted less than 30 days ago: logger . info ( f \"Time elapsed is less than 30 days for { serial_number } \" ) Continue with next edge Compose e-mail with edges last contacted more than or exactly 30 days ago Deliver e-mail logger . info ( \"Last Contact Report sent\" )","title":"Run Last Contact Report job"},{"location":"logging/services/last-contact-report/actions/alert/start_alert_job/","text":"Schedule Last Contact Report job logger . info ( \"Scheduled task: alert report process configured to run first day of each month\" ) If job should be executed on service start: logger . info ( f \"It will be executed now\" ) _alert_job","title":"Start alert job"},{"location":"logging/services/last-contact-report/actions/alert/start_alert_job/#schedule-last-contact-report-job","text":"logger . info ( \"Scheduled task: alert report process configured to run first day of each month\" ) If job should be executed on service start: logger . info ( f \"It will be executed now\" ) _alert_job","title":"Schedule Last Contact Report job"},{"location":"logging/services/last-contact-report/repositories/velocloud_repository/extract_edge_info/","text":"Extract edge info from links with edge info For link in links with edge info: If the state of the edge bound to the link is invalid: logger . info ( f \"Edge in host { velocloud_host } and enterprise { enterprise_name } (ID: { enterprise_id } ) \" f \"has an invalid state. Skipping...\" ) Continue with next link with edge info If the edge bound to the link has never been activated: logger . info ( f \"Edge { edge_name } in host { velocloud_host } and enterprise { enterprise_name } (ID: { enterprise_id } ) \" f \"has never been activated. Skipping...\" ) Continue with next link with edge info","title":"Extract edge info"},{"location":"logging/services/last-contact-report/repositories/velocloud_repository/extract_edge_info/#extract-edge-info-from-links-with-edge-info","text":"For link in links with edge info: If the state of the edge bound to the link is invalid: logger . info ( f \"Edge in host { velocloud_host } and enterprise { enterprise_name } (ID: { enterprise_id } ) \" f \"has an invalid state. Skipping...\" ) Continue with next link with edge info If the edge bound to the link has never been activated: logger . info ( f \"Edge { edge_name } in host { velocloud_host } and enterprise { enterprise_name } (ID: { enterprise_id } ) \" f \"has never been activated. Skipping...\" ) Continue with next link with edge info","title":"Extract edge info from links with edge info"},{"location":"logging/services/last-contact-report/repositories/velocloud_repository/get_all_edges_links/","text":"Get edges across all VCOs For every VCO: get_edges_links_by_host If an error occurred while fetching all edges in the VCO: logger . warning ( f \"Error: could not retrieve edges links by host: { host } \" ) Continue with next VCO","title":"Get all edges links"},{"location":"logging/services/last-contact-report/repositories/velocloud_repository/get_all_edges_links/#get-edges-across-all-vcos","text":"For every VCO: get_edges_links_by_host If an error occurred while fetching all edges in the VCO: logger . warning ( f \"Error: could not retrieve edges links by host: { host } \" ) Continue with next VCO","title":"Get edges across all VCOs"},{"location":"logging/services/last-contact-report/repositories/velocloud_repository/get_edges/","text":"Get edges get_all_edges_links extract_edge_info","title":"Get edges"},{"location":"logging/services/last-contact-report/repositories/velocloud_repository/get_edges/#get-edges","text":"get_all_edges_links extract_edge_info","title":"Get edges"},{"location":"logging/services/last-contact-report/repositories/velocloud_repository/get_edges_links_by_host/","text":"Get links with edge info by VCO logger . info ( f \"Getting edges links from Velocloud for host { host } ...\" ) If there's an error while asking for the data to the velocloud-bridge : err_msg = f \"An error occurred when requesting edge list from { host } -> { e } \" [ ... ] logger . error ( err_msg ) END logger . info ( \"Got edges links from Velocloud!\" ) If response status for get links with edge info is not ok: err_msg = ( f \"Error while retrieving edges links in { self . _config . ENVIRONMENT_NAME . upper () } \" f \"environment: Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg )","title":"Get edges links by host"},{"location":"logging/services/last-contact-report/repositories/velocloud_repository/get_edges_links_by_host/#get-links-with-edge-info-by-vco","text":"logger . info ( f \"Getting edges links from Velocloud for host { host } ...\" ) If there's an error while asking for the data to the velocloud-bridge : err_msg = f \"An error occurred when requesting edge list from { host } -> { e } \" [ ... ] logger . error ( err_msg ) END logger . info ( \"Got edges links from Velocloud!\" ) If response status for get links with edge info is not ok: err_msg = ( f \"Error while retrieving edges links in { self . _config . ENVIRONMENT_NAME . upper () } \" f \"environment: Error { response_status } - { response_body } \" ) [ ... ] logger . error ( err_msg )","title":"Get links with edge info by VCO"},{"location":"logging/services/lumin-billing-report/actions/billing_report/_billing_report_process/","text":"Run Lumin Billing Report job logger . info ( \"Requesting lumin.AI usage details for billing report\" ) get_billing_data_for_period Compose e-mail with billing events from the past month send_to_email logger . info ( \"Lumin.AI Billing Report sent\" )","title":" billing report process"},{"location":"logging/services/lumin-billing-report/actions/billing_report/_billing_report_process/#run-lumin-billing-report-job","text":"logger . info ( \"Requesting lumin.AI usage details for billing report\" ) get_billing_data_for_period Compose e-mail with billing events from the past month send_to_email logger . info ( \"Lumin.AI Billing Report sent\" )","title":"Run Lumin Billing Report job"},{"location":"logging/services/lumin-billing-report/actions/billing_report/start_billing_report_job/","text":"Schedule Lumin Billing Report job logger . info ( \"Scheduled task: billing report process configured to run first day of each month\" ) If job should be executed on service start: logger . info ( f \"It will be executed now\" ) _billing_report_process If the job cannot succeed: logger . exception ( \"Execution failed for billing report\" , event . exception ) The job is triggered again immediately","title":"Start billing report job"},{"location":"logging/services/lumin-billing-report/actions/billing_report/start_billing_report_job/#schedule-lumin-billing-report-job","text":"logger . info ( \"Scheduled task: billing report process configured to run first day of each month\" ) If job should be executed on service start: logger . info ( f \"It will be executed now\" ) _billing_report_process If the job cannot succeed: logger . exception ( \"Execution failed for billing report\" , event . exception ) The job is triggered again immediately","title":"Schedule Lumin Billing Report job"},{"location":"logging/services/lumin-billing-report/clients/email_client/send_to_email/","text":"Send report via e-mail Try to deliver the report via e-mail using the IMAP protocol If an unexpected error happens while trying to deliver the report: logger . exception ( \"Error: Email not sent\" ) END logger . info ( \"Success: Email sent!\" )","title":"Send to email"},{"location":"logging/services/lumin-billing-report/clients/email_client/send_to_email/#send-report-via-e-mail","text":"Try to deliver the report via e-mail using the IMAP protocol If an unexpected error happens while trying to deliver the report: logger . exception ( \"Error: Email not sent\" ) END logger . info ( \"Success: Email sent!\" )","title":"Send report via e-mail"},{"location":"logging/services/lumin-billing-report/clients/lumin_client/get_billing_data_for_period/","text":"Get billing data for a specific time frame Make a call to endpoint POST /api/billing . If there is an error while connecting to the LuminAI API after multiple retries: msg = \"Could not connect to {} with headers {} , body {} \" . format ( self . config [ \"uri\" ], self . headers , d ) logger . exception ( msg )","title":"Get billing data for period"},{"location":"logging/services/lumin-billing-report/clients/lumin_client/get_billing_data_for_period/#get-billing-data-for-a-specific-time-frame","text":"Make a call to endpoint POST /api/billing . If there is an error while connecting to the LuminAI API after multiple retries: msg = \"Could not connect to {} with headers {} , body {} \" . format ( self . config [ \"uri\" ], self . headers , d ) logger . exception ( msg )","title":"Get billing data for a specific time frame"},{"location":"logging/services/lumin-billing-report/repositories/lumin_repository/get_billing_data_for_period/","text":"Get billing data for a specific time frame While there are pages to fetch from the LuminAI API: logger . info ( \"fetching billing data for {} \" . format ( { \"type\" : \",\" . join ( billing_types ), \"start\" : str ( start ), \"end\" : str ( end ), \"start_token\" : start_token } ) ) LuminClient::get_billing_data_for_period","title":"Get billing data for period"},{"location":"logging/services/lumin-billing-report/repositories/lumin_repository/get_billing_data_for_period/#get-billing-data-for-a-specific-time-frame","text":"While there are pages to fetch from the LuminAI API: logger . info ( \"fetching billing data for {} \" . format ( { \"type\" : \",\" . join ( billing_types ), \"start\" : str ( start ), \"end\" : str ( end ), \"start_token\" : start_token } ) ) LuminClient::get_billing_data_for_period","title":"Get billing data for a specific time frame"},{"location":"logging/services/notifications-bridge/actions/send_to_slack/","text":"Subject: notification.slack.request Message arrives at subject If message doesn't have a body: logger . error ( f \"Cannot send to slack with { json . dumps ( payload ) } . JSON malformed\" ) END If message body doesn't have message filter: logger . error ( f 'Cannot send to slack with { json . dumps ( payload ) } . Need parameters \"message\"' ) END send_to_slack logger . info ( f \"Notifications send to slack published in event bus for request { json . dumps ( msg ) } . Message published was { notification_response } \" )","title":"Send to slack"},{"location":"logging/services/notifications-bridge/actions/send_to_slack/#subject-notificationslackrequest","text":"Message arrives at subject If message doesn't have a body: logger . error ( f \"Cannot send to slack with { json . dumps ( payload ) } . JSON malformed\" ) END If message body doesn't have message filter: logger . error ( f 'Cannot send to slack with { json . dumps ( payload ) } . Need parameters \"message\"' ) END send_to_slack logger . info ( f \"Notifications send to slack published in event bus for request { json . dumps ( msg ) } . Message published was { notification_response } \" )","title":"Subject: notification.slack.request"},{"location":"logging/services/notifications-bridge/clients/slack_client/send_to_slack/","text":"Send to slack Call Slack API endpoint webhook with the set of desired query parameters. If there is an error while connecting to Slack API: logger . error ( f \"post(send_to_slack) => ClientConnectionError: { e } \" ) END If there is an unexpected error: logger . error ( f \"post(send_to_slack) => UnexpectedError: { e } \" ) END If the status of the HTTP response is 200 : logger . info ( response ) END If the status of the HTTP response is other: logger . warning ( f \"post(send_to_slack) => response= { response } \" ) END","title":"Send to slack"},{"location":"logging/services/notifications-bridge/clients/slack_client/send_to_slack/#send-to-slack","text":"Call Slack API endpoint webhook with the set of desired query parameters. If there is an error while connecting to Slack API: logger . error ( f \"post(send_to_slack) => ClientConnectionError: { e } \" ) END If there is an unexpected error: logger . error ( f \"post(send_to_slack) => UnexpectedError: { e } \" ) END If the status of the HTTP response is 200 : logger . info ( response ) END If the status of the HTTP response is other: logger . warning ( f \"post(send_to_slack) => response= { response } \" ) END","title":"Send to slack"},{"location":"logging/services/notifications-bridge/repositories/slack_repository/send_to_slack/","text":"Send to slack SlackClient::send_to_slack","title":"Send to slack"},{"location":"logging/services/notifications-bridge/repositories/slack_repository/send_to_slack/#send-to-slack","text":"SlackClient::send_to_slack","title":"Send to slack"},{"location":"logging/services/pyutils_automation/py310/src/framework/nats/client/_pre_recover_cb/","text":"Recover message before consuming it If message is stored to an external storage: logger . warning ( f \"Message received in subject { msg . subject } exceeds the maximum size allowed by NATS. Recovering \" \"it from the external storage...\" ) Depending on the implementation, a call to Redis::recover or RedisLegacy::recover is made","title":"Recover message before consuming it"},{"location":"logging/services/pyutils_automation/py310/src/framework/nats/client/_pre_recover_cb/#recover-message-before-consuming-it","text":"If message is stored to an external storage: logger . warning ( f \"Message received in subject { msg . subject } exceeds the maximum size allowed by NATS. Recovering \" \"it from the external storage...\" ) Depending on the implementation, a call to Redis::recover or RedisLegacy::recover is made","title":"Recover message before consuming it"},{"location":"logging/services/pyutils_automation/py310/src/framework/nats/client/connect/","text":"Connect to the message bus logger . info ( f \"Connecting to NATS servers: { servers } ...\" ) Invoke nats-py's connect method logger . info ( f \"Connected to NATS servers successfully\" )","title":"Connect"},{"location":"logging/services/pyutils_automation/py310/src/framework/nats/client/connect/#connect-to-the-message-bus","text":"logger . info ( f \"Connecting to NATS servers: { servers } ...\" ) Invoke nats-py's connect method logger . info ( f \"Connected to NATS servers successfully\" )","title":"Connect to the message bus"},{"location":"logging/services/pyutils_automation/py310/src/framework/nats/client/publish/","text":"Publish message to the bus If message is too large for NATS to handle (1MB+): logger . warning ( \"Payload exceeds the maximum size allowed by NATS. Storing it to the external storage before \" f \"publishing to subject { subject } ...\" ) Depending on the implementation, a call to Redis::store or RedisLegacy::store is made logger . info ( f \"Publishing payload to subject { subject } ...\" ) Invoke nats-py's publish method The message will be consumed by a subscriber with interest in the subject logger . info ( f \"Payload published to subject { subject } successfully\" ) Consume message from the bus _pre_recover_cb is implicitly called on message arrival Consume message","title":"Publish"},{"location":"logging/services/pyutils_automation/py310/src/framework/nats/client/publish/#publish-message-to-the-bus","text":"If message is too large for NATS to handle (1MB+): logger . warning ( \"Payload exceeds the maximum size allowed by NATS. Storing it to the external storage before \" f \"publishing to subject { subject } ...\" ) Depending on the implementation, a call to Redis::store or RedisLegacy::store is made logger . info ( f \"Publishing payload to subject { subject } ...\" ) Invoke nats-py's publish method The message will be consumed by a subscriber with interest in the subject logger . info ( f \"Payload published to subject { subject } successfully\" )","title":"Publish message to the bus"},{"location":"logging/services/pyutils_automation/py310/src/framework/nats/client/publish/#consume-message-from-the-bus","text":"_pre_recover_cb is implicitly called on message arrival Consume message","title":"Consume message from the bus"},{"location":"logging/services/pyutils_automation/py310/src/framework/nats/client/request/","text":"Publish request message to the bus logger . info ( f \"Requesting a response from subject { subject } ...\" ) Invoke nats-py's request method, which internally calls publish Wait for a response ... logger . info ( f \"Response received from a replier subscribed to subject { subject } \" ) If response message is stored to an external storage: logger . warning ( f \"Response received from subject { subject } exceeds the maximum size allowed by NATS. Recovering it \" \"from the external storage...\" ) Depending on the implementation, a call to Redis::recover or RedisLegacy::recover is made Consume request _pre_recover_cb is implicitly called on request message arrival Consume message Invoke nats-py's respond method with the response message, which internally calls publish","title":"Request"},{"location":"logging/services/pyutils_automation/py310/src/framework/nats/client/request/#publish-request-message-to-the-bus","text":"logger . info ( f \"Requesting a response from subject { subject } ...\" ) Invoke nats-py's request method, which internally calls publish Wait for a response ... logger . info ( f \"Response received from a replier subscribed to subject { subject } \" ) If response message is stored to an external storage: logger . warning ( f \"Response received from subject { subject } exceeds the maximum size allowed by NATS. Recovering it \" \"from the external storage...\" ) Depending on the implementation, a call to Redis::recover or RedisLegacy::recover is made","title":"Publish request message to the bus"},{"location":"logging/services/pyutils_automation/py310/src/framework/nats/client/request/#consume-request","text":"_pre_recover_cb is implicitly called on request message arrival Consume message Invoke nats-py's respond method with the response message, which internally calls publish","title":"Consume request"},{"location":"logging/services/pyutils_automation/py310/src/framework/nats/client/subscribe/","text":"Publish message to the bus logger . info ( f \"Subscribing to subject { subject } with queue group { queue } ...\" ) Invoke nats-py's subscribe method logger . info ( f \"Subscribed to subject successfully\" )","title":"Subscribe"},{"location":"logging/services/pyutils_automation/py310/src/framework/nats/client/subscribe/#publish-message-to-the-bus","text":"logger . info ( f \"Subscribing to subject { subject } with queue group { queue } ...\" ) Invoke nats-py's subscribe method logger . info ( f \"Subscribed to subject successfully\" )","title":"Publish message to the bus"},{"location":"logging/services/pyutils_automation/py310/src/framework/nats/temp_payload_storage/redis/recover/","text":"Recover message to Redis (new style) logger . info ( f \"Retrieving payload stored under Redis key { token } ...\" ) Invoke redis' get method logger . info ( f \"Payload stored under Redis key { key } successfully\" )","title":"Recover"},{"location":"logging/services/pyutils_automation/py310/src/framework/nats/temp_payload_storage/redis/recover/#recover-message-to-redis-new-style","text":"logger . info ( f \"Retrieving payload stored under Redis key { token } ...\" ) Invoke redis' get method logger . info ( f \"Payload stored under Redis key { key } successfully\" )","title":"Recover message to Redis (new style)"},{"location":"logging/services/pyutils_automation/py310/src/framework/nats/temp_payload_storage/redis/store/","text":"Store message to Redis (new style) logger . info ( f \"Storing payload of { len ( payload ) } bytes under Redis key { key } \" ) Invoke redis' set method logger . info ( f \"Payload stored under Redis key { key } successfully\" )","title":"Store"},{"location":"logging/services/pyutils_automation/py310/src/framework/nats/temp_payload_storage/redis/store/#store-message-to-redis-new-style","text":"logger . info ( f \"Storing payload of { len ( payload ) } bytes under Redis key { key } \" ) Invoke redis' set method logger . info ( f \"Payload stored under Redis key { key } successfully\" )","title":"Store message to Redis (new style)"},{"location":"logging/services/pyutils_automation/py310/src/framework/nats/temp_payload_storage/redis_legacy/recover/","text":"Recover message to Redis (legacy style) logger . info ( f \"Retrieving payload stored under Redis key { token } ...\" ) Invoke redis' get method logger . info ( f \"Payload stored under Redis key { token } retrieved successfully\" )","title":"Recover"},{"location":"logging/services/pyutils_automation/py310/src/framework/nats/temp_payload_storage/redis_legacy/recover/#recover-message-to-redis-legacy-style","text":"logger . info ( f \"Retrieving payload stored under Redis key { token } ...\" ) Invoke redis' get method logger . info ( f \"Payload stored under Redis key { token } retrieved successfully\" )","title":"Recover message to Redis (legacy style)"},{"location":"logging/services/pyutils_automation/py310/src/framework/nats/temp_payload_storage/redis_legacy/store/","text":"Store message to Redis (legacy style) logger . info ( f \"Storing payload of { len ( payload ) } bytes under Redis key { token } \" ) Invoke redis' set method logger . info ( f \"Payload stored under Redis key { token } retrieved successfully\" )","title":"Store"},{"location":"logging/services/pyutils_automation/py310/src/framework/nats/temp_payload_storage/redis_legacy/store/#store-message-to-redis-legacy-style","text":"logger . info ( f \"Storing payload of { len ( payload ) } bytes under Redis key { token } \" ) Invoke redis' set method logger . info ( f \"Payload stored under Redis key { token } retrieved successfully\" )","title":"Store message to Redis (legacy style)"},{"location":"logging/services/pyutils_automation/py36/igz/packages/eventbus/action/execute_stateful_action/","text":"Execute action to consume message If service's action is not properly set up: self . logger . error ( f 'The object { self . state_instance } has no method named { self . target_function } ' ) END __check_large_messages_decorator is implicitly called before executing the action for the message","title":"Execute stateful action"},{"location":"logging/services/pyutils_automation/py36/igz/packages/eventbus/action/execute_stateful_action/#execute-action-to-consume-message","text":"If service's action is not properly set up: self . logger . error ( f 'The object { self . state_instance } has no method named { self . target_function } ' ) END __check_large_messages_decorator is implicitly called before executing the action for the message","title":"Execute action to consume message"},{"location":"logging/services/pyutils_automation/py36/igz/packages/eventbus/eventbus/__check_large_messages_decorator/","text":"Recover message before consuming it If message is stored to an external storage: recover_message self . _logger . info ( f 'Message received from topic { event } indicates that the actual message was larger than 1MB ' f 'and was stored with { type ( self . _messages_storage_manager ) . __name__ } .' ) _cb_with_action is implicitly called","title":"  check large messages decorator"},{"location":"logging/services/pyutils_automation/py36/igz/packages/eventbus/eventbus/__check_large_messages_decorator/#recover-message-before-consuming-it","text":"If message is stored to an external storage: recover_message self . _logger . info ( f 'Message received from topic { event } indicates that the actual message was larger than 1MB ' f 'and was stored with { type ( self . _messages_storage_manager ) . __name__ } .' ) _cb_with_action is implicitly called","title":"Recover message before consuming it"},{"location":"logging/services/pyutils_automation/py36/igz/packages/eventbus/eventbus/add_consumer/","text":"Add consumer to event bus self . _logger . info ( f \"Adding consumer { consumer_name } to the event bus...\" ) If consumer has been added to the event bus already: self . _logger . error ( f 'Consumer name { consumer_name } already registered. Skipping...' ) END self . _logger . info ( f \"Consumer { consumer_name } added to the event bus\" )","title":"Add consumer"},{"location":"logging/services/pyutils_automation/py36/igz/packages/eventbus/eventbus/add_consumer/#add-consumer-to-event-bus","text":"self . _logger . info ( f \"Adding consumer { consumer_name } to the event bus...\" ) If consumer has been added to the event bus already: self . _logger . error ( f 'Consumer name { consumer_name } already registered. Skipping...' ) END self . _logger . info ( f \"Consumer { consumer_name } added to the event bus\" )","title":"Add consumer to event bus"},{"location":"logging/services/pyutils_automation/py36/igz/packages/eventbus/eventbus/close_connections/","text":"Close connections for all consumers self . _logger . info ( \"Closing connection for all consumers in the event bus...\" ) For each consumer in the event bus: * close_nats_connections self . _logger . info ( \"Connections closed for all consumers in the event bus\" ) If there is a producer attached to the event bus: self . _logger . info ( \"Closing connection for producer in the event bus...\" ) close_nats_connections self . _logger . info ( \"Closed connection for producer in the event bus\" )","title":"Close connections"},{"location":"logging/services/pyutils_automation/py36/igz/packages/eventbus/eventbus/close_connections/#close-connections-for-all-consumers","text":"self . _logger . info ( \"Closing connection for all consumers in the event bus...\" ) For each consumer in the event bus: * close_nats_connections self . _logger . info ( \"Connections closed for all consumers in the event bus\" ) If there is a producer attached to the event bus: self . _logger . info ( \"Closing connection for producer in the event bus...\" ) close_nats_connections self . _logger . info ( \"Closed connection for producer in the event bus\" )","title":"Close connections for all consumers"},{"location":"logging/services/pyutils_automation/py36/igz/packages/eventbus/eventbus/connect/","text":"Connect all consumers and producers to the message bus self . _logger . info ( f \"Establishing connection to NATS for all consumers...\" ) For all consumers attached to the event bus: * connect_to_nats self . _logger . info ( f \"Connection to NATS established successfully for all consumers\" ) If there is a producer attached to the event bus: self . _logger . info ( f \"Establishing connection to NATS for producer...\" ) connect_to_nats self . _logger . info ( f \"Connection to NATS established successfully for producer\" )","title":"Connect"},{"location":"logging/services/pyutils_automation/py36/igz/packages/eventbus/eventbus/connect/#connect-all-consumers-and-producers-to-the-message-bus","text":"self . _logger . info ( f \"Establishing connection to NATS for all consumers...\" ) For all consumers attached to the event bus: * connect_to_nats self . _logger . info ( f \"Connection to NATS established successfully for all consumers\" ) If there is a producer attached to the event bus: self . _logger . info ( f \"Establishing connection to NATS for producer...\" ) connect_to_nats self . _logger . info ( f \"Connection to NATS established successfully for producer\" )","title":"Connect all consumers and producers to the message bus"},{"location":"logging/services/pyutils_automation/py36/igz/packages/eventbus/eventbus/publish_message/","text":"Publish message to the bus self . _logger . info ( f \"Publishing message to subject { topic } ...\" ) If message is too large for NATS to handle (1MB+): store_message self . _logger . info ( 'Message received in publish() was larger than 1MB so it was stored with ' f ' { type ( self . _messages_storage_manager ) . __name__ } . The token needed to recover it is ' f ' { msg [ \"token\" ] } .' ) publish","title":"Publish message"},{"location":"logging/services/pyutils_automation/py36/igz/packages/eventbus/eventbus/publish_message/#publish-message-to-the-bus","text":"self . _logger . info ( f \"Publishing message to subject { topic } ...\" ) If message is too large for NATS to handle (1MB+): store_message self . _logger . info ( 'Message received in publish() was larger than 1MB so it was stored with ' f ' { type ( self . _messages_storage_manager ) . __name__ } . The token needed to recover it is ' f ' { msg [ \"token\" ] } .' ) publish","title":"Publish message to the bus"},{"location":"logging/services/pyutils_automation/py36/igz/packages/eventbus/eventbus/rpc_request/","text":"Publish request message to the bus If request message is too large for NATS to handle (1MB+): store_message self . _logger . info ( 'Message received in rpc_request() was larger than 1MB so it was stored with ' f ' { type ( self . _messages_storage_manager ) . __name__ } . The token needed to recover it is ' f ' { message [ \"token\" ] } .' ) self . _logger . info ( f \"Requesting a response from subject { subject } ...\" ) rpc_request self . _logger . info ( f \"Response received from a replier subscribed to subject { topic } \" ) If response message is stored to an external storage: self . _logger . info ( f 'Message received from topic { topic } indicates that the actual message was larger than 1MB ' f 'and was stored with { type ( self . _messages_storage_manager ) . __name__ } .' ) recover_message","title":"Rpc request"},{"location":"logging/services/pyutils_automation/py36/igz/packages/eventbus/eventbus/rpc_request/#publish-request-message-to-the-bus","text":"If request message is too large for NATS to handle (1MB+): store_message self . _logger . info ( 'Message received in rpc_request() was larger than 1MB so it was stored with ' f ' { type ( self . _messages_storage_manager ) . __name__ } . The token needed to recover it is ' f ' { message [ \"token\" ] } .' ) self . _logger . info ( f \"Requesting a response from subject { subject } ...\" ) rpc_request self . _logger . info ( f \"Response received from a replier subscribed to subject { topic } \" ) If response message is stored to an external storage: self . _logger . info ( f 'Message received from topic { topic } indicates that the actual message was larger than 1MB ' f 'and was stored with { type ( self . _messages_storage_manager ) . __name__ } .' ) recover_message","title":"Publish request message to the bus"},{"location":"logging/services/pyutils_automation/py36/igz/packages/eventbus/eventbus/subscribe_consumer/","text":"Subscribe consumer from the event bus to subject self . _logger . info ( f \"Subscribing consumer { consumer_name } from the event bus to subject { topic } and adding it under NATS \" f \"queue { queue } ...\" ) subscribe_action self . _logger . info ( f \"Consumer { consumer_name } from the event bus subscribed successfully\" )","title":"Subscribe consumer"},{"location":"logging/services/pyutils_automation/py36/igz/packages/eventbus/eventbus/subscribe_consumer/#subscribe-consumer-from-the-event-bus-to-subject","text":"self . _logger . info ( f \"Subscribing consumer { consumer_name } from the event bus to subject { topic } and adding it under NATS \" f \"queue { queue } ...\" ) subscribe_action self . _logger . info ( f \"Consumer { consumer_name } from the event bus subscribed successfully\" )","title":"Subscribe consumer from the event bus to subject"},{"location":"logging/services/pyutils_automation/py36/igz/packages/eventbus/storage_managers/recover_message/","text":"Recover message from Redis self . _logger . info ( f \"Claiming message stored within Redis (payload: { msg } )...\" ) If the token to retrieve the original message is missing: self . _logger . exception ( f 'Key \"token\" was not found within the incoming payload { msg } ' ) END Invoke redis' get method Invoke redis' delete method self . _logger . info ( f 'Message successfully obtained from Redis' )","title":"Recover message"},{"location":"logging/services/pyutils_automation/py36/igz/packages/eventbus/storage_managers/recover_message/#recover-message-from-redis","text":"self . _logger . info ( f \"Claiming message stored within Redis (payload: { msg } )...\" ) If the token to retrieve the original message is missing: self . _logger . exception ( f 'Key \"token\" was not found within the incoming payload { msg } ' ) END Invoke redis' get method Invoke redis' delete method self . _logger . info ( f 'Message successfully obtained from Redis' )","title":"Recover message from Redis"},{"location":"logging/services/pyutils_automation/py36/igz/packages/eventbus/storage_managers/store_message/","text":"Store message to Redis self . _logger . info ( f 'Storing message within Redis...' ) Invoke redis' set method self . _logger . info ( f 'Message successfully stored within Redis' )","title":"Store message"},{"location":"logging/services/pyutils_automation/py36/igz/packages/eventbus/storage_managers/store_message/#store-message-to-redis","text":"self . _logger . info ( f 'Storing message within Redis...' ) Invoke redis' set method self . _logger . info ( f 'Message successfully stored within Redis' )","title":"Store message to Redis"},{"location":"logging/services/pyutils_automation/py36/igz/packages/nats/clients/_cb_with_action/","text":"Execute action for message self . _logger . info ( f 'Message received from topic { msg_subject } ' ) If there is no action for target subject: self . _logger . error ( f 'No ActionWrapper defined for topic { msg_subject } .' ) END Execute action for subject If execution failed: self . _logger . exception ( \"NATS Client Exception in client happened. \" f \"Error executing action { self . _topic_action [ msg_subject ] . target_function } \" f \"from { type ( self . _topic_action [ msg_subject ] . state_instance ) . __name__ } instance.\" )","title":" cb with action"},{"location":"logging/services/pyutils_automation/py36/igz/packages/nats/clients/_cb_with_action/#execute-action-for-message","text":"self . _logger . info ( f 'Message received from topic { msg_subject } ' ) If there is no action for target subject: self . _logger . error ( f 'No ActionWrapper defined for topic { msg_subject } .' ) END Execute action for subject If execution failed: self . _logger . exception ( \"NATS Client Exception in client happened. \" f \"Error executing action { self . _topic_action [ msg_subject ] . target_function } \" f \"from { type ( self . _topic_action [ msg_subject ] . state_instance ) . __name__ } instance.\" )","title":"Execute action for message"},{"location":"logging/services/pyutils_automation/py36/igz/packages/nats/clients/close_nats_connections/","text":"Close NATS connections self . _logger . info ( \"Draining connections...\" ) For each subscription bound to the NATS client: * Invoke nats-py's drain method self . _logger . info ( \"Connections drained\" ) If the NATS client is connected to NATS: self . _logger . info ( \"Closing connection...\" ) Invoke nats-py's close method self . _logger . info ( \"Connection closed\" )","title":"Close nats connections"},{"location":"logging/services/pyutils_automation/py36/igz/packages/nats/clients/close_nats_connections/#close-nats-connections","text":"self . _logger . info ( \"Draining connections...\" ) For each subscription bound to the NATS client: * Invoke nats-py's drain method self . _logger . info ( \"Connections drained\" ) If the NATS client is connected to NATS: self . _logger . info ( \"Closing connection...\" ) Invoke nats-py's close method self . _logger . info ( \"Connection closed\" )","title":"Close NATS connections"},{"location":"logging/services/pyutils_automation/py36/igz/packages/nats/clients/connect_to_nats/","text":"Connect to the messages bus self . _logger . info ( f \"Connecting client to NATS servers: { self . _config [ 'servers' ] } ...\" ) Invoke nats-py's connect method self . _logger . info ( f \"Connected to NATS servers successfully\" )","title":"Connect to nats"},{"location":"logging/services/pyutils_automation/py36/igz/packages/nats/clients/connect_to_nats/#connect-to-the-messages-bus","text":"self . _logger . info ( f \"Connecting client to NATS servers: { self . _config [ 'servers' ] } ...\" ) Invoke nats-py's connect method self . _logger . info ( f \"Connected to NATS servers successfully\" )","title":"Connect to the messages bus"},{"location":"logging/services/pyutils_automation/py36/igz/packages/nats/clients/publish/","text":"Publish message to the bus self . _logger . info ( f \"Publishing message to subject { topic } ...\" ) If NATS client bound to the action is not connected to NATS servers: self . _logger . warning ( f \"NATS client is disconnected from the NATS server. Resetting connection...\" ) close_nats_connections connect_to_nats Invoke nats-py's publish method The message will be consumed by a subscriber with interest in the subject. self . _logger . info ( f \"Message published to subject { topic } successfully\" ) Consume message from the bus execute_stateful_action is implicitly called on message arrival","title":"Publish"},{"location":"logging/services/pyutils_automation/py36/igz/packages/nats/clients/publish/#publish-message-to-the-bus","text":"self . _logger . info ( f \"Publishing message to subject { topic } ...\" ) If NATS client bound to the action is not connected to NATS servers: self . _logger . warning ( f \"NATS client is disconnected from the NATS server. Resetting connection...\" ) close_nats_connections connect_to_nats Invoke nats-py's publish method The message will be consumed by a subscriber with interest in the subject. self . _logger . info ( f \"Message published to subject { topic } successfully\" )","title":"Publish message to the bus"},{"location":"logging/services/pyutils_automation/py36/igz/packages/nats/clients/publish/#consume-message-from-the-bus","text":"execute_stateful_action is implicitly called on message arrival","title":"Consume message from the bus"},{"location":"logging/services/pyutils_automation/py36/igz/packages/nats/clients/rpc_request/","text":"Publish request message to the bus self . _logger . info ( f \"Publishing request message to subject { topic } ...\" ) If NATS client bound to the action is not connected to NATS servers: self . _logger . warning ( f \"NATS client is disconnected from the NATS server. Resetting connection...\" ) close_nats_connections connect_to_nats Invoke nats-py's timed_request method Wait for a response ... self . _logger . info ( f \"Got response message from subject { topic } \" ) Consume request execute_stateful_action is implicitly called on message arrival","title":"Rpc request"},{"location":"logging/services/pyutils_automation/py36/igz/packages/nats/clients/rpc_request/#publish-request-message-to-the-bus","text":"self . _logger . info ( f \"Publishing request message to subject { topic } ...\" ) If NATS client bound to the action is not connected to NATS servers: self . _logger . warning ( f \"NATS client is disconnected from the NATS server. Resetting connection...\" ) close_nats_connections connect_to_nats Invoke nats-py's timed_request method Wait for a response ... self . _logger . info ( f \"Got response message from subject { topic } \" )","title":"Publish request message to the bus"},{"location":"logging/services/pyutils_automation/py36/igz/packages/nats/clients/rpc_request/#consume-request","text":"execute_stateful_action is implicitly called on message arrival","title":"Consume request"},{"location":"logging/services/pyutils_automation/py36/igz/packages/nats/clients/subscribe_action/","text":"Subscribe action to subject self . _logger . info ( f \"Subscribing action { type ( action . state_instance ) . __name__ } to subject { topic } under NATS queue \" f \" { queue } ...\" ) If NATS client bound to the action is not connected to NATS servers: self . _logger . warning ( f \"NATS client is disconnected from the NATS server. Resetting connection...\" ) close_nats_connections connect_to_nats Invoke nats-py's subscribe method self . _logger . info ( f \"Action { type ( action . state_instance ) . __name__ } subscribed to subject { topic } successfully\" )","title":"Subscribe action"},{"location":"logging/services/pyutils_automation/py36/igz/packages/nats/clients/subscribe_action/#subscribe-action-to-subject","text":"self . _logger . info ( f \"Subscribing action { type ( action . state_instance ) . __name__ } to subject { topic } under NATS queue \" f \" { queue } ...\" ) If NATS client bound to the action is not connected to NATS servers: self . _logger . warning ( f \"NATS client is disconnected from the NATS server. Resetting connection...\" ) close_nats_connections connect_to_nats Invoke nats-py's subscribe method self . _logger . info ( f \"Action { type ( action . state_instance ) . __name__ } subscribed to subject { topic } successfully\" )","title":"Subscribe action to subject"},{"location":"logging/services/service-affecting-monitor/actions/_append_latest_trouble_to_ticket/","text":"Append latest trouble to ticket Documentation self._logger.info( f\"Appending Service Affecting trouble note to ticket {ticket_id} for {trouble.value} trouble detected in \" f\"interface {interface} of edge {serial_number}...\" ) if is_there_any_note_for_trouble self._logger.info( f\"No Service Affecting trouble note will be appended to ticket {ticket_id} for {trouble.value} trouble \" f\"detected in interface {interface} of edge {serial_number}. A note for this trouble was already \" f\"appended to the ticket after the latest re-open (or ticket creation)\" ) if not working_environment == \"production\" self._logger.info( f\"No Service Affecting trouble note will be appended to ticket {ticket_id} for {trouble.value} trouble \" f\"detected in interface {interface} of edge {serial_number}, since the current environment is \" f\"{working_environment.upper()}\" ) Append note to ticket self._logger.info( f\"Service Affecting trouble note for {trouble.value} trouble detected in interface {interface} \" f\"of edge {serial_number} was successfully appended to ticket {ticket_id}!\" )","title":" append latest trouble to ticket"},{"location":"logging/services/service-affecting-monitor/actions/_append_latest_trouble_to_ticket/#append-latest-trouble-to-ticket-documentation","text":"self._logger.info( f\"Appending Service Affecting trouble note to ticket {ticket_id} for {trouble.value} trouble detected in \" f\"interface {interface} of edge {serial_number}...\" ) if is_there_any_note_for_trouble self._logger.info( f\"No Service Affecting trouble note will be appended to ticket {ticket_id} for {trouble.value} trouble \" f\"detected in interface {interface} of edge {serial_number}. A note for this trouble was already \" f\"appended to the ticket after the latest re-open (or ticket creation)\" ) if not working_environment == \"production\" self._logger.info( f\"No Service Affecting trouble note will be appended to ticket {ticket_id} for {trouble.value} trouble \" f\"detected in interface {interface} of edge {serial_number}, since the current environment is \" f\"{working_environment.upper()}\" ) Append note to ticket self._logger.info( f\"Service Affecting trouble note for {trouble.value} trouble detected in interface {interface} \" f\"of edge {serial_number} was successfully appended to ticket {ticket_id}!\" )","title":"Append latest trouble to ticket Documentation"},{"location":"logging/services/service-affecting-monitor/actions/_append_reminder_note/","text":"Append Reminder Note Documentation Launch append_note_to_ticket","title":" append reminder note"},{"location":"logging/services/service-affecting-monitor/actions/_append_reminder_note/#append-reminder-note-documentation","text":"Launch append_note_to_ticket","title":"Append Reminder Note Documentation"},{"location":"logging/services/service-affecting-monitor/actions/_attempt_forward_to_asr/","text":"Attempt forward to asr Documentation self._logger.info( f\"Attempting to forward task of ticket {ticket_id} related to serial {serial_number} to ASR Investigate...\" ) if link_interface_type != \"WIRED\" self._logger.info( f\"Link {interface} is of type {link_interface_type} and not WIRED. Attempting to forward \" f\"to HNOC...\" ) Forward ticket to hnoc queue self._logger.info( f\"Filtering out any of the wired links of serial {serial_number} that contains any of the \" f\"following: \" f'{self._config.ASR_CONFIG[\"link_labels_blacklist\"]} ' f\"in the link label\" ) if not _should_be_forwarded_to_asr self._logger.info( f\"No links with whitelisted labels were found for serial {serial_number}. \" f\"Related detail of ticket {ticket_id} will not be forwarded to {target_queue}.\" ) Get ticket details if other_troubles_in_ticket self._logger.info( f\"Other service affecting troubles were found in ticket id {ticket_id}. Skipping forward\" f\"to asr...\" ) if task_result_note is not None self._logger.info( f\"Detail related to serial {serial_number} of ticket {ticket_id} has already been forwarded to \" f'\"{task_result}\"' ) Change detail work queue Append asr forwarding note","title":" attempt forward to asr"},{"location":"logging/services/service-affecting-monitor/actions/_attempt_forward_to_asr/#attempt-forward-to-asr-documentation","text":"self._logger.info( f\"Attempting to forward task of ticket {ticket_id} related to serial {serial_number} to ASR Investigate...\" ) if link_interface_type != \"WIRED\" self._logger.info( f\"Link {interface} is of type {link_interface_type} and not WIRED. Attempting to forward \" f\"to HNOC...\" ) Forward ticket to hnoc queue self._logger.info( f\"Filtering out any of the wired links of serial {serial_number} that contains any of the \" f\"following: \" f'{self._config.ASR_CONFIG[\"link_labels_blacklist\"]} ' f\"in the link label\" ) if not _should_be_forwarded_to_asr self._logger.info( f\"No links with whitelisted labels were found for serial {serial_number}. \" f\"Related detail of ticket {ticket_id} will not be forwarded to {target_queue}.\" ) Get ticket details if other_troubles_in_ticket self._logger.info( f\"Other service affecting troubles were found in ticket id {ticket_id}. Skipping forward\" f\"to asr...\" ) if task_result_note is not None self._logger.info( f\"Detail related to serial {serial_number} of ticket {ticket_id} has already been forwarded to \" f'\"{task_result}\"' ) Change detail work queue Append asr forwarding note","title":"Attempt forward to asr Documentation"},{"location":"logging/services/service-affecting-monitor/actions/_bandwidth_check/","text":"Bandwidth Check Documentation self._logger.info(\"Looking for bandwidth issues...\") Get links metrics for bandwidth checks Check if link metrics is empty self._logger.info(\"List of links arrived empty while checking bandwidth issues. Skipping...\") Structure link metrics Map cached edges with links metrics and contact info for elem in metrics_with_cache_and_contact_info: if within_threshold self._logger.info( f\"Link {link_status['interface']} from {serial_number} didn't exceed any bandwidth thresholds\" ) * Process bandwidth trouble self._logger.info(\"Finished looking for bandwidth issues!\")","title":" bandwidth check"},{"location":"logging/services/service-affecting-monitor/actions/_bandwidth_check/#bandwidth-check-documentation","text":"self._logger.info(\"Looking for bandwidth issues...\") Get links metrics for bandwidth checks Check if link metrics is empty self._logger.info(\"List of links arrived empty while checking bandwidth issues. Skipping...\") Structure link metrics Map cached edges with links metrics and contact info for elem in metrics_with_cache_and_contact_info: if within_threshold self._logger.info( f\"Link {link_status['interface']} from {serial_number} didn't exceed any bandwidth thresholds\" ) * Process bandwidth trouble self._logger.info(\"Finished looking for bandwidth issues!\")","title":"Bandwidth Check Documentation"},{"location":"logging/services/service-affecting-monitor/actions/_bouncing_check/","text":"Bouncing Check Documentation self._logger.info(\"Looking for bouncing issues...\") Get links metrics for bouncing checks Check if link metrics is empty self._logger.info(\"List of links arrived empty while checking bouncing issues. Skipping...\") Get events by serial and interface Structure link metrics Map cached edges with links metrics and contact info for elem in metrics_with_cache_and_contact_info: if not events self._logger.info( f\"No events were found for {link_status['interface']} from {serial_number} \" f\"while looking for bouncing troubles\" ) if are_bouncing_events_within_threshold self._logger.info( f\"Link {link_status['interface']} from {serial_number} didn't exceed bouncing thresholds\" ) * Process bouncing trouble self._logger.info(\"Finished looking for bouncing issues!\")","title":" bouncing check"},{"location":"logging/services/service-affecting-monitor/actions/_bouncing_check/#bouncing-check-documentation","text":"self._logger.info(\"Looking for bouncing issues...\") Get links metrics for bouncing checks Check if link metrics is empty self._logger.info(\"List of links arrived empty while checking bouncing issues. Skipping...\") Get events by serial and interface Structure link metrics Map cached edges with links metrics and contact info for elem in metrics_with_cache_and_contact_info: if not events self._logger.info( f\"No events were found for {link_status['interface']} from {serial_number} \" f\"while looking for bouncing troubles\" ) if are_bouncing_events_within_threshold self._logger.info( f\"Link {link_status['interface']} from {serial_number} didn't exceed bouncing thresholds\" ) * Process bouncing trouble self._logger.info(\"Finished looking for bouncing issues!\")","title":"Bouncing Check Documentation"},{"location":"logging/services/service-affecting-monitor/actions/_create_affecting_ticket/","text":"Create affecting ticket Documentation self._logger.info( f\"Creating Service Affecting ticket to report a {trouble.value} trouble detected in interface {interface} \" f\"of edge {serial_number}...\" ) if not working_environment == \"production\" self._logger.info( f\"No Service Affecting ticket will be created to report a {trouble.value} trouble detected in \" f\"interface {interface} of edge {serial_number}, since the current environment is \" f\"{working_environment.upper()}\" ) Create affecting ticket self._logger.info( f\"Service Affecting ticket to report {trouble.value} trouble detected in interface {interface} \" f\"of edge {serial_number} was successfully created! Ticket ID is {ticket_id}\" ) Append note to ticket if trouble is not AffectingTroubles.BOUNCING if should_schedule_hnoc_forwarding Schedule forward to hnoc queue else self._logger.info( f\"Ticket_id: {ticket_id} for serial: {serial_number} with link_label: \" f\"{link_data['link_status']['displayName']} is a blacklisted link and \" f\"should not be forwarded to HNOC. Skipping forward to HNOC...\" ) self._logger.info( f\"Sending an email for ticket_id: {ticket_id} \" f\"with serial: {serial_number} instead of scheduling forward to HNOC...\" ) Send initial email milestone notification if email_response[\"status\"] not in range(200, 300) self._logger.error( f\"Reminder email of edge {serial_number} could not be sent for ticket\" f\" {ticket_id}!\" ) Append reminder note if append_note_response[\"status\"] not in range(200, 300) self._logger.error( f\"Reminder note of edge {serial_number} could not be appended to ticket\" f\" {ticket_id}!\" )","title":" create affecting ticket"},{"location":"logging/services/service-affecting-monitor/actions/_create_affecting_ticket/#create-affecting-ticket-documentation","text":"self._logger.info( f\"Creating Service Affecting ticket to report a {trouble.value} trouble detected in interface {interface} \" f\"of edge {serial_number}...\" ) if not working_environment == \"production\" self._logger.info( f\"No Service Affecting ticket will be created to report a {trouble.value} trouble detected in \" f\"interface {interface} of edge {serial_number}, since the current environment is \" f\"{working_environment.upper()}\" ) Create affecting ticket self._logger.info( f\"Service Affecting ticket to report {trouble.value} trouble detected in interface {interface} \" f\"of edge {serial_number} was successfully created! Ticket ID is {ticket_id}\" ) Append note to ticket if trouble is not AffectingTroubles.BOUNCING if should_schedule_hnoc_forwarding Schedule forward to hnoc queue else self._logger.info( f\"Ticket_id: {ticket_id} for serial: {serial_number} with link_label: \" f\"{link_data['link_status']['displayName']} is a blacklisted link and \" f\"should not be forwarded to HNOC. Skipping forward to HNOC...\" ) self._logger.info( f\"Sending an email for ticket_id: {ticket_id} \" f\"with serial: {serial_number} instead of scheduling forward to HNOC...\" ) Send initial email milestone notification if email_response[\"status\"] not in range(200, 300) self._logger.error( f\"Reminder email of edge {serial_number} could not be sent for ticket\" f\" {ticket_id}!\" ) Append reminder note if append_note_response[\"status\"] not in range(200, 300) self._logger.error( f\"Reminder note of edge {serial_number} could not be appended to ticket\" f\" {ticket_id}!\" )","title":"Create affecting ticket Documentation"},{"location":"logging/services/service-affecting-monitor/actions/_forward_ticket_to_hnoc_queue/","text":"Forward ticket to HNOC Documentation self._logger.info( f\"Checking if ticket_id {ticket_id} for serial {serial_number} is resolved before \" f\"attempting to forward to HNOC...\" ) Get ticket details if ticket_details_response[\"status\"] not in range(200, 300) self._logger.error( f\"Getting ticket details of ticket_id: {ticket_id} and serial: {serial_number} \" f\"from Bruin failed: {ticket_details_response}. \" f\"Retrying forward to HNOC...\" ) if is_task_resolved self._logger.info( f\"Ticket_id: {ticket_id} for serial: {serial_number} is resolved. \" f\"Skipping forward to HNOC...\" ) self._logger.info( f\"Ticket_id: {ticket_id} for serial: {serial_number} is not resolved. \" f\"Forwarding to HNOC...\" ) Change detail work queue to hnoc if change_work_queue_response[\"status\"] not in range(200, 300) self._logger.error( f\"Failed to forward ticket_id: {ticket_id} and \" f\"serial: {serial_number} to HNOC Investigate due to bruin \" f\"returning {change_work_queue_response} when attempting to forward to HNOC.\" ) if Exception self._logger.error( f\"An error occurred while trying to forward ticket_id {ticket_id} for serial {serial_number} to HNOC\" f\" -> {e}\" )","title":" forward ticket to hnoc queue"},{"location":"logging/services/service-affecting-monitor/actions/_forward_ticket_to_hnoc_queue/#forward-ticket-to-hnoc-documentation","text":"self._logger.info( f\"Checking if ticket_id {ticket_id} for serial {serial_number} is resolved before \" f\"attempting to forward to HNOC...\" ) Get ticket details if ticket_details_response[\"status\"] not in range(200, 300) self._logger.error( f\"Getting ticket details of ticket_id: {ticket_id} and serial: {serial_number} \" f\"from Bruin failed: {ticket_details_response}. \" f\"Retrying forward to HNOC...\" ) if is_task_resolved self._logger.info( f\"Ticket_id: {ticket_id} for serial: {serial_number} is resolved. \" f\"Skipping forward to HNOC...\" ) self._logger.info( f\"Ticket_id: {ticket_id} for serial: {serial_number} is not resolved. \" f\"Forwarding to HNOC...\" ) Change detail work queue to hnoc if change_work_queue_response[\"status\"] not in range(200, 300) self._logger.error( f\"Failed to forward ticket_id: {ticket_id} and \" f\"serial: {serial_number} to HNOC Investigate due to bruin \" f\"returning {change_work_queue_response} when attempting to forward to HNOC.\" ) if Exception self._logger.error( f\"An error occurred while trying to forward ticket_id {ticket_id} for serial {serial_number} to HNOC\" f\" -> {e}\" )","title":"Forward ticket to HNOC Documentation"},{"location":"logging/services/service-affecting-monitor/actions/_jitter_check/","text":"Jitter Check Documentation self._logger.info(\"Looking for jitter issues...\") Get links metrics for jitter checks Check if link metrics is empty self._logger.info(\"List of links arrived empty while checking jitter issues. Skipping...\") Structure link metrics Map cached edges with links metrics and contact info for elem in metrics_with_cache_and_contact_info: if are_jitter_metrics_within_threshold self._logger.info( f\"Link {link_status['interface']} from {serial_number} didn't exceed jitter thresholds\" ) * Process jitter trouble self._logger.info(\"Finished looking for jitter issues!\")","title":" jitter check"},{"location":"logging/services/service-affecting-monitor/actions/_jitter_check/#jitter-check-documentation","text":"self._logger.info(\"Looking for jitter issues...\") Get links metrics for jitter checks Check if link metrics is empty self._logger.info(\"List of links arrived empty while checking jitter issues. Skipping...\") Structure link metrics Map cached edges with links metrics and contact info for elem in metrics_with_cache_and_contact_info: if are_jitter_metrics_within_threshold self._logger.info( f\"Link {link_status['interface']} from {serial_number} didn't exceed jitter thresholds\" ) * Process jitter trouble self._logger.info(\"Finished looking for jitter issues!\")","title":"Jitter Check Documentation"},{"location":"logging/services/service-affecting-monitor/actions/_latency_check/","text":"Latency Check Documentation self._logger.info(\"Looking for latency issues...\") Get links metrics for latency checks Check if link metrics is empty self._logger.info(\"List of links arrived empty while checking latency issues. Skipping...\") Structure link metrics Map cached edges with links metrics and contact info for elem in metrics_with_cache_and_contact_info: if are_latency_metrics_within_threshold self._logger.info( f\"Link {link_status['interface']} from {serial_number} didn't exceed latency thresholds\" ) * Process latency trouble self._logger.info(\"Finished looking for latency issues!\")","title":" latency check"},{"location":"logging/services/service-affecting-monitor/actions/_latency_check/#latency-check-documentation","text":"self._logger.info(\"Looking for latency issues...\") Get links metrics for latency checks Check if link metrics is empty self._logger.info(\"List of links arrived empty while checking latency issues. Skipping...\") Structure link metrics Map cached edges with links metrics and contact info for elem in metrics_with_cache_and_contact_info: if are_latency_metrics_within_threshold self._logger.info( f\"Link {link_status['interface']} from {serial_number} didn't exceed latency thresholds\" ) * Process latency trouble self._logger.info(\"Finished looking for latency issues!\")","title":"Latency Check Documentation"},{"location":"logging/services/service-affecting-monitor/actions/_map_cached_edges_with_links_metrics_and_contact_info/","text":"Map cached edges with links metrics and contact info documentation for elem in links_metrics if not cached_edge self._logger.info(f\"No cached info was found for edge {serial_number}. Skipping...\")","title":" map cached edges with links metrics and contact info"},{"location":"logging/services/service-affecting-monitor/actions/_map_cached_edges_with_links_metrics_and_contact_info/#map-cached-edges-with-links-metrics-and-contact-info-documentation","text":"for elem in links_metrics if not cached_edge self._logger.info(f\"No cached info was found for edge {serial_number}. Skipping...\")","title":"Map cached edges with links metrics and contact info documentation"},{"location":"logging/services/service-affecting-monitor/actions/_packet_loss_check/","text":"Packet loss Check Documentation self._logger.info(\"Looking for packet loss issues...\") Get links metrics for packet loss checks Check if link metrics is empty self._logger.info(\"List of links arrived empty while checking packet loss issues. Skipping...\") Structure link metrics Map cached edges with links metrics and contact info for elem in metrics_with_cache_and_contact_info: if are_packet_loss_metrics_within_threshold self._logger.info( f\"Link {link_status['interface']} from {serial_number} didn't exceed packet loss thresholds\" ) * Process packet loss trouble self._logger.info(\"Finished looking for packet loss issues!\")","title":" packet loss check"},{"location":"logging/services/service-affecting-monitor/actions/_packet_loss_check/#packet-loss-check-documentation","text":"self._logger.info(\"Looking for packet loss issues...\") Get links metrics for packet loss checks Check if link metrics is empty self._logger.info(\"List of links arrived empty while checking packet loss issues. Skipping...\") Structure link metrics Map cached edges with links metrics and contact info for elem in metrics_with_cache_and_contact_info: if are_packet_loss_metrics_within_threshold self._logger.info( f\"Link {link_status['interface']} from {serial_number} didn't exceed packet loss thresholds\" ) * Process packet loss trouble self._logger.info(\"Finished looking for packet loss issues!\")","title":"Packet loss Check Documentation"},{"location":"logging/services/service-affecting-monitor/actions/_process_affecting_trouble/","text":"Process affecting trouble Documentation self._logger.info( f\"Service Affecting trouble of type {trouble.value} detected in interface {interface} of edge \" f\"{serial_number}\" ) Get open affecting tickets if open_affecting_ticket self._logger.info( f\"An open Service Affecting ticket was found for edge {serial_number}. Ticket ID: {ticket_id}\" ) if task_resolved self._logger.info( f\"Service Affecting ticket with ID {ticket_id} is open, but the task related to edge \" f\"{serial_number} is Resolved. Therefore, the ticket will be considered as Resolved.\" ) else Append latest trouble to ticket else no open_affecting_ticket self._logger.info(f\"No open Service Affecting ticket was found for edge {serial_number}\") if not trouble_processed and not resolved_affecting_ticket Get resolved affecting tickets if not trouble_processed and resolved_affecting_ticket self._logger.info( f\"A resolved Service Affecting ticket was found for edge {serial_number}. Ticket ID: {ticket_id}\" ) Unresolve task for affecting_ticket else self._logger.info(f\"No resolved Service Affecting ticket was found for edge {serial_number}\") if not trouble_processed and not open_affecting_ticket and not resolved_affecting_ticket: self._logger.info(f\"No open or resolved Service Affecting ticket was found for edge {serial_number}\") Create affecting ticket self._logger.info( f\"Service Affecting trouble of type {trouble.value} detected in interface {interface} of edge \" f\"{serial_number} has been processed\" )","title":" process affecting trouble"},{"location":"logging/services/service-affecting-monitor/actions/_process_affecting_trouble/#process-affecting-trouble-documentation","text":"self._logger.info( f\"Service Affecting trouble of type {trouble.value} detected in interface {interface} of edge \" f\"{serial_number}\" ) Get open affecting tickets if open_affecting_ticket self._logger.info( f\"An open Service Affecting ticket was found for edge {serial_number}. Ticket ID: {ticket_id}\" ) if task_resolved self._logger.info( f\"Service Affecting ticket with ID {ticket_id} is open, but the task related to edge \" f\"{serial_number} is Resolved. Therefore, the ticket will be considered as Resolved.\" ) else Append latest trouble to ticket else no open_affecting_ticket self._logger.info(f\"No open Service Affecting ticket was found for edge {serial_number}\") if not trouble_processed and not resolved_affecting_ticket Get resolved affecting tickets if not trouble_processed and resolved_affecting_ticket self._logger.info( f\"A resolved Service Affecting ticket was found for edge {serial_number}. Ticket ID: {ticket_id}\" ) Unresolve task for affecting_ticket else self._logger.info(f\"No resolved Service Affecting ticket was found for edge {serial_number}\") if not trouble_processed and not open_affecting_ticket and not resolved_affecting_ticket: self._logger.info(f\"No open or resolved Service Affecting ticket was found for edge {serial_number}\") Create affecting ticket self._logger.info( f\"Service Affecting trouble of type {trouble.value} detected in interface {interface} of edge \" f\"{serial_number} has been processed\" )","title":"Process affecting trouble Documentation"},{"location":"logging/services/service-affecting-monitor/actions/_process_bandwidth_trouble/","text":"Process bandwidth trouble Documentation Launch _process_affecting_trouble","title":" process bandwidth trouble"},{"location":"logging/services/service-affecting-monitor/actions/_process_bandwidth_trouble/#process-bandwidth-trouble-documentation","text":"Launch _process_affecting_trouble","title":"Process bandwidth trouble Documentation"},{"location":"logging/services/service-affecting-monitor/actions/_process_bouncing_trouble/","text":"Process bouncing trouble Documentation Launch _process_affecting_trouble Launch _attempt_forward_to_asr","title":" process bouncing trouble"},{"location":"logging/services/service-affecting-monitor/actions/_process_bouncing_trouble/#process-bouncing-trouble-documentation","text":"Launch _process_affecting_trouble Launch _attempt_forward_to_asr","title":"Process bouncing trouble Documentation"},{"location":"logging/services/service-affecting-monitor/actions/_process_jitter_trouble/","text":"Process jitter trouble Documentation Launch _process_affecting_trouble","title":" process jitter trouble"},{"location":"logging/services/service-affecting-monitor/actions/_process_jitter_trouble/#process-jitter-trouble-documentation","text":"Launch _process_affecting_trouble","title":"Process jitter trouble Documentation"},{"location":"logging/services/service-affecting-monitor/actions/_process_latency_trouble/","text":"Process latency trouble Documentation Launch _process_affecting_trouble","title":" process latency trouble"},{"location":"logging/services/service-affecting-monitor/actions/_process_latency_trouble/#process-latency-trouble-documentation","text":"Launch _process_affecting_trouble","title":"Process latency trouble Documentation"},{"location":"logging/services/service-affecting-monitor/actions/_process_packet_loss_trouble/","text":"Process packet loss trouble Documentation Launch _process_affecting_trouble","title":" process packet loss trouble"},{"location":"logging/services/service-affecting-monitor/actions/_process_packet_loss_trouble/#process-packet-loss-trouble-documentation","text":"Launch _process_affecting_trouble","title":"Process packet loss trouble Documentation"},{"location":"logging/services/service-affecting-monitor/actions/_run_autoresolve_for_edge/","text":"Run autoresolve for edge Documentation self._logger.info(f\"Starting autoresolve for edge {serial_number}...\") if all_metrics_within_thresholds is empty self._logger.info( f\"At least one metric of edge {serial_number} is not within the threshold. Skipping autoresolve...\" ) Get open affecting tickets if affecting tickets is empty self._logger.info( f\"No affecting ticket found for edge with serial number {serial_number}. Skipping autoresolve...\" ) for affecting_ticket in affecting_tickets if not was_ticket_created_by_automation_engine self._logger.info(f\"Ticket {affecting_ticket_id} was not created by Automation Engine. Skipping autoresolve...\") Get ticket details if remove_auto_resolution_restrictions_for_byob self._logger.info( f\"Task for serial {serial_number} in ticket {affecting_ticket_id} is related to a BYOB link \" f\"and is in the IPA Investigate queue. Ignoring auto-resolution restrictions...\" ) else if not last_trouble_was_detected_recently self._logger.info( f\"Edge with serial number {serial_number} has been under an affecting trouble for a long \" f\"time, so the detail of ticket {affecting_ticket_id} related to it will not be \" f\"autoresolved. Skipping autoresolve...\" ) if is_autoresolve_threshold_maxed_out self._logger.info( f\"Limit to autoresolve detail of ticket {affecting_ticket_id} related to serial \" f\"{serial_number} has been maxed out already. Skipping autoresolve...\" ) if is_task_resolved self._logger.info( f\"Detail of ticket {affecting_ticket_id} related to serial {serial_number} is already \" \"resolved. Skipping autoresolve...\" ) if working_environment != \"production\" self._logger.info( f\"Skipping autoresolve for detail of ticket {affecting_ticket_id} related to serial number \" f\"{serial_number} since the current environment is {working_environment.upper()}\" ) self._logger.info( f\"Autoresolving detail of ticket {affecting_ticket_id} related to serial number {serial_number}...\" ) * Unpause ticket detail * Resolve ticket * Append autoresolve note to ticket self._logger.info( f\"Detail of ticket {affecting_ticket_id} related to serial number {serial_number} was autoresolved!\" ) self._logger.info(f\"Finished autoresolve for edge {serial_number}!\")","title":" run autoresolve for edge"},{"location":"logging/services/service-affecting-monitor/actions/_run_autoresolve_for_edge/#run-autoresolve-for-edge-documentation","text":"self._logger.info(f\"Starting autoresolve for edge {serial_number}...\") if all_metrics_within_thresholds is empty self._logger.info( f\"At least one metric of edge {serial_number} is not within the threshold. Skipping autoresolve...\" ) Get open affecting tickets if affecting tickets is empty self._logger.info( f\"No affecting ticket found for edge with serial number {serial_number}. Skipping autoresolve...\" ) for affecting_ticket in affecting_tickets if not was_ticket_created_by_automation_engine self._logger.info(f\"Ticket {affecting_ticket_id} was not created by Automation Engine. Skipping autoresolve...\") Get ticket details if remove_auto_resolution_restrictions_for_byob self._logger.info( f\"Task for serial {serial_number} in ticket {affecting_ticket_id} is related to a BYOB link \" f\"and is in the IPA Investigate queue. Ignoring auto-resolution restrictions...\" ) else if not last_trouble_was_detected_recently self._logger.info( f\"Edge with serial number {serial_number} has been under an affecting trouble for a long \" f\"time, so the detail of ticket {affecting_ticket_id} related to it will not be \" f\"autoresolved. Skipping autoresolve...\" ) if is_autoresolve_threshold_maxed_out self._logger.info( f\"Limit to autoresolve detail of ticket {affecting_ticket_id} related to serial \" f\"{serial_number} has been maxed out already. Skipping autoresolve...\" ) if is_task_resolved self._logger.info( f\"Detail of ticket {affecting_ticket_id} related to serial {serial_number} is already \" \"resolved. Skipping autoresolve...\" ) if working_environment != \"production\" self._logger.info( f\"Skipping autoresolve for detail of ticket {affecting_ticket_id} related to serial number \" f\"{serial_number} since the current environment is {working_environment.upper()}\" ) self._logger.info( f\"Autoresolving detail of ticket {affecting_ticket_id} related to serial number {serial_number}...\" ) * Unpause ticket detail * Resolve ticket * Append autoresolve note to ticket self._logger.info( f\"Detail of ticket {affecting_ticket_id} related to serial number {serial_number} was autoresolved!\" ) self._logger.info(f\"Finished autoresolve for edge {serial_number}!\")","title":"Run autoresolve for edge Documentation"},{"location":"logging/services/service-affecting-monitor/actions/_run_autoresolve_process/","text":"Run autoresolve process Documentation self._logger.info(\"Starting auto-resolve process...\") * Get links metrics for autoresolve if link metrics is empty self._logger.info(\"List of links metrics arrived empty while running auto-resolve process. Skipping...\") Get events by serial and interface Structure link metrics Map cached edges with links metrics and contact info self._logger.info(f\"Running auto-resolve for {len(edges_with_links_info)} edges\") autoresolve_tasks = [ Run autoresolve for edge for edge in edges_with_links_info] self._logger.info(\"Auto-resolve process finished!\")","title":" run autoresolve process"},{"location":"logging/services/service-affecting-monitor/actions/_run_autoresolve_process/#run-autoresolve-process-documentation","text":"self._logger.info(\"Starting auto-resolve process...\") * Get links metrics for autoresolve if link metrics is empty self._logger.info(\"List of links metrics arrived empty while running auto-resolve process. Skipping...\") Get events by serial and interface Structure link metrics Map cached edges with links metrics and contact info self._logger.info(f\"Running auto-resolve for {len(edges_with_links_info)} edges\") autoresolve_tasks = [ Run autoresolve for edge for edge in edges_with_links_info] self._logger.info(\"Auto-resolve process finished!\")","title":"Run autoresolve process Documentation"},{"location":"logging/services/service-affecting-monitor/actions/_schedule_forward_to_hnoc_queue/","text":"Schedule forward to hnoc queue Documentation self._logger.info( f\"Scheduling HNOC forwarding for ticket_id: {ticket_id} and serial: {serial_number} \" f\"to happen at timestamp: {forward_task_run_date}\" ) Schedule Forward ticket to hnoc queue","title":" schedule forward to hnoc queue"},{"location":"logging/services/service-affecting-monitor/actions/_schedule_forward_to_hnoc_queue/#schedule-forward-to-hnoc-queue-documentation","text":"self._logger.info( f\"Scheduling HNOC forwarding for ticket_id: {ticket_id} and serial: {serial_number} \" f\"to happen at timestamp: {forward_task_run_date}\" ) Schedule Forward ticket to hnoc queue","title":"Schedule forward to hnoc queue Documentation"},{"location":"logging/services/service-affecting-monitor/actions/_service_affecting_monitor_process/","text":"Service Affecting process Documentation self._logger.info(f\"Starting Service Affecting Monitor process now...\") Get cache for affecting monitoring Check if customer cache is empty self._logger.info(\"Got an empty customer cache. Process cannot keep going.\") Latency Check Packet Loss Check Jitter Check Bandwidth Check Bouncing Check Run Autoresolve process self._logger.info(f\"Finished processing all links! Took {round((time.time() - start_time) / 60, 2)} minutes\")","title":" service affecting monitor process"},{"location":"logging/services/service-affecting-monitor/actions/_service_affecting_monitor_process/#service-affecting-process-documentation","text":"self._logger.info(f\"Starting Service Affecting Monitor process now...\") Get cache for affecting monitoring Check if customer cache is empty self._logger.info(\"Got an empty customer cache. Process cannot keep going.\") Latency Check Packet Loss Check Jitter Check Bandwidth Check Bouncing Check Run Autoresolve process self._logger.info(f\"Finished processing all links! Took {round((time.time() - start_time) / 60, 2)} minutes\")","title":"Service Affecting process Documentation"},{"location":"logging/services/service-affecting-monitor/actions/_structure_links_metrics/","text":"Structure links metrics Documentation for link_info in links_metrics if edge_state is None self._logger.info( f\"Edge in host {velocloud_host} and enterprise {enterprise_name} (ID: {enterprise_id}) \" f\"has an invalid state. Skipping...\" ) if edge_state == \"NEVER_ACTIVATED\" self._logger.info( f\"Edge {edge_name} in host {velocloud_host} and enterprise {enterprise_name} (ID: {enterprise_id}) \" f\"has never been activated. Skipping...\" )","title":" structure links metrics"},{"location":"logging/services/service-affecting-monitor/actions/_structure_links_metrics/#structure-links-metrics-documentation","text":"for link_info in links_metrics if edge_state is None self._logger.info( f\"Edge in host {velocloud_host} and enterprise {enterprise_name} (ID: {enterprise_id}) \" f\"has an invalid state. Skipping...\" ) if edge_state == \"NEVER_ACTIVATED\" self._logger.info( f\"Edge {edge_name} in host {velocloud_host} and enterprise {enterprise_name} (ID: {enterprise_id}) \" f\"has never been activated. Skipping...\" )","title":"Structure links metrics Documentation"},{"location":"logging/services/service-affecting-monitor/actions/_unresolve_task_for_affecting_ticket/","text":"Unresolve task for affecting ticket Documentation self._logger.info( f\"Unresolving task related to edge {serial_number} of Service Affecting ticket {ticket_id} due to a \" f\"{trouble.value} trouble detected in interface {interface}...\" ) if not working_environment == \"production\" self._logger.info( f\"Task related to edge {serial_number} of Service Affecting ticket {ticket_id} will not be unresolved \" f\"because of the {trouble.value} trouble detected in interface {interface}, since the current \" f\"environment is {working_environment.upper()}\" ) Open ticket self._logger.info( f\"Task related to edge {serial_number} of Service Affecting ticket {ticket_id} was successfully \" f\"unresolved! The cause was a {trouble.value} trouble detected in interface {interface}\" ) Append note to ticket if should_schedule_hnoc_forwarding self._logger.info( f\"Forwarding reopened task for serial {serial_number} of ticket {ticket_id} to the HNOC queue...\" ) Schedule forward to HNOC queue else self._logger.info( f\"Ticket_id: {ticket_id} for serial: {serial_number} with link_label: \" f\"{link_data['link_status']['displayName']} is a blacklisted link and \" f\"should not be forwarded to HNOC. Skipping forward to HNOC...\" ) self._logger.info( f\"Sending an email for the reopened task of ticket_id: {ticket_id} \" f\"with serial: {serial_number} instead of scheduling forward to HNOC...\" ) Send initial email milestone notification if email_response[\"status\"] not in range(200, 300) self._logger.error( f\"Reminder email of edge {serial_number} could not be sent for ticket\" f\" {ticket_id}!\" ) Append reminder note if append_note_response[\"status\"] not in range(200, 300) self._logger.error( f\"Reminder note of edge {serial_number} could not be appended to ticket\" f\" {ticket_id}!\" )","title":" unresolve task for affecting ticket"},{"location":"logging/services/service-affecting-monitor/actions/_unresolve_task_for_affecting_ticket/#unresolve-task-for-affecting-ticket-documentation","text":"self._logger.info( f\"Unresolving task related to edge {serial_number} of Service Affecting ticket {ticket_id} due to a \" f\"{trouble.value} trouble detected in interface {interface}...\" ) if not working_environment == \"production\" self._logger.info( f\"Task related to edge {serial_number} of Service Affecting ticket {ticket_id} will not be unresolved \" f\"because of the {trouble.value} trouble detected in interface {interface}, since the current \" f\"environment is {working_environment.upper()}\" ) Open ticket self._logger.info( f\"Task related to edge {serial_number} of Service Affecting ticket {ticket_id} was successfully \" f\"unresolved! The cause was a {trouble.value} trouble detected in interface {interface}\" ) Append note to ticket if should_schedule_hnoc_forwarding self._logger.info( f\"Forwarding reopened task for serial {serial_number} of ticket {ticket_id} to the HNOC queue...\" ) Schedule forward to HNOC queue else self._logger.info( f\"Ticket_id: {ticket_id} for serial: {serial_number} with link_label: \" f\"{link_data['link_status']['displayName']} is a blacklisted link and \" f\"should not be forwarded to HNOC. Skipping forward to HNOC...\" ) self._logger.info( f\"Sending an email for the reopened task of ticket_id: {ticket_id} \" f\"with serial: {serial_number} instead of scheduling forward to HNOC...\" ) Send initial email milestone notification if email_response[\"status\"] not in range(200, 300) self._logger.error( f\"Reminder email of edge {serial_number} could not be sent for ticket\" f\" {ticket_id}!\" ) Append reminder note if append_note_response[\"status\"] not in range(200, 300) self._logger.error( f\"Reminder note of edge {serial_number} could not be appended to ticket\" f\" {ticket_id}!\" )","title":"Unresolve task for affecting ticket Documentation"},{"location":"logging/services/service-affecting-monitor/repositories/bruin_repository/append_asr_forwarding_note_to_ticket/","text":"Append asr forwarding note to ticket Documentation Launch append_note_to_ticket","title":"Append asr forwarding note to ticket"},{"location":"logging/services/service-affecting-monitor/repositories/bruin_repository/append_asr_forwarding_note_to_ticket/#append-asr-forwarding-note-to-ticket-documentation","text":"Launch append_note_to_ticket","title":"Append asr forwarding note to ticket Documentation"},{"location":"logging/services/service-affecting-monitor/repositories/bruin_repository/append_autoresolve_note_to_ticket/","text":"Append autoresolve note to ticket Documentation Launch append_note_to_ticket","title":"Append autoresolve note to ticket"},{"location":"logging/services/service-affecting-monitor/repositories/bruin_repository/append_autoresolve_note_to_ticket/#append-autoresolve-note-to-ticket-documentation","text":"Launch append_note_to_ticket","title":"Append autoresolve note to ticket Documentation"},{"location":"logging/services/service-affecting-monitor/repositories/bruin_repository/append_note_to_ticket/","text":"Append note to ticket Documentation self._logger.info(f\"Appending note to ticket {ticket_id}... Note contents: {note}\") self._logger.info(f\"Note appended to ticket {ticket_id}!\") if Exception self._logger.error( f\"An error occurred when appending a ticket note to ticket {ticket_id}. \" f\"Ticket note: {note}. Error: {e}\" ) if response_status not in range(200, 300) self._logger.error( f\"Error while appending note to ticket {ticket_id} in \" f\"{self._config.ENVIRONMENT_NAME.upper()} environment. Note was {note}. Error: \" f\"Error {response_status} - {response_body}\" )","title":"Append note to ticket"},{"location":"logging/services/service-affecting-monitor/repositories/bruin_repository/append_note_to_ticket/#append-note-to-ticket-documentation","text":"self._logger.info(f\"Appending note to ticket {ticket_id}... Note contents: {note}\") self._logger.info(f\"Note appended to ticket {ticket_id}!\") if Exception self._logger.error( f\"An error occurred when appending a ticket note to ticket {ticket_id}. \" f\"Ticket note: {note}. Error: {e}\" ) if response_status not in range(200, 300) self._logger.error( f\"Error while appending note to ticket {ticket_id} in \" f\"{self._config.ENVIRONMENT_NAME.upper()} environment. Note was {note}. Error: \" f\"Error {response_status} - {response_body}\" )","title":"Append note to ticket Documentation"},{"location":"logging/services/service-affecting-monitor/repositories/bruin_repository/change_detail_work_queue/","text":"Change detail work queue Documentation self._logger.info( f\"Changing task result of detail {detail_id} / serial {service_number} in ticket {ticket_id} \" f\"to {task_result}...\" ) if Exception self._logger.error( f\"An error occurred when changing task result of detail {detail_id} / serial {service_number} \" f\"in ticket {ticket_id} to {task_result} -> {e}\" ) if response_status in range(200, 300) self._logger.info( f\"Task result of detail {detail_id} / serial {service_number} in ticket {ticket_id} \" f\"changed to {task_result} successfully!\" ) else self._logger.error( f\"Error while changing task result of detail {detail_id} / serial {service_number} in ticket \" f\"{ticket_id} to {task_result} in {self._config.ENVIRONMENT_NAME.upper()} \" f\"environment: Error {response_status} - {response_body}\" )","title":"Change detail work queue"},{"location":"logging/services/service-affecting-monitor/repositories/bruin_repository/change_detail_work_queue/#change-detail-work-queue-documentation","text":"self._logger.info( f\"Changing task result of detail {detail_id} / serial {service_number} in ticket {ticket_id} \" f\"to {task_result}...\" ) if Exception self._logger.error( f\"An error occurred when changing task result of detail {detail_id} / serial {service_number} \" f\"in ticket {ticket_id} to {task_result} -> {e}\" ) if response_status in range(200, 300) self._logger.info( f\"Task result of detail {detail_id} / serial {service_number} in ticket {ticket_id} \" f\"changed to {task_result} successfully!\" ) else self._logger.error( f\"Error while changing task result of detail {detail_id} / serial {service_number} in ticket \" f\"{ticket_id} to {task_result} in {self._config.ENVIRONMENT_NAME.upper()} \" f\"environment: Error {response_status} - {response_body}\" )","title":"Change detail work queue Documentation"},{"location":"logging/services/service-affecting-monitor/repositories/bruin_repository/change_detail_work_queue_to_hnoc/","text":"Change detail work queue to hnoc Documentation Launch change_detail_work_queue","title":"Change detail work queue to hnoc"},{"location":"logging/services/service-affecting-monitor/repositories/bruin_repository/change_detail_work_queue_to_hnoc/#change-detail-work-queue-to-hnoc-documentation","text":"Launch change_detail_work_queue","title":"Change detail work queue to hnoc Documentation"},{"location":"logging/services/service-affecting-monitor/repositories/bruin_repository/create_affecting_ticket/","text":"Create Affecting ticket Documentation self._logger.info( f\"Creating affecting ticket for serial {service_number} belonging to client {client_id}...\" ) if Exception self._logger.error( f\"An error occurred while creating affecting ticket for client id {client_id} and serial \" f\"{service_number} -> {e}\" ) if response_status in range(200, 300) self._logger.info( f\"Affecting ticket for client {client_id} and serial {service_number} created successfully!\" ) else self._logger.error( f\"Error while opening affecting ticket for client {client_id} and serial {service_number} in \" f\"{self._config.ENVIRONMENT_NAME.upper()} environment: \" f\"Error {response_status} - {response_body}\" )","title":"Create affecting ticket"},{"location":"logging/services/service-affecting-monitor/repositories/bruin_repository/create_affecting_ticket/#create-affecting-ticket-documentation","text":"self._logger.info( f\"Creating affecting ticket for serial {service_number} belonging to client {client_id}...\" ) if Exception self._logger.error( f\"An error occurred while creating affecting ticket for client id {client_id} and serial \" f\"{service_number} -> {e}\" ) if response_status in range(200, 300) self._logger.info( f\"Affecting ticket for client {client_id} and serial {service_number} created successfully!\" ) else self._logger.error( f\"Error while opening affecting ticket for client {client_id} and serial {service_number} in \" f\"{self._config.ENVIRONMENT_NAME.upper()} environment: \" f\"Error {response_status} - {response_body}\" )","title":"Create Affecting ticket Documentation"},{"location":"logging/services/service-affecting-monitor/repositories/bruin_repository/get_affecting_tickets/","text":"Get affecting tickets Launch Get tickets","title":"Get affecting tickets"},{"location":"logging/services/service-affecting-monitor/repositories/bruin_repository/get_affecting_tickets/#get-affecting-tickets","text":"Launch Get tickets","title":"Get affecting tickets"},{"location":"logging/services/service-affecting-monitor/repositories/bruin_repository/get_open_affecting_tickets/","text":"Get open affecting tickets Launch Get affecting tickets","title":"Get open affecting tickets"},{"location":"logging/services/service-affecting-monitor/repositories/bruin_repository/get_open_affecting_tickets/#get-open-affecting-tickets","text":"Launch Get affecting tickets","title":"Get open affecting tickets"},{"location":"logging/services/service-affecting-monitor/repositories/bruin_repository/get_resolved_affecting_tickets/","text":"Get resolved affecting tickets Launch Get affecting tickets","title":"Get resolved affecting tickets"},{"location":"logging/services/service-affecting-monitor/repositories/bruin_repository/get_resolved_affecting_tickets/#get-resolved-affecting-tickets","text":"Launch Get affecting tickets","title":"Get resolved affecting tickets"},{"location":"logging/services/service-affecting-monitor/repositories/bruin_repository/get_ticket_details/","text":"Get Ticket details Documentation self._logger.info(f\"Getting details of ticket {ticket_id} from Bruin...\" if Exception self._logger.error(f\"An error occurred when requesting ticket details from Bruin API for ticket {ticket_id} -> {e}\") if response_status not in range(200, 300) self._logger.error( f\"Error while retrieving details of ticket {ticket_id} in \" f\"{self._config.ENVIRONMENT_NAME.upper()} environment: \" f\"Error {response_status} - {response_body}\" ) else self._logger.info(f\"Got details of ticket {ticket_id} from Bruin!\")","title":"Get ticket details"},{"location":"logging/services/service-affecting-monitor/repositories/bruin_repository/get_ticket_details/#get-ticket-details-documentation","text":"self._logger.info(f\"Getting details of ticket {ticket_id} from Bruin...\" if Exception self._logger.error(f\"An error occurred when requesting ticket details from Bruin API for ticket {ticket_id} -> {e}\") if response_status not in range(200, 300) self._logger.error( f\"Error while retrieving details of ticket {ticket_id} in \" f\"{self._config.ENVIRONMENT_NAME.upper()} environment: \" f\"Error {response_status} - {response_body}\" ) else self._logger.info(f\"Got details of ticket {ticket_id} from Bruin!\")","title":"Get Ticket details Documentation"},{"location":"logging/services/service-affecting-monitor/repositories/bruin_repository/get_tickets/","text":"Get tickets Documentation if not service_number self._logger.info( f\"Getting all tickets with any status of {ticket_statuses}, with ticket topic \" f\"{ticket_topic} and belonging to client {client_id} from Bruin...\" ) else self._logger.info( f\"Getting all tickets with any status of {ticket_statuses}, with ticket topic \" f\"{ticket_topic}, service number {service_number} and belonging to client {client_id} from Bruin...\" ) if Exception self._logger.error( f\"An error occurred when requesting tickets from Bruin API with any status of {ticket_statuses}, \" f\"with ticket topic {ticket_topic} and belonging to client {client_id} -> {e}\" ) if response_status in range(200, 300): if not service_number: self._logger.info( f\"Got all tickets with any status of {ticket_statuses}, with ticket topic \" f\"{ticket_topic} and belonging to client {client_id} from Bruin!\" ) else self._logger.info( f\"Got all tickets with any status of {ticket_statuses}, with ticket topic \" f\"{ticket_topic}, service number {service_number} and belonging to client \" f\"{client_id} from Bruin!\" ) else if not service_number self._logger.error( f\"Error while retrieving tickets with any status of {ticket_statuses}, with ticket topic \" f\"{ticket_topic} and belonging to client {client_id} in \" f\"{self._config.ENVIRONMENT_NAME.upper()} environment: \" f\"Error {response_status} - {response_body}\" ) else self._logger.error( f\"Error while retrieving tickets with any status of {ticket_statuses}, with ticket topic \" f\"{ticket_topic}, service number {service_number} and belonging to client {client_id} in \" f\"{self._config.ENVIRONMENT_NAME.upper()} environment: \" f\"Error {response_status} - {response_body}\" )","title":"Get tickets"},{"location":"logging/services/service-affecting-monitor/repositories/bruin_repository/get_tickets/#get-tickets-documentation","text":"if not service_number self._logger.info( f\"Getting all tickets with any status of {ticket_statuses}, with ticket topic \" f\"{ticket_topic} and belonging to client {client_id} from Bruin...\" ) else self._logger.info( f\"Getting all tickets with any status of {ticket_statuses}, with ticket topic \" f\"{ticket_topic}, service number {service_number} and belonging to client {client_id} from Bruin...\" ) if Exception self._logger.error( f\"An error occurred when requesting tickets from Bruin API with any status of {ticket_statuses}, \" f\"with ticket topic {ticket_topic} and belonging to client {client_id} -> {e}\" ) if response_status in range(200, 300): if not service_number: self._logger.info( f\"Got all tickets with any status of {ticket_statuses}, with ticket topic \" f\"{ticket_topic} and belonging to client {client_id} from Bruin!\" ) else self._logger.info( f\"Got all tickets with any status of {ticket_statuses}, with ticket topic \" f\"{ticket_topic}, service number {service_number} and belonging to client \" f\"{client_id} from Bruin!\" ) else if not service_number self._logger.error( f\"Error while retrieving tickets with any status of {ticket_statuses}, with ticket topic \" f\"{ticket_topic} and belonging to client {client_id} in \" f\"{self._config.ENVIRONMENT_NAME.upper()} environment: \" f\"Error {response_status} - {response_body}\" ) else self._logger.error( f\"Error while retrieving tickets with any status of {ticket_statuses}, with ticket topic \" f\"{ticket_topic}, service number {service_number} and belonging to client {client_id} in \" f\"{self._config.ENVIRONMENT_NAME.upper()} environment: \" f\"Error {response_status} - {response_body}\" )","title":"Get tickets Documentation"},{"location":"logging/services/service-affecting-monitor/repositories/bruin_repository/open_ticket/","text":"Open ticket Documentation self._logger.info(f\"Opening ticket {ticket_id} (affected detail ID: {detail_id})...\") self._logger.info(f\"Ticket {ticket_id} opened!\") if Exception self._logger.error(f\"An error occurred when opening outage ticket {ticket_id} -> {e}\") if response_status not in range(200, 300) self._logger.error( f\"Error while opening outage ticket {ticket_id} in \" f\"{self._config.ENVIRONMENT_NAME.upper()} environment: \" f\"Error {response_status} - {response_body}\" )","title":"Open ticket"},{"location":"logging/services/service-affecting-monitor/repositories/bruin_repository/open_ticket/#open-ticket-documentation","text":"self._logger.info(f\"Opening ticket {ticket_id} (affected detail ID: {detail_id})...\") self._logger.info(f\"Ticket {ticket_id} opened!\") if Exception self._logger.error(f\"An error occurred when opening outage ticket {ticket_id} -> {e}\") if response_status not in range(200, 300) self._logger.error( f\"Error while opening outage ticket {ticket_id} in \" f\"{self._config.ENVIRONMENT_NAME.upper()} environment: \" f\"Error {response_status} - {response_body}\" )","title":"Open ticket Documentation"},{"location":"logging/services/service-affecting-monitor/repositories/bruin_repository/post_notification_email_milestone/","text":"Post notification email milestone Documentation self._logger.info( f\"Sending email for ticket id {ticket_id}, \" f\"service_number {service_number} \" f\"and notification type {notification_type}...\" ) if Exception self._logger.error( f\"An error occurred when sending email for ticket id {ticket_id}, \" f\"service_number {service_number} \" f\"and notification type {notification_type}...-> {e}\" ) if response_status in range(200, 300) self._logger.info( f\"Email sent for ticket {ticket_id}, service number {service_number} \" f\"and notification type {notification_type}!\" ) else self._logger.error( f\"Error while sending email for ticket {ticket_id}, \" f\"service_number {service_number} and notification type {notification_type} in \" f\"{self._config.CURRENT_ENVIRONMENT.upper()} environment: \" f\"Error {response_status} - {response_body}\" )","title":"Post notification email milestone"},{"location":"logging/services/service-affecting-monitor/repositories/bruin_repository/post_notification_email_milestone/#post-notification-email-milestone-documentation","text":"self._logger.info( f\"Sending email for ticket id {ticket_id}, \" f\"service_number {service_number} \" f\"and notification type {notification_type}...\" ) if Exception self._logger.error( f\"An error occurred when sending email for ticket id {ticket_id}, \" f\"service_number {service_number} \" f\"and notification type {notification_type}...-> {e}\" ) if response_status in range(200, 300) self._logger.info( f\"Email sent for ticket {ticket_id}, service number {service_number} \" f\"and notification type {notification_type}!\" ) else self._logger.error( f\"Error while sending email for ticket {ticket_id}, \" f\"service_number {service_number} and notification type {notification_type} in \" f\"{self._config.CURRENT_ENVIRONMENT.upper()} environment: \" f\"Error {response_status} - {response_body}\" )","title":"Post notification email milestone Documentation"},{"location":"logging/services/service-affecting-monitor/repositories/bruin_repository/resolve_ticket/","text":"Resolve ticket Documentation self._logger.info(f\"Resolving detail {detail_id} of ticket {ticket_id}...\") if Exception self._logger.error(f\"An error occurred while resolving detail {detail_id} of ticket {ticket_id} -> {e}\") if response_status in range(200, 300) self._logger.info(f\"Detail {detail_id} of ticket {ticket_id} resolved successfully!\") else self._logger.error( f\"Error while resolving detail {detail_id} of ticket {ticket_id} in \" f\"{self._config.ENVIRONMENT_NAME.upper()} environment: \" f\"Error {response_status} - {response_body}\" )","title":"Resolve ticket"},{"location":"logging/services/service-affecting-monitor/repositories/bruin_repository/resolve_ticket/#resolve-ticket-documentation","text":"self._logger.info(f\"Resolving detail {detail_id} of ticket {ticket_id}...\") if Exception self._logger.error(f\"An error occurred while resolving detail {detail_id} of ticket {ticket_id} -> {e}\") if response_status in range(200, 300) self._logger.info(f\"Detail {detail_id} of ticket {ticket_id} resolved successfully!\") else self._logger.error( f\"Error while resolving detail {detail_id} of ticket {ticket_id} in \" f\"{self._config.ENVIRONMENT_NAME.upper()} environment: \" f\"Error {response_status} - {response_body}\" )","title":"Resolve ticket Documentation"},{"location":"logging/services/service-affecting-monitor/repositories/bruin_repository/send_initial_email_milestone_notification/","text":"Send initial email milestone notification Documentation Launch post_notification_email_milestone","title":"Send initial email milestone notification"},{"location":"logging/services/service-affecting-monitor/repositories/bruin_repository/send_initial_email_milestone_notification/#send-initial-email-milestone-notification-documentation","text":"Launch post_notification_email_milestone","title":"Send initial email milestone notification Documentation"},{"location":"logging/services/service-affecting-monitor/repositories/bruin_repository/unpause_ticket_detail/","text":"Unpause ticket detail Documentation self._logger.info(f\"Unpausing detail of ticket {ticket_id} related to serial number {service_number}...\") if Exception self._logger.error( f\"An error occurred when unpausing detail of ticket {ticket_id} related to serial number \" f\"{service_number}. Error: {e}\" ) if response_status in range(200, 300) self._logger.info( f\"Detail of ticket {ticket_id} related to serial number {service_number}) was unpaused!\" ) else self._logger.error( f\"Error while unpausing detail of ticket {ticket_id} related to serial number {service_number}) in \" f\"{self._config.ENVIRONMENT_NAME.upper()} environment. \" f\"Error: Error {response_status} - {response_body}\" )","title":"Unpause ticket detail"},{"location":"logging/services/service-affecting-monitor/repositories/bruin_repository/unpause_ticket_detail/#unpause-ticket-detail-documentation","text":"self._logger.info(f\"Unpausing detail of ticket {ticket_id} related to serial number {service_number}...\") if Exception self._logger.error( f\"An error occurred when unpausing detail of ticket {ticket_id} related to serial number \" f\"{service_number}. Error: {e}\" ) if response_status in range(200, 300) self._logger.info( f\"Detail of ticket {ticket_id} related to serial number {service_number}) was unpaused!\" ) else self._logger.error( f\"Error while unpausing detail of ticket {ticket_id} related to serial number {service_number}) in \" f\"{self._config.ENVIRONMENT_NAME.upper()} environment. \" f\"Error: Error {response_status} - {response_body}\" )","title":"Unpause ticket detail Documentation"},{"location":"logging/services/service-affecting-monitor/repositories/customer_cache_repository/get_cache/","text":"Get cache Documentation If velo_filter self._logger.info(f\"Getting customer cache for Velocloud host(s) {', '.join(velo_filter.keys())}...\") 2. Else: self._logger.info(f\"Getting customer cache for all Velocloud hosts...\") 3. If Exception : self._logger.error(f\"An error occurred when requesting customer cache -> {e}\") If response status == 202: self._logger.error(response_body) Else: If velo_filter: self._logger.info(f\"Got customer cache for Velocloud host(s) {', '.join(velo_filter.keys())}!\") * Else self._logger.info(f\"Got customer cache for all Velocloud hosts!\")","title":"Get cache"},{"location":"logging/services/service-affecting-monitor/repositories/customer_cache_repository/get_cache/#get-cache-documentation","text":"If velo_filter self._logger.info(f\"Getting customer cache for Velocloud host(s) {', '.join(velo_filter.keys())}...\") 2. Else: self._logger.info(f\"Getting customer cache for all Velocloud hosts...\") 3. If Exception : self._logger.error(f\"An error occurred when requesting customer cache -> {e}\") If response status == 202: self._logger.error(response_body) Else: If velo_filter: self._logger.info(f\"Got customer cache for Velocloud host(s) {', '.join(velo_filter.keys())}!\") * Else self._logger.info(f\"Got customer cache for all Velocloud hosts!\")","title":"Get cache Documentation"},{"location":"logging/services/service-affecting-monitor/repositories/customer_cache_repository/get_cache_for_affecting_monitoring/","text":"Get cache for affecting Documentation Launch get_cache","title":"Get cache for affecting monitoring"},{"location":"logging/services/service-affecting-monitor/repositories/customer_cache_repository/get_cache_for_affecting_monitoring/#get-cache-for-affecting-documentation","text":"Launch get_cache","title":"Get cache for affecting Documentation"},{"location":"logging/services/service-affecting-monitor/repositories/velocloud_repository/get_all_links_metrics/","text":"Get all links metrics Documentation for host in self._config.MONITOR_CONFIG[\"velo_filter\"] * Gets links metrics by host * if status from get_links_metrics_by_host return is not in range(200, 300) self._logger.info(f\"Error: could not retrieve links metrics from Velocloud host {host}\")","title":"Get all links metrics"},{"location":"logging/services/service-affecting-monitor/repositories/velocloud_repository/get_all_links_metrics/#get-all-links-metrics-documentation","text":"for host in self._config.MONITOR_CONFIG[\"velo_filter\"] * Gets links metrics by host * if status from get_links_metrics_by_host return is not in range(200, 300) self._logger.info(f\"Error: could not retrieve links metrics from Velocloud host {host}\")","title":"Get all links metrics Documentation"},{"location":"logging/services/service-affecting-monitor/repositories/velocloud_repository/get_enterprise_events/","text":"Get enterprise events Documentation self._logger.info( f\"Getting events of host {host} and enterprise id {enterprise_id} having any type of {event_types} \" f\"that took place between {past_moment} and {now} from Velocloud...\" ) if Exception : self._logger.error( f\"An error occurred when requesting edge events from Velocloud for host {host} \" f\"and enterprise id {enterprise_id} -> {e}\" ) if response_status in range(200, 300) self._logger.info( f\"Got events of host {host} and enterprise id {enterprise_id} having any type in {event_types} \" f\"that took place between {past_moment} and {now} from Velocloud!\" ) else self._logger.error( f\"Error while retrieving events of host {host} and enterprise id {enterprise_id} having any type \" f\"in {event_types} that took place between {past_moment} and {now} \" f\"in {self._config.ENVIRONMENT_NAME.upper()}\" f\"environment: Error {response_status} - {response_body}\" )","title":"Get enterprise events"},{"location":"logging/services/service-affecting-monitor/repositories/velocloud_repository/get_enterprise_events/#get-enterprise-events-documentation","text":"self._logger.info( f\"Getting events of host {host} and enterprise id {enterprise_id} having any type of {event_types} \" f\"that took place between {past_moment} and {now} from Velocloud...\" ) if Exception : self._logger.error( f\"An error occurred when requesting edge events from Velocloud for host {host} \" f\"and enterprise id {enterprise_id} -> {e}\" ) if response_status in range(200, 300) self._logger.info( f\"Got events of host {host} and enterprise id {enterprise_id} having any type in {event_types} \" f\"that took place between {past_moment} and {now} from Velocloud!\" ) else self._logger.error( f\"Error while retrieving events of host {host} and enterprise id {enterprise_id} having any type \" f\"in {event_types} that took place between {past_moment} and {now} \" f\"in {self._config.ENVIRONMENT_NAME.upper()}\" f\"environment: Error {response_status} - {response_body}\" )","title":"Get enterprise events Documentation"},{"location":"logging/services/service-affecting-monitor/repositories/velocloud_repository/get_events_by_serial_and_interface/","text":"Get events by serial and interface Documentation for host in edges_by_host_and_enterprise for enterprise_id in edges_by_enterprise Get enterprise events for event in enterprise_events if not matching_edge self._logger.info( f'No edge in the customer cache had edge name {event[\"edgeName\"]}. Skipping...' ) self._logger.info( f'Event with edge name {event[\"edgeName\"]} matches edge from customer cache with' f\"serial number {serial}\" )","title":"Get events by serial and interface"},{"location":"logging/services/service-affecting-monitor/repositories/velocloud_repository/get_events_by_serial_and_interface/#get-events-by-serial-and-interface-documentation","text":"for host in edges_by_host_and_enterprise for enterprise_id in edges_by_enterprise Get enterprise events for event in enterprise_events if not matching_edge self._logger.info( f'No edge in the customer cache had edge name {event[\"edgeName\"]}. Skipping...' ) self._logger.info( f'Event with edge name {event[\"edgeName\"]} matches edge from customer cache with' f\"serial number {serial}\" )","title":"Get events by serial and interface Documentation"},{"location":"logging/services/service-affecting-monitor/repositories/velocloud_repository/get_links_metrics_by_host/","text":"Get links metrics by host Documentation self._logger.info( f\"Getting links metrics between {interval['start']} and {interval['end']} \" f\"from Velocloud host {host}...\" ) self._logger.info(f\"Got links metrics from Velocloud host {host}!\") if Exception : self._logger.error(f\"An error occurred when requesting links metrics from Velocloud -> {e}\") if response status not in range(200, 300) self._logger.error( f\"Error while retrieving links metrics in {self._config.ENVIRONMENT_NAME.upper()} \" f\"environment: Error {response_status} - {response_body}\" )","title":"Get links metrics by host"},{"location":"logging/services/service-affecting-monitor/repositories/velocloud_repository/get_links_metrics_by_host/#get-links-metrics-by-host-documentation","text":"self._logger.info( f\"Getting links metrics between {interval['start']} and {interval['end']} \" f\"from Velocloud host {host}...\" ) self._logger.info(f\"Got links metrics from Velocloud host {host}!\") if Exception : self._logger.error(f\"An error occurred when requesting links metrics from Velocloud -> {e}\") if response status not in range(200, 300) self._logger.error( f\"Error while retrieving links metrics in {self._config.ENVIRONMENT_NAME.upper()} \" f\"environment: Error {response_status} - {response_body}\" )","title":"Get links metrics by host Documentation"},{"location":"logging/services/service-affecting-monitor/repositories/velocloud_repository/get_links_metrics_for_autoresolve/","text":"Get links metrics for autoresolve Documentation Launch get_all_links_metrics","title":"Get links metrics for autoresolve"},{"location":"logging/services/service-affecting-monitor/repositories/velocloud_repository/get_links_metrics_for_autoresolve/#get-links-metrics-for-autoresolve-documentation","text":"Launch get_all_links_metrics","title":"Get links metrics for autoresolve Documentation"},{"location":"logging/services/service-affecting-monitor/repositories/velocloud_repository/get_links_metrics_for_bandwidth_checks/","text":"Get links metrics for bandwidth checks Documentation Launch get_all_links_metrics","title":"Get links metrics for bandwidth checks"},{"location":"logging/services/service-affecting-monitor/repositories/velocloud_repository/get_links_metrics_for_bandwidth_checks/#get-links-metrics-for-bandwidth-checks-documentation","text":"Launch get_all_links_metrics","title":"Get links metrics for bandwidth checks Documentation"},{"location":"logging/services/service-affecting-monitor/repositories/velocloud_repository/get_links_metrics_for_bouncing_checks/","text":"Get links metrics for bouncing checks Documentation Launch get_all_links_metrics","title":"Get links metrics for bouncing checks"},{"location":"logging/services/service-affecting-monitor/repositories/velocloud_repository/get_links_metrics_for_bouncing_checks/#get-links-metrics-for-bouncing-checks-documentation","text":"Launch get_all_links_metrics","title":"Get links metrics for bouncing checks Documentation"},{"location":"logging/services/service-affecting-monitor/repositories/velocloud_repository/get_links_metrics_for_jitter_checks/","text":"Get links metrics for jitter checks Documentation Launch get_all_links_metrics","title":"Get links metrics for jitter checks"},{"location":"logging/services/service-affecting-monitor/repositories/velocloud_repository/get_links_metrics_for_jitter_checks/#get-links-metrics-for-jitter-checks-documentation","text":"Launch get_all_links_metrics","title":"Get links metrics for jitter checks Documentation"},{"location":"logging/services/service-affecting-monitor/repositories/velocloud_repository/get_links_metrics_for_latency_checks/","text":"Get links metrics for latency checks Documentation Launch get_all_links_metrics","title":"Get links metrics for latency checks"},{"location":"logging/services/service-affecting-monitor/repositories/velocloud_repository/get_links_metrics_for_latency_checks/#get-links-metrics-for-latency-checks-documentation","text":"Launch get_all_links_metrics","title":"Get links metrics for latency checks Documentation"},{"location":"logging/services/service-affecting-monitor/repositories/velocloud_repository/get_links_metrics_for_packet_loss_checks/","text":"Get links metrics for packet loss checks Documentation Launch get_all_links_metrics","title":"Get links metrics for packet loss checks"},{"location":"logging/services/service-affecting-monitor/repositories/velocloud_repository/get_links_metrics_for_packet_loss_checks/#get-links-metrics-for-packet-loss-checks-documentation","text":"Launch get_all_links_metrics","title":"Get links metrics for packet loss checks Documentation"},{"location":"logging/services/service-outage-monitor/actions/outage_monitoring/_append_reminder_note/","text":"Append reminder note append_note_to_ticket","title":" append reminder note"},{"location":"logging/services/service-outage-monitor/actions/outage_monitoring/_append_reminder_note/#append-reminder-note","text":"append_note_to_ticket","title":"Append reminder note"},{"location":"logging/services/service-outage-monitor/actions/outage_monitoring/_append_triage_note/","text":"Append triage note get_last_edge_events If status not OK: self._logger.warning(f\"Don't found last edge events for edge id: {edge_full_id}. Skipping append triage \" f\"note ...\") get_ticket_details If status not OK: self._logger.warning(f\"Don't found ticket details for ticket id: {ticket_id}. Skipping append triage \" f\"note ...\") build_triage_note self._logger.info(f\"Appending triage note to detail {ticket_detail_id} (serial {serial_number}) of ticket {ticket_id}...\") append_triage_note","title":" append triage note"},{"location":"logging/services/service-outage-monitor/actions/outage_monitoring/_append_triage_note/#append-triage-note","text":"get_last_edge_events If status not OK: self._logger.warning(f\"Don't found last edge events for edge id: {edge_full_id}. Skipping append triage \" f\"note ...\") get_ticket_details If status not OK: self._logger.warning(f\"Don't found ticket details for ticket id: {ticket_id}. Skipping append triage \" f\"note ...\") build_triage_note self._logger.info(f\"Appending triage note to detail {ticket_detail_id} (serial {serial_number}) of ticket {ticket_id}...\") append_triage_note","title":"Append triage note"},{"location":"logging/services/service-outage-monitor/actions/outage_monitoring/_attempt_forward_to_asr/","text":"Attempt forward to asr self._logger.info(f\"Attempting to forward task of ticket {ticket_id} related to serial {serial_number} to ASR Investigate...\") * If faulty edge: self._logger.info(f\"Outage of serial {serial_number} is caused by a faulty edge. Related detail of ticket {ticket_id} \" \"will not be forwarded to ASR Investigate.\") self._logger.info(f\"Searching serial {serial_number} for any wired links\") * If not wired links: self._logger.info(f\"No wired links are disconnected for serial {serial_number}. Related detail of ticket {ticket_id} \" \"will not be forwarded to ASR Investigate.\") self._logger.info(f\"Filtering out any of the wired links of serial {serial_number} that contains any of the \" f'following: {self._config.MONITOR_CONFIG[\"blacklisted_link_labels_for_asr_forwards\"]} ' f\"in the link label\") * If not whitelist links: self._logger.info(f\"No links with whitelisted labels were found for serial {serial_number}. \" f\"Related detail of ticket {ticket_id} will not be forwarded to ASR Investigate.\") * get_ticket_details * If status not Ok: self._logger.info(f\"Bad status calling get ticket details. Skipping forward asr ...\") self._logger.info(f\"Notes of ticket {ticket_id}: {notes_from_outage_ticket}\") * If task result note: self._logger.info(f\"Detail related to serial {serial_number} of ticket {ticket_id} has already been forwarded to \" f'\"{target_queue}\"') * change_detail_work_queue * If status of change detail work queue in Ok: * append_asr_forwarding_note","title":" attempt forward to asr"},{"location":"logging/services/service-outage-monitor/actions/outage_monitoring/_attempt_forward_to_asr/#attempt-forward-to-asr","text":"self._logger.info(f\"Attempting to forward task of ticket {ticket_id} related to serial {serial_number} to ASR Investigate...\") * If faulty edge: self._logger.info(f\"Outage of serial {serial_number} is caused by a faulty edge. Related detail of ticket {ticket_id} \" \"will not be forwarded to ASR Investigate.\") self._logger.info(f\"Searching serial {serial_number} for any wired links\") * If not wired links: self._logger.info(f\"No wired links are disconnected for serial {serial_number}. Related detail of ticket {ticket_id} \" \"will not be forwarded to ASR Investigate.\") self._logger.info(f\"Filtering out any of the wired links of serial {serial_number} that contains any of the \" f'following: {self._config.MONITOR_CONFIG[\"blacklisted_link_labels_for_asr_forwards\"]} ' f\"in the link label\") * If not whitelist links: self._logger.info(f\"No links with whitelisted labels were found for serial {serial_number}. \" f\"Related detail of ticket {ticket_id} will not be forwarded to ASR Investigate.\") * get_ticket_details * If status not Ok: self._logger.info(f\"Bad status calling get ticket details. Skipping forward asr ...\") self._logger.info(f\"Notes of ticket {ticket_id}: {notes_from_outage_ticket}\") * If task result note: self._logger.info(f\"Detail related to serial {serial_number} of ticket {ticket_id} has already been forwarded to \" f'\"{target_queue}\"') * change_detail_work_queue * If status of change detail work queue in Ok: * append_asr_forwarding_note","title":"Attempt forward to asr"},{"location":"logging/services/service-outage-monitor/actions/outage_monitoring/_attempt_ticket_creation/","text":"Attempt ticket creation self._logger.info(f\"[{outage_type.value}] Attempting outage ticket creation for serial {serial_number}...\") create_outage_ticket self._logger.info(f\"[{outage_type.value}] Bruin response for ticket creation for edge {edge}: \" f\"{ticket_creation_response}\") If status is OK: self._logger.info(f\"[{outage_type.value}] Successfully created outage ticket for edge {edge}.\") _append_triage_note _change_severity If should schedule forward to hnoc queue: schedule_forward_to_hnoc_queue Else: self._logger.info(f\"Ticket_id: {ticket_id} for serial: {serial_number} \" f\"with link_data: {edge_links} has a blacklisted link and \" f\"should not be forwarded to HNOC. Skipping forward to HNOC...\") self._logger.info( f\"Sending an email for ticket_id: {ticket_id} \" f\"with serial: {serial_number} instead of scheduling forward to HNOC...\" ) send_initial_email_milestone_notification If send email milestone status not ok: self._logger.error( f\"Reminder email of edge {serial_number} could not be sent for ticket\" f\" {ticket_id}!\" ) Else: _append_reminder_note If append reminder note status is not ok: self._logger.error( f\"Reminder note of edge {serial_number} could not be appended to ticket\" f\" {ticket_id}!\" ) _check_for_digi_reboot If status 409: self._logger.info(f\"[{outage_type.value}] Faulty edge {serial_number} already has an outage ticket in \" f\"progress (ID = {ticket_id}). Skipping outage ticket creation for \" \"this edge...\") _change_ticket_severity If change severity is different to NOT_CHANGED: If should schedule hnoc forwarding: schedule_forward_to_hnoc_queue Else: self._logger.info(f\"Ticket_id: {ticket_id} for serial: {serial_number} \" f\"with link_data: {edge_links} has a blacklisted link and \" f\"should not be forwarded to HNOC. Skipping forward to HNOC...\") get_ticket_details _send_reminder * * * * * * * * * * * * ** MIRAR ESTO _check_for_failed_digi_reboot _attempt_forward_to_asr If status 471: self._logger.info(f\"[{outage_type.value}] Faulty edge {serial_number} has a resolved outage ticket \" f\"(ID = {ticket_id}). Re-opening ticket...\") _reopen_outage_ticket _change_ticket_severity If should schedule hnoc forwarding: schedule_forward_to_hnoc_queue Else: self._logger.info(f\"Ticket_id: {ticket_id} for serial: {serial_number} \" f\"with link_data: {edge_links} has a blacklisted link and \" f\"should not be forwarded to HNOC. Skipping forward to HNOC...\") self._logger.info( f\"Sending an email for ticket_id: {ticket_id} \" f\"with serial: {serial_number} instead of scheduling forward to HNOC...\" ) send_initial_email_milestone_notification If send email is not Ok: self._logger.error(f\"Reminder email of edge {serial_number} could not be sent for ticket\" f\" {ticket_id}!\") Else: _append_reminder_note If append reminder is not Ok: self._logger.error(f\"Reminder note of edge {serial_number} could not be appended to ticket\" f\" {ticket_id}!\") If status 492 self._logger.info(f\"[{outage_type.value}] Faulty edge {serial_number} has a resolved outage ticket \" f\"(ID = {ticket_id}). Its ticket detail was automatically unresolved \" f\"by Bruin. Appending reopen note to ticket...\") _append_triage_note _change_ticket_severity If should schedule hnoc forwarding: schedule_forward_to_hnoc_queue Else: self._logger.info(f\"Ticket_id: {ticket_id} for serial: {serial_number} \" f\"with link_data: {edge_links} has a blacklisted link and \" f\"should not be forwarded to HNOC. Skipping forward to HNOC...\") self._logger.info(f\"Sending an email for ticket_id: {ticket_id} \" f\"with serial: {serial_number} instead of scheduling forward to HNOC...\") send_initial_email_milestone_notification If send email is not Ok: self._logger.error(f\"Reminder email of edge {serial_number} could not be sent for ticket\" f\" {ticket_id}!\") Else: _append_reminder_note If append note is Ok: self._logger.error(f\"Reminder note of edge {serial_number} could not be appended to ticket\" f\" {ticket_id}!\") If status 473: self._logger.info(f\"[{outage_type.value}] There is a resolve outage ticket for the same location of faulty \" f\"edge {serial_number} (ticket ID = {ticket_id}). The ticket was \" f\"automatically unresolved by Bruin and a new ticket detail for serial {serial_number} was \" f\"appended to it. Appending initial triage note for this service number...\") _append_triage_note _change_ticket_severity If should schedule hnoc forwarding: schedule_forward_to_hnoc_queue Else: self._logger.info(f\"Ticket_id: {ticket_id} for serial: {serial_number} \" f\"with link_data: {edge_links} has a blacklisted link and \" f\"should not be forwarded to HNOC. Skipping forward to HNOC...\") self._logger.info(f\"Sending an email for ticket_id: {ticket_id} \" f\"with serial: {serial_number} instead of scheduling forward to HNOC...\") send_initial_email_milestone_notification If send email status is no Ok: self._logger.error(f\"Reminder email of edge {serial_number} could not be sent for ticket\" f\" {ticket_id}!\") Else: _append_reminder_note If append note is not Ok: self._logger.error(f\"Reminder note of edge {serial_number} could not be appended to ticket\" f\" {ticket_id}!\")","title":" attempt ticket creation"},{"location":"logging/services/service-outage-monitor/actions/outage_monitoring/_attempt_ticket_creation/#attempt-ticket-creation","text":"self._logger.info(f\"[{outage_type.value}] Attempting outage ticket creation for serial {serial_number}...\") create_outage_ticket self._logger.info(f\"[{outage_type.value}] Bruin response for ticket creation for edge {edge}: \" f\"{ticket_creation_response}\") If status is OK: self._logger.info(f\"[{outage_type.value}] Successfully created outage ticket for edge {edge}.\") _append_triage_note _change_severity If should schedule forward to hnoc queue: schedule_forward_to_hnoc_queue Else: self._logger.info(f\"Ticket_id: {ticket_id} for serial: {serial_number} \" f\"with link_data: {edge_links} has a blacklisted link and \" f\"should not be forwarded to HNOC. Skipping forward to HNOC...\") self._logger.info( f\"Sending an email for ticket_id: {ticket_id} \" f\"with serial: {serial_number} instead of scheduling forward to HNOC...\" ) send_initial_email_milestone_notification If send email milestone status not ok: self._logger.error( f\"Reminder email of edge {serial_number} could not be sent for ticket\" f\" {ticket_id}!\" ) Else: _append_reminder_note If append reminder note status is not ok: self._logger.error( f\"Reminder note of edge {serial_number} could not be appended to ticket\" f\" {ticket_id}!\" ) _check_for_digi_reboot If status 409: self._logger.info(f\"[{outage_type.value}] Faulty edge {serial_number} already has an outage ticket in \" f\"progress (ID = {ticket_id}). Skipping outage ticket creation for \" \"this edge...\") _change_ticket_severity If change severity is different to NOT_CHANGED: If should schedule hnoc forwarding: schedule_forward_to_hnoc_queue Else: self._logger.info(f\"Ticket_id: {ticket_id} for serial: {serial_number} \" f\"with link_data: {edge_links} has a blacklisted link and \" f\"should not be forwarded to HNOC. Skipping forward to HNOC...\") get_ticket_details _send_reminder * * * * * * * * * * * * ** MIRAR ESTO _check_for_failed_digi_reboot _attempt_forward_to_asr If status 471: self._logger.info(f\"[{outage_type.value}] Faulty edge {serial_number} has a resolved outage ticket \" f\"(ID = {ticket_id}). Re-opening ticket...\") _reopen_outage_ticket _change_ticket_severity If should schedule hnoc forwarding: schedule_forward_to_hnoc_queue Else: self._logger.info(f\"Ticket_id: {ticket_id} for serial: {serial_number} \" f\"with link_data: {edge_links} has a blacklisted link and \" f\"should not be forwarded to HNOC. Skipping forward to HNOC...\") self._logger.info( f\"Sending an email for ticket_id: {ticket_id} \" f\"with serial: {serial_number} instead of scheduling forward to HNOC...\" ) send_initial_email_milestone_notification If send email is not Ok: self._logger.error(f\"Reminder email of edge {serial_number} could not be sent for ticket\" f\" {ticket_id}!\") Else: _append_reminder_note If append reminder is not Ok: self._logger.error(f\"Reminder note of edge {serial_number} could not be appended to ticket\" f\" {ticket_id}!\") If status 492 self._logger.info(f\"[{outage_type.value}] Faulty edge {serial_number} has a resolved outage ticket \" f\"(ID = {ticket_id}). Its ticket detail was automatically unresolved \" f\"by Bruin. Appending reopen note to ticket...\") _append_triage_note _change_ticket_severity If should schedule hnoc forwarding: schedule_forward_to_hnoc_queue Else: self._logger.info(f\"Ticket_id: {ticket_id} for serial: {serial_number} \" f\"with link_data: {edge_links} has a blacklisted link and \" f\"should not be forwarded to HNOC. Skipping forward to HNOC...\") self._logger.info(f\"Sending an email for ticket_id: {ticket_id} \" f\"with serial: {serial_number} instead of scheduling forward to HNOC...\") send_initial_email_milestone_notification If send email is not Ok: self._logger.error(f\"Reminder email of edge {serial_number} could not be sent for ticket\" f\" {ticket_id}!\") Else: _append_reminder_note If append note is Ok: self._logger.error(f\"Reminder note of edge {serial_number} could not be appended to ticket\" f\" {ticket_id}!\") If status 473: self._logger.info(f\"[{outage_type.value}] There is a resolve outage ticket for the same location of faulty \" f\"edge {serial_number} (ticket ID = {ticket_id}). The ticket was \" f\"automatically unresolved by Bruin and a new ticket detail for serial {serial_number} was \" f\"appended to it. Appending initial triage note for this service number...\") _append_triage_note _change_ticket_severity If should schedule hnoc forwarding: schedule_forward_to_hnoc_queue Else: self._logger.info(f\"Ticket_id: {ticket_id} for serial: {serial_number} \" f\"with link_data: {edge_links} has a blacklisted link and \" f\"should not be forwarded to HNOC. Skipping forward to HNOC...\") self._logger.info(f\"Sending an email for ticket_id: {ticket_id} \" f\"with serial: {serial_number} instead of scheduling forward to HNOC...\") send_initial_email_milestone_notification If send email status is no Ok: self._logger.error(f\"Reminder email of edge {serial_number} could not be sent for ticket\" f\" {ticket_id}!\") Else: _append_reminder_note If append note is not Ok: self._logger.error(f\"Reminder note of edge {serial_number} could not be appended to ticket\" f\" {ticket_id}!\")","title":"Attempt ticket creation"},{"location":"logging/services/service-outage-monitor/actions/outage_monitoring/_change_ticket_severity/","text":"Change ticket severity self._logger.info(f\"[{outage_type.value}] Attempting outage ticket creation for serial {serial_number}...\") If is a faulty edge: self._logger.info(f\"Severity level of ticket {ticket_id} is about to be changed, as the root cause of the outage issue \" f\"is that edge {serial_number} is offline.\") change_ticket_severity_for_offline_edge Else: If check ticket tasks get_ticket_details If response status is not OK: self._logger.warning(f\"Bad response calling get ticket details for ticket id: {ticket_id}. \" f\"The ticket severity don't change\") If ticket have multiple unresolved task self._logger.info(f\"Severity level of ticket {ticket_id} will remain the same, as the root cause of the outage \" f\"issue is that at least one link of edge {serial_number} is disconnected, and this ticket \" f\"has multiple unresolved tasks.\") self._logger.info(f\"Severity level of ticket {ticket_id} is about to be changed, as the root cause of the outage issue \" f\"is that at least one link of edge {serial_number} is disconnected, and this ticket has a single \" \"unresolved task.\") get_ticket_details self._logger.warning( f\"Bad response calling get ticket for ticket id: {ticket_id}. The ticket severity don't change!\") If ticket already in severity level: self._logger.info( f\"Ticket {ticket_id} is already in severity level {target_severity}, so there is no need \" \"to change it.\") If change severity task response is not ok self._logger.info( f\"Bad response for change severity task. The ticket severity don't change\") self._logger.info( f\"Finished changing severity level of ticket {ticket_id} to {target_severity}!\" )","title":" change ticket severity"},{"location":"logging/services/service-outage-monitor/actions/outage_monitoring/_change_ticket_severity/#change-ticket-severity","text":"self._logger.info(f\"[{outage_type.value}] Attempting outage ticket creation for serial {serial_number}...\") If is a faulty edge: self._logger.info(f\"Severity level of ticket {ticket_id} is about to be changed, as the root cause of the outage issue \" f\"is that edge {serial_number} is offline.\") change_ticket_severity_for_offline_edge Else: If check ticket tasks get_ticket_details If response status is not OK: self._logger.warning(f\"Bad response calling get ticket details for ticket id: {ticket_id}. \" f\"The ticket severity don't change\") If ticket have multiple unresolved task self._logger.info(f\"Severity level of ticket {ticket_id} will remain the same, as the root cause of the outage \" f\"issue is that at least one link of edge {serial_number} is disconnected, and this ticket \" f\"has multiple unresolved tasks.\") self._logger.info(f\"Severity level of ticket {ticket_id} is about to be changed, as the root cause of the outage issue \" f\"is that at least one link of edge {serial_number} is disconnected, and this ticket has a single \" \"unresolved task.\") get_ticket_details self._logger.warning( f\"Bad response calling get ticket for ticket id: {ticket_id}. The ticket severity don't change!\") If ticket already in severity level: self._logger.info( f\"Ticket {ticket_id} is already in severity level {target_severity}, so there is no need \" \"to change it.\") If change severity task response is not ok self._logger.info( f\"Bad response for change severity task. The ticket severity don't change\") self._logger.info( f\"Finished changing severity level of ticket {ticket_id} to {target_severity}!\" )","title":"Change ticket severity"},{"location":"logging/services/service-outage-monitor/actions/outage_monitoring/_check_for_digi_reboot/","text":"Check for digi reboot self._logger.info(f\"Checking edge {serial_number} for DiGi Links\") * reboot_link * If status of reboot link is not Ok: self._logger.info(f'Attempting DiGi reboot of link with MAC address of {digi_link[\"logical_id\"]}' f\"in edge {serial_number}\") * append_digi_reboot_note * If status not Ok: self._logger.warning(f\" Bad status calling to append digi reboot note. Can't append the note\")","title":" check for digi reboot"},{"location":"logging/services/service-outage-monitor/actions/outage_monitoring/_check_for_digi_reboot/#check-for-digi-reboot","text":"self._logger.info(f\"Checking edge {serial_number} for DiGi Links\") * reboot_link * If status of reboot link is not Ok: self._logger.info(f'Attempting DiGi reboot of link with MAC address of {digi_link[\"logical_id\"]}' f\"in edge {serial_number}\") * append_digi_reboot_note * If status not Ok: self._logger.warning(f\" Bad status calling to append digi reboot note. Can't append the note\")","title":"Check for digi reboot"},{"location":"logging/services/service-outage-monitor/actions/outage_monitoring/_check_for_failed_digi_reboot/","text":"Check for failed digi reboot self._logger.info(f\"Checking edge {serial_number} for DiGi Links\") * for link in digi_links: * get_ticket_details * If status is not Ok: self._logger.info(f\"Bad status calling to get ticket details checking failed digi reboot.\" f\" Skipping link ...\") * If not find digi note: self._logger.info(f\"No DiGi note was found for ticket {ticket_id}\") * If rebooted recently: self._logger.info(f\"The last DiGi reboot attempt for Edge {serial_number} did not occur \" f'{self._config.MONITOR_CONFIG[\"last_digi_reboot_seconds\"] / 60} or more mins ago.') * If interface note is same that link: * If not find wireless: self._logger.info(f'Task results has already been changed to \"{target_queue}\"') * change_detail_work_queue * If status Ok: * append_task_result_change_note * Else: * reboot_link * If reboot link status Ok: self._logger.info(f'Attempting DiGi reboot of link with MAC address of {digi_link[\"logical_id\"]}' f\"in edge {serial_number}\") * append_digi_reboot_note","title":" check for failed digi reboot"},{"location":"logging/services/service-outage-monitor/actions/outage_monitoring/_check_for_failed_digi_reboot/#check-for-failed-digi-reboot","text":"self._logger.info(f\"Checking edge {serial_number} for DiGi Links\") * for link in digi_links: * get_ticket_details * If status is not Ok: self._logger.info(f\"Bad status calling to get ticket details checking failed digi reboot.\" f\" Skipping link ...\") * If not find digi note: self._logger.info(f\"No DiGi note was found for ticket {ticket_id}\") * If rebooted recently: self._logger.info(f\"The last DiGi reboot attempt for Edge {serial_number} did not occur \" f'{self._config.MONITOR_CONFIG[\"last_digi_reboot_seconds\"] / 60} or more mins ago.') * If interface note is same that link: * If not find wireless: self._logger.info(f'Task results has already been changed to \"{target_queue}\"') * change_detail_work_queue * If status Ok: * append_task_result_change_note * Else: * reboot_link * If reboot link status Ok: self._logger.info(f'Attempting DiGi reboot of link with MAC address of {digi_link[\"logical_id\"]}' f\"in edge {serial_number}\") * append_digi_reboot_note","title":"Check for failed digi reboot"},{"location":"logging/services/service-outage-monitor/actions/outage_monitoring/_map_cached_edges_with_edges_status/","text":"Map cached edges with edges status Documentation for edge in edges: If not edge status: self._logger.info(f'No edge status was found for cached edge {cached_edge[\"serial_number\"]}. ' \"Skipping...\") If host == metvco03.mettel.net and enterprise id == 124: self._logger.info(f\"Edge {edge} was appended to the list of edges that have no status but\" f\"are in the customer cache.\")","title":" map cached edges with edges status"},{"location":"logging/services/service-outage-monitor/actions/outage_monitoring/_map_cached_edges_with_edges_status/#map-cached-edges-with-edges-status-documentation","text":"for edge in edges: If not edge status: self._logger.info(f'No edge status was found for cached edge {cached_edge[\"serial_number\"]}. ' \"Skipping...\") If host == metvco03.mettel.net and enterprise id == 124: self._logger.info(f\"Edge {edge} was appended to the list of edges that have no status but\" f\"are in the customer cache.\")","title":"Map cached edges with edges status Documentation"},{"location":"logging/services/service-outage-monitor/actions/outage_monitoring/_outage_monitoring_process/","text":"Outage monitor process self._logger.info(f\"[outage_monitoring_process] Start with map cache!\") Get cache for outage monitor Check if cache status is not 200 self._logger.warning(\"Not found cache for service outage. Stop the outage monitoring process\" self._logger.info(\"[outage_monitoring_process] Ignoring blacklisted edges...\") self._logger.info(f\"List of serials from customer cache: {serials_for_monitoring}\") self._logger.info(\"[outage_monitoring_process] Creating list of whitelisted serials for autoresolve...\") self._logger.info(\"[outage_monitoring_process] Splitting cache by host\") self._logger.info(\"[outage_monitoring_process] Cache split\") _process_velocloud_host self._logger.info( f\"[outage_monitoring_process] Outage monitoring process finished! Elapsed time:\" f\"{round((stop - start) / 60, 2)} minutes\" )","title":" outage monitoring process"},{"location":"logging/services/service-outage-monitor/actions/outage_monitoring/_outage_monitoring_process/#outage-monitor-process","text":"self._logger.info(f\"[outage_monitoring_process] Start with map cache!\") Get cache for outage monitor Check if cache status is not 200 self._logger.warning(\"Not found cache for service outage. Stop the outage monitoring process\" self._logger.info(\"[outage_monitoring_process] Ignoring blacklisted edges...\") self._logger.info(f\"List of serials from customer cache: {serials_for_monitoring}\") self._logger.info(\"[outage_monitoring_process] Creating list of whitelisted serials for autoresolve...\") self._logger.info(\"[outage_monitoring_process] Splitting cache by host\") self._logger.info(\"[outage_monitoring_process] Cache split\") _process_velocloud_host self._logger.info( f\"[outage_monitoring_process] Outage monitoring process finished! Elapsed time:\" f\"{round((stop - start) / 60, 2)} minutes\" )","title":"Outage monitor process"},{"location":"logging/services/service-outage-monitor/actions/outage_monitoring/_process_velocloud_host/","text":"Process velocloud host Documentation self._logger.info(f\"Processing {len(host_cache)} edges in Velocloud {host}...\") get_link_with_edge_info If status get link with edge info not OK: self._logger.warning(f\"Not found links with edge info for host: {host}. Stop process velocloud host\") get_network_enterprises If status get network enterprises not OK: self._logger.warning(f\"Not found network enterprises for host: {host}. Stop process velocloud host\") self._logger.warning(f\"Link status with edge info from Velocloud: {links_with_edge_info}\") grouped_links_by_edge self._logger.info( \"Adding HA info to existing edges, and putting standby edges under monitoring as if they were \" \"standalone edges...\" ) map_edges_with_ha_info self._logger.info(f\"Service Outage monitoring is about to check {len(all_edges)} edges\") self._logger.info(f\"{len(serials_with_ha_disabled)} edges have HA disabled: {serials_with_ha_disabled}\") self._logger.info(f\"{len(serials_with_ha_enabled)} edges have HA enabled: {serials_with_ha_enabled}\") self._logger.info(f\"{len(primary_serials)} edges are the primary of a HA pair: {primary_serials}\") self._logger.info(f\"{len(standby_serials)} edges are the standby of a HA pair: {standby_serials}\") map_cached_edges_with_edges_status self._logger.info(f\"Mapped cache serials with status: {mapped_serials_w_status}\") For outage in outages: self._logger.info(f'{outage_type.value} serials: {[e[\"status\"][\"edgeSerialNumber\"] for e in down_edges]}') self._logger.info( f\"{outage_type.value} serials that should be documented: \" f'{[e[\"status\"][\"edgeSerialNumber\"] for e in relevant_down_edges]}' ) If relevant down edges: self._logger.info(f\"{len(relevant_down_edges)} edges were detected in {outage_type.value} state.\") attempt_ticket_creation If ticket creation None: self._logger.error(f\"[{outage_type.value}] Error while attempting ticket creation(s) for edge \" f\"with Business Grade Link(s): {ex}\") _schedule_recheck_job_for_edges Else: self._logger.info( f\"No edges were detected in {outage_type.value} state. \" f\"No ticket creations will trigger for this outage type\" ) self._logger.info(f'Healthy serials: {[e[\"status\"][\"edgeSerialNumber\"] for e in healthy_edges]}') IF healthy edges: self._logger.info( f\"{len(healthy_edges)} edges were detected in healthy state. Running autoresolve for all of them...\" ) _run_ticket_autoresolve_for_edge Else: self._logger.info( \"No edges were detected in healthy state. Autoresolve won't be triggered\" ) self._logger.info(f\"Elapsed time processing edges in host {host}: {round((stop - start) / 60, 2)} minutes\")","title":" process velocloud host"},{"location":"logging/services/service-outage-monitor/actions/outage_monitoring/_process_velocloud_host/#process-velocloud-host-documentation","text":"self._logger.info(f\"Processing {len(host_cache)} edges in Velocloud {host}...\") get_link_with_edge_info If status get link with edge info not OK: self._logger.warning(f\"Not found links with edge info for host: {host}. Stop process velocloud host\") get_network_enterprises If status get network enterprises not OK: self._logger.warning(f\"Not found network enterprises for host: {host}. Stop process velocloud host\") self._logger.warning(f\"Link status with edge info from Velocloud: {links_with_edge_info}\") grouped_links_by_edge self._logger.info( \"Adding HA info to existing edges, and putting standby edges under monitoring as if they were \" \"standalone edges...\" ) map_edges_with_ha_info self._logger.info(f\"Service Outage monitoring is about to check {len(all_edges)} edges\") self._logger.info(f\"{len(serials_with_ha_disabled)} edges have HA disabled: {serials_with_ha_disabled}\") self._logger.info(f\"{len(serials_with_ha_enabled)} edges have HA enabled: {serials_with_ha_enabled}\") self._logger.info(f\"{len(primary_serials)} edges are the primary of a HA pair: {primary_serials}\") self._logger.info(f\"{len(standby_serials)} edges are the standby of a HA pair: {standby_serials}\") map_cached_edges_with_edges_status self._logger.info(f\"Mapped cache serials with status: {mapped_serials_w_status}\") For outage in outages: self._logger.info(f'{outage_type.value} serials: {[e[\"status\"][\"edgeSerialNumber\"] for e in down_edges]}') self._logger.info( f\"{outage_type.value} serials that should be documented: \" f'{[e[\"status\"][\"edgeSerialNumber\"] for e in relevant_down_edges]}' ) If relevant down edges: self._logger.info(f\"{len(relevant_down_edges)} edges were detected in {outage_type.value} state.\") attempt_ticket_creation If ticket creation None: self._logger.error(f\"[{outage_type.value}] Error while attempting ticket creation(s) for edge \" f\"with Business Grade Link(s): {ex}\") _schedule_recheck_job_for_edges Else: self._logger.info( f\"No edges were detected in {outage_type.value} state. \" f\"No ticket creations will trigger for this outage type\" ) self._logger.info(f'Healthy serials: {[e[\"status\"][\"edgeSerialNumber\"] for e in healthy_edges]}') IF healthy edges: self._logger.info( f\"{len(healthy_edges)} edges were detected in healthy state. Running autoresolve for all of them...\" ) _run_ticket_autoresolve_for_edge Else: self._logger.info( \"No edges were detected in healthy state. Autoresolve won't be triggered\" ) self._logger.info(f\"Elapsed time processing edges in host {host}: {round((stop - start) / 60, 2)} minutes\")","title":"Process velocloud host Documentation"},{"location":"logging/services/service-outage-monitor/actions/outage_monitoring/_recheck_edges_for_ticket_creation/","text":"Recheck edges for ticket creation self._logger.info(f\"[{outage_type.value}] Re-checking {len(outage_edges)} edges in outage state prior to ticket creation...\") self._logger.info(f\"[{outage_type.value}] Edges in outage before quarantine recheck: {outage_edges}\") * get_links_with_edge_info * If get links with edge info status not Ok: self._logger.warning(f\"Bad status calling to get links with edge info for host: {host}. Skipping recheck ...\") * get_network_enterprises * If get network enterprises tatus not Ok: self._logger.warning(f\"Bad status calling to get network enterprises info for host: {host}. Skipping recheck ...\") self._logger.info(f\"[{outage_type.value}] Velocloud edge status response in quarantine recheck: \" f\"{links_with_edge_info_response}\") * group_links_by_edge self._logger.info(f\"[{outage_type.value}] Adding HA info to existing edges, and putting standby edges under monitoring as if \" \"they were standalone edges...\") * map_edges_with_ha_info * get_edges_with_standbys_as_standalone_edges * _map_cached_edges_with_edges_status self._logger.info(f\"[{outage_type.value}] Current status of edges that were in outage state: {edges_full_info}\") self._logger.info(f\"[{outage_type.value}] Edges still in outage state after recheck: {edges_still_down}\") self._logger.info(f\"[{outage_type.value}] Serials still in outage state after recheck: {serials_still_down}\") self._logger.info(f\"[{outage_type.value}] Edges that are healthy after recheck: {healthy_edges}\") self._logger.info(f\"[{outage_type.value}] Serials that are healthy after recheck: {healthy_serials}\") * If edges still down: self._logger.info(f\"[{outage_type.value}] {len(edges_still_down)} edges are still in outage state after re-check. \" \"Attempting outage ticket creation for all of them...\") * If environment PRODUCTION: * _attempt_ticket_creation * If error in attempt ticket creation: self._logger.error(f\"[{outage_type.value}] Error while attempting ticket creation(s) for edge in \" f\"the quarantine: {ex}\") * Else: self._logger.info(f\"[{outage_type.value}] Not starting outage ticket creation for {len(edges_still_down)} faulty \" f\"edges because the current working environment is {working_environment.upper()}.\") * Else: self._logger.info(f\"[{outage_type.value}] No edges were detected in outage state after re-check. \" \"Outage tickets won't be created\") * If healthy edges: self._logger.info( f\"[{outage_type.value}] {len(healthy_edges)} edges were detected in healthy state after re-check. '\" \"Running autoresolve for all of them...\" ) self._logger.info( f\"[{outage_type.value}] Edges that are going to be attempted to autoresolve: {healthy_edges}\" ) * _run_ticket_autoresolve_for_edge * Else: self._logger.info( f\"[{outage_type.value}] No edges were detected in healthy state. \" \"Autoresolve won't be triggered\" ) self._logger.info(f\"[{outage_type.value}] Re-check process finished for {len(outage_edges)} edges\")","title":" recheck edges for ticket creation"},{"location":"logging/services/service-outage-monitor/actions/outage_monitoring/_recheck_edges_for_ticket_creation/#recheck-edges-for-ticket-creation","text":"self._logger.info(f\"[{outage_type.value}] Re-checking {len(outage_edges)} edges in outage state prior to ticket creation...\") self._logger.info(f\"[{outage_type.value}] Edges in outage before quarantine recheck: {outage_edges}\") * get_links_with_edge_info * If get links with edge info status not Ok: self._logger.warning(f\"Bad status calling to get links with edge info for host: {host}. Skipping recheck ...\") * get_network_enterprises * If get network enterprises tatus not Ok: self._logger.warning(f\"Bad status calling to get network enterprises info for host: {host}. Skipping recheck ...\") self._logger.info(f\"[{outage_type.value}] Velocloud edge status response in quarantine recheck: \" f\"{links_with_edge_info_response}\") * group_links_by_edge self._logger.info(f\"[{outage_type.value}] Adding HA info to existing edges, and putting standby edges under monitoring as if \" \"they were standalone edges...\") * map_edges_with_ha_info * get_edges_with_standbys_as_standalone_edges * _map_cached_edges_with_edges_status self._logger.info(f\"[{outage_type.value}] Current status of edges that were in outage state: {edges_full_info}\") self._logger.info(f\"[{outage_type.value}] Edges still in outage state after recheck: {edges_still_down}\") self._logger.info(f\"[{outage_type.value}] Serials still in outage state after recheck: {serials_still_down}\") self._logger.info(f\"[{outage_type.value}] Edges that are healthy after recheck: {healthy_edges}\") self._logger.info(f\"[{outage_type.value}] Serials that are healthy after recheck: {healthy_serials}\") * If edges still down: self._logger.info(f\"[{outage_type.value}] {len(edges_still_down)} edges are still in outage state after re-check. \" \"Attempting outage ticket creation for all of them...\") * If environment PRODUCTION: * _attempt_ticket_creation * If error in attempt ticket creation: self._logger.error(f\"[{outage_type.value}] Error while attempting ticket creation(s) for edge in \" f\"the quarantine: {ex}\") * Else: self._logger.info(f\"[{outage_type.value}] Not starting outage ticket creation for {len(edges_still_down)} faulty \" f\"edges because the current working environment is {working_environment.upper()}.\") * Else: self._logger.info(f\"[{outage_type.value}] No edges were detected in outage state after re-check. \" \"Outage tickets won't be created\") * If healthy edges: self._logger.info( f\"[{outage_type.value}] {len(healthy_edges)} edges were detected in healthy state after re-check. '\" \"Running autoresolve for all of them...\" ) self._logger.info( f\"[{outage_type.value}] Edges that are going to be attempted to autoresolve: {healthy_edges}\" ) * _run_ticket_autoresolve_for_edge * Else: self._logger.info( f\"[{outage_type.value}] No edges were detected in healthy state. \" \"Autoresolve won't be triggered\" ) self._logger.info(f\"[{outage_type.value}] Re-check process finished for {len(outage_edges)} edges\")","title":"Recheck edges for ticket creation"},{"location":"logging/services/service-outage-monitor/actions/outage_monitoring/_reopen_outage_ticket/","text":"Reopen outage ticket self._logger.info(f\"Reopening outage ticket {ticket_id} for serial {serial_number}...\") * get_ticket_details * If get ticket details status is not Ok: self._logger.info(f\"Bad status calling to get ticket details. Skipping reopen ticket ...\") * open_ticket * If open ticket status is Ok: self._logger.info(f\"Detail {detail_id_for_reopening} of outage ticket {ticket_id} reopened successfully.\") * _append_triage_note * Else: self._logger.error(f\"Reopening for detail {detail_id_for_reopening} of outage ticket {ticket_id} failed.\")","title":" reopen outage ticket"},{"location":"logging/services/service-outage-monitor/actions/outage_monitoring/_reopen_outage_ticket/#reopen-outage-ticket","text":"self._logger.info(f\"Reopening outage ticket {ticket_id} for serial {serial_number}...\") * get_ticket_details * If get ticket details status is not Ok: self._logger.info(f\"Bad status calling to get ticket details. Skipping reopen ticket ...\") * open_ticket * If open ticket status is Ok: self._logger.info(f\"Detail {detail_id_for_reopening} of outage ticket {ticket_id} reopened successfully.\") * _append_triage_note * Else: self._logger.error(f\"Reopening for detail {detail_id_for_reopening} of outage ticket {ticket_id} failed.\")","title":"Reopen outage ticket"},{"location":"logging/services/service-outage-monitor/actions/outage_monitoring/_run_ticket_autoresolve_for_edge/","text":"Run ticket autoresolve for edge self._logger.info(f\"[ticket-autoresolve] Starting autoresolve for edge {serial_number}...\") If serial number not in autoresolve serial whitelist: self._logger.info(f\"[ticket-autoresolve] Skipping autoresolve for edge {serial_number} because its \" f\"serial ({serial_number}) is not whitelisted.\") get_open_outage_tickets self._logger.info(f\"Bad status calling for outage tickets for client id: {client_id} and serial: {serial_number}. \" f\"Skipping autoresolve ...\") If not found outage tickets: self._logger.info(f\"[ticket-autoresolve] No outage ticket found for edge {serial_number}. \" f\"Skipping autoresolve...\") If ticket not created by automation: self._logger.info(f\"Ticket {outage_ticket_id} was not created by Automation Engine. Skipping autoresolve...\") get_ticket_details self._logger.info(f\"Bad status calling get ticket details for outage ticket: {outage_ticket_id}. \" f\"Skipping autoresolve ...\") If has faulty BYOB link and is ticket task in ipa queue: self._logger.info(f\"Task for serial {serial_number} in ticket {outage_ticket_id} is related to a BYOB link \" f\"and is in the IPA Investigate queue. Ignoring auto-resolution restrictions...\") Else: If was last outage detect recently: self._logger.info(f\"Edge {serial_number} has been in outage state for a long time, so detail {ticket_detail_id} \" f\"(serial {serial_number}) of ticket {outage_ticket_id} will not be autoresolved. Skipping \" f\"autoresolve...\") If can't autoresolve one time more: self._logger.info(f\"[ticket-autoresolve] Limit to autoresolve detail {ticket_detail_id} (serial {serial_number}) \" f\"of ticket {outage_ticket_id} linked to edge {serial_number} has been maxed out already. \" \"Skipping autoresolve...\") If is detail resolved: self._logger.info(f\"Detail {ticket_detail_id} (serial {serial_number}) of ticket {outage_ticket_id} is already \" \"resolved. Skipping autoresolve...\") If not PRODUCTION: self._logger.info(f\"[ticket-autoresolve] Skipping autoresolve for edge {serial_number} since the \" f\"current environment is {working_environment.upper()}.\") self._logger.info(f\"Autoresolving detail {ticket_detail_id} of ticket {outage_ticket_id} linked to edge \" f\"{serial_number} with serial number {serial_number}...\") unpause_ticket_detail resolve_ticket self._logger.warning(f\"Bad status calling resolve ticket for outage ticket_id: {outage_ticket_id} and\" f\"ticket detail: {ticket_detail_id}. Skipping autoresolve ...\") append_autoresolve_note_to_ticket self._logger.info( f\"Detail {ticket_detail_id} (serial {serial_number}) of ticket {outage_ticket_id} linked to \" f\"edge {serial_number} was autoresolved!\" )","title":" run ticket autoresolve for edge"},{"location":"logging/services/service-outage-monitor/actions/outage_monitoring/_run_ticket_autoresolve_for_edge/#run-ticket-autoresolve-for-edge","text":"self._logger.info(f\"[ticket-autoresolve] Starting autoresolve for edge {serial_number}...\") If serial number not in autoresolve serial whitelist: self._logger.info(f\"[ticket-autoresolve] Skipping autoresolve for edge {serial_number} because its \" f\"serial ({serial_number}) is not whitelisted.\") get_open_outage_tickets self._logger.info(f\"Bad status calling for outage tickets for client id: {client_id} and serial: {serial_number}. \" f\"Skipping autoresolve ...\") If not found outage tickets: self._logger.info(f\"[ticket-autoresolve] No outage ticket found for edge {serial_number}. \" f\"Skipping autoresolve...\") If ticket not created by automation: self._logger.info(f\"Ticket {outage_ticket_id} was not created by Automation Engine. Skipping autoresolve...\") get_ticket_details self._logger.info(f\"Bad status calling get ticket details for outage ticket: {outage_ticket_id}. \" f\"Skipping autoresolve ...\") If has faulty BYOB link and is ticket task in ipa queue: self._logger.info(f\"Task for serial {serial_number} in ticket {outage_ticket_id} is related to a BYOB link \" f\"and is in the IPA Investigate queue. Ignoring auto-resolution restrictions...\") Else: If was last outage detect recently: self._logger.info(f\"Edge {serial_number} has been in outage state for a long time, so detail {ticket_detail_id} \" f\"(serial {serial_number}) of ticket {outage_ticket_id} will not be autoresolved. Skipping \" f\"autoresolve...\") If can't autoresolve one time more: self._logger.info(f\"[ticket-autoresolve] Limit to autoresolve detail {ticket_detail_id} (serial {serial_number}) \" f\"of ticket {outage_ticket_id} linked to edge {serial_number} has been maxed out already. \" \"Skipping autoresolve...\") If is detail resolved: self._logger.info(f\"Detail {ticket_detail_id} (serial {serial_number}) of ticket {outage_ticket_id} is already \" \"resolved. Skipping autoresolve...\") If not PRODUCTION: self._logger.info(f\"[ticket-autoresolve] Skipping autoresolve for edge {serial_number} since the \" f\"current environment is {working_environment.upper()}.\") self._logger.info(f\"Autoresolving detail {ticket_detail_id} of ticket {outage_ticket_id} linked to edge \" f\"{serial_number} with serial number {serial_number}...\") unpause_ticket_detail resolve_ticket self._logger.warning(f\"Bad status calling resolve ticket for outage ticket_id: {outage_ticket_id} and\" f\"ticket detail: {ticket_detail_id}. Skipping autoresolve ...\") append_autoresolve_note_to_ticket self._logger.info( f\"Detail {ticket_detail_id} (serial {serial_number}) of ticket {outage_ticket_id} linked to \" f\"edge {serial_number} was autoresolved!\" )","title":"Run ticket autoresolve for edge"},{"location":"logging/services/service-outage-monitor/actions/outage_monitoring/_schedule_recheck_job_for_edges/","text":"Schedule recheck job for edges self._logger.info(f\"Scheduling recheck job for {len(edges)} edges in {outage_type.value} state...\") * _recheck_edges_for_ticket_creation self._logger.info(f\"Edges in {outage_type.value} state scheduled for recheck successfully\")","title":" schedule recheck job for edges"},{"location":"logging/services/service-outage-monitor/actions/outage_monitoring/_schedule_recheck_job_for_edges/#schedule-recheck-job-for-edges","text":"self._logger.info(f\"Scheduling recheck job for {len(edges)} edges in {outage_type.value} state...\") * _recheck_edges_for_ticket_creation self._logger.info(f\"Edges in {outage_type.value} state scheduled for recheck successfully\")","title":"Schedule recheck job for edges"},{"location":"logging/services/service-outage-monitor/actions/outage_monitoring/_send_reminder/","text":"Send reminder self._logger.info(f\"Attempting to send reminder for service number {service_number} to ticket {ticket_id}\") * If not should reminder notification: self._logger.info(f\"No Reminder note will be appended for service number {service_number} to ticket {ticket_id},\" f\" since either the last documentation cycle started or the last reminder\" f\" was sent too recently\") * If working environment not PRODUCTION: self._logger.info(f\"No Reminder note will be appended for service number {service_number} to ticket {ticket_id} since \" f\"the current environment is {working_environment.upper()}\") * send_reminder_email_milestone_notification * If status not OK: self._logger.error(f\"Reminder email of edge {service_number} could not be sent for ticket\" f\" {ticket_id}!\") * _append_reminder_note * If status to append reminder note not Ok: self._logger.error(f\"Reminder note of edge {service_number} could not be appended to ticket\" f\" {ticket_id}!\") self._logger.error(f\"Reminder note of edge {service_number} was successfully appended to ticket\" f\" {ticket_id}!\")","title":" send reminder"},{"location":"logging/services/service-outage-monitor/actions/outage_monitoring/_send_reminder/#send-reminder","text":"self._logger.info(f\"Attempting to send reminder for service number {service_number} to ticket {ticket_id}\") * If not should reminder notification: self._logger.info(f\"No Reminder note will be appended for service number {service_number} to ticket {ticket_id},\" f\" since either the last documentation cycle started or the last reminder\" f\" was sent too recently\") * If working environment not PRODUCTION: self._logger.info(f\"No Reminder note will be appended for service number {service_number} to ticket {ticket_id} since \" f\"the current environment is {working_environment.upper()}\") * send_reminder_email_milestone_notification * If status not OK: self._logger.error(f\"Reminder email of edge {service_number} could not be sent for ticket\" f\" {ticket_id}!\") * _append_reminder_note * If status to append reminder note not Ok: self._logger.error(f\"Reminder note of edge {service_number} could not be appended to ticket\" f\" {ticket_id}!\") self._logger.error(f\"Reminder note of edge {service_number} was successfully appended to ticket\" f\" {ticket_id}!\")","title":"Send reminder"},{"location":"logging/services/service-outage-monitor/actions/outage_monitoring/append_note_to_ticket/","text":"Append note to ticket","title":"Append note to ticket"},{"location":"logging/services/service-outage-monitor/actions/outage_monitoring/append_note_to_ticket/#append-note-to-ticket","text":"","title":"Append note to ticket"},{"location":"logging/services/service-outage-monitor/actions/outage_monitoring/change_detail_work_queue_to_hnoc/","text":"Change detail work queue to hnoc change_detail_work_queue If change detail work queue status is ok: self._logger.info(f\"Ticket {ticket_id} and serial {serial_number} task result changed to {task_result}\") Else: self._logger.error( f\"Failed to forward ticket_id {ticket_id} and \" f\"serial {serial_number} to {target_queue} due to bruin \" f\"returning {change_detail_work_queue_response} when attempting to forward to HNOC.\" )","title":"Change detail work queue to hnoc"},{"location":"logging/services/service-outage-monitor/actions/outage_monitoring/change_detail_work_queue_to_hnoc/#change-detail-work-queue-to-hnoc","text":"change_detail_work_queue If change detail work queue status is ok: self._logger.info(f\"Ticket {ticket_id} and serial {serial_number} task result changed to {task_result}\") Else: self._logger.error( f\"Failed to forward ticket_id {ticket_id} and \" f\"serial {serial_number} to {target_queue} due to bruin \" f\"returning {change_detail_work_queue_response} when attempting to forward to HNOC.\" )","title":"Change detail work queue to hnoc"},{"location":"logging/services/service-outage-monitor/actions/outage_monitoring/forward_ticket_to_hnoc_queue/","text":"Forward_ticket_to_hnoc_queue self._logger.info(f\"Checking if ticket_id {ticket_id} for serial {serial_number} is resolved before \" f\"attempting to forward to HNOC...\") * get_ticket_details * If ticket details status is not OK self._logger.info(f\"Getting ticket details of ticket_id {ticket_id} and serial {serial_number} \" f\"from Bruin failed: {ticket_details_response}. \" f\"Retrying forward to HNOC...\") * If detail is resolved: self._logger.info(f\"Ticket id {ticket_id} for serial {serial_number} is resolved. \" f\"Skipping forward to HNOC...\") self._logger.info(f\"Ticket id {ticket_id} for serial {serial_number} is not resolved. \" f\"Forwarding to HNOC...\") * change_detail_work_queue_to_hnoc * If Exception: self._logger.error(f\"An error occurred while trying to forward ticket_id {ticket_id} for serial {serial_number} to HNOC\" f\" -> {e}\")","title":"Forward ticket to hnoc queue"},{"location":"logging/services/service-outage-monitor/actions/outage_monitoring/forward_ticket_to_hnoc_queue/#forward_ticket_to_hnoc_queue","text":"self._logger.info(f\"Checking if ticket_id {ticket_id} for serial {serial_number} is resolved before \" f\"attempting to forward to HNOC...\") * get_ticket_details * If ticket details status is not OK self._logger.info(f\"Getting ticket details of ticket_id {ticket_id} and serial {serial_number} \" f\"from Bruin failed: {ticket_details_response}. \" f\"Retrying forward to HNOC...\") * If detail is resolved: self._logger.info(f\"Ticket id {ticket_id} for serial {serial_number} is resolved. \" f\"Skipping forward to HNOC...\") self._logger.info(f\"Ticket id {ticket_id} for serial {serial_number} is not resolved. \" f\"Forwarding to HNOC...\") * change_detail_work_queue_to_hnoc * If Exception: self._logger.error(f\"An error occurred while trying to forward ticket_id {ticket_id} for serial {serial_number} to HNOC\" f\" -> {e}\")","title":"Forward_ticket_to_hnoc_queue"},{"location":"logging/services/service-outage-monitor/actions/outage_monitoring/schedule_forward_to_hnoc_queue/","text":"Schedule forward to hnoc queue self._logger.info(f\"Scheduling HNOC forwarding for ticket_id {ticket_id} and serial {serial_number}\" f\" to happen at timestamp: {forward_task_run_date}\") * Add job * forward_ticket_to_hnoc_queue","title":"Schedule forward to hnoc queue"},{"location":"logging/services/service-outage-monitor/actions/outage_monitoring/schedule_forward_to_hnoc_queue/#schedule-forward-to-hnoc-queue","text":"self._logger.info(f\"Scheduling HNOC forwarding for ticket_id {ticket_id} and serial {serial_number}\" f\" to happen at timestamp: {forward_task_run_date}\") * Add job * forward_ticket_to_hnoc_queue","title":"Schedule forward to hnoc queue"},{"location":"logging/services/service-outage-monitor/actions/outage_monitoring/start_service_outage_monitoring/","text":"Start service outage monitoring ( start the process of outage ) self._logger.info(\"Scheduling Service Outage Monitor job...\") * If exe on start: self._logger.info(\"Service Outage Monitor job is going to be executed immediately\") * _outage_monitoring_process * If Exception: self._logger.error(f\"Skipping start of Service Outage Monitoring job. Reason: {conflict}\")","title":"Start service outage monitoring"},{"location":"logging/services/service-outage-monitor/actions/outage_monitoring/start_service_outage_monitoring/#start-service-outage-monitoring-start-the-process-of-outage","text":"self._logger.info(\"Scheduling Service Outage Monitor job...\") * If exe on start: self._logger.info(\"Service Outage Monitor job is going to be executed immediately\") * _outage_monitoring_process * If Exception: self._logger.error(f\"Skipping start of Service Outage Monitoring job. Reason: {conflict}\")","title":"Start service outage monitoring (start the process of outage)"},{"location":"logging/services/service-outage-monitor/actions/triage/_append_new_triage_notes_based_on_recent_events/","text":"Append new triage notes based on recent events self._logger.info(f\"Appending new triage note to detail {ticket_detail_id} of ticket {ticket_id}...\") self._logger.info( f\"Getting events for serial {service_number} (detail {ticket_detail_id}) in ticket \" f\"{ticket_id} before applying triage...\" ) * get_last_edge_events * If get last events status is not Ok: self._logger.warning(f\"Bad status calling get last edge events for edge: {edge_full_id}. \" f\"Skipping append triage notes based in recent events ...\") * If not recent events: self._logger.info( f\"No events were found for edge {service_number} starting from {events_lookup_timestamp}. \" f\"Not appending any new triage notes to detail {ticket_detail_id} of ticket {ticket_id}.\" ) * For chunk in event chunked: * If environment is PRODUCTION: * append_note_to_ticket * If append note status is not Ok: self._logger.warning(f\"Bad status apeending note to ticket: {ticket_id}. Skipping append note ...\") self._logger.info(f\"Triage appended to detail {ticket_detail_id} of ticket {ticket_id}!\") * Else: self._logger.info(f\"Triage appended to detail {ticket_detail_id} of ticket {ticket_id}!\") * If note appended: * _notify_triage_note_was_appended_to_ticket","title":" append new triage notes based on recent events"},{"location":"logging/services/service-outage-monitor/actions/triage/_append_new_triage_notes_based_on_recent_events/#append-new-triage-notes-based-on-recent-events","text":"self._logger.info(f\"Appending new triage note to detail {ticket_detail_id} of ticket {ticket_id}...\") self._logger.info( f\"Getting events for serial {service_number} (detail {ticket_detail_id}) in ticket \" f\"{ticket_id} before applying triage...\" ) * get_last_edge_events * If get last events status is not Ok: self._logger.warning(f\"Bad status calling get last edge events for edge: {edge_full_id}. \" f\"Skipping append triage notes based in recent events ...\") * If not recent events: self._logger.info( f\"No events were found for edge {service_number} starting from {events_lookup_timestamp}. \" f\"Not appending any new triage notes to detail {ticket_detail_id} of ticket {ticket_id}.\" ) * For chunk in event chunked: * If environment is PRODUCTION: * append_note_to_ticket * If append note status is not Ok: self._logger.warning(f\"Bad status apeending note to ticket: {ticket_id}. Skipping append note ...\") self._logger.info(f\"Triage appended to detail {ticket_detail_id} of ticket {ticket_id}!\") * Else: self._logger.info(f\"Triage appended to detail {ticket_detail_id} of ticket {ticket_id}!\") * If note appended: * _notify_triage_note_was_appended_to_ticket","title":"Append new triage notes based on recent events"},{"location":"logging/services/service-outage-monitor/actions/triage/_build_edges_status_by_serial/","text":"Build edges status by serial get_edges_for_triage get_network_enterprises_for_triage map_edges_with_ha_info","title":" build edges status by serial"},{"location":"logging/services/service-outage-monitor/actions/triage/_build_edges_status_by_serial/#build-edges-status-by-serial","text":"get_edges_for_triage get_network_enterprises_for_triage map_edges_with_ha_info","title":"Build edges status by serial"},{"location":"logging/services/service-outage-monitor/actions/triage/_filter_irrelevant_notes_in_tickets/","text":"Filter irrelevant notes in tickets For ticket in tickets: self._logger.info(f'Filtering notes for ticket_id: {ticket[\"ticket_id\"]} to contain relevant notes')","title":" filter irrelevant notes in tickets"},{"location":"logging/services/service-outage-monitor/actions/triage/_filter_irrelevant_notes_in_tickets/#filter-irrelevant-notes-in-tickets","text":"For ticket in tickets: self._logger.info(f'Filtering notes for ticket_id: {ticket[\"ticket_id\"]} to contain relevant notes')","title":"Filter irrelevant notes in tickets"},{"location":"logging/services/service-outage-monitor/actions/triage/_filter_tickets_and_details_related_to_edges_under_monitoring/","text":"Filter tickets and details related to edges under monitoring For ticket in tickets: self._logger.info(f'Checking ticket_id: {ticket[\"ticket_id\"]} for relevant details') If not relevant details: self._logger.info(f'Ticket with ticket_id: {ticket[\"ticket_id\"]} has no relevant details') self._logger.info( f'Ticket with ticket_id: {ticket[\"ticket_id\"]} contains relevant details.' f\"Appending to relevant_tickets list ...\" )","title":" filter tickets and details related to edges under monitoring"},{"location":"logging/services/service-outage-monitor/actions/triage/_filter_tickets_and_details_related_to_edges_under_monitoring/#filter-tickets-and-details-related-to-edges-under-monitoring","text":"For ticket in tickets: self._logger.info(f'Checking ticket_id: {ticket[\"ticket_id\"]} for relevant details') If not relevant details: self._logger.info(f'Ticket with ticket_id: {ticket[\"ticket_id\"]} has no relevant details') self._logger.info( f'Ticket with ticket_id: {ticket[\"ticket_id\"]} contains relevant details.' f\"Appending to relevant_tickets list ...\" )","title":"Filter tickets and details related to edges under monitoring"},{"location":"logging/services/service-outage-monitor/actions/triage/_get_all_open_tickets_with_details_for_monitored_companies/","text":"Get all open tickets with details for monitored companies get_open_outage_tickets If get open outage status is not Ok: self._logger.warning(f\"Bad status calling to open tickets. Return an empty list ...\") self._logger.info(\"Getting all opened tickets details for each open ticket ...\") _get_open_tickets_with_details_by_ticket_id self._logger.info(\"Finished getting all opened ticket details!\")","title":" get all open tickets with details for monitored companies"},{"location":"logging/services/service-outage-monitor/actions/triage/_get_all_open_tickets_with_details_for_monitored_companies/#get-all-open-tickets-with-details-for-monitored-companies","text":"get_open_outage_tickets If get open outage status is not Ok: self._logger.warning(f\"Bad status calling to open tickets. Return an empty list ...\") self._logger.info(\"Getting all opened tickets details for each open ticket ...\") _get_open_tickets_with_details_by_ticket_id self._logger.info(\"Finished getting all opened ticket details!\")","title":"Get all open tickets with details for monitored companies"},{"location":"logging/services/service-outage-monitor/actions/triage/_get_open_tickets_with_details_by_ticket_id/","text":"Get open tickets with details by ticket id get_ticket_details If get ticket detail status is not Ok: self._logger.warning( f\"Bad status calling get ticket details for ticket id: {ticket_id}. \" f\"Skipping get ticket details ...\") If not ticket details: self._logger.info( f\"Ticket {ticket_id} doesn't have any detail under ticketDetails key. \" f\"Skipping...\" ) self._logger.info(f\"Got details for ticket {ticket_id}!\") If Exception: self._logger.error( f\"An error occurred while trying to get tickets details for ticket_id {ticket_id} -> {e}\" )","title":" get open tickets with details by ticket id"},{"location":"logging/services/service-outage-monitor/actions/triage/_get_open_tickets_with_details_by_ticket_id/#get-open-tickets-with-details-by-ticket-id","text":"get_ticket_details If get ticket detail status is not Ok: self._logger.warning( f\"Bad status calling get ticket details for ticket id: {ticket_id}. \" f\"Skipping get ticket details ...\") If not ticket details: self._logger.info( f\"Ticket {ticket_id} doesn't have any detail under ticketDetails key. \" f\"Skipping...\" ) self._logger.info(f\"Got details for ticket {ticket_id}!\") If Exception: self._logger.error( f\"An error occurred while trying to get tickets details for ticket_id {ticket_id} -> {e}\" )","title":"Get open tickets with details by ticket id"},{"location":"logging/services/service-outage-monitor/actions/triage/_get_ticket_details_with_and_without_triage/","text":"Get ticket details with and without triage For ticket in tickets: self._logger.info(f\"Checking details of ticket_id: {ticket_id}\") For detail in ticket details: self._logger.info( f\"Checking for triage notes in ticket_id: {ticket_id} \" f\"relating to serial number: {serial_number}\" ) If notes related to serial: self._logger.info( f\"No triage notes found in ticket_id: {ticket_id} \" f\"for serial number {serial_number}. \" f\"Adding to ticket_details_without_triage list...\" ) Else: sself._logger.info( f\"Triage note found in ticket_id: {ticket_id} \" f\"for serial number {serial_number}. \" f\"Adding to ticket_details_with_triage list...\" )","title":" get ticket details with and without triage"},{"location":"logging/services/service-outage-monitor/actions/triage/_get_ticket_details_with_and_without_triage/#get-ticket-details-with-and-without-triage","text":"For ticket in tickets: self._logger.info(f\"Checking details of ticket_id: {ticket_id}\") For detail in ticket details: self._logger.info( f\"Checking for triage notes in ticket_id: {ticket_id} \" f\"relating to serial number: {serial_number}\" ) If notes related to serial: self._logger.info( f\"No triage notes found in ticket_id: {ticket_id} \" f\"for serial number {serial_number}. \" f\"Adding to ticket_details_without_triage list...\" ) Else: sself._logger.info( f\"Triage note found in ticket_id: {ticket_id} \" f\"for serial number {serial_number}. \" f\"Adding to ticket_details_with_triage list...\" )","title":"Get ticket details with and without triage"},{"location":"logging/services/service-outage-monitor/actions/triage/_notify_triage_note_was_appended_to_ticket/","text":"Notify triage note was appended to ticket self._logger.info(f\"Triage appended to detail {ticket_detail_id} (serial: {service_number}) of ticket {ticket_id}. \" f\"Details at https://app.bruin.com/t/{ticket_id}\")","title":" notify triage note was appended to ticket"},{"location":"logging/services/service-outage-monitor/actions/triage/_notify_triage_note_was_appended_to_ticket/#notify-triage-note-was-appended-to-ticket","text":"self._logger.info(f\"Triage appended to detail {ticket_detail_id} (serial: {service_number}) of ticket {ticket_id}. \" f\"Details at https://app.bruin.com/t/{ticket_id}\")","title":"Notify triage note was appended to ticket"},{"location":"logging/services/service-outage-monitor/actions/triage/_process_ticket_details_with_triage/","text":"Process ticket details with triage self._logger.info(\"Processing ticket details with triage...\") * For detail in details: self._logger.info(f\"Processing detail {ticket_detail_id} with triage of ticket {ticket_id}...\") self._logger.info( f\"Checking if events need to be appended to detail {ticket_detail_id} of ticket {ticket_id}...\" ) * If ticket note append recently: self._logger.info( f\"The last triage note was appended to detail {ticket_detail_id} of ticket \" f\"{ticket_id} not long ago so no new triage note will be appended for now\" ) self._logger.info(f\"Appending events to detail {ticket_detail_id} of ticket {ticket_id}...\") * _append_new_triage_notes_based_on_recent_events self._logger.info(f\"Events appended to detail {ticket_detail_id} of ticket {ticket_id}!\") self._logger.info(f\"Finished processing detail {ticket_detail_id} of ticket {ticket_id}!\") self._logger.info(\"Finished processing ticket details with triage!\")","title":" process ticket details with triage"},{"location":"logging/services/service-outage-monitor/actions/triage/_process_ticket_details_with_triage/#process-ticket-details-with-triage","text":"self._logger.info(\"Processing ticket details with triage...\") * For detail in details: self._logger.info(f\"Processing detail {ticket_detail_id} with triage of ticket {ticket_id}...\") self._logger.info( f\"Checking if events need to be appended to detail {ticket_detail_id} of ticket {ticket_id}...\" ) * If ticket note append recently: self._logger.info( f\"The last triage note was appended to detail {ticket_detail_id} of ticket \" f\"{ticket_id} not long ago so no new triage note will be appended for now\" ) self._logger.info(f\"Appending events to detail {ticket_detail_id} of ticket {ticket_id}...\") * _append_new_triage_notes_based_on_recent_events self._logger.info(f\"Events appended to detail {ticket_detail_id} of ticket {ticket_id}!\") self._logger.info(f\"Finished processing detail {ticket_detail_id} of ticket {ticket_id}!\") self._logger.info(\"Finished processing ticket details with triage!\")","title":"Process ticket details with triage"},{"location":"logging/services/service-outage-monitor/actions/triage/_process_ticket_details_without_triage/","text":"Process ticket details without triage self._logger.info(\"Processing ticket details without triage...\") * For detail in details: self._logger.info(f\"Processing detail {ticket_detail_id} without triage of ticket {ticket_id}...\") * If not outage type: self._logger.info( f\"Edge {serial_number} is no longer down, so the initial triage note won't be posted to ticket \" f\"{ticket_id}. Posting events of the last 24 hours to the ticket so it's not blank...\" ) * _append_new_triage_notes_based_on_recent_events * Else: self._logger.info( f\"Edge {serial_number} is in {outage_type.value} state. Posting initial triage note to ticket \" f\"{ticket_id}...\" ) * If not document outage: self._logger.info( f\"Edge {serial_number} is down, but it doesn't qualify to be documented as a Service Outage in \" f\"ticket {ticket_id}. Most probable thing is that the edge is the standby of a HA pair, and \" \"standbys in outage state are only documented in the event of a Soft Down. Skipping...\" ) * get_last_edge_events * If get last edge events not Ok: self._logger.warning(f\"Bad status calling to get last edge events. \" f\"Skipping process details without details ...\") self._logger.info(f\"Finished processing detail {ticket_detail_id} of ticket {ticket_id}!\") self._logger.info(\"Finished processing ticket details without triage!\")","title":" process ticket details without triage"},{"location":"logging/services/service-outage-monitor/actions/triage/_process_ticket_details_without_triage/#process-ticket-details-without-triage","text":"self._logger.info(\"Processing ticket details without triage...\") * For detail in details: self._logger.info(f\"Processing detail {ticket_detail_id} without triage of ticket {ticket_id}...\") * If not outage type: self._logger.info( f\"Edge {serial_number} is no longer down, so the initial triage note won't be posted to ticket \" f\"{ticket_id}. Posting events of the last 24 hours to the ticket so it's not blank...\" ) * _append_new_triage_notes_based_on_recent_events * Else: self._logger.info( f\"Edge {serial_number} is in {outage_type.value} state. Posting initial triage note to ticket \" f\"{ticket_id}...\" ) * If not document outage: self._logger.info( f\"Edge {serial_number} is down, but it doesn't qualify to be documented as a Service Outage in \" f\"ticket {ticket_id}. Most probable thing is that the edge is the standby of a HA pair, and \" \"standbys in outage state are only documented in the event of a Soft Down. Skipping...\" ) * get_last_edge_events * If get last edge events not Ok: self._logger.warning(f\"Bad status calling to get last edge events. \" f\"Skipping process details without details ...\") self._logger.info(f\"Finished processing detail {ticket_detail_id} of ticket {ticket_id}!\") self._logger.info(\"Finished processing ticket details without triage!\")","title":"Process ticket details without triage"},{"location":"logging/services/service-outage-monitor/actions/triage/_run_tickets_polling/","text":"Run tickets polling self._logger.info(f\"Starting triage process...\") * get_cache_for_triage_monitoring self._logger.info(\"Getting all open tickets for all customers...\") * _get_all_open_tickets_with_details_for_monitored_companies self._logger.info( f\"Got all {len(open_tickets)} open tickets for all customers. \" f\"Filtering them to get only the ones under the device list\" ) * _filter_tickets_and_details_related_to_edges_under_monitoring self._logger.info( f\"Got {len(relevant_open_tickets)} relevant tickets for all customers. \" f\"Cleaning them up to exclude all invalid notes...\" ) * _filter_irrelevant_notes_in_tickets self._logger.info(f\"Splitting relevant tickets in tickets with and without triage...\") * _get_ticket_details_with_and_without_triage self._logger.info( f\"Ticket details split successfully. \" f\"Ticket details with triage: {len(details_with_triage)}. \" f\"Ticket details without triage: {len(details_without_triage)}. \" \"Processing both sets...\" ) * _build_edges_status_by_serial * _process_ticket_details_with_triage self._logger.info(f\"Triage process finished! took {time.time() - total_start_time} seconds\")","title":" run tickets polling"},{"location":"logging/services/service-outage-monitor/actions/triage/_run_tickets_polling/#run-tickets-polling","text":"self._logger.info(f\"Starting triage process...\") * get_cache_for_triage_monitoring self._logger.info(\"Getting all open tickets for all customers...\") * _get_all_open_tickets_with_details_for_monitored_companies self._logger.info( f\"Got all {len(open_tickets)} open tickets for all customers. \" f\"Filtering them to get only the ones under the device list\" ) * _filter_tickets_and_details_related_to_edges_under_monitoring self._logger.info( f\"Got {len(relevant_open_tickets)} relevant tickets for all customers. \" f\"Cleaning them up to exclude all invalid notes...\" ) * _filter_irrelevant_notes_in_tickets self._logger.info(f\"Splitting relevant tickets in tickets with and without triage...\") * _get_ticket_details_with_and_without_triage self._logger.info( f\"Ticket details split successfully. \" f\"Ticket details with triage: {len(details_with_triage)}. \" f\"Ticket details without triage: {len(details_without_triage)}. \" \"Processing both sets...\" ) * _build_edges_status_by_serial * _process_ticket_details_with_triage self._logger.info(f\"Triage process finished! took {time.time() - total_start_time} seconds\")","title":"Run tickets polling"},{"location":"logging/services/service-outage-monitor/repositories/bruin_repository/append_asr_forwarding_note/","text":"Append asr forwarding note append_note_to_ticket","title":"Append asr forwarding note"},{"location":"logging/services/service-outage-monitor/repositories/bruin_repository/append_asr_forwarding_note/#append-asr-forwarding-note","text":"append_note_to_ticket","title":"Append asr forwarding note"},{"location":"logging/services/service-outage-monitor/repositories/bruin_repository/append_autoresolve_note_to_ticket/","text":"Append autoresolve note to ticket append_note_to_ticket","title":"Append autoresolve note to ticket"},{"location":"logging/services/service-outage-monitor/repositories/bruin_repository/append_autoresolve_note_to_ticket/#append-autoresolve-note-to-ticket","text":"append_note_to_ticket","title":"Append autoresolve note to ticket"},{"location":"logging/services/service-outage-monitor/repositories/bruin_repository/append_digi_reboot_note/","text":"Append digi reboot note append_note_to_ticket","title":"Append digi reboot note"},{"location":"logging/services/service-outage-monitor/repositories/bruin_repository/append_digi_reboot_note/#append-digi-reboot-note","text":"append_note_to_ticket","title":"Append digi reboot note"},{"location":"logging/services/service-outage-monitor/repositories/bruin_repository/append_note_to_ticket/","text":"Append note to ticket If service number: self._logger.info(f'Appending note for service number(s) {\", \".join(service_numbers)} in ticket {ticket_id}...') Else: self._logger.info(f\"Appending note for all service number(s) in ticket {ticket_id}...\") If Exception: self._logger.error(f\"An error occurred when appending a ticket note to ticket {ticket_id}. \" f\"Ticket note: {note}. Error: {e}\") If status not ok: self._logger.error(f\"Error while appending note to ticket {ticket_id} in \" f\"{self._config.CURRENT_ENVIRONMENT.upper()} environment. Note was {note}. Error: \" f\"Error {response_status} - {response_body}\")","title":"Append note to ticket"},{"location":"logging/services/service-outage-monitor/repositories/bruin_repository/append_note_to_ticket/#append-note-to-ticket","text":"If service number: self._logger.info(f'Appending note for service number(s) {\", \".join(service_numbers)} in ticket {ticket_id}...') Else: self._logger.info(f\"Appending note for all service number(s) in ticket {ticket_id}...\") If Exception: self._logger.error(f\"An error occurred when appending a ticket note to ticket {ticket_id}. \" f\"Ticket note: {note}. Error: {e}\") If status not ok: self._logger.error(f\"Error while appending note to ticket {ticket_id} in \" f\"{self._config.CURRENT_ENVIRONMENT.upper()} environment. Note was {note}. Error: \" f\"Error {response_status} - {response_body}\")","title":"Append note to ticket"},{"location":"logging/services/service-outage-monitor/repositories/bruin_repository/append_task_result_change_note/","text":"Append task result change note append_note_to_ticket","title":"Append task result change note"},{"location":"logging/services/service-outage-monitor/repositories/bruin_repository/append_task_result_change_note/#append-task-result-change-note","text":"append_note_to_ticket","title":"Append task result change note"},{"location":"logging/services/service-outage-monitor/repositories/bruin_repository/append_triage_note/","text":"Append triage note If environment is DEV: self._logger.info(f\"Triage note would have been appended to detail {ticket_detail_id} of ticket {ticket_id}\" f\"(serial: {service_number}). Note: {ticket_note}. Details at app.bruin.com/t/{ticket_id}\") Elif environment is PRODUCTION: If len of ticket note is lower than 1500: append_note_to_ticket Else: Split lines and send in blocks: append_note_to_ticket","title":"Append triage note"},{"location":"logging/services/service-outage-monitor/repositories/bruin_repository/append_triage_note/#append-triage-note","text":"If environment is DEV: self._logger.info(f\"Triage note would have been appended to detail {ticket_detail_id} of ticket {ticket_id}\" f\"(serial: {service_number}). Note: {ticket_note}. Details at app.bruin.com/t/{ticket_id}\") Elif environment is PRODUCTION: If len of ticket note is lower than 1500: append_note_to_ticket Else: Split lines and send in blocks: append_note_to_ticket","title":"Append triage note"},{"location":"logging/services/service-outage-monitor/repositories/bruin_repository/change_detail_work_queue/","text":"Change detail work queue self._logger.info(f\"Changing task result for ticket {ticket_id} and detail id {detail_id} for device {serial_number} to {task_result}...\") * If Exception: self._logger.error(f\"An error occurred when changing task result for ticket {ticket_id} and serial{serial_number}\") * If status ok: self._logger.info(f\"Ticket {ticket_id} and serial {serial_number} task result changed to {task_result}\") * Else: self._logger.info(f\"Error while changing task result for ticket {ticket_id} and serial {serial_number} in \" f\"{self._config.CURRENT_ENVIRONMENT.upper()} environment: \" f\"Error {response_status} - {response_body}\")","title":"Change detail work queue"},{"location":"logging/services/service-outage-monitor/repositories/bruin_repository/change_detail_work_queue/#change-detail-work-queue","text":"self._logger.info(f\"Changing task result for ticket {ticket_id} and detail id {detail_id} for device {serial_number} to {task_result}...\") * If Exception: self._logger.error(f\"An error occurred when changing task result for ticket {ticket_id} and serial{serial_number}\") * If status ok: self._logger.info(f\"Ticket {ticket_id} and serial {serial_number} task result changed to {task_result}\") * Else: self._logger.info(f\"Error while changing task result for ticket {ticket_id} and serial {serial_number} in \" f\"{self._config.CURRENT_ENVIRONMENT.upper()} environment: \" f\"Error {response_status} - {response_body}\")","title":"Change detail work queue"},{"location":"logging/services/service-outage-monitor/repositories/bruin_repository/change_ticket_severity/","text":"Change severity self._logger.info(f\"Changing severity level of ticket {ticket_id} to {severity_level}...\") If Exception: self._logger.error(f\"An error occurred when changing the severity level of ticket {ticket_id} to {severity_level} -> {e}\") If status is 200: self._logger.info(f\"Severity level of ticket {ticket_id} successfully changed to {severity_level}!\") Else: self._logger.error(f\"Error while changing severity of ticket {ticket_id} to {severity_level} in \" f\"{self._config.CURRENT_ENVIRONMENT.upper()} environment: \" f\"Error {response_status} - {response_body}\")","title":"Change severity"},{"location":"logging/services/service-outage-monitor/repositories/bruin_repository/change_ticket_severity/#change-severity","text":"self._logger.info(f\"Changing severity level of ticket {ticket_id} to {severity_level}...\") If Exception: self._logger.error(f\"An error occurred when changing the severity level of ticket {ticket_id} to {severity_level} -> {e}\") If status is 200: self._logger.info(f\"Severity level of ticket {ticket_id} successfully changed to {severity_level}!\") Else: self._logger.error(f\"Error while changing severity of ticket {ticket_id} to {severity_level} in \" f\"{self._config.CURRENT_ENVIRONMENT.upper()} environment: \" f\"Error {response_status} - {response_body}\")","title":"Change severity"},{"location":"logging/services/service-outage-monitor/repositories/bruin_repository/change_ticket_severity_for_disconnected_links/","text":"Change ticket severity for disconnected links change_ticket_severity","title":"Change ticket severity for disconnected links"},{"location":"logging/services/service-outage-monitor/repositories/bruin_repository/change_ticket_severity_for_disconnected_links/#change-ticket-severity-for-disconnected-links","text":"change_ticket_severity","title":"Change ticket severity for disconnected links"},{"location":"logging/services/service-outage-monitor/repositories/bruin_repository/change_ticket_severity_for_offline_edge/","text":"Change ticket severity for offline edges change_ticket_severity","title":"Change ticket severity for offline edge"},{"location":"logging/services/service-outage-monitor/repositories/bruin_repository/change_ticket_severity_for_offline_edge/#change-ticket-severity-for-offline-edges","text":"change_ticket_severity","title":"Change ticket severity for offline edges"},{"location":"logging/services/service-outage-monitor/repositories/bruin_repository/create_outage_ticket/","text":"Create outage ticket Documentation self._logger.info(f\"Creating outage ticket for device {service_number} that belongs to client {client_id}...\") ``` * If Exception: ``` self._logger.error(f\"An error occurred when creating outage ticket for device {service_number} belong to client {client_id} -> {e}\") ``` self._logger.info(f\"Outage ticket for device {service_number} that belongs to client {client_id} created!\") * If not a correct status self._logger.error(f\"Error while creating outage ticket for device {service_number} that belongs to client \" f\"{client_id} in {self._config.CURRENT_ENVIRONMENT.upper()} environment: \" f\"Error {response_status} - {response_body}\") ```","title":"Create outage ticket"},{"location":"logging/services/service-outage-monitor/repositories/bruin_repository/create_outage_ticket/#create-outage-ticket-documentation","text":"self._logger.info(f\"Creating outage ticket for device {service_number} that belongs to client {client_id}...\") ``` * If Exception: ``` self._logger.error(f\"An error occurred when creating outage ticket for device {service_number} belong to client {client_id} -> {e}\") ``` self._logger.info(f\"Outage ticket for device {service_number} that belongs to client {client_id} created!\") * If not a correct status self._logger.error(f\"Error while creating outage ticket for device {service_number} that belongs to client \" f\"{client_id} in {self._config.CURRENT_ENVIRONMENT.upper()} environment: \" f\"Error {response_status} - {response_body}\") ```","title":"Create outage ticket Documentation"},{"location":"logging/services/service-outage-monitor/repositories/bruin_repository/get_open_outage_tickets/","text":"Get open outage tickets get_outage_tickets","title":"Get open outage tickets"},{"location":"logging/services/service-outage-monitor/repositories/bruin_repository/get_open_outage_tickets/#get-open-outage-tickets","text":"get_outage_tickets","title":"Get open outage tickets"},{"location":"logging/services/service-outage-monitor/repositories/bruin_repository/get_outage_tickets/","text":"Get outage tickets * get_ticket","title":"Get outage tickets"},{"location":"logging/services/service-outage-monitor/repositories/bruin_repository/get_outage_tickets/#get-outage-tickets","text":"* get_ticket","title":"Get outage tickets"},{"location":"logging/services/service-outage-monitor/repositories/bruin_repository/get_ticket/","text":"Get ticket self._logger.info(f'Getting all tickets with parameters of {request[\"body\"]} from Bruin...') * If Exception: self._logger.error(f'An error occurred when requesting tickets from Bruin API with parameters of {request[\"body\"]} -> {e}') * If status ok: self._logger.info(f'Got all tickets with parameters of {request[\"body\"]} from Bruin!') * Else: self._logger.error(f'Error while retrieving tickets with parameters of {request[\"body\"]} in ' f\"{self._config.CURRENT_ENVIRONMENT.upper()} environment: \" f\"Error {response_status} - {response_body}\")","title":"Get ticket"},{"location":"logging/services/service-outage-monitor/repositories/bruin_repository/get_ticket/#get-ticket","text":"self._logger.info(f'Getting all tickets with parameters of {request[\"body\"]} from Bruin...') * If Exception: self._logger.error(f'An error occurred when requesting tickets from Bruin API with parameters of {request[\"body\"]} -> {e}') * If status ok: self._logger.info(f'Got all tickets with parameters of {request[\"body\"]} from Bruin!') * Else: self._logger.error(f'Error while retrieving tickets with parameters of {request[\"body\"]} in ' f\"{self._config.CURRENT_ENVIRONMENT.upper()} environment: \" f\"Error {response_status} - {response_body}\")","title":"Get ticket"},{"location":"logging/services/service-outage-monitor/repositories/bruin_repository/get_ticket_details/","text":"Get ticket details self._logger.info(f\"Getting details of ticket {ticket_id} from Bruin...\") * If Exception: self._logger.error(f\"An error occurred when requesting ticket details from Bruin API for ticket {ticket_id} -> {e}\") self._logger.info(f\"Got details of ticket {ticket_id} from Bruin!\") * If status not 200: self._logger.error(f\"Error while retrieving details of ticket {ticket_id} in {self._config.CURRENT_ENVIRONMENT.upper()} environment: Error {response_status} - {response_body}\")","title":"Get ticket details"},{"location":"logging/services/service-outage-monitor/repositories/bruin_repository/get_ticket_details/#get-ticket-details","text":"self._logger.info(f\"Getting details of ticket {ticket_id} from Bruin...\") * If Exception: self._logger.error(f\"An error occurred when requesting ticket details from Bruin API for ticket {ticket_id} -> {e}\") self._logger.info(f\"Got details of ticket {ticket_id} from Bruin!\") * If status not 200: self._logger.error(f\"Error while retrieving details of ticket {ticket_id} in {self._config.CURRENT_ENVIRONMENT.upper()} environment: Error {response_status} - {response_body}\")","title":"Get ticket details"},{"location":"logging/services/service-outage-monitor/repositories/bruin_repository/open_ticket/","text":"Open ticket self._logger.info(f\"Opening ticket {ticket_id} (affected detail ID: {detail_id})...\") * If Exception: self._logger.error(f\"An error occurred when opening outage ticket {ticket_id} -> {e}\") self._logger.info(f\"Ticket {ticket_id} opened!\") * If status ok: self._logger.info(f\"Ticket {ticket_id} and serial {serial_number} task result changed to {task_result}\") * Else: self._logger.error(f\"Error while opening outage ticket {ticket_id} in \" f\"{self._config.CURRENT_ENVIRONMENT.upper()} environment: \" f\"Error {response_status} - {response_body}\")","title":"Open ticket"},{"location":"logging/services/service-outage-monitor/repositories/bruin_repository/open_ticket/#open-ticket","text":"self._logger.info(f\"Opening ticket {ticket_id} (affected detail ID: {detail_id})...\") * If Exception: self._logger.error(f\"An error occurred when opening outage ticket {ticket_id} -> {e}\") self._logger.info(f\"Ticket {ticket_id} opened!\") * If status ok: self._logger.info(f\"Ticket {ticket_id} and serial {serial_number} task result changed to {task_result}\") * Else: self._logger.error(f\"Error while opening outage ticket {ticket_id} in \" f\"{self._config.CURRENT_ENVIRONMENT.upper()} environment: \" f\"Error {response_status} - {response_body}\")","title":"Open ticket"},{"location":"logging/services/service-outage-monitor/repositories/bruin_repository/post_notification_email_milestone/","text":"post notification email milestone self._logger.info(f\"Sending email for ticket id {ticket_id}, service_number {service_number} and notification type {notification_type}...\") * If Exception: self._logger.info(f\"An error occurred when sending email for ticket id {ticket_id}, service_number {service_number} and notification type {notification_type}...-> {e}\") * If status ok: self._logger.info(f\"Email sent for ticket {ticket_id}, service number {service_number} and notification type {notification_type}!\") * Else: self._logger.info(f\"Error while sending email for ticket {ticket_id}, service_number {service_number} and notification type {notification_type} in \" f\"{self._config.CURRENT_ENVIRONMENT.upper()} environment: \" f\"Error {response_status} - {response_body}\")","title":"Post notification email milestone"},{"location":"logging/services/service-outage-monitor/repositories/bruin_repository/post_notification_email_milestone/#post-notification-email-milestone","text":"self._logger.info(f\"Sending email for ticket id {ticket_id}, service_number {service_number} and notification type {notification_type}...\") * If Exception: self._logger.info(f\"An error occurred when sending email for ticket id {ticket_id}, service_number {service_number} and notification type {notification_type}...-> {e}\") * If status ok: self._logger.info(f\"Email sent for ticket {ticket_id}, service number {service_number} and notification type {notification_type}!\") * Else: self._logger.info(f\"Error while sending email for ticket {ticket_id}, service_number {service_number} and notification type {notification_type} in \" f\"{self._config.CURRENT_ENVIRONMENT.upper()} environment: \" f\"Error {response_status} - {response_body}\")","title":"post notification email milestone"},{"location":"logging/services/service-outage-monitor/repositories/bruin_repository/resolve_ticket/","text":"Resolve ticket detail self._logger.info(f\"Resolving ticket {ticket_id} (affected detail ID: {detail_id})...\") * If Exception: self._logger.error(f\"An error occurred when resolving ticket {ticket_id} -> {e}\") self._logger.info(f\"Ticket {ticket_id} resolved!\") * If status not ok: self._logger.error(f\"Error while resolving ticket {ticket_id} in {self._config.CURRENT_ENVIRONMENT.upper()} \" f\"environment: Error {response_status} - {response_body}\")","title":"Resolve ticket"},{"location":"logging/services/service-outage-monitor/repositories/bruin_repository/resolve_ticket/#resolve-ticket-detail","text":"self._logger.info(f\"Resolving ticket {ticket_id} (affected detail ID: {detail_id})...\") * If Exception: self._logger.error(f\"An error occurred when resolving ticket {ticket_id} -> {e}\") self._logger.info(f\"Ticket {ticket_id} resolved!\") * If status not ok: self._logger.error(f\"Error while resolving ticket {ticket_id} in {self._config.CURRENT_ENVIRONMENT.upper()} \" f\"environment: Error {response_status} - {response_body}\")","title":"Resolve ticket detail"},{"location":"logging/services/service-outage-monitor/repositories/bruin_repository/send_initial_email_milestone_notification/","text":"send initial email milestone notification post_notification_email_milestone","title":"Send initial email milestone notification"},{"location":"logging/services/service-outage-monitor/repositories/bruin_repository/send_initial_email_milestone_notification/#send-initial-email-milestone-notification","text":"post_notification_email_milestone","title":"send initial email milestone notification"},{"location":"logging/services/service-outage-monitor/repositories/bruin_repository/send_reminder_email_milestone_notification/","text":"Send reminder email milestone notification post_notification_email_milestone","title":"Send reminder email milestone notification"},{"location":"logging/services/service-outage-monitor/repositories/bruin_repository/send_reminder_email_milestone_notification/#send-reminder-email-milestone-notification","text":"post_notification_email_milestone","title":"Send reminder email milestone notification"},{"location":"logging/services/service-outage-monitor/repositories/bruin_repository/unpause_ticket_detail/","text":"Unpause ticket detail self._logger.info(f\"Unpausing detail {detail_id} (serial {service_number}) of ticket {ticket_id}...\") * If Exception: self._logger.error(f\"An error occurred when unpausing detail {detail_id} (serial {service_number}) of ticket {ticket_id}. \" f\"Error: {e}\") * If status ok: self._logger.info(f\"Detail {detail_id} (serial {service_number}) of ticket {ticket_id} was unpaused!\") * Else: self._logger.error(f\"Error while unpausing detail {detail_id} (serial {service_number}) of ticket {ticket_id} in \" f\"{self._config.CURRENT_ENVIRONMENT.upper()} environment. \" f\"Error: Error {response_status} - {response_body}\")","title":"Unpause ticket detail"},{"location":"logging/services/service-outage-monitor/repositories/bruin_repository/unpause_ticket_detail/#unpause-ticket-detail","text":"self._logger.info(f\"Unpausing detail {detail_id} (serial {service_number}) of ticket {ticket_id}...\") * If Exception: self._logger.error(f\"An error occurred when unpausing detail {detail_id} (serial {service_number}) of ticket {ticket_id}. \" f\"Error: {e}\") * If status ok: self._logger.info(f\"Detail {detail_id} (serial {service_number}) of ticket {ticket_id} was unpaused!\") * Else: self._logger.error(f\"Error while unpausing detail {detail_id} (serial {service_number}) of ticket {ticket_id} in \" f\"{self._config.CURRENT_ENVIRONMENT.upper()} environment. \" f\"Error: Error {response_status} - {response_body}\")","title":"Unpause ticket detail"},{"location":"logging/services/service-outage-monitor/repositories/customer_cache_repository/get_cache/","text":"get cache Documentation If velo_filter self._logger.info(f\"Getting customer cache for Velocloud host(s) {', '.join(velo_filter.keys())}...\") 2. Else: self._logger.info(f\"Getting customer cache for all Velocloud hosts...\") 3. If Exception : self._logger.error(f\"An error occurred when requesting customer cache -> {e}\") If response status == 202: self._logger.error(response_body) Else: If velo_filter: self._logger.info(f\"Got customer cache for Velocloud host(s) {', '.join(velo_filter.keys())}!\") * Else self._logger.info(f\"Got customer cache for all Velocloud hosts!\")","title":"Get cache"},{"location":"logging/services/service-outage-monitor/repositories/customer_cache_repository/get_cache/#get-cache-documentation","text":"If velo_filter self._logger.info(f\"Getting customer cache for Velocloud host(s) {', '.join(velo_filter.keys())}...\") 2. Else: self._logger.info(f\"Getting customer cache for all Velocloud hosts...\") 3. If Exception : self._logger.error(f\"An error occurred when requesting customer cache -> {e}\") If response status == 202: self._logger.error(response_body) Else: If velo_filter: self._logger.info(f\"Got customer cache for Velocloud host(s) {', '.join(velo_filter.keys())}!\") * Else self._logger.info(f\"Got customer cache for all Velocloud hosts!\")","title":"get cache Documentation"},{"location":"logging/services/service-outage-monitor/repositories/customer_cache_repository/get_cache_for_outage_monitoring/","text":"get cache for outage Documentation Launch get_cache","title":"Get cache for outage monitoring"},{"location":"logging/services/service-outage-monitor/repositories/customer_cache_repository/get_cache_for_outage_monitoring/#get-cache-for-outage-documentation","text":"Launch get_cache","title":"get cache for outage Documentation"},{"location":"logging/services/service-outage-monitor/repositories/customer_cache_repository/get_cache_for_triage_monitoring/","text":"Get cache for triage monitoring get_cache","title":"Get cache for triage monitoring"},{"location":"logging/services/service-outage-monitor/repositories/customer_cache_repository/get_cache_for_triage_monitoring/#get-cache-for-triage-monitoring","text":"get_cache","title":"Get cache for triage monitoring"},{"location":"logging/services/service-outage-monitor/repositories/digi_repository/reboot_link/","text":"Reboot link self._logger.info(f\"Rebooting DiGi link of ticket {ticket_id} from Bruin...\") * If Exception: self._logger.error(f\"An error occurred when attempting a DiGi reboot for ticket {ticket_id} -> {e}\") self._logger.info(f\"Got details of ticket {ticket_id} from Bruin!\") * If status not ok: self._logger.error(f\"Error while attempting a DiGi reboot for ticket {ticket_id} in {self._config.CURRENT_ENVIRONMENT.upper()} environment: Error {response_status} - {response_body}\")","title":"Reboot link"},{"location":"logging/services/service-outage-monitor/repositories/digi_repository/reboot_link/#reboot-link","text":"self._logger.info(f\"Rebooting DiGi link of ticket {ticket_id} from Bruin...\") * If Exception: self._logger.error(f\"An error occurred when attempting a DiGi reboot for ticket {ticket_id} -> {e}\") self._logger.info(f\"Got details of ticket {ticket_id} from Bruin!\") * If status not ok: self._logger.error(f\"Error while attempting a DiGi reboot for ticket {ticket_id} in {self._config.CURRENT_ENVIRONMENT.upper()} environment: Error {response_status} - {response_body}\")","title":"Reboot link"},{"location":"logging/services/service-outage-monitor/repositories/ha_repository/get_edges_with_standbys_as_standalone_edges/","text":"Map edges with HA info Documentation","title":"Get edges with standbys as standalone edges"},{"location":"logging/services/service-outage-monitor/repositories/ha_repository/get_edges_with_standbys_as_standalone_edges/#map-edges-with-ha-info-documentation","text":"","title":"Map edges with HA info Documentation"},{"location":"logging/services/service-outage-monitor/repositories/ha_repository/map_edges_with_ha_info/","text":"Map edges with HA info Documentation for edge in edges If not edge ha info: self._logger.warning(f\"No HA info was found for edge {serial_number}. Skipping...\") If is not a raw ha state under monitoring self._logger.info( f\"HA partner for {serial_number} is in state {ha_state}, so HA will be considered as disabled for \" \"this edge\" )","title":"Map edges with ha info"},{"location":"logging/services/service-outage-monitor/repositories/ha_repository/map_edges_with_ha_info/#map-edges-with-ha-info-documentation","text":"for edge in edges If not edge ha info: self._logger.warning(f\"No HA info was found for edge {serial_number}. Skipping...\") If is not a raw ha state under monitoring self._logger.info( f\"HA partner for {serial_number} is in state {ha_state}, so HA will be considered as disabled for \" \"this edge\" )","title":"Map edges with HA info Documentation"},{"location":"logging/services/service-outage-monitor/repositories/triage_repository/build_triage_note/","text":"Build triage note This function don't have logs, only generate a note as string","title":"Build triage note"},{"location":"logging/services/service-outage-monitor/repositories/triage_repository/build_triage_note/#build-triage-note","text":"This function don't have logs, only generate a note as string","title":"Build triage note"},{"location":"logging/services/service-outage-monitor/repositories/triage_repository/start_triage_job/","text":"Start triage job (star process of triage) self._logger.info( f\"Scheduled task: service outage triage configured to run every \" f'{self._config.TRIAGE_CONFIG[\"polling_minutes\"]} minutes' ) * If exec on start: self._logger.info(f\"It will be executed now\") * _run_tickets_polling","title":"Start triage job"},{"location":"logging/services/service-outage-monitor/repositories/triage_repository/start_triage_job/#start-triage-job-star-process-of-triage","text":"self._logger.info( f\"Scheduled task: service outage triage configured to run every \" f'{self._config.TRIAGE_CONFIG[\"polling_minutes\"]} minutes' ) * If exec on start: self._logger.info(f\"It will be executed now\") * _run_tickets_polling","title":"Start triage job (star process of triage)"},{"location":"logging/services/service-outage-monitor/repositories/velocloud_repository/get_edge_events/","text":"Get edge events self._logger.info(f\"Getting events of edge {json.dumps(edge_full_id)} having any type of {event_types} that took place \" f\"between {from_} and {to} from Velocloud...\") * If Exception: self._logger.error(f\"An error occurred when requesting edge events from Velocloud for edge \" f\"{json.dumps(edge_full_id)} -> {e}\") self._logger.info(f\"Got events of edge {json.dumps(edge_full_id)} having any type in {event_types} that took place \" f\"between {from_} and {to} from Velocloud!\") * If status not ok: self._logger.error(f\"Error while retrieving events of edge {json.dumps(edge_full_id)} having any type in \" f\"{event_types} that took place between {from_} and {to} in \" f\"{self._config.CURRENT_ENVIRONMENT.upper()} environment: \" f\"Error {response_status} - {response_body}\")","title":"Get edge events"},{"location":"logging/services/service-outage-monitor/repositories/velocloud_repository/get_edge_events/#get-edge-events","text":"self._logger.info(f\"Getting events of edge {json.dumps(edge_full_id)} having any type of {event_types} that took place \" f\"between {from_} and {to} from Velocloud...\") * If Exception: self._logger.error(f\"An error occurred when requesting edge events from Velocloud for edge \" f\"{json.dumps(edge_full_id)} -> {e}\") self._logger.info(f\"Got events of edge {json.dumps(edge_full_id)} having any type in {event_types} that took place \" f\"between {from_} and {to} from Velocloud!\") * If status not ok: self._logger.error(f\"Error while retrieving events of edge {json.dumps(edge_full_id)} having any type in \" f\"{event_types} that took place between {from_} and {to} in \" f\"{self._config.CURRENT_ENVIRONMENT.upper()} environment: \" f\"Error {response_status} - {response_body}\")","title":"Get edge events"},{"location":"logging/services/service-outage-monitor/repositories/velocloud_repository/get_edges_for_triage/","text":"Get edges for triage For host in triage host: get_links_with_edge_info Is get links with edge info status is not Ok: self._logger.info(f\"Error: could not retrieve edges links by host: {host}\")","title":"Get edges for triage"},{"location":"logging/services/service-outage-monitor/repositories/velocloud_repository/get_edges_for_triage/#get-edges-for-triage","text":"For host in triage host: get_links_with_edge_info Is get links with edge info status is not Ok: self._logger.info(f\"Error: could not retrieve edges links by host: {host}\")","title":"Get edges for triage"},{"location":"logging/services/service-outage-monitor/repositories/velocloud_repository/get_last_edge_events/","text":"Get last edge events get_edge_events","title":"Get last edge events"},{"location":"logging/services/service-outage-monitor/repositories/velocloud_repository/get_last_edge_events/#get-last-edge-events","text":"get_edge_events","title":"Get last edge events"},{"location":"logging/services/service-outage-monitor/repositories/velocloud_repository/get_links_with_edge_info/","text":"Get Links with edge info Documentation self._logger.info(f\"Getting links with edge info from Velocloud for host {velocloud_host}...\") If Exception self._logger.error(f\"An error occurred when requesting edge list from Velocloud -> {e}\") * If status OK: self._logger.info(f\"Got links with edge info from Velocloud for host {velocloud_host}!\") * Else: self._logger.error(f\"Error while retrieving links with edge info in {self._config.ENVIRONMENT_NAME.upper()} \" f\"environment: Error {response_status} - {response_body}\")","title":"Get links with edge info"},{"location":"logging/services/service-outage-monitor/repositories/velocloud_repository/get_links_with_edge_info/#get-links-with-edge-info-documentation","text":"self._logger.info(f\"Getting links with edge info from Velocloud for host {velocloud_host}...\") If Exception self._logger.error(f\"An error occurred when requesting edge list from Velocloud -> {e}\") * If status OK: self._logger.info(f\"Got links with edge info from Velocloud for host {velocloud_host}!\") * Else: self._logger.error(f\"Error while retrieving links with edge info in {self._config.ENVIRONMENT_NAME.upper()} \" f\"environment: Error {response_status} - {response_body}\")","title":"Get Links with edge info Documentation"},{"location":"logging/services/service-outage-monitor/repositories/velocloud_repository/get_network_enterprises/","text":"Get network enterprises Documentation If enterprises ids: self._logger.info( f\"Getting network information for all edges belonging to enterprises \" f\"{', '.join(map(str, enterprise_ids))} in host {velocloud_host}...\" ) * Else: self._logger.info( \"Getting network information for all edges belonging to all enterprises in host \" f\"{velocloud_host}...\" ) If Exception self._logger.error(f\"An error occurred when requesting network info from Velocloud host {velocloud_host} -> {e}\") * If status OK: If enterprises ids: self._logger.info( f\"Got network information for all edges belonging to enterprises \" f\"{', '.join(map(str, enterprise_ids))} in host {velocloud_host}!\" ) * Else: self._logger.info( f\"Got network information for all edges belonging to all enterprises in host {velocloud_host}!\" ) Else: self._logger.error(f\"Error while retrieving network info from Velocloud host {velocloud_host} in \" f\"{self._config.ENVIRONMENT_NAME.upper()} environment: Error {response_status} - {response_body}\")","title":"Get network enterprises"},{"location":"logging/services/service-outage-monitor/repositories/velocloud_repository/get_network_enterprises/#get-network-enterprises-documentation","text":"If enterprises ids: self._logger.info( f\"Getting network information for all edges belonging to enterprises \" f\"{', '.join(map(str, enterprise_ids))} in host {velocloud_host}...\" ) * Else: self._logger.info( \"Getting network information for all edges belonging to all enterprises in host \" f\"{velocloud_host}...\" ) If Exception self._logger.error(f\"An error occurred when requesting network info from Velocloud host {velocloud_host} -> {e}\") * If status OK: If enterprises ids: self._logger.info( f\"Got network information for all edges belonging to enterprises \" f\"{', '.join(map(str, enterprise_ids))} in host {velocloud_host}!\" ) * Else: self._logger.info( f\"Got network information for all edges belonging to all enterprises in host {velocloud_host}!\" ) Else: self._logger.error(f\"Error while retrieving network info from Velocloud host {velocloud_host} in \" f\"{self._config.ENVIRONMENT_NAME.upper()} environment: Error {response_status} - {response_body}\")","title":"Get network enterprises Documentation"},{"location":"logging/services/service-outage-monitor/repositories/velocloud_repository/get_network_enterprises_for_triage/","text":"Get network enterprises for triage For host in triage host: get_network_enterprises If get network enterprises status is not ok: self._logger.error(f\"Could not retrieve network enterprises for triage using host {host}\")","title":"Get network enterprises for triage"},{"location":"logging/services/service-outage-monitor/repositories/velocloud_repository/get_network_enterprises_for_triage/#get-network-enterprises-for-triage","text":"For host in triage host: get_network_enterprises If get network enterprises status is not ok: self._logger.error(f\"Could not retrieve network enterprises for triage using host {host}\")","title":"Get network enterprises for triage"},{"location":"logging/services/service-outage-monitor/repositories/velocloud_repository/group_links_by_edge/","text":"Process velocloud host Documentation for link in links If not edge state: self._logger.info( f\"Edge in host {velocloud_host} and enterprise {enterprise_name} (ID: {enterprise_id}) \" f\"has an invalid state. Skipping...\" ) If edge state is \"NEVER_ACTIVATED\" self._logger.info( f\"Edge {edge_name} in host {velocloud_host} and enterprise {enterprise_name} (ID: {enterprise_id}) \" f\"has never been activated. Skipping...\" )","title":"Group links by edge"},{"location":"logging/services/service-outage-monitor/repositories/velocloud_repository/group_links_by_edge/#process-velocloud-host-documentation","text":"for link in links If not edge state: self._logger.info( f\"Edge in host {velocloud_host} and enterprise {enterprise_name} (ID: {enterprise_id}) \" f\"has an invalid state. Skipping...\" ) If edge state is \"NEVER_ACTIVATED\" self._logger.info( f\"Edge {edge_name} in host {velocloud_host} and enterprise {enterprise_name} (ID: {enterprise_id}) \" f\"has never been activated. Skipping...\" )","title":"Process velocloud host Documentation"},{"location":"logging/services/servicenow-bridge/actions/report_incident/","text":"Subject: servicenow.incident.report.request Message arrives at subject If message doesn't have body : log . error ( f \"Cannot report incident with { json . dumps ( payload ) } . Must include body in request\" ) END If message body doesn't have host , gateway , summary , note and link filters: log . error ( f \"Cannot report incident using { json . dumps ( payload ) } . JSON malformed\" ) END report_incident log . info ( f \"Report incident response: { response } \" )","title":"Report incident"},{"location":"logging/services/servicenow-bridge/actions/report_incident/#subject-servicenowincidentreportrequest","text":"Message arrives at subject If message doesn't have body : log . error ( f \"Cannot report incident with { json . dumps ( payload ) } . Must include body in request\" ) END If message body doesn't have host , gateway , summary , note and link filters: log . error ( f \"Cannot report incident using { json . dumps ( payload ) } . JSON malformed\" ) END report_incident log . info ( f \"Report incident response: { response } \" )","title":"Subject: servicenow.incident.report.request"},{"location":"logging/services/servicenow-bridge/clients/servicenow_client/_get_access_token/","text":"Get API access token log . info ( \"Getting ServiceNow access token...\" ) Make a call to POST /oauth_token.do using the set of credentials provided. If there's an error while making the call to the ServiceNow API: log . exception ( e ) END If the status of the HTTP response is 401 : log . error ( \"Failed to get a ServiceNow access token\" ) END log . info ( \"Got ServiceNow access token!\" )","title":" get access token"},{"location":"logging/services/servicenow-bridge/clients/servicenow_client/_get_access_token/#get-api-access-token","text":"log . info ( \"Getting ServiceNow access token...\" ) Make a call to POST /oauth_token.do using the set of credentials provided. If there's an error while making the call to the ServiceNow API: log . exception ( e ) END If the status of the HTTP response is 401 : log . error ( \"Failed to get a ServiceNow access token\" ) END log . info ( \"Got ServiceNow access token!\" )","title":"Get API access token"},{"location":"logging/services/servicenow-bridge/clients/servicenow_client/_request/","text":"Make an HTTP request to ServiceNow API Make a call to the desired API endpoint with the specified payload or query parameters. If there's an error while making the call to the ServiceNow API: log . exception ( e ) END If the status of the HTTP response is 401 : log . error ( f \"Got 401 from Bruin. Re-logging in...\" ) _get_access_token Retry same exact HTTP call.","title":" request"},{"location":"logging/services/servicenow-bridge/clients/servicenow_client/_request/#make-an-http-request-to-servicenow-api","text":"Make a call to the desired API endpoint with the specified payload or query parameters. If there's an error while making the call to the ServiceNow API: log . exception ( e ) END If the status of the HTTP response is 401 : log . error ( f \"Got 401 from Bruin. Re-logging in...\" ) _get_access_token Retry same exact HTTP call.","title":"Make an HTTP request to ServiceNow API"},{"location":"logging/services/servicenow-bridge/clients/servicenow_client/report_incident/","text":"Report incident log . info ( f \"Reporting incident with payload: { payload } \" ) log . info ( f \"to URL { self . _base_url } /api/g_mtcm/intelygenz\" ) Call _request , which ultimately makes a call to POST /api/g_mtcm/intelygenz with the desired payload.","title":"Report incident"},{"location":"logging/services/servicenow-bridge/clients/servicenow_client/report_incident/#report-incident","text":"log . info ( f \"Reporting incident with payload: { payload } \" ) log . info ( f \"to URL { self . _base_url } /api/g_mtcm/intelygenz\" ) Call _request , which ultimately makes a call to POST /api/g_mtcm/intelygenz with the desired payload.","title":"Report incident"},{"location":"logging/services/servicenow-bridge/repositories/servicenow_repository/servicenow_repository/","text":"Report incident ServiceNowClient::report_incident","title":"Servicenow repository"},{"location":"logging/services/servicenow-bridge/repositories/servicenow_repository/servicenow_repository/#report-incident","text":"ServiceNowClient::report_incident","title":"Report incident"},{"location":"logging/services/velocloud-bridge/actions/edge_events_for_alert/","text":"Subject: alert.request.event.edge Message arrives at subject If message doesn't have a body: logger . error ( f \"Cannot get edge events with { json . dumps ( payload ) } . JSON malformed\" ) END If message body doesn't have edge , start_date , or end_date filters: logger . error ( f 'Cannot get edge events with { json . dumps ( payload ) } . Need parameters \"edge\", \"start_date\" and ' f '\"end_date\"' ) END If filter field is specified in filters to pull specific event types: logger . info ( f \"Event types filter { filter_ } will be used to get events for edge { edge } \" ) If limit field is specified in filters to pull a certain number of events: logger . info ( f \"Will fetch up to { limit } events for edge { edge } \" ) logger . info ( f \"Getting events for edge { edge } ...\" ) get_all_edge_events logger . info ( f \"Edge events published for request { json . dumps ( payload ) } . Message published was { response } \" )","title":"Edge events for alert"},{"location":"logging/services/velocloud-bridge/actions/edge_events_for_alert/#subject-alertrequesteventedge","text":"Message arrives at subject If message doesn't have a body: logger . error ( f \"Cannot get edge events with { json . dumps ( payload ) } . JSON malformed\" ) END If message body doesn't have edge , start_date , or end_date filters: logger . error ( f 'Cannot get edge events with { json . dumps ( payload ) } . Need parameters \"edge\", \"start_date\" and ' f '\"end_date\"' ) END If filter field is specified in filters to pull specific event types: logger . info ( f \"Event types filter { filter_ } will be used to get events for edge { edge } \" ) If limit field is specified in filters to pull a certain number of events: logger . info ( f \"Will fetch up to { limit } events for edge { edge } \" ) logger . info ( f \"Getting events for edge { edge } ...\" ) get_all_edge_events logger . info ( f \"Edge events published for request { json . dumps ( payload ) } . Message published was { response } \" )","title":"Subject: alert.request.event.edge"},{"location":"logging/services/velocloud-bridge/actions/enterprise_edge_list/","text":"Subject: request.enterprises.edges Message arrives at subject If message doesn't have a body: logger . error ( f \"Cannot get enterprise edges with { json . dumps ( payload ) } . JSON malformed\" ) END If message body doesn't have edge , start_date , or end_date filters: logger . error ( f 'Cannot get edge events with { json . dumps ( payload ) } . Need parameters \"edge\", \"start_date\" and \"end_date\"' ) END logger . info ( f \"Getting edges for host { host } and enterprise { enterprise_id } ...\" ) get_enterprise_edges logger . info ( f \"Sent list of enterprise edges for enterprise { enterprise_id } and host { host } \" )","title":"Enterprise edge list"},{"location":"logging/services/velocloud-bridge/actions/enterprise_edge_list/#subject-requestenterprisesedges","text":"Message arrives at subject If message doesn't have a body: logger . error ( f \"Cannot get enterprise edges with { json . dumps ( payload ) } . JSON malformed\" ) END If message body doesn't have edge , start_date , or end_date filters: logger . error ( f 'Cannot get edge events with { json . dumps ( payload ) } . Need parameters \"edge\", \"start_date\" and \"end_date\"' ) END logger . info ( f \"Getting edges for host { host } and enterprise { enterprise_id } ...\" ) get_enterprise_edges logger . info ( f \"Sent list of enterprise edges for enterprise { enterprise_id } and host { host } \" )","title":"Subject: request.enterprises.edges"},{"location":"logging/services/velocloud-bridge/actions/enterprise_events_for_alert/","text":"Subject: alert.request.event.enterprise Message arrives at subject If message doesn't have a body: logger . error ( f \"Cannot get enterprise events with { json . dumps ( payload ) } . JSON malformed\" ) END If message body doesn't have host , enterprise_id start_date , or end_date filters: logger . error ( f 'Cannot get edge events with { json . dumps ( payload ) } . Need parameters \"host\", \"enterprise_id\", ' f '\"start_date\" and \"end_date\"' ) END If filter field is specified in filters to pull specific event types: logger . info ( f \"Event types filter { filter_ } will be used to get events for enterprise { enterprise_id } of host { host } \" ) If limit field is specified in filters to pull a certain number of events: logger . info ( f \"Will fetch up to { limit } events for enterprise { enterprise_id } of host { host } \" ) logger . info ( f \"Getting events for enterprise { enterprise_id } of host { host } ...\" ) get_all_enterprise_events logger . info ( f \"Enterprise events published for request { json . dumps ( payload ) } . Message published was { response } \" )","title":"Enterprise events for alert"},{"location":"logging/services/velocloud-bridge/actions/enterprise_events_for_alert/#subject-alertrequestevententerprise","text":"Message arrives at subject If message doesn't have a body: logger . error ( f \"Cannot get enterprise events with { json . dumps ( payload ) } . JSON malformed\" ) END If message body doesn't have host , enterprise_id start_date , or end_date filters: logger . error ( f 'Cannot get edge events with { json . dumps ( payload ) } . Need parameters \"host\", \"enterprise_id\", ' f '\"start_date\" and \"end_date\"' ) END If filter field is specified in filters to pull specific event types: logger . info ( f \"Event types filter { filter_ } will be used to get events for enterprise { enterprise_id } of host { host } \" ) If limit field is specified in filters to pull a certain number of events: logger . info ( f \"Will fetch up to { limit } events for enterprise { enterprise_id } of host { host } \" ) logger . info ( f \"Getting events for enterprise { enterprise_id } of host { host } ...\" ) get_all_enterprise_events logger . info ( f \"Enterprise events published for request { json . dumps ( payload ) } . Message published was { response } \" )","title":"Subject: alert.request.event.enterprise"},{"location":"logging/services/velocloud-bridge/actions/enterprise_name_list_response/","text":"Subject: request.enterprises.names Message arrives at subject If message doesn't have a body: logger . error ( f \"Cannot get enterprise names with { json . dumps ( payload ) } . JSON malformed\" ) END logger . info ( \"Sending enterprise name list\" ) get_all_enterprise_names logger . info ( \"Enterprise name list sent\" )","title":"Enterprise name list response"},{"location":"logging/services/velocloud-bridge/actions/enterprise_name_list_response/#subject-requestenterprisesnames","text":"Message arrives at subject If message doesn't have a body: logger . error ( f \"Cannot get enterprise names with { json . dumps ( payload ) } . JSON malformed\" ) END logger . info ( \"Sending enterprise name list\" ) get_all_enterprise_names logger . info ( \"Enterprise name list sent\" )","title":"Subject: request.enterprises.names"},{"location":"logging/services/velocloud-bridge/actions/gateway_status_metrics/","text":"Subject: request.gateway.status.metrics Message arrives at subject If message doesn't have the expected format: logger . warning ( f \"Wrong request message: msg= { msg } , validation_error= { e } \" ) END logger . info ( f \"Getting gateway status metrics for gateway { gateway_id } on host { host } in interval { interval } ...\" ) get_gateway_status_metrics logger . info ( f \"Sent gateway status metrics for gateway { gateway_id } on host { host } in interval { interval } \" )","title":"Gateway status metrics"},{"location":"logging/services/velocloud-bridge/actions/gateway_status_metrics/#subject-requestgatewaystatusmetrics","text":"Message arrives at subject If message doesn't have the expected format: logger . warning ( f \"Wrong request message: msg= { msg } , validation_error= { e } \" ) END logger . info ( f \"Getting gateway status metrics for gateway { gateway_id } on host { host } in interval { interval } ...\" ) get_gateway_status_metrics logger . info ( f \"Sent gateway status metrics for gateway { gateway_id } on host { host } in interval { interval } \" )","title":"Subject: request.gateway.status.metrics"},{"location":"logging/services/velocloud-bridge/actions/get_edge_links_series/","text":"Subject: request.edge.links.series Message arrives at subject If message doesn't have a body: logger . error ( f \"Cannot get edge links series with { json . dumps ( payload ) } . JSON malformed\" ) END If message body doesn't have the appropriate shape: logger . error ( f \"Cannot get edge links series with { json . dumps ( payload ) } . Make sure it complies with the shape of \" f \" { REQUEST_MODEL } \" ) END If body's payload doesn't have any filter of enterpriseId , edgeId , interval and metrics : logger . error ( f 'Cannot get edge links series with { json . dumps ( payload ) } . Need parameters \"enterpriseId\", \"edgeId\", ' f '\"interval\" and \"metrics\" under \"payload\"' ) END logger . info ( f \"Getting edge links series from host { host } using payload { payload } ...\" ) get_edge_links_series logger . info ( f \"Published edge links series for host { host } and payload { payload } \" )","title":"Get edge links series"},{"location":"logging/services/velocloud-bridge/actions/get_edge_links_series/#subject-requestedgelinksseries","text":"Message arrives at subject If message doesn't have a body: logger . error ( f \"Cannot get edge links series with { json . dumps ( payload ) } . JSON malformed\" ) END If message body doesn't have the appropriate shape: logger . error ( f \"Cannot get edge links series with { json . dumps ( payload ) } . Make sure it complies with the shape of \" f \" { REQUEST_MODEL } \" ) END If body's payload doesn't have any filter of enterpriseId , edgeId , interval and metrics : logger . error ( f 'Cannot get edge links series with { json . dumps ( payload ) } . Need parameters \"enterpriseId\", \"edgeId\", ' f '\"interval\" and \"metrics\" under \"payload\"' ) END logger . info ( f \"Getting edge links series from host { host } using payload { payload } ...\" ) get_edge_links_series logger . info ( f \"Published edge links series for host { host } and payload { payload } \" )","title":"Subject: request.edge.links.series"},{"location":"logging/services/velocloud-bridge/actions/links_configuration/","text":"Subject: request.links.configuration Message arrives at subject If message doesn't have a body: logger . error ( f \"Cannot get links configuration with { json . dumps ( payload ) } . JSON malformed\" ) END If message body doesn't have edge , start_date , or end_date filters: logger . error ( f 'Cannot get links configuration with { json . dumps ( payload ) } . Need parameters \"host\", \"enterprise_id\" ' f 'and \"edge_id\"' ) END logger . info ( f \"Getting links configuration for edge { edge_full_id } ...\" ) get_links_configuration logger . info ( f \"Published links configuration for edge { edge_full_id } \" )","title":"Links configuration"},{"location":"logging/services/velocloud-bridge/actions/links_configuration/#subject-requestlinksconfiguration","text":"Message arrives at subject If message doesn't have a body: logger . error ( f \"Cannot get links configuration with { json . dumps ( payload ) } . JSON malformed\" ) END If message body doesn't have edge , start_date , or end_date filters: logger . error ( f 'Cannot get links configuration with { json . dumps ( payload ) } . Need parameters \"host\", \"enterprise_id\" ' f 'and \"edge_id\"' ) END logger . info ( f \"Getting links configuration for edge { edge_full_id } ...\" ) get_links_configuration logger . info ( f \"Published links configuration for edge { edge_full_id } \" )","title":"Subject: request.links.configuration"},{"location":"logging/services/velocloud-bridge/actions/links_metric_info/","text":"Subject: get.links.metric.info Message arrives at subject If message doesn't have a body: logger . error ( f 'Cannot get links metric info: \"body\" is missing in the request' ) END If message body doesn't have host filter: logger . error ( f 'Cannot get links metric info: \"host\" is missing in the body of the request' ) END If message body doesn't have interval filter: logger . error ( f 'Cannot get links metric info: \"interval\" is missing in the body of the request' ) END logger . info ( f 'Getting links metric info from Velocloud host \" { velocloud_host } \"...' ) get_links_metric_info logger . info ( f \"Published links metric info for request { payload } \" )","title":"Links metric info"},{"location":"logging/services/velocloud-bridge/actions/links_metric_info/#subject-getlinksmetricinfo","text":"Message arrives at subject If message doesn't have a body: logger . error ( f 'Cannot get links metric info: \"body\" is missing in the request' ) END If message body doesn't have host filter: logger . error ( f 'Cannot get links metric info: \"host\" is missing in the body of the request' ) END If message body doesn't have interval filter: logger . error ( f 'Cannot get links metric info: \"interval\" is missing in the body of the request' ) END logger . info ( f 'Getting links metric info from Velocloud host \" { velocloud_host } \"...' ) get_links_metric_info logger . info ( f \"Published links metric info for request { payload } \" )","title":"Subject: get.links.metric.info"},{"location":"logging/services/velocloud-bridge/actions/links_with_edge_info/","text":"Subject: get.links.with.edge.info Message arrives at subject If message doesn't have a body: logger . error ( f 'Cannot get links with edge info: \"body\" is missing in the request' ) END If message body doesn't have host filter: logger . error ( f 'Cannot get links with edge info: \"host\" is missing in the body of the request' ) END logger . info ( f 'Getting links with edge info from Velocloud host \" { velocloud_host } \"...' ) get_links_with_edge_info logger . info ( f \"Response sent for request { payload } \" )","title":"Links with edge info"},{"location":"logging/services/velocloud-bridge/actions/links_with_edge_info/#subject-getlinkswithedgeinfo","text":"Message arrives at subject If message doesn't have a body: logger . error ( f 'Cannot get links with edge info: \"body\" is missing in the request' ) END If message body doesn't have host filter: logger . error ( f 'Cannot get links with edge info: \"host\" is missing in the body of the request' ) END logger . info ( f 'Getting links with edge info from Velocloud host \" { velocloud_host } \"...' ) get_links_with_edge_info logger . info ( f \"Response sent for request { payload } \" )","title":"Subject: get.links.with.edge.info"},{"location":"logging/services/velocloud-bridge/actions/network_enterprise_edge_list/","text":"Subject: request.network.enterprise.edges Message arrives at subject If message doesn't have a body: logger . error ( f \"Cannot get network enterprise edge list with { json . dumps ( payload ) } . JSON malformed\" ) END If message body doesn't have host and enterprise_ids filters: logger . error ( f 'Cannot get network enterprise edge list with { json . dumps ( payload ) } . Need parameters \"host\" and ' f '\"enterprise_ids\"' ) END logger . info ( f \"Getting network enterprise edge list for host { host } and enterprises { enterprise_ids } \" ) get_network_enterprise_edges logger . info ( f \"Sent list of network enterprises edges for enterprises: { enterprise_ids } and host { host } \" )","title":"Network enterprise edge list"},{"location":"logging/services/velocloud-bridge/actions/network_enterprise_edge_list/#subject-requestnetworkenterpriseedges","text":"Message arrives at subject If message doesn't have a body: logger . error ( f \"Cannot get network enterprise edge list with { json . dumps ( payload ) } . JSON malformed\" ) END If message body doesn't have host and enterprise_ids filters: logger . error ( f 'Cannot get network enterprise edge list with { json . dumps ( payload ) } . Need parameters \"host\" and ' f '\"enterprise_ids\"' ) END logger . info ( f \"Getting network enterprise edge list for host { host } and enterprises { enterprise_ids } \" ) get_network_enterprise_edges logger . info ( f \"Sent list of network enterprises edges for enterprises: { enterprise_ids } and host { host } \" )","title":"Subject: request.network.enterprise.edges"},{"location":"logging/services/velocloud-bridge/actions/network_gateway_list/","text":"Subject: request.network.gateway.list Message arrives at subject If message doesn't have the expected format: logger . warning ( f \"Wrong request message: msg= { msg } , validation_error= { e } \" ) END logger . info ( f \"Getting network gateway list on host { host } ...\" ) get_network_gateways logger . info ( f \"Sent network gateway list on host { host } \" )","title":"Network gateway list"},{"location":"logging/services/velocloud-bridge/actions/network_gateway_list/#subject-requestnetworkgatewaylist","text":"Message arrives at subject If message doesn't have the expected format: logger . warning ( f \"Wrong request message: msg= { msg } , validation_error= { e } \" ) END logger . info ( f \"Getting network gateway list on host { host } ...\" ) get_network_gateways logger . info ( f \"Sent network gateway list on host { host } \" )","title":"Subject: request.network.gateway.list"},{"location":"logging/services/velocloud-bridge/app_entrypoint/app/","text":"App entrypoint app_logger . info ( \"Velocloud bridge starting...\" )","title":"App"},{"location":"logging/services/velocloud-bridge/app_entrypoint/app/#app-entrypoint","text":"app_logger . info ( \"Velocloud bridge starting...\" )","title":"App entrypoint"},{"location":"logging/services/velocloud-bridge/clients/velocloud_client/__log_result/","text":"Log result If result status is 400 : logger . error ( f \"Got error from Velocloud -> { body } \" ) If result status is 401 : logger . error ( f \"Authentication error -> { body } \" ) If result status is between 500 and 512 (both inclusive): logger . error ( f \"Got { status } from Velocloud\" )","title":"  log result"},{"location":"logging/services/velocloud-bridge/clients/velocloud_client/__log_result/#log-result","text":"If result status is 400 : logger . error ( f \"Got error from Velocloud -> { body } \" ) If result status is 401 : logger . error ( f \"Authentication error -> { body } \" ) If result status is between 500 and 512 (both inclusive): logger . error ( f \"Got { status } from Velocloud\" )","title":"Log result"},{"location":"logging/services/velocloud-bridge/clients/velocloud_client/__login_if_needed/","text":"Login if needed If auth token expired for a particular VeloCloud host: logger . info ( f \"Auth token expired for host { velocloud_host } . Logging in...\" ) _login","title":"  login if needed"},{"location":"logging/services/velocloud-bridge/clients/velocloud_client/__login_if_needed/#login-if-needed","text":"If auth token expired for a particular VeloCloud host: logger . info ( f \"Auth token expired for host { velocloud_host } . Logging in...\" ) _login","title":"Login if needed"},{"location":"logging/services/velocloud-bridge/clients/velocloud_client/_connect_to_all_hosts/","text":"Connect to all hosts logger . info ( f \"Connecting to all hosts...\" ) For each VeloCloud host: _login","title":" connect to all hosts"},{"location":"logging/services/velocloud-bridge/clients/velocloud_client/_connect_to_all_hosts/#connect-to-all-hosts","text":"logger . info ( f \"Connecting to all hosts...\" ) For each VeloCloud host: _login","title":"Connect to all hosts"},{"location":"logging/services/velocloud-bridge/clients/velocloud_client/_json_return/","text":"JSON return If the response has errors: If the response indicates that the authentication token expired: logger . info ( f \"Response returned: { response } . Logging in...\" ) _login Otherwise: logger . error ( f \"Error response returned: { response } \" )","title":" json return"},{"location":"logging/services/velocloud-bridge/clients/velocloud_client/_json_return/#json-return","text":"If the response has errors: If the response indicates that the authentication token expired: logger . info ( f \"Response returned: { response } . Logging in...\" ) _login Otherwise: logger . error ( f \"Error response returned: { response } \" )","title":"JSON return"},{"location":"logging/services/velocloud-bridge/clients/velocloud_client/_login/","text":"Login logger . info ( f \"Logging in to host { host } ...\" ) Call VeloCloud API endpoint POST /login/operatorLogin with the set of desired parameters. If the status of the HTTP response is between 200 and 300 (both inclusive): logger . info ( f \"Logged in to host { host } successfully\" ) Otherwise: logger . error ( f \"Got HTTP { response . status } while logging in to host { host } \" ) If there was an exception: logger . exception ( e )","title":" login"},{"location":"logging/services/velocloud-bridge/clients/velocloud_client/_login/#login","text":"logger . info ( f \"Logging in to host { host } ...\" ) Call VeloCloud API endpoint POST /login/operatorLogin with the set of desired parameters. If the status of the HTTP response is between 200 and 300 (both inclusive): logger . info ( f \"Logged in to host { host } successfully\" ) Otherwise: logger . error ( f \"Got HTTP { response . status } while logging in to host { host } \" ) If there was an exception: logger . exception ( e )","title":"Login"},{"location":"logging/services/velocloud-bridge/clients/velocloud_client/get_all_enterprise_names/","text":"Get all enterprise names For each available VeloCloud host: get_monitoring_aggregates If response status of get monitoring aggregates for current VeloCloud host is not ok: logger . error ( f \"Function [get_all_enterprise_names] Error: \\n \" f \"Status : { res [ 'status' ] } , \\n \" f \"Error Message: { res [ 'body' ] } \" ) Continue to next VeloCloud host","title":"Get all enterprise names"},{"location":"logging/services/velocloud-bridge/clients/velocloud_client/get_all_enterprise_names/#get-all-enterprise-names","text":"For each available VeloCloud host: get_monitoring_aggregates If response status of get monitoring aggregates for current VeloCloud host is not ok: logger . error ( f \"Function [get_all_enterprise_names] Error: \\n \" f \"Status : { res [ 'status' ] } , \\n \" f \"Error Message: { res [ 'body' ] } \" ) Continue to next VeloCloud host","title":"Get all enterprise names"},{"location":"logging/services/velocloud-bridge/clients/velocloud_client/get_all_events/","text":"Get all events If there's no cookie for the VeloCloud host: logger . error ( f \"Cannot find a cookie for { host } \" ) _login END logger . info ( f \"Getting all events from host { host } using payload { body } ...\" ) Call VeloCloud API endpoint POST /event/getEnterpriseEvents with the set of desired parameters. If the status of the HTTP response is 200 : logger . info ( f \"Got HTTP 200 from POST /event/getEnterpriseEvents for host { host } and payload { body } \" ) END If the status of the HTTP response is 400 : logger . error ( f \"Got HTTP 400 from Velocloud: { response_json } \" ) END If the status of the HTTP response is between 500 and 512 (both inclusive): logger . error ( f \"Got HTTP { response . status } from Velocloud\" ) END","title":"Get all events"},{"location":"logging/services/velocloud-bridge/clients/velocloud_client/get_all_events/#get-all-events","text":"If there's no cookie for the VeloCloud host: logger . error ( f \"Cannot find a cookie for { host } \" ) _login END logger . info ( f \"Getting all events from host { host } using payload { body } ...\" ) Call VeloCloud API endpoint POST /event/getEnterpriseEvents with the set of desired parameters. If the status of the HTTP response is 200 : logger . info ( f \"Got HTTP 200 from POST /event/getEnterpriseEvents for host { host } and payload { body } \" ) END If the status of the HTTP response is 400 : logger . error ( f \"Got HTTP 400 from Velocloud: { response_json } \" ) END If the status of the HTTP response is between 500 and 512 (both inclusive): logger . error ( f \"Got HTTP { response . status } from Velocloud\" ) END","title":"Get all events"},{"location":"logging/services/velocloud-bridge/clients/velocloud_client/get_edge_configuration_modules/","text":"Get edge configuration modules If there's no cookie for the VeloCloud host: logger . error ( f \"Cannot find a cookie for { host } \" ) _login __log_result END logger . info ( f 'Trying to get edge links series for payload { payload } from Velocloud host \" { velocloud_host } \"...' ) Call VeloCloud API endpoint POST /edge/getEdgeConfigurationModules with the set of desired parameters. If there's an error while connecting to VeloCloud API: __log_result END If the status of the HTTP response is between 500 and 512 (both inclusive): __log_result END __login_if_needed logger . info ( f \"Got HTTP { response . status } from Velocloud after fetching edge link series for { payload } \" f \"and host { velocloud_host } \" ) __log_result","title":"Get edge configuration modules"},{"location":"logging/services/velocloud-bridge/clients/velocloud_client/get_edge_configuration_modules/#get-edge-configuration-modules","text":"If there's no cookie for the VeloCloud host: logger . error ( f \"Cannot find a cookie for { host } \" ) _login __log_result END logger . info ( f 'Trying to get edge links series for payload { payload } from Velocloud host \" { velocloud_host } \"...' ) Call VeloCloud API endpoint POST /edge/getEdgeConfigurationModules with the set of desired parameters. If there's an error while connecting to VeloCloud API: __log_result END If the status of the HTTP response is between 500 and 512 (both inclusive): __log_result END __login_if_needed logger . info ( f \"Got HTTP { response . status } from Velocloud after fetching edge link series for { payload } \" f \"and host { velocloud_host } \" ) __log_result","title":"Get edge configuration modules"},{"location":"logging/services/velocloud-bridge/clients/velocloud_client/get_edge_links_series/","text":"Get edge links series If there's no cookie for the VeloCloud host: logger . error ( f \"Cannot find a cookie for { host } \" ) _login __log_result END logger . info ( f 'Trying to get edge links series for payload { payload } from Velocloud host \" { velocloud_host } \"...' ) Call VeloCloud API endpoint POST /metrics/getEdgeLinkSeries with the set of desired parameters. If there's an error while connecting to VeloCloud API: __log_result END If the status of the HTTP response is between 500 and 512 (both inclusive): __log_result END __login_if_needed logger . info ( f \"Got HTTP { response . status } from Velocloud after fetching edge link series for { payload } \" f \"and host { velocloud_host } \" ) __log_result","title":"Get edge links series"},{"location":"logging/services/velocloud-bridge/clients/velocloud_client/get_edge_links_series/#get-edge-links-series","text":"If there's no cookie for the VeloCloud host: logger . error ( f \"Cannot find a cookie for { host } \" ) _login __log_result END logger . info ( f 'Trying to get edge links series for payload { payload } from Velocloud host \" { velocloud_host } \"...' ) Call VeloCloud API endpoint POST /metrics/getEdgeLinkSeries with the set of desired parameters. If there's an error while connecting to VeloCloud API: __log_result END If the status of the HTTP response is between 500 and 512 (both inclusive): __log_result END __login_if_needed logger . info ( f \"Got HTTP { response . status } from Velocloud after fetching edge link series for { payload } \" f \"and host { velocloud_host } \" ) __log_result","title":"Get edge links series"},{"location":"logging/services/velocloud-bridge/clients/velocloud_client/get_enterprise_edges/","text":"Get enterprise edges If there's no cookie for the VeloCloud host: logger . error ( f \"Cannot find a cookie for { host } \" ) _login __log_result END logger . info ( f \"Getting all enterprise edges from enterprise ID { enterprise_id } and\" f ' from Velocloud host \" { velocloud_host } \"...' ) Call VeloCloud API endpoint POST /enterprise/getEnterpriseEdges with the set of desired parameters. If there's an error while connecting to VeloCloud API: __log_result END If the status of the HTTP response is between 500 and 512 (both inclusive): __log_result END __login_if_needed logger . info ( f \"Got HTTP { response . status } from Velocloud after getting enterprise edges for enterprise { enterprise_id } \" f \"and host { velocloud_host } \" ) __log_result","title":"Get enterprise edges"},{"location":"logging/services/velocloud-bridge/clients/velocloud_client/get_enterprise_edges/#get-enterprise-edges","text":"If there's no cookie for the VeloCloud host: logger . error ( f \"Cannot find a cookie for { host } \" ) _login __log_result END logger . info ( f \"Getting all enterprise edges from enterprise ID { enterprise_id } and\" f ' from Velocloud host \" { velocloud_host } \"...' ) Call VeloCloud API endpoint POST /enterprise/getEnterpriseEdges with the set of desired parameters. If there's an error while connecting to VeloCloud API: __log_result END If the status of the HTTP response is between 500 and 512 (both inclusive): __log_result END __login_if_needed logger . info ( f \"Got HTTP { response . status } from Velocloud after getting enterprise edges for enterprise { enterprise_id } \" f \"and host { velocloud_host } \" ) __log_result","title":"Get enterprise edges"},{"location":"logging/services/velocloud-bridge/clients/velocloud_client/get_gateway_status_metrics/","text":"Get gateway status metrics If there's no cookie for the VeloCloud host: logger . error ( f \"Cannot find a cookie for { host } \" ) _login __log_result END logger . info ( f \"Getting gateway status metrics for gateway { gateway_id } and host { velocloud_host } in \" f \"interval { interval } ...\" ) Call VeloCloud API endpoint POST /metrics/getGatewayStatusMetrics with the set of desired parameters. If there's an error while connecting to VeloCloud API: __log_result END If the status of the HTTP response is between 500 and 512 (both inclusive): __log_result END If the status of the HTTP response is 400 : __log_result END __login_if_needed logger . info ( f \"Got HTTP { response . status } from Velocloud after getting gateway status metrics for gateway { gateway_id } \" f \"and host { velocloud_host } in interval { interval } \" ) __log_result","title":"Get gateway status metrics"},{"location":"logging/services/velocloud-bridge/clients/velocloud_client/get_gateway_status_metrics/#get-gateway-status-metrics","text":"If there's no cookie for the VeloCloud host: logger . error ( f \"Cannot find a cookie for { host } \" ) _login __log_result END logger . info ( f \"Getting gateway status metrics for gateway { gateway_id } and host { velocloud_host } in \" f \"interval { interval } ...\" ) Call VeloCloud API endpoint POST /metrics/getGatewayStatusMetrics with the set of desired parameters. If there's an error while connecting to VeloCloud API: __log_result END If the status of the HTTP response is between 500 and 512 (both inclusive): __log_result END If the status of the HTTP response is 400 : __log_result END __login_if_needed logger . info ( f \"Got HTTP { response . status } from Velocloud after getting gateway status metrics for gateway { gateway_id } \" f \"and host { velocloud_host } in interval { interval } \" ) __log_result","title":"Get gateway status metrics"},{"location":"logging/services/velocloud-bridge/clients/velocloud_client/get_links_metric_info/","text":"Get links metric info If there's no cookie for the VeloCloud host: logger . error ( f \"Cannot find a cookie for { host } \" ) _login __log_result END logger . info ( f 'Getting links metric info from Velocloud host \" { velocloud_host } \" for interval { interval } ...' ) Call VeloCloud API endpoint POST /monitoring/getAggregateEdgeLinkMetrics with the set of desired parameters. If there's an error while connecting to VeloCloud API: __log_result END If the status of the HTTP response is between 500 and 512 (both inclusive): __log_result END __login_if_needed logger . info ( f \"Got HTTP { response . status } from Velocloud after claiming links metric info for host { velocloud_host } and \" f \"interval { interval } \" ) __log_result","title":"Get links metric info"},{"location":"logging/services/velocloud-bridge/clients/velocloud_client/get_links_metric_info/#get-links-metric-info","text":"If there's no cookie for the VeloCloud host: logger . error ( f \"Cannot find a cookie for { host } \" ) _login __log_result END logger . info ( f 'Getting links metric info from Velocloud host \" { velocloud_host } \" for interval { interval } ...' ) Call VeloCloud API endpoint POST /monitoring/getAggregateEdgeLinkMetrics with the set of desired parameters. If there's an error while connecting to VeloCloud API: __log_result END If the status of the HTTP response is between 500 and 512 (both inclusive): __log_result END __login_if_needed logger . info ( f \"Got HTTP { response . status } from Velocloud after claiming links metric info for host { velocloud_host } and \" f \"interval { interval } \" ) __log_result","title":"Get links metric info"},{"location":"logging/services/velocloud-bridge/clients/velocloud_client/get_links_with_edge_info/","text":"Get links with edge info If there's no cookie for the VeloCloud host: logger . error ( f \"Cannot find a cookie for { host } \" ) _login __log_result END logger . info ( f 'Getting links with edge info from Velocloud host \" { velocloud_host } \"...' ) Call VeloCloud API endpoint POST /monitoring/getEnterpriseEdgeLinkStatus with the set of desired parameters. If there's an error while connecting to VeloCloud API: __log_result END If the status of the HTTP response is between 500 and 512 (both inclusive): __log_result END __login_if_needed logger . info ( f \"Got HTTP { response . status } from Velocloud after claiming links with edge info for host { velocloud_host } \" ) __log_result","title":"Get links with edge info"},{"location":"logging/services/velocloud-bridge/clients/velocloud_client/get_links_with_edge_info/#get-links-with-edge-info","text":"If there's no cookie for the VeloCloud host: logger . error ( f \"Cannot find a cookie for { host } \" ) _login __log_result END logger . info ( f 'Getting links with edge info from Velocloud host \" { velocloud_host } \"...' ) Call VeloCloud API endpoint POST /monitoring/getEnterpriseEdgeLinkStatus with the set of desired parameters. If there's an error while connecting to VeloCloud API: __log_result END If the status of the HTTP response is between 500 and 512 (both inclusive): __log_result END __login_if_needed logger . info ( f \"Got HTTP { response . status } from Velocloud after claiming links with edge info for host { velocloud_host } \" ) __log_result","title":"Get links with edge info"},{"location":"logging/services/velocloud-bridge/clients/velocloud_client/get_monitoring_aggregates/","text":"Get monitoring aggregates logger . info ( f \"Getting monitoring aggregates for host { host } \" ) Call VeloCloud API endpoint POST /monitoring/getAggregates . If the status of the HTTP response is 200 : logger . info ( f \"Got HTTP 200 from POST /monitoring/getAggregates for host { host } \" ) _json_return END If the status of the HTTP response is 400 : logger . error ( f \"Got HTTP 400 from Velocloud { response_json } \" ) If the status of the HTTP response is between 500 and 512 (both inclusive): logger . error ( f \"Got HTTP { response . status } \" )","title":"Get monitoring aggregates"},{"location":"logging/services/velocloud-bridge/clients/velocloud_client/get_monitoring_aggregates/#get-monitoring-aggregates","text":"logger . info ( f \"Getting monitoring aggregates for host { host } \" ) Call VeloCloud API endpoint POST /monitoring/getAggregates . If the status of the HTTP response is 200 : logger . info ( f \"Got HTTP 200 from POST /monitoring/getAggregates for host { host } \" ) _json_return END If the status of the HTTP response is 400 : logger . error ( f \"Got HTTP 400 from Velocloud { response_json } \" ) If the status of the HTTP response is between 500 and 512 (both inclusive): logger . error ( f \"Got HTTP { response . status } \" )","title":"Get monitoring aggregates"},{"location":"logging/services/velocloud-bridge/clients/velocloud_client/get_network_enterprises/","text":"Get network enterprises logger . info ( f \"Getting network enterprise edges for host { velocloud_host } and enterprises { enterprise_ids } ...\" ) Call VeloCloud API endpoint POST /network/getNetworkEnterprises with the set of desired parameters. If there's an error while connecting to VeloCloud API: __log_result END If the status of the HTTP response is between 500 and 512 (both inclusive): __log_result END If the status of the HTTP response is 400 : __log_result END If the status of the HTTP response is any other: __login_if_needed logger . info ( f \"Got HTTP { response . status } from Velocloud after getting enterprise ids: { enterprise_ids } \" f \"from host { velocloud_host } \" ) __log_result","title":"Get network enterprises"},{"location":"logging/services/velocloud-bridge/clients/velocloud_client/get_network_enterprises/#get-network-enterprises","text":"logger . info ( f \"Getting network enterprise edges for host { velocloud_host } and enterprises { enterprise_ids } ...\" ) Call VeloCloud API endpoint POST /network/getNetworkEnterprises with the set of desired parameters. If there's an error while connecting to VeloCloud API: __log_result END If the status of the HTTP response is between 500 and 512 (both inclusive): __log_result END If the status of the HTTP response is 400 : __log_result END If the status of the HTTP response is any other: __login_if_needed logger . info ( f \"Got HTTP { response . status } from Velocloud after getting enterprise ids: { enterprise_ids } \" f \"from host { velocloud_host } \" ) __log_result","title":"Get network enterprises"},{"location":"logging/services/velocloud-bridge/clients/velocloud_client/get_network_gateways/","text":"Get network gateways If there's no cookie for the VeloCloud host: logger . error ( f \"Cannot find a cookie for { host } \" ) _login __log_result END logger . info ( f \"Getting network gateways for host { velocloud_host } ...\" ) Call VeloCloud API endpoint POST /network/getNetworkGateways with the set of desired parameters. If there's an error while connecting to VeloCloud API: __log_result END If the status of the HTTP response is between 500 and 512 (both inclusive): __log_result END If the status of the HTTP response is 400 : __log_result END __login_if_needed logger . info ( f \"Got HTTP { response . status } from Velocloud after getting network gateways for host { velocloud_host } \" ) __log_result","title":"Get network gateways"},{"location":"logging/services/velocloud-bridge/clients/velocloud_client/get_network_gateways/#get-network-gateways","text":"If there's no cookie for the VeloCloud host: logger . error ( f \"Cannot find a cookie for { host } \" ) _login __log_result END logger . info ( f \"Getting network gateways for host { velocloud_host } ...\" ) Call VeloCloud API endpoint POST /network/getNetworkGateways with the set of desired parameters. If there's an error while connecting to VeloCloud API: __log_result END If the status of the HTTP response is between 500 and 512 (both inclusive): __log_result END If the status of the HTTP response is 400 : __log_result END __login_if_needed logger . info ( f \"Got HTTP { response . status } from Velocloud after getting network gateways for host { velocloud_host } \" ) __log_result","title":"Get network gateways"},{"location":"logging/services/velocloud-bridge/clients/velocloud_client/schedule_connect_to_all_hosts/","text":"Schedule connect to all hosts logger . info ( f \"Scheduling job to connect to all hosts...\" ) _connect_to_all_hosts is scheduled to trigger immediately and then periodically If that job had already been scheduled: logger . error ( f \"Skipping start of job to connect to all hosts. Reason: { conflict } \" ) Otherwise: logger . info ( f \"Job to connect to all hosts has been scheduled\" )","title":"Schedule connect to all hosts"},{"location":"logging/services/velocloud-bridge/clients/velocloud_client/schedule_connect_to_all_hosts/#schedule-connect-to-all-hosts","text":"logger . info ( f \"Scheduling job to connect to all hosts...\" ) _connect_to_all_hosts is scheduled to trigger immediately and then periodically If that job had already been scheduled: logger . error ( f \"Skipping start of job to connect to all hosts. Reason: { conflict } \" ) Otherwise: logger . info ( f \"Job to connect to all hosts has been scheduled\" )","title":"Schedule connect to all hosts"},{"location":"logging/services/velocloud-bridge/repositories/velocloud_repository/_get_all_events/","text":"Get all events If event types filter is defined: logger . info ( f \"Using event type filter { filter_events_status_list } to get all events from host { host } \" ) logger . info ( f \"Getting all events from host { host } using filters { body } \" ) get_all_events If response status for get all events is not ok: logger . error ( f \"Could not get all events from { host } using filters { body } . Response: { response } \" )","title":"Get all events"},{"location":"logging/services/velocloud-bridge/repositories/velocloud_repository/_get_all_events/#get-all-events","text":"If event types filter is defined: logger . info ( f \"Using event type filter { filter_events_status_list } to get all events from host { host } \" ) logger . info ( f \"Getting all events from host { host } using filters { body } \" ) get_all_events If response status for get all events is not ok: logger . error ( f \"Could not get all events from { host } using filters { body } . Response: { response } \" )","title":"Get all events"},{"location":"logging/services/velocloud-bridge/repositories/velocloud_repository/get_all_edge_events/","text":"Get all edge events logger . info ( f \"Getting events for edge { edge } between { start } and { end } ...\" ) _get_all_events","title":"Get all edge events"},{"location":"logging/services/velocloud-bridge/repositories/velocloud_repository/get_all_edge_events/#get-all-edge-events","text":"logger . info ( f \"Getting events for edge { edge } between { start } and { end } ...\" ) _get_all_events","title":"Get all edge events"},{"location":"logging/services/velocloud-bridge/repositories/velocloud_repository/get_all_enterprise_events/","text":"Get all enterprise events logger . info ( f \"Getting events from enterprise { enterprise } of host { host } between { start } and { end } \" ) _get_all_events","title":"Get all enterprise events"},{"location":"logging/services/velocloud-bridge/repositories/velocloud_repository/get_all_enterprise_events/#get-all-enterprise-events","text":"logger . info ( f \"Getting events from enterprise { enterprise } of host { host } between { start } and { end } \" ) _get_all_events","title":"Get all enterprise events"},{"location":"logging/services/velocloud-bridge/repositories/velocloud_repository/get_all_enterprise_names/","text":"Get all enterprise names logger . info ( \"Getting all enterprise names\" ) get_all_enterprise_names If response status for get all enterprise names is not ok: logger . error ( f \"Error { enterprises [ 'status' ] } , error: { enterprises [ 'body' ] } \" )","title":"Get all enterprise names"},{"location":"logging/services/velocloud-bridge/repositories/velocloud_repository/get_all_enterprise_names/#get-all-enterprise-names","text":"logger . info ( \"Getting all enterprise names\" ) get_all_enterprise_names If response status for get all enterprise names is not ok: logger . error ( f \"Error { enterprises [ 'status' ] } , error: { enterprises [ 'body' ] } \" )","title":"Get all enterprise names"},{"location":"logging/services/velocloud-bridge/repositories/velocloud_repository/get_edge_links_series/","text":"Get edge links series get_edge_links_series","title":"Get edge links series"},{"location":"logging/services/velocloud-bridge/repositories/velocloud_repository/get_edge_links_series/#get-edge-links-series","text":"get_edge_links_series","title":"Get edge links series"},{"location":"logging/services/velocloud-bridge/repositories/velocloud_repository/get_enterprise_edges/","text":"Get enterprise edges get_enterprise_edges","title":"Get enterprise edges"},{"location":"logging/services/velocloud-bridge/repositories/velocloud_repository/get_enterprise_edges/#get-enterprise-edges","text":"get_enterprise_edges","title":"Get enterprise edges"},{"location":"logging/services/velocloud-bridge/repositories/velocloud_repository/get_gateway_status_metrics/","text":"Get gateway status metrics get_gateway_status_metrics","title":"Get gateway status metrics"},{"location":"logging/services/velocloud-bridge/repositories/velocloud_repository/get_gateway_status_metrics/#get-gateway-status-metrics","text":"get_gateway_status_metrics","title":"Get gateway status metrics"},{"location":"logging/services/velocloud-bridge/repositories/velocloud_repository/get_links_configuration/","text":"Get links configuration get_edge_configuration_modules If response status for get edge configuration modules is not ok: logger . error ( f \"Could not get links configuration for edge { edge_full_id } . Response: { config_modules_response } \" ) END If response does not have a WAN configuration module: logger . warning ( f \"No WAN module was found for edge { edge_full_id } \" ) END If WAN configuration module does not have links configurations: logger . warning ( f \"No links configuration was found in WAN module of edge { edge_full_id } \" ) END","title":"Get links configuration"},{"location":"logging/services/velocloud-bridge/repositories/velocloud_repository/get_links_configuration/#get-links-configuration","text":"get_edge_configuration_modules If response status for get edge configuration modules is not ok: logger . error ( f \"Could not get links configuration for edge { edge_full_id } . Response: { config_modules_response } \" ) END If response does not have a WAN configuration module: logger . warning ( f \"No WAN module was found for edge { edge_full_id } \" ) END If WAN configuration module does not have links configurations: logger . warning ( f \"No links configuration was found in WAN module of edge { edge_full_id } \" ) END","title":"Get links configuration"},{"location":"logging/services/velocloud-bridge/repositories/velocloud_repository/get_links_metric_info/","text":"Get links metric info get_links_metric_info If response status for get links metric info is not ok: logger . error ( f \"Could not get links metric info for host { velocloud_host } and interval { interval } . Response: \" f \" { links_metric_info_response } \" ) END","title":"Get links metric info"},{"location":"logging/services/velocloud-bridge/repositories/velocloud_repository/get_links_metric_info/#get-links-metric-info","text":"get_links_metric_info If response status for get links metric info is not ok: logger . error ( f \"Could not get links metric info for host { velocloud_host } and interval { interval } . Response: \" f \" { links_metric_info_response } \" ) END","title":"Get links metric info"},{"location":"logging/services/velocloud-bridge/repositories/velocloud_repository/get_links_with_edge_info/","text":"Get links with edge info get_links_with_edge_info If response status for get links with edge info is not ok: logger . error ( f \"Could not get links with edge info for host { velocloud_host } . Response: \" f \" { links_with_edge_info_response } \" ) END","title":"Get links with edge info"},{"location":"logging/services/velocloud-bridge/repositories/velocloud_repository/get_links_with_edge_info/#get-links-with-edge-info","text":"get_links_with_edge_info If response status for get links with edge info is not ok: logger . error ( f \"Could not get links with edge info for host { velocloud_host } . Response: \" f \" { links_with_edge_info_response } \" ) END","title":"Get links with edge info"},{"location":"logging/services/velocloud-bridge/repositories/velocloud_repository/get_network_enterprise_edges/","text":"Get network enterprise edges get_network_enterprises If response status for get network enterprises is not ok: logger . error ( f \"Could not get network enterprise edges for host { host } and enterprises { enterprise_ids } . Response: \" f \" { enterprise_edges_response } \" ) END If the list of enterprises from the response is empty: logger . warning ( f \"No enterprises found for host { host } and enterprise ids { enterprise_ids } \" ) END If enterprises have edges associated: logger . info ( f \"Found { len ( edges ) } edges for host { host } and enterprise ids { enterprise_ids } \" ) Otherwise: logger . warning ( f \"No edges found for host { host } and enterprise ids { enterprise_ids } \" )","title":"Get network enterprise edges"},{"location":"logging/services/velocloud-bridge/repositories/velocloud_repository/get_network_enterprise_edges/#get-network-enterprise-edges","text":"get_network_enterprises If response status for get network enterprises is not ok: logger . error ( f \"Could not get network enterprise edges for host { host } and enterprises { enterprise_ids } . Response: \" f \" { enterprise_edges_response } \" ) END If the list of enterprises from the response is empty: logger . warning ( f \"No enterprises found for host { host } and enterprise ids { enterprise_ids } \" ) END If enterprises have edges associated: logger . info ( f \"Found { len ( edges ) } edges for host { host } and enterprise ids { enterprise_ids } \" ) Otherwise: logger . warning ( f \"No edges found for host { host } and enterprise ids { enterprise_ids } \" )","title":"Get network enterprise edges"},{"location":"logging/services/velocloud-bridge/repositories/velocloud_repository/get_network_gateways/","text":"Get network gateways get_network_gateways If response status for get network gateways is not ok: logger . error ( f \"Could not get network gateways for host { host } . Response: { response } \" ) END","title":"Get network gateways"},{"location":"logging/services/velocloud-bridge/repositories/velocloud_repository/get_network_gateways/#get-network-gateways","text":"get_network_gateways If response status for get network gateways is not ok: logger . error ( f \"Could not get network gateways for host { host } . Response: { response } \" ) END","title":"Get network gateways"},{"location":"manual_configurations/INIT_AUTOMATION_PROJECT/","text":"Pre requisites AWS user credentials AWS SSH keys credentials Terraform Description The Automation Engine project at this moment is deployed in AWS infrastructure with all FEDRAMP requirements meet, this is the reason why we select the CI/CD tool of AWS to manage the application life cycle; to take advantage of the OKTA and AWS SSO access, permission and logs of every action in the Automation APP. To init the project and be able to start using these CI/CD tool we need to follow some manual steps/configurations. Considerations Ensure that your AWS credentials have the required permissions to create the listed resources , if not terraform will fail. In terraform we use a feature called workspace as a representation of the environment . The actual environments are: pro and mirror , but could be more in the future. Any change must be applied manually in all regions and pushed to the repository by the authorized operator. The definition of this resources are located in a separated repository of Automation Engine one. A manual git repository was already created that contain the terraform definition of the CI/CD tool in the master branch. This manual repository has subsequently created a job in the pipelines (automated) that performs backups together with the rest of the infrastructure. Steps Configure AWS credentials by follow the official docs . Configure AWS SSH keys credentials by follow the official docs . Clone the repository: git clone ssh://git-codecommit.us-east-1.amazonaws.com/v1/repos/fedramp-pipelines CD to the repo folder cd fedramp-pipelines/ Initializate terraformn: terraform init Select workspace/environment: terraform workspace select <environemt> Verify changes and apply (if theres a problem in the plan step, just fix an try again): terraform plan terraform apply Do the last two steps for the other environments Push the changes to the repository: git commit git push Application results Afther terraform apply of all environments, the pipelines will be configured in each separated region and will be prepared to manage Automation Engine application life cycle. This terraform project will create the follow resources in each environment: aws_codebuild_project.stages[\"deploy\"] aws_codebuild_project.stages[\"integrity\"] aws_codebuild_project.stages[\"observability\"] aws_codebuild_project.stages[\"terraform\"] aws_codebuild_project.stages[\"validate\"] aws_codecommit_approval_rule_template.approval aws_codecommit_approval_rule_template_association.approval_association aws_codecommit_repository.git aws_codepipeline.pipeline_master aws_iam_policy.pipelines aws_iam_role.pipelines aws_iam_role_policy_attachment.pipelines aws_s3_bucket.pipelines aws_s3_bucket_acl.pipelines aws_security_group.codebuild","title":"Init Automation Engine project"},{"location":"manual_configurations/INIT_AUTOMATION_PROJECT/#pre-requisites","text":"AWS user credentials AWS SSH keys credentials Terraform","title":"Pre requisites"},{"location":"manual_configurations/INIT_AUTOMATION_PROJECT/#description","text":"The Automation Engine project at this moment is deployed in AWS infrastructure with all FEDRAMP requirements meet, this is the reason why we select the CI/CD tool of AWS to manage the application life cycle; to take advantage of the OKTA and AWS SSO access, permission and logs of every action in the Automation APP. To init the project and be able to start using these CI/CD tool we need to follow some manual steps/configurations.","title":"Description"},{"location":"manual_configurations/INIT_AUTOMATION_PROJECT/#considerations","text":"Ensure that your AWS credentials have the required permissions to create the listed resources , if not terraform will fail. In terraform we use a feature called workspace as a representation of the environment . The actual environments are: pro and mirror , but could be more in the future. Any change must be applied manually in all regions and pushed to the repository by the authorized operator. The definition of this resources are located in a separated repository of Automation Engine one. A manual git repository was already created that contain the terraform definition of the CI/CD tool in the master branch. This manual repository has subsequently created a job in the pipelines (automated) that performs backups together with the rest of the infrastructure.","title":"Considerations"},{"location":"manual_configurations/INIT_AUTOMATION_PROJECT/#steps","text":"Configure AWS credentials by follow the official docs . Configure AWS SSH keys credentials by follow the official docs . Clone the repository: git clone ssh://git-codecommit.us-east-1.amazonaws.com/v1/repos/fedramp-pipelines CD to the repo folder cd fedramp-pipelines/ Initializate terraformn: terraform init Select workspace/environment: terraform workspace select <environemt> Verify changes and apply (if theres a problem in the plan step, just fix an try again): terraform plan terraform apply Do the last two steps for the other environments Push the changes to the repository: git commit git push","title":"Steps"},{"location":"manual_configurations/INIT_AUTOMATION_PROJECT/#application-results","text":"Afther terraform apply of all environments, the pipelines will be configured in each separated region and will be prepared to manage Automation Engine application life cycle. This terraform project will create the follow resources in each environment: aws_codebuild_project.stages[\"deploy\"] aws_codebuild_project.stages[\"integrity\"] aws_codebuild_project.stages[\"observability\"] aws_codebuild_project.stages[\"terraform\"] aws_codebuild_project.stages[\"validate\"] aws_codecommit_approval_rule_template.approval aws_codecommit_approval_rule_template_association.approval_association aws_codecommit_repository.git aws_codepipeline.pipeline_master aws_iam_policy.pipelines aws_iam_role.pipelines aws_iam_role_policy_attachment.pipelines aws_s3_bucket.pipelines aws_s3_bucket_acl.pipelines aws_security_group.codebuild","title":"Application results"},{"location":"manual_configurations/OKTA_CONFIGURATIONS/","text":"Pre requisites Okta Account AWS Account Description Because of FEDRAMP we need to implement as a team a IdP that control all users and permissions related to MetTel projects that are made by Intelygenz. For automatic synchronization we are going to create SCIM sync between OKTA and AWS SSO, because of that, groups and users are going to be synced if someone deletes/create a group/user in Okta. Considerations Remove a user/group don't revoke the session tokens in AWS, the minimum duration of these tokens are of 1h. Info here Using the same Okta group for both assignments and group push is not currently supported. To maintain consistent group memberships between Okta and AWS SSO, you need to create a separate group and configure it to push groups to AWS SSO. Info here If you update a user\u2019s address you must have streetAddress, city, state, zipCode and the countryCode value specified. If any of these values are not specified for the Okta user at the time of synchronization, the user or changes to the user will not be provisioned. Info here Entitlements and role attributes are not supported and cannot be synced to AWS SSO. Info here Steps Configure IdP with Okta, this is the guide . Create the following groups: OKTA-IPA-FED-INT-PRIVILEGED: Internal users Federated privileged group on the federal account. Administration accounts. OKTA-IPA-FED-INT-NON-PRIVILEGED: Internal users Federated non privileged group on the federal account. OKTA-IPA-COM-INT-PRIVILEGED: Internal users Commercial privileged group on the commercial account. Administration accounts. OKTA-IPA-COM-INT-NON-PRIVILEGED: Internal users Federated privileged group on the commercial account. Administration accounts. OKTA-IPA-FED-EXT-PRIVILEGED: External users Federated privileged group on the federal account. Administration accounts. OKTA-IPA-FED-EXT-NON-PRIVILEGED: External users Federated non privileged group on the federal account. OKTA-IPA-COM-EXT-PRIVILEGED: External users Commercial privileged group on the commercial account. Administration accounts. OKTA-IPA-COM-EXT-NON-PRIVILEGED: External users Federated privileged group on the commercial account. Administration accounts. Associate permissions to groups. Guide Privileged accounts will have general administrator permissions Non privileged accounts will only have access to logs on cloud watch and grafana Revoke permissions Because of the problem of token duration of 1h that can not be revoked from okta, there is a manual procedure to delete the access from AWS SSO. For revoking access follow this guide","title":"AWS SSO Okta configurations"},{"location":"manual_configurations/OKTA_CONFIGURATIONS/#pre-requisites","text":"Okta Account AWS Account","title":"Pre requisites"},{"location":"manual_configurations/OKTA_CONFIGURATIONS/#description","text":"Because of FEDRAMP we need to implement as a team a IdP that control all users and permissions related to MetTel projects that are made by Intelygenz. For automatic synchronization we are going to create SCIM sync between OKTA and AWS SSO, because of that, groups and users are going to be synced if someone deletes/create a group/user in Okta.","title":"Description"},{"location":"manual_configurations/OKTA_CONFIGURATIONS/#considerations","text":"Remove a user/group don't revoke the session tokens in AWS, the minimum duration of these tokens are of 1h. Info here Using the same Okta group for both assignments and group push is not currently supported. To maintain consistent group memberships between Okta and AWS SSO, you need to create a separate group and configure it to push groups to AWS SSO. Info here If you update a user\u2019s address you must have streetAddress, city, state, zipCode and the countryCode value specified. If any of these values are not specified for the Okta user at the time of synchronization, the user or changes to the user will not be provisioned. Info here Entitlements and role attributes are not supported and cannot be synced to AWS SSO. Info here","title":"Considerations"},{"location":"manual_configurations/OKTA_CONFIGURATIONS/#steps","text":"Configure IdP with Okta, this is the guide . Create the following groups: OKTA-IPA-FED-INT-PRIVILEGED: Internal users Federated privileged group on the federal account. Administration accounts. OKTA-IPA-FED-INT-NON-PRIVILEGED: Internal users Federated non privileged group on the federal account. OKTA-IPA-COM-INT-PRIVILEGED: Internal users Commercial privileged group on the commercial account. Administration accounts. OKTA-IPA-COM-INT-NON-PRIVILEGED: Internal users Federated privileged group on the commercial account. Administration accounts. OKTA-IPA-FED-EXT-PRIVILEGED: External users Federated privileged group on the federal account. Administration accounts. OKTA-IPA-FED-EXT-NON-PRIVILEGED: External users Federated non privileged group on the federal account. OKTA-IPA-COM-EXT-PRIVILEGED: External users Commercial privileged group on the commercial account. Administration accounts. OKTA-IPA-COM-EXT-NON-PRIVILEGED: External users Federated privileged group on the commercial account. Administration accounts. Associate permissions to groups. Guide Privileged accounts will have general administrator permissions Non privileged accounts will only have access to logs on cloud watch and grafana","title":"Steps"},{"location":"manual_configurations/OKTA_CONFIGURATIONS/#revoke-permissions","text":"Because of the problem of token duration of 1h that can not be revoked from okta, there is a manual procedure to delete the access from AWS SSO. For revoking access follow this guide","title":"Revoke permissions"},{"location":"manual_configurations/OKTA_JWT/","text":"Creation of Oauth Application for Data Highway API Pre requisites Okta Account AWS Account Description API needs a way to verify the access of vendors and internal users provided from Okta. They way to do it is about provide a JWT from Okta with a company name information on it. Group API access First steep is about the creation of a group for the API access, only members with his group will access the API. The groups must have the next values: * Name: IGZ-INT-DATA-HIGHWAY-API * Description: API Data highway access group. Name: IGZ-EXT-DATA-HIGHWAY-API Description: API Data highway access group. Create Application server To create an application destined for the API, we are gonna need to go to \"Applications/Applications\" and click on create app integration A new form will show and we need to fill it with the next information: App integration name: IGZ-DATA-HIGHWAY-API Grant type: Select \"Authorization Code\" and \"Resource Owner Password\" Controlled access: Select \"Limit access to selected groups\" Selected groups: IGZ-INT-DATA-HIGHWAY-API, IGZ-EXT-DATA-HIGHWAY-API Click Save. Create Authorization server In the Admin Dashboard, go to security/API and click on add authorization server. We will need to fill the name, audience, and description. the next values are the selected ones: Name: API-DATA-HIGHWAY Audience: API-DATA-HIGHWAY Description: API data highway access. After filling this form, click on the save button. 3. With the Authorization server created, we need to add some extra configurations. Go to the Claims menu following the next image 1. Click on \"Add claim\" 2. Fill the new claim with the next information: 1. Name: organization 2. Include in token type: \"Id Token\" - \"Always\" 3. Value type: \"Expression\" 4. Value: user.organization 5. Include in: \"Any scope\" 4. Go to access policies menu following the next image: 1. in this menu click in the button \"Add new access policy\" 2. it will appear a new form, fill it with the next values and click on create policy: 1. Name: IGZ-DATA-HIGHWAY-API-JWT-ACCESS-POLICY 2. Description: Api JWT access policy. 3. Assign to: IGZ-INT-DATA-HIGHWAY-API, IGZ-EXT-DATA-HIGHWAY-API 3. After closing the form, select the policy created and click on the \"Add rule\" button. And fill the form with the next information: 1. Rule Name: IGZ-DATA-HIGHWAY-API-ACCESS-RULE 2. Grant type is: Select \"Client credentials\" and \"Resource Owner Password\" 3. Assigned the app and a member of one of the following: Add the groups \"IGZ-INT-DATA-HIGHWAY-API, IGZ-EXT-DATA-HIGHWAY-API\". 4. The following scopes: profiles and openid 5. but will expire if not used every: 1 h Update Application with new parameters we are going to need to go to \"Applications/Applications\" and update the configuration of the application \"IGZ-DATA-HIGHWAY-API\". Disable User consent in general configurations.","title":"AWS SSO Okta JWT token"},{"location":"manual_configurations/OKTA_JWT/#creation-of-oauth-application-for-data-highway-api","text":"","title":"Creation of Oauth Application for Data Highway API"},{"location":"manual_configurations/OKTA_JWT/#pre-requisites","text":"Okta Account AWS Account","title":"Pre requisites"},{"location":"manual_configurations/OKTA_JWT/#description","text":"API needs a way to verify the access of vendors and internal users provided from Okta. They way to do it is about provide a JWT from Okta with a company name information on it.","title":"Description"},{"location":"manual_configurations/OKTA_JWT/#group-api-access","text":"First steep is about the creation of a group for the API access, only members with his group will access the API. The groups must have the next values: * Name: IGZ-INT-DATA-HIGHWAY-API * Description: API Data highway access group. Name: IGZ-EXT-DATA-HIGHWAY-API Description: API Data highway access group.","title":"Group API access"},{"location":"manual_configurations/OKTA_JWT/#create-application-server","text":"To create an application destined for the API, we are gonna need to go to \"Applications/Applications\" and click on create app integration A new form will show and we need to fill it with the next information: App integration name: IGZ-DATA-HIGHWAY-API Grant type: Select \"Authorization Code\" and \"Resource Owner Password\" Controlled access: Select \"Limit access to selected groups\" Selected groups: IGZ-INT-DATA-HIGHWAY-API, IGZ-EXT-DATA-HIGHWAY-API Click Save.","title":"Create Application server"},{"location":"manual_configurations/OKTA_JWT/#create-authorization-server","text":"In the Admin Dashboard, go to security/API and click on add authorization server. We will need to fill the name, audience, and description. the next values are the selected ones: Name: API-DATA-HIGHWAY Audience: API-DATA-HIGHWAY Description: API data highway access. After filling this form, click on the save button. 3. With the Authorization server created, we need to add some extra configurations. Go to the Claims menu following the next image 1. Click on \"Add claim\" 2. Fill the new claim with the next information: 1. Name: organization 2. Include in token type: \"Id Token\" - \"Always\" 3. Value type: \"Expression\" 4. Value: user.organization 5. Include in: \"Any scope\" 4. Go to access policies menu following the next image: 1. in this menu click in the button \"Add new access policy\" 2. it will appear a new form, fill it with the next values and click on create policy: 1. Name: IGZ-DATA-HIGHWAY-API-JWT-ACCESS-POLICY 2. Description: Api JWT access policy. 3. Assign to: IGZ-INT-DATA-HIGHWAY-API, IGZ-EXT-DATA-HIGHWAY-API 3. After closing the form, select the policy created and click on the \"Add rule\" button. And fill the form with the next information: 1. Rule Name: IGZ-DATA-HIGHWAY-API-ACCESS-RULE 2. Grant type is: Select \"Client credentials\" and \"Resource Owner Password\" 3. Assigned the app and a member of one of the following: Add the groups \"IGZ-INT-DATA-HIGHWAY-API, IGZ-EXT-DATA-HIGHWAY-API\". 4. The following scopes: profiles and openid 5. but will expire if not used every: 1 h","title":"Create Authorization server"},{"location":"manual_configurations/OKTA_JWT/#update-application-with-new-parameters","text":"we are going to need to go to \"Applications/Applications\" and update the configuration of the application \"IGZ-DATA-HIGHWAY-API\". Disable User consent in general configurations.","title":"Update Application with new parameters"},{"location":"manual_procedures/API_VENDOR_ACCESS/","text":"Pre requisites Okta Account AWS Account Description This procedure explains how to give access to a specific vendor to the data highway API. Vendor requirements Provide a static trusted IP of the vendor MetTel configurations MetTel needs to do these next steps: The Okta vendor account into OKTA group DATA-HIGHWAY-API Vendor profile filled with the organization name of their company. API gateway configurations On the data highway team: Add the trusted static IP on the API gateway access policy.","title":"Vendor access to the API"},{"location":"manual_procedures/API_VENDOR_ACCESS/#pre-requisites","text":"Okta Account AWS Account","title":"Pre requisites"},{"location":"manual_procedures/API_VENDOR_ACCESS/#description","text":"This procedure explains how to give access to a specific vendor to the data highway API.","title":"Description"},{"location":"manual_procedures/API_VENDOR_ACCESS/#vendor-requirements","text":"Provide a static trusted IP of the vendor","title":"Vendor requirements"},{"location":"manual_procedures/API_VENDOR_ACCESS/#mettel-configurations","text":"MetTel needs to do these next steps: The Okta vendor account into OKTA group DATA-HIGHWAY-API Vendor profile filled with the organization name of their company.","title":"MetTel configurations"},{"location":"manual_procedures/API_VENDOR_ACCESS/#api-gateway-configurations","text":"On the data highway team: Add the trusted static IP on the API gateway access policy.","title":"API gateway configurations"},{"location":"manual_procedures/EMERGENCY_PLAN/","text":"","title":"Emergency recovery plan"},{"location":"manual_procedures/SWITCH_AUTOMATION_ENGINE_REGION/","text":"Pre requisites AWS user credentials AWS SSH keys credentials Verify AWS Personal Health Dashboard Verify AWS Services Health Dashboard Description The Automation Engine application is prepared to be deployed in different AWS regions, each region is associated with an environment . At this moment we have two environments: pro and mirror in us-east-1 and us-west-1 respectively; but we can have more in the future. By default the application is deployed in pro environment but can change by updating a variable in the repository. This way if we suffer a disaster and lose the main region we can easily deploy the application in the mirror region, this is the goal of this procedure. Considerations Ensure that your AWS credentials have Codecommit permission to interact with Automation Engine repository in all available regions. We have configured a git mirroring from pro to mirror environment, by that way we always have updated the repo in the mirror region. The actual environments are: pro and mirror , but could be more in the future. Master branch is protected, you can't commit directly to it, you must create a new branch and do a pull request. An authorized team member must accept your PR once the changes was verified. Once the pipeline run, if we check logs, we can verify that is possible that terraform failed the execution of union resources(AWS resources that create links between regions), this is originated by AWS unavailability in one region. This behavior is expected since we assume that an AWS Region is not working properly; this job is allowed to fail for this reason, if any other task fails the pipeline will end with an error. Posible situation We have all active infrastructure and application in pro ( us-east-1 ), then AWS suffer a disaster in Nort Virginia region( us-east-1 ) and we lost the activity and respondes from AWS resources; we must assume that all resources are unavailable. It's time to star using the resources in the mirror region( us-west-1 ) by following the next steps: Steps Verify AWS Health Dashboards to confirm AWS services availabily per region. Confirm that our services in the main region( us-east-1 ) are unavailable. Clone the repository from the mirror region( us-west-1 ): git clone ssh://git-codecommit.us-west-1.amazonaws.com/v1/repos/fedramp-automation-engine Create a new branch with the name switch-automation-engine-region . cd fedramp-automation-engine git branch -b switch-automation-engine-region Edit ACTIVE_ENVIRONMENT default value in infra-as-code/basic-infra/common_info.tf file variable \"ACTIVE_ENVIRONMENT\" { default = \"pro\" <---- put the desired environment here, example: \"mirror\" description = \"Active environment in aws\" } Push the changes to the repository: git commit git push Go to AWS Codecommit console in mirror region( us-west-1 ), in pull request section of the automation repo and create a new PR After the approve from the authorized team member, merge to master in the same AWS codecommit console. Git merge results Once the merge is complete, this will trigger a pipeline in the mirror region( us-west-1 ) that will create the infrastructure based in the variable ACTIVE_ENVIRONMENT , this means that the application will be deployed in the region where we previously confirm that AWS has no issues.","title":"Switch Automation Engine region"},{"location":"manual_procedures/SWITCH_AUTOMATION_ENGINE_REGION/#pre-requisites","text":"AWS user credentials AWS SSH keys credentials Verify AWS Personal Health Dashboard Verify AWS Services Health Dashboard","title":"Pre requisites"},{"location":"manual_procedures/SWITCH_AUTOMATION_ENGINE_REGION/#description","text":"The Automation Engine application is prepared to be deployed in different AWS regions, each region is associated with an environment . At this moment we have two environments: pro and mirror in us-east-1 and us-west-1 respectively; but we can have more in the future. By default the application is deployed in pro environment but can change by updating a variable in the repository. This way if we suffer a disaster and lose the main region we can easily deploy the application in the mirror region, this is the goal of this procedure.","title":"Description"},{"location":"manual_procedures/SWITCH_AUTOMATION_ENGINE_REGION/#considerations","text":"Ensure that your AWS credentials have Codecommit permission to interact with Automation Engine repository in all available regions. We have configured a git mirroring from pro to mirror environment, by that way we always have updated the repo in the mirror region. The actual environments are: pro and mirror , but could be more in the future. Master branch is protected, you can't commit directly to it, you must create a new branch and do a pull request. An authorized team member must accept your PR once the changes was verified. Once the pipeline run, if we check logs, we can verify that is possible that terraform failed the execution of union resources(AWS resources that create links between regions), this is originated by AWS unavailability in one region. This behavior is expected since we assume that an AWS Region is not working properly; this job is allowed to fail for this reason, if any other task fails the pipeline will end with an error.","title":"Considerations"},{"location":"manual_procedures/SWITCH_AUTOMATION_ENGINE_REGION/#posible-situation","text":"We have all active infrastructure and application in pro ( us-east-1 ), then AWS suffer a disaster in Nort Virginia region( us-east-1 ) and we lost the activity and respondes from AWS resources; we must assume that all resources are unavailable. It's time to star using the resources in the mirror region( us-west-1 ) by following the next steps:","title":"Posible situation"},{"location":"manual_procedures/SWITCH_AUTOMATION_ENGINE_REGION/#steps","text":"Verify AWS Health Dashboards to confirm AWS services availabily per region. Confirm that our services in the main region( us-east-1 ) are unavailable. Clone the repository from the mirror region( us-west-1 ): git clone ssh://git-codecommit.us-west-1.amazonaws.com/v1/repos/fedramp-automation-engine Create a new branch with the name switch-automation-engine-region . cd fedramp-automation-engine git branch -b switch-automation-engine-region Edit ACTIVE_ENVIRONMENT default value in infra-as-code/basic-infra/common_info.tf file variable \"ACTIVE_ENVIRONMENT\" { default = \"pro\" <---- put the desired environment here, example: \"mirror\" description = \"Active environment in aws\" } Push the changes to the repository: git commit git push Go to AWS Codecommit console in mirror region( us-west-1 ), in pull request section of the automation repo and create a new PR After the approve from the authorized team member, merge to master in the same AWS codecommit console.","title":"Steps"},{"location":"manual_procedures/SWITCH_AUTOMATION_ENGINE_REGION/#git-merge-results","text":"Once the merge is complete, this will trigger a pipeline in the mirror region( us-west-1 ) that will create the infrastructure based in the variable ACTIVE_ENVIRONMENT , this means that the application will be deployed in the region where we previously confirm that AWS has no issues.","title":"Git merge results"},{"location":"metrics-definitions/","text":"Metrics Definitions This folder will contain all the metrics created to track functional and business values that improve the overall observability of the system. There will be one markdown file per metric in this folder. The filename will be the metric name and it will contain all the descriptions and possible label combinations. Naming conventions must follow the Prometheus Best Practices for naming and units . List of metrics Metric Description tasks_created Task Creations tasks_reopened Task Re-Opens tasks_forwarded Task Forwards tasks_autoresolved Task Auto-Resolves velocloud_fetcher_to_kafka_messages_attempts VeloCloud fetcher attempts to kafka velocloud_fetcher_to_kafka_messages_status VeloCloud fetcher errors when pushing to kafka","title":"Metrics definitions"},{"location":"metrics-definitions/#metrics-definitions","text":"This folder will contain all the metrics created to track functional and business values that improve the overall observability of the system. There will be one markdown file per metric in this folder. The filename will be the metric name and it will contain all the descriptions and possible label combinations. Naming conventions must follow the Prometheus Best Practices for naming and units .","title":"Metrics Definitions"},{"location":"metrics-definitions/#list-of-metrics","text":"Metric Description tasks_created Task Creations tasks_reopened Task Re-Opens tasks_forwarded Task Forwards tasks_autoresolved Task Auto-Resolves velocloud_fetcher_to_kafka_messages_attempts VeloCloud fetcher attempts to kafka velocloud_fetcher_to_kafka_messages_status VeloCloud fetcher errors when pushing to kafka","title":"List of metrics"},{"location":"metrics-definitions/tasks_autoresolved/","text":"Task Auto-Resolves Metric name: tasks_autoresolved Metric type: Counter Data store: Prometheus Service Outage Monitor Description: Number of service outage tasks related to VeloCloud edges that have been auto-resolved by the service-outage-monitor . Labels: feature: Service Outage Monitor system: VeloCloud topic: VOO client: [<client> | FIS | Other] host: <host> outage_type: [Hard Down (no HA) | Hard Down (HA) | Soft Down (HA) | Link Down (no HA) | Link Down (HA) | Unknown] severity: [2 | 3] has_digi: [True | False | Unknown] has_byob: [True | False | Unknown] link_types: [Wired | Wireless | Both | None | Unknown] Service Affecting Monitor Description: Number of service affecting tasks related to VeloCloud edges that have been auto-resolved by the service-affecting-monitor . Labels: feature: Service Affecting Monitor system: VeloCloud topic: VAS client: [<client> | FIS | Other] host: <host> severity: 3 trouble: [Latency | Packet Loss | Jitter | Bandwidth Over Utilization | Circuit Instability | Multiple | Unknown] has_byob: [True | False] link_types: [Wired | Wireless | Unknown] InterMapper Outage Monitor Description: Number of service outage tasks related to InterMapper devices that have been auto-resolved by the intermapper-outage-monitor . Labels: feature: InterMapper Outage Monitor system: InterMapper topic: VOO severity: 2 event: <event> is_piab: [True | False] TNBA Monitor Description: Number of tasks related to VeloCloud edges that have been auto-resolved by the tnba-monitor . Labels: feature: TNBA Monitor system: VeloCloud topic: [VOO | VAS] client: [<client> | FIS | Other] host: <host> severity: [2 | 3] Hawkeye Outage Monitor Description: Number of service outage tasks related to Ixia probes that have been auto-resolved by the hawkeye-outage-monitor . Labels: feature: Hawkeye Outage Monitor system: Ixia topic: VOO client: [<client> | FIS | Other] outage_type: [Node To Node | Real Service | Both | None | Unknown] severity: 2","title":"Task Auto-Resolves #"},{"location":"metrics-definitions/tasks_autoresolved/#task-auto-resolves","text":"Metric name: tasks_autoresolved Metric type: Counter Data store: Prometheus","title":"Task Auto-Resolves"},{"location":"metrics-definitions/tasks_autoresolved/#service-outage-monitor","text":"Description: Number of service outage tasks related to VeloCloud edges that have been auto-resolved by the service-outage-monitor . Labels: feature: Service Outage Monitor system: VeloCloud topic: VOO client: [<client> | FIS | Other] host: <host> outage_type: [Hard Down (no HA) | Hard Down (HA) | Soft Down (HA) | Link Down (no HA) | Link Down (HA) | Unknown] severity: [2 | 3] has_digi: [True | False | Unknown] has_byob: [True | False | Unknown] link_types: [Wired | Wireless | Both | None | Unknown]","title":"Service Outage Monitor"},{"location":"metrics-definitions/tasks_autoresolved/#service-affecting-monitor","text":"Description: Number of service affecting tasks related to VeloCloud edges that have been auto-resolved by the service-affecting-monitor . Labels: feature: Service Affecting Monitor system: VeloCloud topic: VAS client: [<client> | FIS | Other] host: <host> severity: 3 trouble: [Latency | Packet Loss | Jitter | Bandwidth Over Utilization | Circuit Instability | Multiple | Unknown] has_byob: [True | False] link_types: [Wired | Wireless | Unknown]","title":"Service Affecting Monitor"},{"location":"metrics-definitions/tasks_autoresolved/#intermapper-outage-monitor","text":"Description: Number of service outage tasks related to InterMapper devices that have been auto-resolved by the intermapper-outage-monitor . Labels: feature: InterMapper Outage Monitor system: InterMapper topic: VOO severity: 2 event: <event> is_piab: [True | False]","title":"InterMapper Outage Monitor"},{"location":"metrics-definitions/tasks_autoresolved/#tnba-monitor","text":"Description: Number of tasks related to VeloCloud edges that have been auto-resolved by the tnba-monitor . Labels: feature: TNBA Monitor system: VeloCloud topic: [VOO | VAS] client: [<client> | FIS | Other] host: <host> severity: [2 | 3]","title":"TNBA Monitor"},{"location":"metrics-definitions/tasks_autoresolved/#hawkeye-outage-monitor","text":"Description: Number of service outage tasks related to Ixia probes that have been auto-resolved by the hawkeye-outage-monitor . Labels: feature: Hawkeye Outage Monitor system: Ixia topic: VOO client: [<client> | FIS | Other] outage_type: [Node To Node | Real Service | Both | None | Unknown] severity: 2","title":"Hawkeye Outage Monitor"},{"location":"metrics-definitions/tasks_created/","text":"Task Creations Metric name: tasks_created Metric type: Counter Data store: Prometheus Service Outage Monitor Description: Number of service outage tasks related to VeloCloud edges that have been created by the service-outage-monitor . Labels: feature: Service Outage Monitor system: VeloCloud topic: VOO client: [<client> | FIS | Other] host: <host> outage_type: [Hard Down (no HA) | Hard Down (HA) | Soft Down (HA) | Link Down (no HA) | Link Down (HA)] severity: [2 | 3] has_digi: [True | False] has_byob: [True | False] link_types: [Wired | Wireless | Both | None] Service Affecting Monitor Description: Number of service affecting tasks related to VeloCloud edges that have been created by the service-affecting-monitor . Labels: feature: Service Affecting Monitor system: VeloCloud topic: VAS client: [<client> | FIS | Other] host: <host> severity: 3 trouble: [Latency | Packet Loss | Jitter | Bandwidth Over Utilization | Circuit Instability] has_byob: [True | False] link_types: [Wired | Wireless] InterMapper Outage Monitor Description: Number of service outage tasks related to InterMapper devices that have been created by the intermapper-outage-monitor . Labels: feature: InterMapper Outage Monitor system: InterMapper topic: VOO severity: 2 event: <event> is_piab: [True | False] Gateway Monitor Description: Number of ServiceNow incidents related to VeloCloud gateways that have been created by the gateway-monitor . Labels: feature: Gateway Monitor system: VeloCloud host: <host> trouble: [Offline | Tunnel Count] Hawkeye Outage Monitor Description: Number of service outage tasks related to Ixia probes that have been created by the hawkeye-outage-monitor . Labels: feature: Hawkeye Outage Monitor system: Ixia topic: VOO client: [<client> | FIS | Other] outage_type: [Node To Node | Real Service | Both | None] severity: 2 Fraud Monitor Description: Number of service affecting tasks related to Fraud alerts that have been created by the fraud-monitor . Labels: feature: Fraud Monitor system: MetTel Fraud Alerts topic: VAS severity: 3 trouble: [Possible Fraud | Request Rate Monitor Violation]","title":"Task Creations #"},{"location":"metrics-definitions/tasks_created/#task-creations","text":"Metric name: tasks_created Metric type: Counter Data store: Prometheus","title":"Task Creations"},{"location":"metrics-definitions/tasks_created/#service-outage-monitor","text":"Description: Number of service outage tasks related to VeloCloud edges that have been created by the service-outage-monitor . Labels: feature: Service Outage Monitor system: VeloCloud topic: VOO client: [<client> | FIS | Other] host: <host> outage_type: [Hard Down (no HA) | Hard Down (HA) | Soft Down (HA) | Link Down (no HA) | Link Down (HA)] severity: [2 | 3] has_digi: [True | False] has_byob: [True | False] link_types: [Wired | Wireless | Both | None]","title":"Service Outage Monitor"},{"location":"metrics-definitions/tasks_created/#service-affecting-monitor","text":"Description: Number of service affecting tasks related to VeloCloud edges that have been created by the service-affecting-monitor . Labels: feature: Service Affecting Monitor system: VeloCloud topic: VAS client: [<client> | FIS | Other] host: <host> severity: 3 trouble: [Latency | Packet Loss | Jitter | Bandwidth Over Utilization | Circuit Instability] has_byob: [True | False] link_types: [Wired | Wireless]","title":"Service Affecting Monitor"},{"location":"metrics-definitions/tasks_created/#intermapper-outage-monitor","text":"Description: Number of service outage tasks related to InterMapper devices that have been created by the intermapper-outage-monitor . Labels: feature: InterMapper Outage Monitor system: InterMapper topic: VOO severity: 2 event: <event> is_piab: [True | False]","title":"InterMapper Outage Monitor"},{"location":"metrics-definitions/tasks_created/#gateway-monitor","text":"Description: Number of ServiceNow incidents related to VeloCloud gateways that have been created by the gateway-monitor . Labels: feature: Gateway Monitor system: VeloCloud host: <host> trouble: [Offline | Tunnel Count]","title":"Gateway Monitor"},{"location":"metrics-definitions/tasks_created/#hawkeye-outage-monitor","text":"Description: Number of service outage tasks related to Ixia probes that have been created by the hawkeye-outage-monitor . Labels: feature: Hawkeye Outage Monitor system: Ixia topic: VOO client: [<client> | FIS | Other] outage_type: [Node To Node | Real Service | Both | None] severity: 2","title":"Hawkeye Outage Monitor"},{"location":"metrics-definitions/tasks_created/#fraud-monitor","text":"Description: Number of service affecting tasks related to Fraud alerts that have been created by the fraud-monitor . Labels: feature: Fraud Monitor system: MetTel Fraud Alerts topic: VAS severity: 3 trouble: [Possible Fraud | Request Rate Monitor Violation]","title":"Fraud Monitor"},{"location":"metrics-definitions/tasks_forwarded/","text":"Task Forwards Metric name: tasks_forwarded Metric type: Counter Data store: Prometheus Service Outage Monitor Description: Number of service outage tasks related to VeloCloud edges that have been forwarded by the service-outage-monitor . Labels: feature: Service Outage Monitor system: VeloCloud topic: VOO client: [<client> | FIS | Other] host: <host> outage_type: [Hard Down (no HA) | Hard Down (HA) | Soft Down (HA) | Link Down (no HA) | Link Down (HA)] severity: [2 | 3] has_digi: [True | False] has_byob: [True | False] link_types: [Wired | Wireless | Both | None] target_queue: [HNOC Investigate | ASR Investigate | Wireless Repair Intervention Needed] Service Affecting Monitor Description: Number of service affecting tasks related to VeloCloud edges that have been forwarded by the service-affecting-monitor . Labels: feature: Service Affecting Monitor system: VeloCloud topic: VAS client: [<client> | FIS | Other] host: <host> severity: 3 trouble: [Latency | Packet Loss | Jitter | Bandwidth Over Utilization | Circuit Instability] has_byob: [True | False] link_types: [Wired | Wireless] target_queue: [HNOC Investigate | ASR Investigate] InterMapper Outage Monitor Description: Number of service outage tasks related to InterMapper devices that have been forwarded by the intermapper-outage-monitor . Labels: feature: InterMapper Outage Monitor system: InterMapper topic: VOO severity: 2 event: <event> is_piab: [True | False] target_queue: [HNOC Investigate | IPA Investigate] Fraud Monitor Description: Number of service affecting tasks related to Fraud alerts that have been forwarded by the fraud-monitor . Labels: feature: Fraud Monitor system: MetTel Fraud Alerts topic: VAS severity: 3 trouble: [Possible Fraud | Request Rate Monitor Violation] target_queue: HNOC Investigate","title":"Task Forwards #"},{"location":"metrics-definitions/tasks_forwarded/#task-forwards","text":"Metric name: tasks_forwarded Metric type: Counter Data store: Prometheus","title":"Task Forwards"},{"location":"metrics-definitions/tasks_forwarded/#service-outage-monitor","text":"Description: Number of service outage tasks related to VeloCloud edges that have been forwarded by the service-outage-monitor . Labels: feature: Service Outage Monitor system: VeloCloud topic: VOO client: [<client> | FIS | Other] host: <host> outage_type: [Hard Down (no HA) | Hard Down (HA) | Soft Down (HA) | Link Down (no HA) | Link Down (HA)] severity: [2 | 3] has_digi: [True | False] has_byob: [True | False] link_types: [Wired | Wireless | Both | None] target_queue: [HNOC Investigate | ASR Investigate | Wireless Repair Intervention Needed]","title":"Service Outage Monitor"},{"location":"metrics-definitions/tasks_forwarded/#service-affecting-monitor","text":"Description: Number of service affecting tasks related to VeloCloud edges that have been forwarded by the service-affecting-monitor . Labels: feature: Service Affecting Monitor system: VeloCloud topic: VAS client: [<client> | FIS | Other] host: <host> severity: 3 trouble: [Latency | Packet Loss | Jitter | Bandwidth Over Utilization | Circuit Instability] has_byob: [True | False] link_types: [Wired | Wireless] target_queue: [HNOC Investigate | ASR Investigate]","title":"Service Affecting Monitor"},{"location":"metrics-definitions/tasks_forwarded/#intermapper-outage-monitor","text":"Description: Number of service outage tasks related to InterMapper devices that have been forwarded by the intermapper-outage-monitor . Labels: feature: InterMapper Outage Monitor system: InterMapper topic: VOO severity: 2 event: <event> is_piab: [True | False] target_queue: [HNOC Investigate | IPA Investigate]","title":"InterMapper Outage Monitor"},{"location":"metrics-definitions/tasks_forwarded/#fraud-monitor","text":"Description: Number of service affecting tasks related to Fraud alerts that have been forwarded by the fraud-monitor . Labels: feature: Fraud Monitor system: MetTel Fraud Alerts topic: VAS severity: 3 trouble: [Possible Fraud | Request Rate Monitor Violation] target_queue: HNOC Investigate","title":"Fraud Monitor"},{"location":"metrics-definitions/tasks_reopened/","text":"Task Re-Opens Metric name: tasks_reopened Metric type: Counter Data store: Prometheus Service Outage Monitor Description: Number of service outage tasks related to VeloCloud edges that have been re-opened by the service-outage-monitor . Labels: feature: Service Outage Monitor system: VeloCloud topic: VOO client: [<client> | FIS | Other] host: <host> outage_type: [Hard Down (no HA) | Hard Down (HA) | Soft Down (HA) | Link Down (no HA) | Link Down (HA)] severity: [2 | 3] has_digi: [True | False] has_byob: [True | False] link_types: [Wired | Wireless | Both | None] Service Affecting Monitor Description: Number of service affecting tasks related to VeloCloud edges that have been re-opened by the service-affecting-monitor . Labels: feature: Service Affecting Monitor system: VeloCloud topic: VAS client: [<client> | FIS | Other] host: <host> severity: 3 trouble: [Latency | Packet Loss | Jitter | Bandwidth Over Utilization | Circuit Instability] has_byob: [True | False] link_types: [Wired | Wireless] InterMapper Outage Monitor Description: Number of service outage tasks related to InterMapper devices that have been re-opened by the intermapper-outage-monitor . Labels: feature: InterMapper Outage Monitor system: InterMapper topic: VOO severity: 2 event: <event> is_piab: [True | False] Gateway Monitor Description: Number of ServiceNow incidents related to VeloCloud gateways that have been re-opened by the gateway-monitor . Labels: feature: Gateway Monitor system: VeloCloud host: <host> trouble: [Offline | Tunnel Count] Hawkeye Outage Monitor Description: Number of service outage tasks related to Ixia probes that have been re-opened by the hawkeye-outage-monitor . Labels: feature: Hawkeye Outage Monitor system: Ixia topic: VOO client: [<client> | FIS | Other] outage_type: [Node To Node | Real Service | Both | None] severity: 2 Fraud Monitor Description: Number of service affecting tasks related to Fraud alerts that have been re-opened by the fraud-monitor . Labels: feature: Fraud Monitor system: MetTel Fraud Alerts topic: VAS severity: 3 trouble: [Possible Fraud | Request Rate Monitor Violation]","title":"Task Re-Opens #"},{"location":"metrics-definitions/tasks_reopened/#task-re-opens","text":"Metric name: tasks_reopened Metric type: Counter Data store: Prometheus","title":"Task Re-Opens"},{"location":"metrics-definitions/tasks_reopened/#service-outage-monitor","text":"Description: Number of service outage tasks related to VeloCloud edges that have been re-opened by the service-outage-monitor . Labels: feature: Service Outage Monitor system: VeloCloud topic: VOO client: [<client> | FIS | Other] host: <host> outage_type: [Hard Down (no HA) | Hard Down (HA) | Soft Down (HA) | Link Down (no HA) | Link Down (HA)] severity: [2 | 3] has_digi: [True | False] has_byob: [True | False] link_types: [Wired | Wireless | Both | None]","title":"Service Outage Monitor"},{"location":"metrics-definitions/tasks_reopened/#service-affecting-monitor","text":"Description: Number of service affecting tasks related to VeloCloud edges that have been re-opened by the service-affecting-monitor . Labels: feature: Service Affecting Monitor system: VeloCloud topic: VAS client: [<client> | FIS | Other] host: <host> severity: 3 trouble: [Latency | Packet Loss | Jitter | Bandwidth Over Utilization | Circuit Instability] has_byob: [True | False] link_types: [Wired | Wireless]","title":"Service Affecting Monitor"},{"location":"metrics-definitions/tasks_reopened/#intermapper-outage-monitor","text":"Description: Number of service outage tasks related to InterMapper devices that have been re-opened by the intermapper-outage-monitor . Labels: feature: InterMapper Outage Monitor system: InterMapper topic: VOO severity: 2 event: <event> is_piab: [True | False]","title":"InterMapper Outage Monitor"},{"location":"metrics-definitions/tasks_reopened/#gateway-monitor","text":"Description: Number of ServiceNow incidents related to VeloCloud gateways that have been re-opened by the gateway-monitor . Labels: feature: Gateway Monitor system: VeloCloud host: <host> trouble: [Offline | Tunnel Count]","title":"Gateway Monitor"},{"location":"metrics-definitions/tasks_reopened/#hawkeye-outage-monitor","text":"Description: Number of service outage tasks related to Ixia probes that have been re-opened by the hawkeye-outage-monitor . Labels: feature: Hawkeye Outage Monitor system: Ixia topic: VOO client: [<client> | FIS | Other] outage_type: [Node To Node | Real Service | Both | None] severity: 2","title":"Hawkeye Outage Monitor"},{"location":"metrics-definitions/tasks_reopened/#fraud-monitor","text":"Description: Number of service affecting tasks related to Fraud alerts that have been re-opened by the fraud-monitor . Labels: feature: Fraud Monitor system: MetTel Fraud Alerts topic: VAS severity: 3 trouble: [Possible Fraud | Request Rate Monitor Violation]","title":"Fraud Monitor"},{"location":"metrics-definitions/velocloud_fetcher_to_kafka_messages_attempts/","text":"VeloCloud fetcher attempts to kafka Metric name: velocloud_fetcher_to_kafka_messages_attempts Metric type: Counter Data store: Prometheus VeloCloud - Attempts total messages to Kafka Description: Number of attempts sending messages to kafka. Labels: schema_name: <schema_name> environment: [develop | master]","title":"VeloCloud fetcher attempts to kafka #"},{"location":"metrics-definitions/velocloud_fetcher_to_kafka_messages_attempts/#velocloud-fetcher-attempts-to-kafka","text":"Metric name: velocloud_fetcher_to_kafka_messages_attempts Metric type: Counter Data store: Prometheus","title":"VeloCloud fetcher attempts to kafka"},{"location":"metrics-definitions/velocloud_fetcher_to_kafka_messages_attempts/#velocloud-attempts-total-messages-to-kafka","text":"Description: Number of attempts sending messages to kafka. Labels: schema_name: <schema_name> environment: [develop | master]","title":"VeloCloud - Attempts total messages to Kafka"},{"location":"metrics-definitions/velocloud_fetcher_to_kafka_messages_status/","text":"VeloCloud fetcher errors when pushing to kafka Metric name: velocloud_fetcher_to_kafka_messages_status Metric type: Counter Data store: Prometheus VeloCloud - Status of Messages sent to Kafka Description: Number of OK calls or Errors when pushing data to the kafka server. Labels: schema_name: <schema_name> status: [OK | ERROR] environment: [develop | master]","title":"VeloCloud fetcher errors when pushing to kafka #"},{"location":"metrics-definitions/velocloud_fetcher_to_kafka_messages_status/#velocloud-fetcher-errors-when-pushing-to-kafka","text":"Metric name: velocloud_fetcher_to_kafka_messages_status Metric type: Counter Data store: Prometheus","title":"VeloCloud fetcher errors when pushing to kafka"},{"location":"metrics-definitions/velocloud_fetcher_to_kafka_messages_status/#velocloud-status-of-messages-sent-to-kafka","text":"Description: Number of OK calls or Errors when pushing data to the kafka server. Labels: schema_name: <schema_name> status: [OK | ERROR] environment: [develop | master]","title":"VeloCloud - Status of Messages sent to Kafka"},{"location":"parameters/parameters/","text":"Parameter Store parameters Name Description Link to AWS /automation-engine/common/autoresolve-day-end-hour Defines the hour at which the day ends and the night starts for dynamic auto-resolution times https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/autoresolve-day-end-hour/description?region=us-east-1&tab=Table /automation-engine/common/autoresolve-day-start-hour Defines the hour at which the night ends and the day starts for dynamic auto-resolution times https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/autoresolve-day-start-hour/description?region=us-east-1&tab=Table /automation-engine/common/bruin-ipa-system-username Name of the user that performs operations in Bruin on behalf of the IPA system https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/bruin-ipa-system-username/description?region=us-east-1&tab=Table /automation-engine/common/customer-cache/refresh-check-interval Defines how often the next refresh flag is checked to decide if it's time to refresh the cache or not https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/customer-cache/refresh-check-interval/description?region=us-east-1&tab=Table /automation-engine/common/customer-cache/refresh-job-interval Defines how often the cache is refreshed https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/customer-cache/refresh-job-interval/description?region=us-east-1&tab=Table /automation-engine/common/customer-cache/whitelisted-management-statuses Management statuses that should be considered in the caching process https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/customer-cache/whitelisted-management-statuses/description?region=us-east-1&tab=Table /automation-engine/common/digi-bridge/digi-headers List of possible headers included in all DiGi links https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/digi-bridge/digi-headers/description?region=us-east-1&tab=Table /automation-engine/common/digi-bridge/digi-reboot-api-token-ttl Auth tokens TTL https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/digi-bridge/digi-reboot-api-token-ttl/description?region=us-east-1&tab=Table /automation-engine/common/digi-reboot-report/logs-lookup-interval Defines how much time back to look for DiGi Reboot logs https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/digi-reboot-report/logs-lookup-interval/description?region=us-east-1&tab=Table /automation-engine/common/digi-reboot-report/report-job-interval Defines how often the report is built and sent https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/digi-reboot-report/report-job-interval/description?region=us-east-1&tab=Table /automation-engine/common/dri-bridge/base-url Base URL for DRI API https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/dri-bridge/base-url/description?region=us-east-1&tab=Table /automation-engine/common/dri-bridge/dri-data-redis-ttl Defines how much time the data retrieved from DRI for a specific device can be stored and served from Redis https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/dri-bridge/dri-data-redis-ttl/description?region=us-east-1&tab=Table /automation-engine/common/dri-bridge/password Password to log into DRI API https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/dri-bridge/password/description?region=us-east-1&tab=Table /automation-engine/common/dri-bridge/username Username to log into DRI API https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/dri-bridge/username/description?region=us-east-1&tab=Table /automation-engine/common/email-tagger-monitor/api-endpoint-prefix API server endpoint prefix for incoming requests https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/email-tagger-monitor/api-endpoint-prefix/description?region=us-east-1&tab=Table /automation-engine/common/email-tagger-monitor/max-concurrent-emails Defines how many simultaneous emails are processed https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/email-tagger-monitor/max-concurrent-emails/description?region=us-east-1&tab=Table /automation-engine/common/email-tagger-monitor/new-emails-job-interval Defines how often new emails received from Bruin are processed https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/email-tagger-monitor/new-emails-job-interval/description?region=us-east-1&tab=Table /automation-engine/common/email-tagger-monitor/new-tickets-job-interval Defines how often new tickets received from Bruin are sent to the KRE to train the AI model https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/email-tagger-monitor/new-tickets-job-interval/description?region=us-east-1&tab=Table /automation-engine/common/email-tagger-monitor/reply-email-ttl Reply emails time to live (in milliseconds) when storing them to Redis https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/email-tagger-monitor/reply-email-ttl/description?region=us-east-1&tab=Table /automation-engine/common/fraud-monitor/alerts-lookup-days How many days to look back for Fraud alerts in the desired e-mail inbox https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/fraud-monitor/alerts-lookup-days/description?region=us-east-1&tab=Table /automation-engine/common/fraud-monitor/default-client-info-for-did-without-inventory Default client info used when the DID device in the Fraud alert does not have an inventory assigned in Bruin https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/fraud-monitor/default-client-info-for-did-without-inventory/description?region=us-east-1&tab=Table /automation-engine/common/fraud-monitor/default-contact-for-new-tickets Default contact details used when a Fraud is reported as a Service Affecting ticket https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/fraud-monitor/default-contact-for-new-tickets/description?region=us-east-1&tab=Table /automation-engine/common/fraud-monitor/monitoring-job-interval Defines how often Fraud e-mails are checked to report them as Service Affecting tickets https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/fraud-monitor/monitoring-job-interval/description?region=us-east-1&tab=Table /automation-engine/common/fraud-monitor/observed-inbox-senders Senders addresses whose e-mail messages represent Fraud alerts https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/fraud-monitor/observed-inbox-senders/description?region=us-east-1&tab=Table /automation-engine/common/gateway-monitor/first-gateway-lookup-interval Lookup interval for the first time gateway statuses are retrieved https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/gateway-monitor/first-gateway-lookup-interval/description?region=us-east-1&tab=Table /automation-engine/common/gateway-monitor/monitoring-job-interval Defines how often gateways are checked to find and report incidents https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/gateway-monitor/monitoring-job-interval/description?region=us-east-1&tab=Table /automation-engine/common/gateway-monitor/second-gateway-lookup-interval Lookup interval for the second time gateway statuses are retrieved https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/gateway-monitor/second-gateway-lookup-interval/description?region=us-east-1&tab=Table /automation-engine/common/gateway-monitor/blacklisted-gateways List of gateway names that are excluded from gateway monitoring https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/gateway-monitor/blacklisted-gateways/description?region=us-east-1&tab=Table /automation-engine/common/gateway-monitor/offline-trouble-enabled Enable or disable the offline trouble check https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/gateway-monitor/offline-trouble-enabled/description?region=us-east-1&tab=Table /automation-engine/common/gateway-monitor/tunnel-count-threshold Threshold for tunnel count troubles https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/gateway-monitor/tunnel-count-threshold/description?region=us-east-1&tab=Table /automation-engine/common/gateway-monitor/tunnel-count-trouble-enabled Enable or disable the tunnel count trouble check https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/gateway-monitor/tunnel-count-trouble-enabled/description?region=us-east-1&tab=Table /automation-engine/common/hawkeye-affecting-monitor/monitored-product-category Bruin's product category under monitoring https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/hawkeye-affecting-monitor/monitored-product-category/description?region=us-east-1&tab=Table /automation-engine/common/hawkeye-affecting-monitor/monitoring-job-interval Defines how often devices are checked to find and report issues https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/hawkeye-affecting-monitor/monitoring-job-interval/description?region=us-east-1&tab=Table /automation-engine/common/hawkeye-affecting-monitor/probes-tests-results-lookup-interval Defines how much time back to look for probes' tests results https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/hawkeye-affecting-monitor/probes-tests-results-lookup-interval/description?region=us-east-1&tab=Table /automation-engine/common/hawkeye-bridge/base-url Base URL to access Hawkeye API https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/hawkeye-bridge/base-url/description?region=us-east-1&tab=Table /automation-engine/common/hawkeye-bridge/client-password Client password to log into Hawkeye API https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/hawkeye-bridge/client-password/description?region=us-east-1&tab=Table /automation-engine/common/hawkeye-bridge/client-username Client username to log into Hawkeye API https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/hawkeye-bridge/client-username/description?region=us-east-1&tab=Table /automation-engine/common/hawkeye-customer-cache/refresh-job-interval Defines how often the cache is refreshed https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/hawkeye-customer-cache/refresh-job-interval/description?region=us-east-1&tab=Table /automation-engine/common/hawkeye-customer-cache/whitelisted-management-statuses Management statuses that should be considered in the caching process https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/hawkeye-customer-cache/whitelisted-management-statuses/description?region=us-east-1&tab=Table /automation-engine/common/hawkeye-outage-monitor/grace-period-to-autoresolve-after-last-documented-outage Defines for how long a ticket can be auto-resolved after the last documented outage https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/hawkeye-outage-monitor/grace-period-to-autoresolve-after-last-documented-outage/description?region=us-east-1&tab=Table /automation-engine/common/hawkeye-outage-monitor/monitored-product-category Bruin's product category under monitoring https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/hawkeye-outage-monitor/monitored-product-category/description?region=us-east-1&tab=Table /automation-engine/common/hawkeye-outage-monitor/monitoring-job-interval Defines how often devices are checked to find and report issues https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/hawkeye-outage-monitor/monitoring-job-interval/description?region=us-east-1&tab=Table /automation-engine/common/hawkeye-outage-monitor/quarantine-for-devices-in-outage Defines how much time to wait before checking if a particular device is still in outage state https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/hawkeye-outage-monitor/quarantine-for-devices-in-outage/description?region=us-east-1&tab=Table /automation-engine/common/intermapper-outage-monitor/dri-parameters-for-piab-notes Parameters to fetch from DRI to include them in InterMapper notes for PIAB devices https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/intermapper-outage-monitor/dri-parameters-for-piab-notes/description?region=us-east-1&tab=Table /automation-engine/common/intermapper-outage-monitor/grace-period-to-autoresolve-after-last-documented-outage-day-time Defines for how long a ticket can be auto-resolved after the last documented trouble during the day https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/intermapper-outage-monitor/grace-period-to-autoresolve-after-last-documented-outage-day-time/description?region=us-east-1&tab=Table /automation-engine/common/intermapper-outage-monitor/grace-period-to-autoresolve-after-last-documented-outage-night-time Defines for how long a ticket can be auto-resolved after the last documented trouble during the night https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/intermapper-outage-monitor/grace-period-to-autoresolve-after-last-documented-outage-night-time/description?region=us-east-1&tab=Table /automation-engine/common/intermapper-outage-monitor/max-autoresolves-per-ticket Defines how many times a ticket can be auto-resolved https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/intermapper-outage-monitor/max-autoresolves-per-ticket/description?region=us-east-1&tab=Table /automation-engine/common/intermapper-outage-monitor/max-concurrent-email-batches Defines how many simultaneous email batches related to the same InterMapper asset are processed https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/intermapper-outage-monitor/max-concurrent-email-batches/description?region=us-east-1&tab=Table /automation-engine/common/intermapper-outage-monitor/monitor-piab-devices Enable or disable monitoring of PIAB devices https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/intermapper-outage-monitor/monitor-piab-devices/description?region=us-east-1&tab=Table /automation-engine/common/intermapper-outage-monitor/monitored-up-events InterMapper events considered as UP https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/intermapper-outage-monitor/monitored-up-events/description?region=us-east-1&tab=Table /automation-engine/common/intermapper-outage-monitor/monitoring-job-interval Defines how often InterMapper events are checked to find and report issues https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/intermapper-outage-monitor/monitoring-job-interval/description?region=us-east-1&tab=Table /automation-engine/common/intermapper-outage-monitor/observed-inbox-senders Senders addresses whose e-mail messages represent InterMapper events https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/intermapper-outage-monitor/observed-inbox-senders/description?region=us-east-1&tab=Table /automation-engine/common/timezone Timezone used for periodic jobs, timestamps, etc https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/timezone/description?region=us-east-1&tab=Table /automation-engine/common/intermapper-outage-monitor/events-lookup-days How many days to look back for InterMapper events in the desired e-mail inbox https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/intermapper-outage-monitor/events-lookup-days/description?region=us-east-1&tab=Table /automation-engine/common/intermapper-outage-monitor/max-emails-to-retrieve How many emails to retrieve at most for InterMapper events in the desired e-mail inbox https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/intermapper-outage-monitor/max-emails-to-retrieve/description?region=us-east-1&tab=Table /automation-engine/common/intermapper-outage-monitor/monitored-down-events InterMapper events considered as DOWN https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/intermapper-outage-monitor/monitored-down-events/description?region=us-east-1&tab=Table /automation-engine/common/intermapper-outage-monitor/whitelisted-product-categories-for-autoresolve Defines which Bruin product categories are taken into account when auto-resolving tickets https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/intermapper-outage-monitor/whitelisted-product-categories-for-autoresolve/description?region=us-east-1&tab=Table /automation-engine/common/link-labels-blacklisted-from-asr-forwards List of link labels that are excluded from forwards to the ASR queue https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/link-labels-blacklisted-from-asr-forwards/description?region=us-east-1&tab=Table /automation-engine/common/link-labels-blacklisted-from-hnoc-forwards List of link labels that are excluded from forwards to the HNOC queue https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/link-labels-blacklisted-from-hnoc-forwards/description?region=us-east-1&tab=Table /automation-engine/common/lumin-billing-report/access-token Access token for Lumin's Billing API https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/lumin-billing-report/access-token/description?region=us-east-1&tab=Table /automation-engine/common/lumin-billing-report/customer-name Name of the customer for which the Billing Report will be generated https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/lumin-billing-report/customer-name/description?region=us-east-1&tab=Table /automation-engine/common/lumin-billing-report/email-account-for-message-delivery-password Email account used to send messages to other accounts (password) https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/lumin-billing-report/email-account-for-message-delivery-password/description?region=us-east-1&tab=Table /automation-engine/common/lumin-billing-report/lumin-billing-api-base-url Base URL for Lumin's Billing API https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/lumin-billing-report/lumin-billing-api-base-url/description?region=us-east-1&tab=Table /automation-engine/common/lumin-billing-report/recipient Email address to send the report to https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/lumin-billing-report/recipient/description?region=us-east-1&tab=Table /automation-engine/common/metrics/relevant-clients List of relevant client names to use on Prometheus metrics labels https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/metrics/relevant-clients/description?region=us-east-1&tab=Table /automation-engine/common/nats/endpoint-url Nats endpoint URL for messaging https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/nats/endpoint-url/description?region=us-east-1&tab=Table /automation-engine/common/email-bridge/email-account-for-message-delivery-password Email account used to send messages to other accounts (password) https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/email-bridge/email-account-for-message-delivery-password/description?region=us-east-1&tab=Table /automation-engine/common/email-bridge/email-account-for-message-delivery-username Email account used to send messages to other accounts (username) https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/email-bridge/email-account-for-message-delivery-username/description?region=us-east-1&tab=Table /automation-engine/common/papertrail/host Papertrail host to send logs https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/papertrail/host/description?region=us-east-1&tab=Table /automation-engine/common/papertrail/port Papertrail port to send logs https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/papertrail/port/description?region=us-east-1&tab=Table /automation-engine/common/repair-tickets-monitor/max-concurrent-closed-tickets-for-feedback Defines how many simultaneous new closed tickets are sent to the KRE to train the AI model https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/repair-tickets-monitor/max-concurrent-closed-tickets-for-feedback/description?region=us-east-1&tab=Table /automation-engine/common/repair-tickets-monitor/max-concurrent-created-tickets-for-feedback Defines how many simultaneous new created tickets are sent to the KRE to train the AI model https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/repair-tickets-monitor/max-concurrent-created-tickets-for-feedback/description?region=us-east-1&tab=Table /automation-engine/common/repair-tickets-monitor/max-concurrent-emails-for-monitoring Defines how many simultaneous tagged emails are processed https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/repair-tickets-monitor/max-concurrent-emails-for-monitoring/description?region=us-east-1&tab=Table /automation-engine/common/repair-tickets-monitor/new-closed-tickets-feedback-job-interval Defines how often new closed tickets fetched from Bruin are sent to the KRE to train the AI model https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/repair-tickets-monitor/new-closed-tickets-feedback-job-interval/description?region=us-east-1&tab=Table /automation-engine/common/repair-tickets-monitor/new-created-tickets-feedback-job-interval Defines how often new created tickets fetched from Bruin are sent to the KRE to train the AI model https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/repair-tickets-monitor/new-created-tickets-feedback-job-interval/description?region=us-east-1&tab=Table /automation-engine/common/repair-tickets-monitor/rta-monitor-job-interval Defines how often new emails tagged by the E-mail Tagger are processed https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/repair-tickets-monitor/rta-monitor-job-interval/description?region=us-east-1&tab=Table /automation-engine/common/repair-tickets-monitor/tag-ids-mapping Mapping of tag names and their corresponding numeric ID, as defined in the AI model https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/repair-tickets-monitor/tag-ids-mapping/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/daily-bandwidth-report/enabled-customers-per-host Mapping of VeloCloud hosts and Bruin customer IDs for whom this report will trigger periodically https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/daily-bandwidth-report/enabled-customers-per-host/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/daily-bandwidth-report/execution-cron-expression Cron expression that determines when to build and deliver this report https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/daily-bandwidth-report/execution-cron-expression/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/daily-bandwidth-report/lookup-interval Defines how much time back to look for bandwidth metrics and Bruin tickets https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/daily-bandwidth-report/lookup-interval/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/daily-bandwidth-report/recipients List of recipients that will get these reports https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/daily-bandwidth-report/recipients/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/monitor/autoresolve-lookup-interval Defines how much time back to look for all kinds of metrics while running auto-resolves https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/monitor/autoresolve-lookup-interval/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/monitor/bandwidth-over-utilization-monitoring-lookup-interval Defines how much time back to look for Bandwidth metrics in Bandwidth Over Utilization checks https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/monitor/bandwidth-over-utilization-monitoring-lookup-interval/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/monitor/bandwidth-over-utilization-monitoring-threshold Threshold for Bandwidth Over Utilization troubles https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/monitor/bandwidth-over-utilization-monitoring-threshold/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/monitor/circuit-instability-autoresolve-threshold Max DOWN events allowed in Circuit Instability checks while auto-resolving tickets https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/monitor/circuit-instability-autoresolve-threshold/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/monitor/circuit-instability-monitoring-lookup-interval Defines how much time back to look for DOWN events in Circuit Instability checks https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/monitor/circuit-instability-monitoring-lookup-interval/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/monitor/circuit-instability-monitoring-threshold Threshold for Circuit Instability troubles https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/monitor/circuit-instability-monitoring-threshold/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/monitor/customers-to-always-use-default-contact-info [Monitoring] List Bruin customers that should always use the default contact info https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/monitor/customers-to-always-use-default-contact-info/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/monitor/customers-with-bandwidth-over-utilization-monitoring List of client IDs for which Bandwidth Over Utilization checks are enabled https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/monitor/customers-with-bandwidth-over-utilization-monitoring/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/monitor/default-contact-info-per-customer Mapping of VeloCloud hosts, Bruin customers and default contact info https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/monitor/default-contact-info-per-customer/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/monitor/grace-period-to-autoresolve-after-last-documented-trouble-day-time Defines for how long a ticket can be auto-resolved after the last documented trouble during the day https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/monitor/grace-period-to-autoresolve-after-last-documented-trouble-day-time/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/monitor/grace-period-to-autoresolve-after-last-documented-trouble-night-time Defines for how long a ticket can be auto-resolved after the last documented trouble during the night https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/monitor/grace-period-to-autoresolve-after-last-documented-trouble-night-time/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/monitor/jitter-monitoring-lookup-interval Defines how much time back to look for Jitter metrics in Jitter checks https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/monitor/jitter-monitoring-lookup-interval/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/monitor/jitter-monitoring-threshold Threshold for Jitter troubles https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/monitor/jitter-monitoring-threshold/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/monitor/latency-monitoring-lookup-interval Defines how much time back to look for Latency metrics in Latency checks https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/monitor/latency-monitoring-lookup-interval/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/monitor/latency-monitoring-threshold Threshold for Latency troubles https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/monitor/latency-monitoring-threshold/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/monitor/max-autoresolves-per-ticket Defines how many times a ticket can be auto-resolved https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/monitor/max-autoresolves-per-ticket/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/monitor/monitoring-job-interval Defines how often devices are checked to find and report issues https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/monitor/monitoring-job-interval/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/monitor/packet-loss-monitoring-lookup-interval Defines how much time back to look for Packet Loss metrics in Packet Loss checks https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/monitor/packet-loss-monitoring-lookup-interval/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/monitor/packet-loss-monitoring-threshold Threshold for Packet Loss troubles https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/monitor/packet-loss-monitoring-threshold/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/monitor/wait-time-before-sending-new-milestone-reminder How long we need to wait for the milestone reminder email to be sent https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/monitor/wait-time-before-sending-new-milestone-reminder/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/monitored-product-category Bruin's product category under monitoring https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/monitored-product-category/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/reoccurring-trouble-report/recipients-per-host-and-customer Mapping of VeloCloud hosts, Bruin customer IDs and recipients of these reports https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/reoccurring-trouble-report/recipients-per-host-and-customer/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/reoccurring-trouble-report/reported-troubles Troubles that will be reported https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/reoccurring-trouble-report/reported-troubles/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/reoccurring-trouble-report/default-contacts List of default contacts to whom this report will always be delivered to https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/reoccurring-trouble-report/default-contacts/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/reoccurring-trouble-report/execution-cron-expression Cron expression that determines when to build and deliver this report https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/reoccurring-trouble-report/execution-cron-expression/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/reoccurring-trouble-report/reoccurring-trouble-tickets-threshold Number of different tickets a trouble must appear in for a particular edge and interface to include it in the report https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/reoccurring-trouble-report/reoccurring-trouble-tickets-threshold/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/reoccurring-trouble-report/tickets-lookup-interval Defines how much time back to look for Bruin tickets https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/reoccurring-trouble-report/tickets-lookup-interval/description?region=us-east-1&tab=Table /automation-engine/common/service-outage/monitor/business-grade-link-labels List of labels that define a link as business grade https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-outage/monitor/business-grade-link-labels/description?region=us-east-1&tab=Table /automation-engine/common/service-outage/monitor/grace-period-before-attempting-new-digi-reboots Defines for how long the monitor will wait before attempting a new DiGi Reboot on an edge https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-outage/monitor/grace-period-before-attempting-new-digi-reboots/description?region=us-east-1&tab=Table /automation-engine/common/service-outage/monitor/grace-period-to-autoresolve-after-last-documented-outage-day-time Defines for how long a ticket can be auto-resolved after the last documented trouble during the day https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-outage/monitor/grace-period-to-autoresolve-after-last-documented-outage-day-time/description?region=us-east-1&tab=Table /automation-engine/common/service-outage/monitor/grace-period-to-autoresolve-after-last-documented-outage-night-time Defines for how long a ticket can be auto-resolved after the last documented trouble during the night https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-outage/monitor/grace-period-to-autoresolve-after-last-documented-outage-night-time/description?region=us-east-1&tab=Table /automation-engine/common/service-outage/monitor/max-autoresolves-per-ticket Defines how many times a ticket can be auto-resolved https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-outage/monitor/max-autoresolves-per-ticket/description?region=us-east-1&tab=Table /automation-engine/common/service-outage/monitor/missing-edges-from-cache-report-recipient E-mail address that will receive a tiny report showing which edges from VeloCloud responses are not in the cache of customers https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-outage/monitor/missing-edges-from-cache-report-recipient/description?region=us-east-1&tab=Table /automation-engine/common/service-outage/monitor/monitoring-job-interval Defines how often devices are checked to find and report issues https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-outage/monitor/monitoring-job-interval/description?region=us-east-1&tab=Table /automation-engine/common/service-outage/monitor/quarantine-for-edges-in-ha-hard-down-outage Defines how much time to wait before re-checking an edge currently in Hard Down (HA) state https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-outage/monitor/quarantine-for-edges-in-ha-hard-down-outage/description?region=us-east-1&tab=Table /automation-engine/common/service-outage/monitor/quarantine-for-edges-in-ha-link-down-outage Defines how much time to wait before re-checking an edge currently in Link Down (HA) state https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-outage/monitor/quarantine-for-edges-in-ha-link-down-outage/description?region=us-east-1&tab=Table /automation-engine/common/service-outage/monitor/quarantine-for-edges-in-ha-soft-down-outage Defines how much time to wait before re-checking an edge currently in Soft Down (HA) state https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-outage/monitor/quarantine-for-edges-in-ha-soft-down-outage/description?region=us-east-1&tab=Table /automation-engine/common/service-outage/monitor/quarantine-for-edges-in-hard-down-outage Defines how much time to wait before re-checking an edge currently in Hard Down state https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-outage/monitor/quarantine-for-edges-in-hard-down-outage/description?region=us-east-1&tab=Table /automation-engine/common/service-outage/monitor/quarantine-for-edges-in-link-down-outage Defines how much time to wait before re-checking an edge currently in Link Down state https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-outage/monitor/quarantine-for-edges-in-link-down-outage/description?region=us-east-1&tab=Table /automation-engine/common/service-outage/monitor/severity-for-edge-down-outages Severity level for Edge Down outages https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-outage/monitor/severity-for-edge-down-outages/description?region=us-east-1&tab=Table /automation-engine/common/service-outage/monitor/severity-for-link-down-outages Severity level for Link Down outages https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-outage/monitor/severity-for-link-down-outages/description?region=us-east-1&tab=Table /automation-engine/common/service-outage/monitor/wait-time-before-sending-new-milestone-reminder How long we need to wait for the milestone reminder email to be sent https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-outage/monitor/wait-time-before-sending-new-milestone-reminder/description?region=us-east-1&tab=Table /automation-engine/common/service-outage/monitored-product-category Bruin's product category under monitoring https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-outage/monitored-product-category/description?region=us-east-1&tab=Table /automation-engine/common/service-outage/triage/last-note-interval Defines how long the last note on a ticket is considered recent https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-outage/triage/last-note-interval/description?region=us-east-1&tab=Table /automation-engine/common/service-outage/triage/max-events-per-event-note Defines how many events will be included in events notes https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-outage/triage/max-events-per-event-note/description?region=us-east-1&tab=Table /automation-engine/common/service-outage/triage/monitoring-job-interval Defines how often tickets are checked to see if it needs an initial triage or events note https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-outage/triage/monitoring-job-interval/description?region=us-east-1&tab=Table /automation-engine/common/tnba-feedback/feedback-job-interval Defines how often tickets are pulled from Bruin and sent to the KRE to train the predictive model https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/tnba-feedback/feedback-job-interval/description?region=us-east-1&tab=Table /automation-engine/common/tnba-feedback/grace-period-before-resending-tickets Defines for how long a ticket needs to wait before being re-sent to the KRE https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/tnba-feedback/grace-period-before-resending-tickets/description?region=us-east-1&tab=Table /automation-engine/common/tnba-feedback/monitored-product-category Bruin's product category under monitoring https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/tnba-feedback/monitored-product-category/description?region=us-east-1&tab=Table /automation-engine/common/tnba-monitor/grace-period-before-appending-new-tnba-notes Defines for how long a ticket needs to wait since it was opened before appending a new TNBA note https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/tnba-monitor/grace-period-before-appending-new-tnba-notes/description?region=us-east-1&tab=Table /automation-engine/common/tnba-monitor/grace-period-before-monitoring-tickets-based-on-last-documented-outage Defines for how long a Service Outage ticket needs to wait after the last documented outage to get a new TNBA note appended https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/tnba-monitor/grace-period-before-monitoring-tickets-based-on-last-documented-outage/description?region=us-east-1&tab=Table /automation-engine/common/tnba-monitor/min-required-confidence-for-request-and-repair-completed-predictions Defines the minimum confidence level required to consider a Request Completed / Repair Completed prediction accurate in TNBA auto-resolves https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/tnba-monitor/min-required-confidence-for-request-and-repair-completed-predictions/description?region=us-east-1&tab=Table /automation-engine/common/tnba-monitor/monitored-product-category Bruin's product category under monitoring https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/tnba-monitor/monitored-product-category/description?region=us-east-1&tab=Table /automation-engine/common/tnba-monitor/monitoring-job-interval Defines how often tickets are checked to see if they need a new TNBA note https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/tnba-monitor/monitoring-job-interval/description?region=us-east-1&tab=Table /automation-engine/common/umbrella-hosts VeloCloud hosts that act as an umbrella for all clients hosted on them https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/umbrella-hosts/description?region=us-east-1&tab=Table /automation-engine/dev/bruin-bridge/base-url Base URL for Bruin's DEV API https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/bruin-bridge/base-url/description?region=us-east-1&tab=Table /automation-engine/dev/bruin-bridge/client-id Client ID credential to authenticate against Bruin's DEV API https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/bruin-bridge/client-id/description?region=us-east-1&tab=Table /automation-engine/dev/bruin-bridge/client-secret Client secret credential to authenticate against Bruin's DEV API https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/bruin-bridge/client-secret/description?region=us-east-1&tab=Table /automation-engine/dev/bruin-bridge/login-url Login URL for Bruin's DEV API https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/bruin-bridge/login-url/description?region=us-east-1&tab=Table /automation-engine/dev/bruin-bridge/test-base-url Base URL for Bruin's TEST API https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/bruin-bridge/test-base-url/description?region=us-east-1&tab=Table /automation-engine/dev/bruin-bridge/test-client-id Client ID credential to authenticate against Bruin's TEST API https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/bruin-bridge/test-client-id/description?region=us-east-1&tab=Table /automation-engine/dev/bruin-bridge/test-client-secret Client secret credential to authenticate against Bruin's TEST API https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/bruin-bridge/test-client-secret/description?region=us-east-1&tab=Table /automation-engine/dev/bruin-bridge/test-login-url Login URL for Bruin's TEST API https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/bruin-bridge/test-login-url/description?region=us-east-1&tab=Table /automation-engine/dev/customer-cache/blacklisted-clients-with-pending-status Client IDs whose edges have Pending management status that should be ignored in the caching process https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/customer-cache/blacklisted-clients-with-pending-status/description?region=us-east-1&tab=Table /automation-engine/dev/customer-cache/blacklisted-edges VeloCloud edges that should be ignored in the caching process https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/customer-cache/blacklisted-edges/description?region=us-east-1&tab=Table /automation-engine/dev/customer-cache/duplicate-inventories-recipient E-mail address that will get e-mails with a relation of service numbers that have multiple Bruin inventories https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/customer-cache/duplicate-inventories-recipient/description?region=us-east-1&tab=Table /automation-engine/dev/customer-cache/velocloud-hosts VeloCloud hosts whose edges will be stored to the cache https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/customer-cache/velocloud-hosts/description?region=us-east-1&tab=Table /automation-engine/dev/digi-bridge/digi-reboot-api-base-url Base URL for Digi API https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/digi-bridge/digi-reboot-api-base-url/description?region=us-east-1&tab=Table /automation-engine/dev/digi-bridge/digi-reboot-api-client-id Client ID credentials for Digi API https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/digi-bridge/digi-reboot-api-client-id/description?region=us-east-1&tab=Table /automation-engine/dev/digi-bridge/digi-reboot-api-client-secret Client Secret credentials for Digi API https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/digi-bridge/digi-reboot-api-client-secret/description?region=us-east-1&tab=Table /automation-engine/dev/digi-reboot-report/report-recipient Email address to send the report to https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/digi-reboot-report/report-recipient/description?region=us-east-1&tab=Table /automation-engine/dev/email-tagger-kre-bridge/kre-base-url Base URL for E-mail Tagger's KRE https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/email-tagger-kre-bridge/kre-base-url/description?region=us-east-1&tab=Table /automation-engine/dev/email-tagger-monitor/api-request-key API request key for incoming requests https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/email-tagger-monitor/api-request-key/description?region=us-east-1&tab=Table /automation-engine/dev/email-tagger-monitor/api-request-signature-secret-key API signature secret key for incoming requests https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/email-tagger-monitor/api-request-signature-secret-key/description?region=us-east-1&tab=Table /automation-engine/dev/external-secrets/iam-role-arn The ARN of the AWS IAM role necessary to manage parameter store and secret manager https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/external-secrets/iam-role-arn/description?region=us-east-1&tab=Table /automation-engine/dev/fraud-monitor/observed-inbox-email-address E-mail account that receives Fraud e-mails for later analysis https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/fraud-monitor/observed-inbox-email-address/description?region=us-east-1&tab=Table /automation-engine/dev/gateway-monitor/monitored-velocloud-hosts VeloCloud hosts whose gateways will be monitored https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/gateway-monitor/monitored-velocloud-hosts/description?region=us-east-1&tab=Table /automation-engine/dev/hawkeye-customer-cache/duplicate-inventories-recipient E-mail address that will get e-mails with a relation of service numbers that have multiple Bruin inventories https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/hawkeye-customer-cache/duplicate-inventories-recipient/description?region=us-east-1&tab=Table /automation-engine/dev/intermapper-outage-monitor/observed-inbox-email-address E-mail account that receives InterMapper events for later analysis https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/intermapper-outage-monitor/observed-inbox-email-address/description?region=us-east-1&tab=Table /automation-engine/dev/last-contact-report/monitored-velocloud-hosts VeloCloud hosts whose edges will be used to build the report https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/last-contact-report/monitored-velocloud-hosts/description?region=us-east-1&tab=Table /automation-engine/dev/last-contact-report/report-recipient Email address to send the report to https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/last-contact-report/report-recipient/description?region=us-east-1&tab=Table /automation-engine/dev/email-bridge/monitorable-email-accounts Mapping of e-mail addresses and passwords whose inboxes can be read for later analysis https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/email-bridge/monitorable-email-accounts/description?region=us-east-1&tab=Table /automation-engine/dev/notifications-bridge/slack-webhook-url Slack webhook to send messages https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/notifications-bridge/slack-webhook-url/description?region=us-east-1&tab=Table /automation-engine/dev/papertrail/enabled Enable/Disable Papertrail logs https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/papertrail/enabled/description?region=us-east-1&tab=Table /automation-engine/dev/redis/customer-cache-hostname Customer Cache Redis hostname https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/redis/customer-cache-hostname/description?region=us-east-1&tab=Table /automation-engine/dev/redis/email-tagger-hostname Email Tagger Redis Hostname https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/redis/email-tagger-hostname/description?region=us-east-1&tab=Table /automation-engine/dev/redis/main-hostname Main Redis server for Automation-Engine https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/redis/main-hostname/description?region=us-east-1&tab=Table /automation-engine/dev/redis/tnba-feedback-hostname TNBA Feedback hostname https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/redis/tnba-feedback-hostname/description?region=us-east-1&tab=Table /automation-engine/dev/repair-tickets-kre-bridge/kre-base-url Base URL for RTA's KRE https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/repair-tickets-kre-bridge/kre-base-url/description?region=us-east-1&tab=Table /automation-engine/dev/service-affecting/monitor/monitored-velocloud-hosts VeloCloud hosts whose edges will be monitored https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/service-affecting/monitor/monitored-velocloud-hosts/description?region=us-east-1&tab=Table /automation-engine/dev/service-outage/monitor/blacklisted-edges List of edges that are excluded from Service Outage monitoring https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/service-outage/monitor/blacklisted-edges/description?region=us-east-1&tab=Table /automation-engine/dev/service-outage/monitor/monitored-velocloud-hosts VeloCloud hosts whose edges will be monitored https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/service-outage/monitor/monitored-velocloud-hosts/description?region=us-east-1&tab=Table /automation-engine/dev/service-outage/triage/monitored-velocloud-hosts VeloCloud hosts whose edges will be monitored https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/service-outage/triage/monitored-velocloud-hosts/description?region=us-east-1&tab=Table /automation-engine/dev/servicenow-bridge/base-url Base URL for the ServiceNow API https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/servicenow-bridge/base-url/description?region=us-east-1&tab=Table /automation-engine/dev/servicenow-bridge/client-id OAuth client ID for the ServiceNow API https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/servicenow-bridge/client-id/description?region=us-east-1&tab=Table /automation-engine/dev/servicenow-bridge/client-secret OAuth client secret for the ServiceNow API https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/servicenow-bridge/client-secret/description?region=us-east-1&tab=Table /automation-engine/dev/servicenow-bridge/password Password for the ServiceNow API https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/servicenow-bridge/password/description?region=us-east-1&tab=Table /automation-engine/dev/servicenow-bridge/username Username for the ServiceNow API https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/servicenow-bridge/username/description?region=us-east-1&tab=Table /automation-engine/dev/t7-bridge/kre-base-url Base URL for TNBA's KRE https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/t7-bridge/kre-base-url/description?region=us-east-1&tab=Table /automation-engine/dev/tnba-feedback/monitored-velocloud-hosts VeloCloud hosts whose edges will be monitored https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/tnba-feedback/monitored-velocloud-hosts/description?region=us-east-1&tab=Table /automation-engine/dev/tnba-monitor/blacklisted-edges List of edges that are excluded from TNBA monitoring https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/tnba-monitor/blacklisted-edges/description?region=us-east-1&tab=Table /automation-engine/dev/tnba-monitor/monitored-velocloud-hosts VeloCloud hosts whose edges will be monitored https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/tnba-monitor/monitored-velocloud-hosts/description?region=us-east-1&tab=Table /automation-engine/dev/velocloud-bridge/velocloud-credentials Velocloud credentials https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/velocloud-bridge/velocloud-credentials/description?region=us-east-1&tab=Table /automation-engine/pro/bruin-bridge/base-url https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/bruin-bridge/base-url/description?region=us-east-1&tab=Table /automation-engine/pro/bruin-bridge/client-id https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/bruin-bridge/client-id/description?region=us-east-1&tab=Table /automation-engine/pro/bruin-bridge/client-secret https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/bruin-bridge/client-secret/description?region=us-east-1&tab=Table /automation-engine/pro/bruin-bridge/login-url https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/bruin-bridge/login-url/description?region=us-east-1&tab=Table /automation-engine/pro/bruin-bridge/test-base-url https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/bruin-bridge/test-base-url/description?region=us-east-1&tab=Table /automation-engine/pro/bruin-bridge/test-client-id https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/bruin-bridge/test-client-id/description?region=us-east-1&tab=Table /automation-engine/pro/bruin-bridge/test-client-secret https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/bruin-bridge/test-client-secret/description?region=us-east-1&tab=Table /automation-engine/pro/bruin-bridge/test-login-url https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/bruin-bridge/test-login-url/description?region=us-east-1&tab=Table /automation-engine/pro/customer-cache/blacklisted-clients-with-pending-status https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/customer-cache/blacklisted-clients-with-pending-status/description?region=us-east-1&tab=Table /automation-engine/pro/customer-cache/blacklisted-edges https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/customer-cache/blacklisted-edges/description?region=us-east-1&tab=Table /automation-engine/pro/customer-cache/duplicate-inventories-recipient https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/customer-cache/duplicate-inventories-recipient/description?region=us-east-1&tab=Table /automation-engine/pro/customer-cache/velocloud-hosts https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/customer-cache/velocloud-hosts/description?region=us-east-1&tab=Table /automation-engine/pro/digi-bridge/digi-reboot-api-base-url https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/digi-bridge/digi-reboot-api-base-url/description?region=us-east-1&tab=Table /automation-engine/pro/digi-bridge/digi-reboot-api-client-id https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/digi-bridge/digi-reboot-api-client-id/description?region=us-east-1&tab=Table /automation-engine/pro/digi-bridge/digi-reboot-api-client-secret https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/digi-bridge/digi-reboot-api-client-secret/description?region=us-east-1&tab=Table /automation-engine/pro/digi-reboot-report/report-recipient https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/digi-reboot-report/report-recipient/description?region=us-east-1&tab=Table /automation-engine/pro/email-tagger-kre-bridge/kre-base-url https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/email-tagger-kre-bridge/kre-base-url/description?region=us-east-1&tab=Table /automation-engine/pro/digi-bridge/digi-reboot-api-base-url https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/digi-bridge/digi-reboot-api-base-url/description?region=us-east-1&tab=Table /automation-engine/pro/digi-reboot-report/report-recipient https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/digi-reboot-report/report-recipient/description?region=us-east-1&tab=Table /automation-engine/pro/email-tagger-kre-bridge/kre-base-url https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/email-tagger-kre-bridge/kre-base-url/description?region=us-east-1&tab=Table /automation-engine/pro/email-tagger-monitor/api-request-key https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/email-tagger-monitor/api-request-key/description?region=us-east-1&tab=Table /automation-engine/pro/email-tagger-monitor/api-request-signature-secret-key https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/email-tagger-monitor/api-request-signature-secret-key/description?region=us-east-1&tab=Table /automation-engine/pro/external-secrets/iam-role-arn The ARN of the AWS IAM role necessary to manage parameter store and secret manager https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/external-secrets/iam-role-arn/description?region=us-east-1&tab=Table /automation-engine/pro/fraud-monitor/observed-inbox-email-address https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/fraud-monitor/observed-inbox-email-address/description?region=us-east-1&tab=Table /automation-engine/pro/gateway-monitor/monitored-velocloud-hosts VeloCloud hosts whose gateways will be monitored https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/gateway-monitor/monitored-velocloud-hosts/description?region=us-east-1&tab=Table /automation-engine/pro/hawkeye-customer-cache/duplicate-inventories-recipient https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/hawkeye-customer-cache/duplicate-inventories-recipient/description?region=us-east-1&tab=Table /automation-engine/pro/intermapper-outage-monitor/observed-inbox-email-address https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/intermapper-outage-monitor/observed-inbox-email-address/description?region=us-east-1&tab=Table /automation-engine/pro/last-contact-report/monitored-velocloud-hosts https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/last-contact-report/monitored-velocloud-hosts/description?region=us-east-1&tab=Table /automation-engine/pro/last-contact-report/report-recipient https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/last-contact-report/report-recipient/description?region=us-east-1&tab=Table /automation-engine/pro/email-bridge/monitorable-email-accounts https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/email-bridge/monitorable-email-accounts/description?region=us-east-1&tab=Table /automation-engine/pro/notifications-bridge/slack-webhook-url https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/notifications-bridge/slack-webhook-url/description?region=us-east-1&tab=Table /automation-engine/pro/papertrail/enabled https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/papertrail/enabled/description?region=us-east-1&tab=Table /automation-engine/pro/redis/customer-cache-hostname https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/redis/customer-cache-hostname/description?region=us-east-1&tab=Table /automation-engine/pro/redis/email-tagger-hostname https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/redis/email-tagger-hostname/description?region=us-east-1&tab=Table /automation-engine/pro/redis/main-hostname https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/redis/main-hostname/description?region=us-east-1&tab=Table /automation-engine/pro/redis/tnba-feedback-hostname https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/redis/tnba-feedback-hostname/description?region=us-east-1&tab=Table /automation-engine/pro/repair-tickets-kre-bridge/kre-base-url https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/repair-tickets-kre-bridge/kre-base-url/description?region=us-east-1&tab=Table /automation-engine/pro/service-affecting/monitor/monitored-velocloud-hosts https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/service-affecting/monitor/monitored-velocloud-hosts/description?region=us-east-1&tab=Table /automation-engine/pro/service-outage/monitor/blacklisted-edges https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/service-outage/monitor/blacklisted-edges/description?region=us-east-1&tab=Table /automation-engine/pro/service-outage/monitor/monitored-velocloud-hosts https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/service-outage/monitor/monitored-velocloud-hosts/description?region=us-east-1&tab=Table /automation-engine/pro/service-outage/triage/monitored-velocloud-hosts https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/service-outage/triage/monitored-velocloud-hosts/description?region=us-east-1&tab=Table /automation-engine/pro/t7-bridge/kre-base-url https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/t7-bridge/kre-base-url/description?region=us-east-1&tab=Table /automation-engine/pro/tnba-feedback/monitored-velocloud-hosts https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/tnba-feedback/monitored-velocloud-hosts/description?region=us-east-1&tab=Table /automation-engine/pro/tnba-monitor/blacklisted-edges https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/tnba-monitor/blacklisted-edges/description?region=us-east-1&tab=Table /automation-engine/pro/tnba-monitor/monitored-velocloud-hosts https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/tnba-monitor/monitored-velocloud-hosts/description?region=us-east-1&tab=Table /automation-engine/pro/velocloud-bridge/velocloud-credentials https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/velocloud-bridge/velocloud-credentials/description?region=us-east-1&tab=Table /data-highway/develop/metrics-velocloud-api/ALLOW_ORIGINS Metrics allow origins https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/develop/metrics-velocloud-api/ALLOW_ORIGINS/description?region=us-east-1&tab=Table /data-highway/develop/metrics-velocloud-api/WAREHOUSE Metrics velocloud api snowflake warehouse to execute the queries https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/develop/metrics-velocloud-api/WAREHOUSE/description?region=us-east-1&tab=Table /data-highway/develop/shared/SECRET_JWT Velocloud hosts to fetch data from https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/develop/shared/SECRET_JWT/description?region=us-east-1&tab=Table /data-highway/develop/velocloud-fetcher/BLACKLISTED_VENDORS Blacklisted vendors https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/develop/velocloud-fetcher/BLACKLISTED_VENDORS/description?region=us-east-1&tab=Table /data-highway/develop/velocloud-fetcher/BOOTSTRAP_SERVERS Bootstrap servers https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/develop/velocloud-fetcher/BOOTSTRAP_SERVERS/description?region=us-east-1&tab=Table /data-highway/develop/velocloud-fetcher/KAFKA_PASSWORD Kafka develop password to publish velocloud data on Kafka https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/develop/velocloud-fetcher/KAFKA_PASSWORD/description?region=us-east-1&tab=Table /data-highway/develop/velocloud-fetcher/KAFKA_REGISTRY_SCHEMA_CREDENTIALS Kafka registry credential https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/develop/velocloud-fetcher/KAFKA_REGISTRY_SCHEMA_CREDENTIALS/description?region=us-east-1&tab=Table /data-highway/develop/velocloud-fetcher/KAFKA_REGISTRY_SCHEMA_URL Kafka registry URL https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/develop/velocloud-fetcher/KAFKA_REGISTRY_SCHEMA_URL/description?region=us-east-1&tab=Table /data-highway/develop/velocloud-fetcher/KAFKA_SSL_CA_FILE Kafka develop ssl ca path of Kafka https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/develop/velocloud-fetcher/KAFKA_SSL_CA_FILE/description?region=us-east-1&tab=Table /data-highway/develop/velocloud-fetcher/KAFKA_USERNAME Kafka develop username to publish velocloud data on kafka https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/develop/velocloud-fetcher/KAFKA_USERNAME/description?region=us-east-1&tab=Table /data-highway/develop/velocloud-fetcher/METRICS_LIST Metrics list https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/develop/velocloud-fetcher/METRICS_LIST/description?region=us-east-1&tab=Table /data-highway/develop/velocloud-fetcher/VELOCLOUD_CREDENTIALS Velocloud hosts credentials https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/develop/velocloud-fetcher/VELOCLOUD_CREDENTIALS/description?region=us-east-1&tab=Table /data-highway/develop/velocloud-fetcher/VELOCLOUD_FETCHER_BYPASS_AVRO_ENFORCEMENT_FOR_SCHEMAS Bypass velocloud pruner for schemas https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/develop/velocloud-fetcher/VELOCLOUD_FETCHER_BYPASS_AVRO_ENFORCEMENT_FOR_SCHEMAS/description?region=us-east-1&tab=Table /data-highway/develop/velocloud-fetcher/VELOCLOUD_FETCHER_BYPASS_PRUNER_FOR_SCHEMAS Metrics list https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/develop/velocloud-fetcher/VELOCLOUD_FETCHER_BYPASS_PRUNER_FOR_SCHEMAS/description?region=us-east-1&tab=Table /data-highway/develop/velocloud-fetcher/VELOCLOUD_HOSTS Velocloud hosts to fetch data from https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/develop/velocloud-fetcher/VELOCLOUD_HOSTS/description?region=us-east-1&tab=Table /data-highway/develop/velocloud-fetcher/VELOCLOUD_VERIFY_SSL Velocloud verify ssl https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/develop/velocloud-fetcher/VELOCLOUD_VERIFY_SSL/description?region=us-east-1&tab=Table /data-highway/master/metrics-velocloud-api/ALLOW_ORIGINS Metrics allow origins https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/master/metrics-velocloud-api/ALLOW_ORIGINS/description?region=us-east-1&tab=Table /data-highway/master/metrics-velocloud-api/WAREHOUSE Metrics velocloud api snowflake warehouse to execute the queries https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/master/metrics-velocloud-api/WAREHOUSE/description?region=us-east-1&tab=Table /data-highway/master/shared/SECRET_JWT Velocloud hosts to fetch data from https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/master/shared/SECRET_JWT/description?region=us-east-1&tab=Table /data-highway/master/velocloud-fetcher/BOOTSTRAP_SERVERS Bootstrap servers https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/master/velocloud-fetcher/BOOTSTRAP_SERVERS/description?region=us-east-1&tab=Table /data-highway/master/velocloud-fetcher/ENTERPRISES_ID Enterprises IDs https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/master/velocloud-fetcher/ENTERPRISES_ID/description?region=us-east-1&tab=Table /data-highway/master/velocloud-fetcher/KAFKA_PASSWORD Kafka master password to publish velocloud data on Kafka https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/master/velocloud-fetcher/KAFKA_PASSWORD/description?region=us-east-1&tab=Table /data-highway/master/velocloud-fetcher/KAFKA_REGISTRY_SCHEMA_CREDENTIALS Kafka registry credential https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/master/velocloud-fetcher/KAFKA_REGISTRY_SCHEMA_CREDENTIALS/description?region=us-east-1&tab=Table /data-highway/master/velocloud-fetcher/KAFKA_REGISTRY_SCHEMA_URL Kafka registry URL https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/master/velocloud-fetcher/KAFKA_REGISTRY_SCHEMA_URL/description?region=us-east-1&tab=Table /data-highway/master/velocloud-fetcher/KAFKA_SSL_CA_FILE Kafka master ssl ca path of Kafka https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/master/velocloud-fetcher/KAFKA_SSL_CA_FILE/description?region=us-east-1&tab=Table /data-highway/master/velocloud-fetcher/KAFKA_USERNAME Kafka master username to publish velocloud data on kafka https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/master/velocloud-fetcher/KAFKA_USERNAME/description?region=us-east-1&tab=Table /data-highway/master/velocloud-fetcher/VELOCLOUD_CREDENTIALS Velocloud hosts credentials https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/master/velocloud-fetcher/VELOCLOUD_CREDENTIALS/description?region=us-east-1&tab=Table /data-highway/master/velocloud-fetcher/VELOCLOUD_FETCHER_BYPASS_AVRO_ENFORCEMENT_FOR_SCHEMAS Bypass velocloud pruner for schemas https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/master/velocloud-fetcher/VELOCLOUD_FETCHER_BYPASS_AVRO_ENFORCEMENT_FOR_SCHEMAS/description?region=us-east-1&tab=Table /data-highway/master/velocloud-fetcher/VELOCLOUD_FETCHER_BYPASS_PRUNER_FOR_SCHEMAS Metrics list https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/master/velocloud-fetcher/VELOCLOUD_FETCHER_BYPASS_PRUNER_FOR_SCHEMAS/description?region=us-east-1&tab=Table /data-highway/master/velocloud-fetcher/VELOCLOUD_HOSTS Velocloud hosts to fetch data from https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/master/velocloud-fetcher/VELOCLOUD_HOSTS/description?region=us-east-1&tab=Table /data-highway/master/velocloud-fetcher/VELOCLOUD_VERIFY_SSL Velocloud verify ssl https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/master/velocloud-fetcher/VELOCLOUD_VERIFY_SSL/description?region=us-east-1&tab=Table","title":"Parameter Store parameters"},{"location":"parameters/parameters/#parameter-store-parameters","text":"Name Description Link to AWS /automation-engine/common/autoresolve-day-end-hour Defines the hour at which the day ends and the night starts for dynamic auto-resolution times https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/autoresolve-day-end-hour/description?region=us-east-1&tab=Table /automation-engine/common/autoresolve-day-start-hour Defines the hour at which the night ends and the day starts for dynamic auto-resolution times https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/autoresolve-day-start-hour/description?region=us-east-1&tab=Table /automation-engine/common/bruin-ipa-system-username Name of the user that performs operations in Bruin on behalf of the IPA system https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/bruin-ipa-system-username/description?region=us-east-1&tab=Table /automation-engine/common/customer-cache/refresh-check-interval Defines how often the next refresh flag is checked to decide if it's time to refresh the cache or not https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/customer-cache/refresh-check-interval/description?region=us-east-1&tab=Table /automation-engine/common/customer-cache/refresh-job-interval Defines how often the cache is refreshed https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/customer-cache/refresh-job-interval/description?region=us-east-1&tab=Table /automation-engine/common/customer-cache/whitelisted-management-statuses Management statuses that should be considered in the caching process https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/customer-cache/whitelisted-management-statuses/description?region=us-east-1&tab=Table /automation-engine/common/digi-bridge/digi-headers List of possible headers included in all DiGi links https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/digi-bridge/digi-headers/description?region=us-east-1&tab=Table /automation-engine/common/digi-bridge/digi-reboot-api-token-ttl Auth tokens TTL https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/digi-bridge/digi-reboot-api-token-ttl/description?region=us-east-1&tab=Table /automation-engine/common/digi-reboot-report/logs-lookup-interval Defines how much time back to look for DiGi Reboot logs https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/digi-reboot-report/logs-lookup-interval/description?region=us-east-1&tab=Table /automation-engine/common/digi-reboot-report/report-job-interval Defines how often the report is built and sent https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/digi-reboot-report/report-job-interval/description?region=us-east-1&tab=Table /automation-engine/common/dri-bridge/base-url Base URL for DRI API https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/dri-bridge/base-url/description?region=us-east-1&tab=Table /automation-engine/common/dri-bridge/dri-data-redis-ttl Defines how much time the data retrieved from DRI for a specific device can be stored and served from Redis https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/dri-bridge/dri-data-redis-ttl/description?region=us-east-1&tab=Table /automation-engine/common/dri-bridge/password Password to log into DRI API https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/dri-bridge/password/description?region=us-east-1&tab=Table /automation-engine/common/dri-bridge/username Username to log into DRI API https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/dri-bridge/username/description?region=us-east-1&tab=Table /automation-engine/common/email-tagger-monitor/api-endpoint-prefix API server endpoint prefix for incoming requests https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/email-tagger-monitor/api-endpoint-prefix/description?region=us-east-1&tab=Table /automation-engine/common/email-tagger-monitor/max-concurrent-emails Defines how many simultaneous emails are processed https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/email-tagger-monitor/max-concurrent-emails/description?region=us-east-1&tab=Table /automation-engine/common/email-tagger-monitor/new-emails-job-interval Defines how often new emails received from Bruin are processed https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/email-tagger-monitor/new-emails-job-interval/description?region=us-east-1&tab=Table /automation-engine/common/email-tagger-monitor/new-tickets-job-interval Defines how often new tickets received from Bruin are sent to the KRE to train the AI model https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/email-tagger-monitor/new-tickets-job-interval/description?region=us-east-1&tab=Table /automation-engine/common/email-tagger-monitor/reply-email-ttl Reply emails time to live (in milliseconds) when storing them to Redis https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/email-tagger-monitor/reply-email-ttl/description?region=us-east-1&tab=Table /automation-engine/common/fraud-monitor/alerts-lookup-days How many days to look back for Fraud alerts in the desired e-mail inbox https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/fraud-monitor/alerts-lookup-days/description?region=us-east-1&tab=Table /automation-engine/common/fraud-monitor/default-client-info-for-did-without-inventory Default client info used when the DID device in the Fraud alert does not have an inventory assigned in Bruin https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/fraud-monitor/default-client-info-for-did-without-inventory/description?region=us-east-1&tab=Table /automation-engine/common/fraud-monitor/default-contact-for-new-tickets Default contact details used when a Fraud is reported as a Service Affecting ticket https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/fraud-monitor/default-contact-for-new-tickets/description?region=us-east-1&tab=Table /automation-engine/common/fraud-monitor/monitoring-job-interval Defines how often Fraud e-mails are checked to report them as Service Affecting tickets https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/fraud-monitor/monitoring-job-interval/description?region=us-east-1&tab=Table /automation-engine/common/fraud-monitor/observed-inbox-senders Senders addresses whose e-mail messages represent Fraud alerts https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/fraud-monitor/observed-inbox-senders/description?region=us-east-1&tab=Table /automation-engine/common/gateway-monitor/first-gateway-lookup-interval Lookup interval for the first time gateway statuses are retrieved https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/gateway-monitor/first-gateway-lookup-interval/description?region=us-east-1&tab=Table /automation-engine/common/gateway-monitor/monitoring-job-interval Defines how often gateways are checked to find and report incidents https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/gateway-monitor/monitoring-job-interval/description?region=us-east-1&tab=Table /automation-engine/common/gateway-monitor/second-gateway-lookup-interval Lookup interval for the second time gateway statuses are retrieved https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/gateway-monitor/second-gateway-lookup-interval/description?region=us-east-1&tab=Table /automation-engine/common/gateway-monitor/blacklisted-gateways List of gateway names that are excluded from gateway monitoring https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/gateway-monitor/blacklisted-gateways/description?region=us-east-1&tab=Table /automation-engine/common/gateway-monitor/offline-trouble-enabled Enable or disable the offline trouble check https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/gateway-monitor/offline-trouble-enabled/description?region=us-east-1&tab=Table /automation-engine/common/gateway-monitor/tunnel-count-threshold Threshold for tunnel count troubles https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/gateway-monitor/tunnel-count-threshold/description?region=us-east-1&tab=Table /automation-engine/common/gateway-monitor/tunnel-count-trouble-enabled Enable or disable the tunnel count trouble check https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/gateway-monitor/tunnel-count-trouble-enabled/description?region=us-east-1&tab=Table /automation-engine/common/hawkeye-affecting-monitor/monitored-product-category Bruin's product category under monitoring https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/hawkeye-affecting-monitor/monitored-product-category/description?region=us-east-1&tab=Table /automation-engine/common/hawkeye-affecting-monitor/monitoring-job-interval Defines how often devices are checked to find and report issues https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/hawkeye-affecting-monitor/monitoring-job-interval/description?region=us-east-1&tab=Table /automation-engine/common/hawkeye-affecting-monitor/probes-tests-results-lookup-interval Defines how much time back to look for probes' tests results https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/hawkeye-affecting-monitor/probes-tests-results-lookup-interval/description?region=us-east-1&tab=Table /automation-engine/common/hawkeye-bridge/base-url Base URL to access Hawkeye API https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/hawkeye-bridge/base-url/description?region=us-east-1&tab=Table /automation-engine/common/hawkeye-bridge/client-password Client password to log into Hawkeye API https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/hawkeye-bridge/client-password/description?region=us-east-1&tab=Table /automation-engine/common/hawkeye-bridge/client-username Client username to log into Hawkeye API https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/hawkeye-bridge/client-username/description?region=us-east-1&tab=Table /automation-engine/common/hawkeye-customer-cache/refresh-job-interval Defines how often the cache is refreshed https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/hawkeye-customer-cache/refresh-job-interval/description?region=us-east-1&tab=Table /automation-engine/common/hawkeye-customer-cache/whitelisted-management-statuses Management statuses that should be considered in the caching process https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/hawkeye-customer-cache/whitelisted-management-statuses/description?region=us-east-1&tab=Table /automation-engine/common/hawkeye-outage-monitor/grace-period-to-autoresolve-after-last-documented-outage Defines for how long a ticket can be auto-resolved after the last documented outage https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/hawkeye-outage-monitor/grace-period-to-autoresolve-after-last-documented-outage/description?region=us-east-1&tab=Table /automation-engine/common/hawkeye-outage-monitor/monitored-product-category Bruin's product category under monitoring https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/hawkeye-outage-monitor/monitored-product-category/description?region=us-east-1&tab=Table /automation-engine/common/hawkeye-outage-monitor/monitoring-job-interval Defines how often devices are checked to find and report issues https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/hawkeye-outage-monitor/monitoring-job-interval/description?region=us-east-1&tab=Table /automation-engine/common/hawkeye-outage-monitor/quarantine-for-devices-in-outage Defines how much time to wait before checking if a particular device is still in outage state https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/hawkeye-outage-monitor/quarantine-for-devices-in-outage/description?region=us-east-1&tab=Table /automation-engine/common/intermapper-outage-monitor/dri-parameters-for-piab-notes Parameters to fetch from DRI to include them in InterMapper notes for PIAB devices https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/intermapper-outage-monitor/dri-parameters-for-piab-notes/description?region=us-east-1&tab=Table /automation-engine/common/intermapper-outage-monitor/grace-period-to-autoresolve-after-last-documented-outage-day-time Defines for how long a ticket can be auto-resolved after the last documented trouble during the day https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/intermapper-outage-monitor/grace-period-to-autoresolve-after-last-documented-outage-day-time/description?region=us-east-1&tab=Table /automation-engine/common/intermapper-outage-monitor/grace-period-to-autoresolve-after-last-documented-outage-night-time Defines for how long a ticket can be auto-resolved after the last documented trouble during the night https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/intermapper-outage-monitor/grace-period-to-autoresolve-after-last-documented-outage-night-time/description?region=us-east-1&tab=Table /automation-engine/common/intermapper-outage-monitor/max-autoresolves-per-ticket Defines how many times a ticket can be auto-resolved https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/intermapper-outage-monitor/max-autoresolves-per-ticket/description?region=us-east-1&tab=Table /automation-engine/common/intermapper-outage-monitor/max-concurrent-email-batches Defines how many simultaneous email batches related to the same InterMapper asset are processed https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/intermapper-outage-monitor/max-concurrent-email-batches/description?region=us-east-1&tab=Table /automation-engine/common/intermapper-outage-monitor/monitor-piab-devices Enable or disable monitoring of PIAB devices https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/intermapper-outage-monitor/monitor-piab-devices/description?region=us-east-1&tab=Table /automation-engine/common/intermapper-outage-monitor/monitored-up-events InterMapper events considered as UP https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/intermapper-outage-monitor/monitored-up-events/description?region=us-east-1&tab=Table /automation-engine/common/intermapper-outage-monitor/monitoring-job-interval Defines how often InterMapper events are checked to find and report issues https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/intermapper-outage-monitor/monitoring-job-interval/description?region=us-east-1&tab=Table /automation-engine/common/intermapper-outage-monitor/observed-inbox-senders Senders addresses whose e-mail messages represent InterMapper events https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/intermapper-outage-monitor/observed-inbox-senders/description?region=us-east-1&tab=Table /automation-engine/common/timezone Timezone used for periodic jobs, timestamps, etc https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/timezone/description?region=us-east-1&tab=Table /automation-engine/common/intermapper-outage-monitor/events-lookup-days How many days to look back for InterMapper events in the desired e-mail inbox https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/intermapper-outage-monitor/events-lookup-days/description?region=us-east-1&tab=Table /automation-engine/common/intermapper-outage-monitor/max-emails-to-retrieve How many emails to retrieve at most for InterMapper events in the desired e-mail inbox https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/intermapper-outage-monitor/max-emails-to-retrieve/description?region=us-east-1&tab=Table /automation-engine/common/intermapper-outage-monitor/monitored-down-events InterMapper events considered as DOWN https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/intermapper-outage-monitor/monitored-down-events/description?region=us-east-1&tab=Table /automation-engine/common/intermapper-outage-monitor/whitelisted-product-categories-for-autoresolve Defines which Bruin product categories are taken into account when auto-resolving tickets https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/intermapper-outage-monitor/whitelisted-product-categories-for-autoresolve/description?region=us-east-1&tab=Table /automation-engine/common/link-labels-blacklisted-from-asr-forwards List of link labels that are excluded from forwards to the ASR queue https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/link-labels-blacklisted-from-asr-forwards/description?region=us-east-1&tab=Table /automation-engine/common/link-labels-blacklisted-from-hnoc-forwards List of link labels that are excluded from forwards to the HNOC queue https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/link-labels-blacklisted-from-hnoc-forwards/description?region=us-east-1&tab=Table /automation-engine/common/lumin-billing-report/access-token Access token for Lumin's Billing API https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/lumin-billing-report/access-token/description?region=us-east-1&tab=Table /automation-engine/common/lumin-billing-report/customer-name Name of the customer for which the Billing Report will be generated https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/lumin-billing-report/customer-name/description?region=us-east-1&tab=Table /automation-engine/common/lumin-billing-report/email-account-for-message-delivery-password Email account used to send messages to other accounts (password) https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/lumin-billing-report/email-account-for-message-delivery-password/description?region=us-east-1&tab=Table /automation-engine/common/lumin-billing-report/lumin-billing-api-base-url Base URL for Lumin's Billing API https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/lumin-billing-report/lumin-billing-api-base-url/description?region=us-east-1&tab=Table /automation-engine/common/lumin-billing-report/recipient Email address to send the report to https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/lumin-billing-report/recipient/description?region=us-east-1&tab=Table /automation-engine/common/metrics/relevant-clients List of relevant client names to use on Prometheus metrics labels https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/metrics/relevant-clients/description?region=us-east-1&tab=Table /automation-engine/common/nats/endpoint-url Nats endpoint URL for messaging https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/nats/endpoint-url/description?region=us-east-1&tab=Table /automation-engine/common/email-bridge/email-account-for-message-delivery-password Email account used to send messages to other accounts (password) https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/email-bridge/email-account-for-message-delivery-password/description?region=us-east-1&tab=Table /automation-engine/common/email-bridge/email-account-for-message-delivery-username Email account used to send messages to other accounts (username) https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/email-bridge/email-account-for-message-delivery-username/description?region=us-east-1&tab=Table /automation-engine/common/papertrail/host Papertrail host to send logs https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/papertrail/host/description?region=us-east-1&tab=Table /automation-engine/common/papertrail/port Papertrail port to send logs https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/papertrail/port/description?region=us-east-1&tab=Table /automation-engine/common/repair-tickets-monitor/max-concurrent-closed-tickets-for-feedback Defines how many simultaneous new closed tickets are sent to the KRE to train the AI model https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/repair-tickets-monitor/max-concurrent-closed-tickets-for-feedback/description?region=us-east-1&tab=Table /automation-engine/common/repair-tickets-monitor/max-concurrent-created-tickets-for-feedback Defines how many simultaneous new created tickets are sent to the KRE to train the AI model https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/repair-tickets-monitor/max-concurrent-created-tickets-for-feedback/description?region=us-east-1&tab=Table /automation-engine/common/repair-tickets-monitor/max-concurrent-emails-for-monitoring Defines how many simultaneous tagged emails are processed https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/repair-tickets-monitor/max-concurrent-emails-for-monitoring/description?region=us-east-1&tab=Table /automation-engine/common/repair-tickets-monitor/new-closed-tickets-feedback-job-interval Defines how often new closed tickets fetched from Bruin are sent to the KRE to train the AI model https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/repair-tickets-monitor/new-closed-tickets-feedback-job-interval/description?region=us-east-1&tab=Table /automation-engine/common/repair-tickets-monitor/new-created-tickets-feedback-job-interval Defines how often new created tickets fetched from Bruin are sent to the KRE to train the AI model https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/repair-tickets-monitor/new-created-tickets-feedback-job-interval/description?region=us-east-1&tab=Table /automation-engine/common/repair-tickets-monitor/rta-monitor-job-interval Defines how often new emails tagged by the E-mail Tagger are processed https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/repair-tickets-monitor/rta-monitor-job-interval/description?region=us-east-1&tab=Table /automation-engine/common/repair-tickets-monitor/tag-ids-mapping Mapping of tag names and their corresponding numeric ID, as defined in the AI model https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/repair-tickets-monitor/tag-ids-mapping/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/daily-bandwidth-report/enabled-customers-per-host Mapping of VeloCloud hosts and Bruin customer IDs for whom this report will trigger periodically https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/daily-bandwidth-report/enabled-customers-per-host/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/daily-bandwidth-report/execution-cron-expression Cron expression that determines when to build and deliver this report https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/daily-bandwidth-report/execution-cron-expression/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/daily-bandwidth-report/lookup-interval Defines how much time back to look for bandwidth metrics and Bruin tickets https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/daily-bandwidth-report/lookup-interval/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/daily-bandwidth-report/recipients List of recipients that will get these reports https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/daily-bandwidth-report/recipients/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/monitor/autoresolve-lookup-interval Defines how much time back to look for all kinds of metrics while running auto-resolves https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/monitor/autoresolve-lookup-interval/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/monitor/bandwidth-over-utilization-monitoring-lookup-interval Defines how much time back to look for Bandwidth metrics in Bandwidth Over Utilization checks https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/monitor/bandwidth-over-utilization-monitoring-lookup-interval/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/monitor/bandwidth-over-utilization-monitoring-threshold Threshold for Bandwidth Over Utilization troubles https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/monitor/bandwidth-over-utilization-monitoring-threshold/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/monitor/circuit-instability-autoresolve-threshold Max DOWN events allowed in Circuit Instability checks while auto-resolving tickets https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/monitor/circuit-instability-autoresolve-threshold/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/monitor/circuit-instability-monitoring-lookup-interval Defines how much time back to look for DOWN events in Circuit Instability checks https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/monitor/circuit-instability-monitoring-lookup-interval/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/monitor/circuit-instability-monitoring-threshold Threshold for Circuit Instability troubles https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/monitor/circuit-instability-monitoring-threshold/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/monitor/customers-to-always-use-default-contact-info [Monitoring] List Bruin customers that should always use the default contact info https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/monitor/customers-to-always-use-default-contact-info/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/monitor/customers-with-bandwidth-over-utilization-monitoring List of client IDs for which Bandwidth Over Utilization checks are enabled https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/monitor/customers-with-bandwidth-over-utilization-monitoring/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/monitor/default-contact-info-per-customer Mapping of VeloCloud hosts, Bruin customers and default contact info https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/monitor/default-contact-info-per-customer/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/monitor/grace-period-to-autoresolve-after-last-documented-trouble-day-time Defines for how long a ticket can be auto-resolved after the last documented trouble during the day https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/monitor/grace-period-to-autoresolve-after-last-documented-trouble-day-time/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/monitor/grace-period-to-autoresolve-after-last-documented-trouble-night-time Defines for how long a ticket can be auto-resolved after the last documented trouble during the night https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/monitor/grace-period-to-autoresolve-after-last-documented-trouble-night-time/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/monitor/jitter-monitoring-lookup-interval Defines how much time back to look for Jitter metrics in Jitter checks https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/monitor/jitter-monitoring-lookup-interval/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/monitor/jitter-monitoring-threshold Threshold for Jitter troubles https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/monitor/jitter-monitoring-threshold/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/monitor/latency-monitoring-lookup-interval Defines how much time back to look for Latency metrics in Latency checks https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/monitor/latency-monitoring-lookup-interval/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/monitor/latency-monitoring-threshold Threshold for Latency troubles https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/monitor/latency-monitoring-threshold/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/monitor/max-autoresolves-per-ticket Defines how many times a ticket can be auto-resolved https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/monitor/max-autoresolves-per-ticket/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/monitor/monitoring-job-interval Defines how often devices are checked to find and report issues https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/monitor/monitoring-job-interval/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/monitor/packet-loss-monitoring-lookup-interval Defines how much time back to look for Packet Loss metrics in Packet Loss checks https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/monitor/packet-loss-monitoring-lookup-interval/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/monitor/packet-loss-monitoring-threshold Threshold for Packet Loss troubles https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/monitor/packet-loss-monitoring-threshold/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/monitor/wait-time-before-sending-new-milestone-reminder How long we need to wait for the milestone reminder email to be sent https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/monitor/wait-time-before-sending-new-milestone-reminder/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/monitored-product-category Bruin's product category under monitoring https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/monitored-product-category/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/reoccurring-trouble-report/recipients-per-host-and-customer Mapping of VeloCloud hosts, Bruin customer IDs and recipients of these reports https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/reoccurring-trouble-report/recipients-per-host-and-customer/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/reoccurring-trouble-report/reported-troubles Troubles that will be reported https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/reoccurring-trouble-report/reported-troubles/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/reoccurring-trouble-report/default-contacts List of default contacts to whom this report will always be delivered to https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/reoccurring-trouble-report/default-contacts/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/reoccurring-trouble-report/execution-cron-expression Cron expression that determines when to build and deliver this report https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/reoccurring-trouble-report/execution-cron-expression/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/reoccurring-trouble-report/reoccurring-trouble-tickets-threshold Number of different tickets a trouble must appear in for a particular edge and interface to include it in the report https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/reoccurring-trouble-report/reoccurring-trouble-tickets-threshold/description?region=us-east-1&tab=Table /automation-engine/common/service-affecting/reoccurring-trouble-report/tickets-lookup-interval Defines how much time back to look for Bruin tickets https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-affecting/reoccurring-trouble-report/tickets-lookup-interval/description?region=us-east-1&tab=Table /automation-engine/common/service-outage/monitor/business-grade-link-labels List of labels that define a link as business grade https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-outage/monitor/business-grade-link-labels/description?region=us-east-1&tab=Table /automation-engine/common/service-outage/monitor/grace-period-before-attempting-new-digi-reboots Defines for how long the monitor will wait before attempting a new DiGi Reboot on an edge https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-outage/monitor/grace-period-before-attempting-new-digi-reboots/description?region=us-east-1&tab=Table /automation-engine/common/service-outage/monitor/grace-period-to-autoresolve-after-last-documented-outage-day-time Defines for how long a ticket can be auto-resolved after the last documented trouble during the day https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-outage/monitor/grace-period-to-autoresolve-after-last-documented-outage-day-time/description?region=us-east-1&tab=Table /automation-engine/common/service-outage/monitor/grace-period-to-autoresolve-after-last-documented-outage-night-time Defines for how long a ticket can be auto-resolved after the last documented trouble during the night https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-outage/monitor/grace-period-to-autoresolve-after-last-documented-outage-night-time/description?region=us-east-1&tab=Table /automation-engine/common/service-outage/monitor/max-autoresolves-per-ticket Defines how many times a ticket can be auto-resolved https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-outage/monitor/max-autoresolves-per-ticket/description?region=us-east-1&tab=Table /automation-engine/common/service-outage/monitor/missing-edges-from-cache-report-recipient E-mail address that will receive a tiny report showing which edges from VeloCloud responses are not in the cache of customers https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-outage/monitor/missing-edges-from-cache-report-recipient/description?region=us-east-1&tab=Table /automation-engine/common/service-outage/monitor/monitoring-job-interval Defines how often devices are checked to find and report issues https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-outage/monitor/monitoring-job-interval/description?region=us-east-1&tab=Table /automation-engine/common/service-outage/monitor/quarantine-for-edges-in-ha-hard-down-outage Defines how much time to wait before re-checking an edge currently in Hard Down (HA) state https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-outage/monitor/quarantine-for-edges-in-ha-hard-down-outage/description?region=us-east-1&tab=Table /automation-engine/common/service-outage/monitor/quarantine-for-edges-in-ha-link-down-outage Defines how much time to wait before re-checking an edge currently in Link Down (HA) state https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-outage/monitor/quarantine-for-edges-in-ha-link-down-outage/description?region=us-east-1&tab=Table /automation-engine/common/service-outage/monitor/quarantine-for-edges-in-ha-soft-down-outage Defines how much time to wait before re-checking an edge currently in Soft Down (HA) state https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-outage/monitor/quarantine-for-edges-in-ha-soft-down-outage/description?region=us-east-1&tab=Table /automation-engine/common/service-outage/monitor/quarantine-for-edges-in-hard-down-outage Defines how much time to wait before re-checking an edge currently in Hard Down state https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-outage/monitor/quarantine-for-edges-in-hard-down-outage/description?region=us-east-1&tab=Table /automation-engine/common/service-outage/monitor/quarantine-for-edges-in-link-down-outage Defines how much time to wait before re-checking an edge currently in Link Down state https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-outage/monitor/quarantine-for-edges-in-link-down-outage/description?region=us-east-1&tab=Table /automation-engine/common/service-outage/monitor/severity-for-edge-down-outages Severity level for Edge Down outages https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-outage/monitor/severity-for-edge-down-outages/description?region=us-east-1&tab=Table /automation-engine/common/service-outage/monitor/severity-for-link-down-outages Severity level for Link Down outages https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-outage/monitor/severity-for-link-down-outages/description?region=us-east-1&tab=Table /automation-engine/common/service-outage/monitor/wait-time-before-sending-new-milestone-reminder How long we need to wait for the milestone reminder email to be sent https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-outage/monitor/wait-time-before-sending-new-milestone-reminder/description?region=us-east-1&tab=Table /automation-engine/common/service-outage/monitored-product-category Bruin's product category under monitoring https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-outage/monitored-product-category/description?region=us-east-1&tab=Table /automation-engine/common/service-outage/triage/last-note-interval Defines how long the last note on a ticket is considered recent https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-outage/triage/last-note-interval/description?region=us-east-1&tab=Table /automation-engine/common/service-outage/triage/max-events-per-event-note Defines how many events will be included in events notes https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-outage/triage/max-events-per-event-note/description?region=us-east-1&tab=Table /automation-engine/common/service-outage/triage/monitoring-job-interval Defines how often tickets are checked to see if it needs an initial triage or events note https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/service-outage/triage/monitoring-job-interval/description?region=us-east-1&tab=Table /automation-engine/common/tnba-feedback/feedback-job-interval Defines how often tickets are pulled from Bruin and sent to the KRE to train the predictive model https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/tnba-feedback/feedback-job-interval/description?region=us-east-1&tab=Table /automation-engine/common/tnba-feedback/grace-period-before-resending-tickets Defines for how long a ticket needs to wait before being re-sent to the KRE https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/tnba-feedback/grace-period-before-resending-tickets/description?region=us-east-1&tab=Table /automation-engine/common/tnba-feedback/monitored-product-category Bruin's product category under monitoring https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/tnba-feedback/monitored-product-category/description?region=us-east-1&tab=Table /automation-engine/common/tnba-monitor/grace-period-before-appending-new-tnba-notes Defines for how long a ticket needs to wait since it was opened before appending a new TNBA note https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/tnba-monitor/grace-period-before-appending-new-tnba-notes/description?region=us-east-1&tab=Table /automation-engine/common/tnba-monitor/grace-period-before-monitoring-tickets-based-on-last-documented-outage Defines for how long a Service Outage ticket needs to wait after the last documented outage to get a new TNBA note appended https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/tnba-monitor/grace-period-before-monitoring-tickets-based-on-last-documented-outage/description?region=us-east-1&tab=Table /automation-engine/common/tnba-monitor/min-required-confidence-for-request-and-repair-completed-predictions Defines the minimum confidence level required to consider a Request Completed / Repair Completed prediction accurate in TNBA auto-resolves https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/tnba-monitor/min-required-confidence-for-request-and-repair-completed-predictions/description?region=us-east-1&tab=Table /automation-engine/common/tnba-monitor/monitored-product-category Bruin's product category under monitoring https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/tnba-monitor/monitored-product-category/description?region=us-east-1&tab=Table /automation-engine/common/tnba-monitor/monitoring-job-interval Defines how often tickets are checked to see if they need a new TNBA note https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/tnba-monitor/monitoring-job-interval/description?region=us-east-1&tab=Table /automation-engine/common/umbrella-hosts VeloCloud hosts that act as an umbrella for all clients hosted on them https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/common/umbrella-hosts/description?region=us-east-1&tab=Table /automation-engine/dev/bruin-bridge/base-url Base URL for Bruin's DEV API https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/bruin-bridge/base-url/description?region=us-east-1&tab=Table /automation-engine/dev/bruin-bridge/client-id Client ID credential to authenticate against Bruin's DEV API https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/bruin-bridge/client-id/description?region=us-east-1&tab=Table /automation-engine/dev/bruin-bridge/client-secret Client secret credential to authenticate against Bruin's DEV API https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/bruin-bridge/client-secret/description?region=us-east-1&tab=Table /automation-engine/dev/bruin-bridge/login-url Login URL for Bruin's DEV API https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/bruin-bridge/login-url/description?region=us-east-1&tab=Table /automation-engine/dev/bruin-bridge/test-base-url Base URL for Bruin's TEST API https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/bruin-bridge/test-base-url/description?region=us-east-1&tab=Table /automation-engine/dev/bruin-bridge/test-client-id Client ID credential to authenticate against Bruin's TEST API https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/bruin-bridge/test-client-id/description?region=us-east-1&tab=Table /automation-engine/dev/bruin-bridge/test-client-secret Client secret credential to authenticate against Bruin's TEST API https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/bruin-bridge/test-client-secret/description?region=us-east-1&tab=Table /automation-engine/dev/bruin-bridge/test-login-url Login URL for Bruin's TEST API https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/bruin-bridge/test-login-url/description?region=us-east-1&tab=Table /automation-engine/dev/customer-cache/blacklisted-clients-with-pending-status Client IDs whose edges have Pending management status that should be ignored in the caching process https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/customer-cache/blacklisted-clients-with-pending-status/description?region=us-east-1&tab=Table /automation-engine/dev/customer-cache/blacklisted-edges VeloCloud edges that should be ignored in the caching process https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/customer-cache/blacklisted-edges/description?region=us-east-1&tab=Table /automation-engine/dev/customer-cache/duplicate-inventories-recipient E-mail address that will get e-mails with a relation of service numbers that have multiple Bruin inventories https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/customer-cache/duplicate-inventories-recipient/description?region=us-east-1&tab=Table /automation-engine/dev/customer-cache/velocloud-hosts VeloCloud hosts whose edges will be stored to the cache https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/customer-cache/velocloud-hosts/description?region=us-east-1&tab=Table /automation-engine/dev/digi-bridge/digi-reboot-api-base-url Base URL for Digi API https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/digi-bridge/digi-reboot-api-base-url/description?region=us-east-1&tab=Table /automation-engine/dev/digi-bridge/digi-reboot-api-client-id Client ID credentials for Digi API https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/digi-bridge/digi-reboot-api-client-id/description?region=us-east-1&tab=Table /automation-engine/dev/digi-bridge/digi-reboot-api-client-secret Client Secret credentials for Digi API https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/digi-bridge/digi-reboot-api-client-secret/description?region=us-east-1&tab=Table /automation-engine/dev/digi-reboot-report/report-recipient Email address to send the report to https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/digi-reboot-report/report-recipient/description?region=us-east-1&tab=Table /automation-engine/dev/email-tagger-kre-bridge/kre-base-url Base URL for E-mail Tagger's KRE https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/email-tagger-kre-bridge/kre-base-url/description?region=us-east-1&tab=Table /automation-engine/dev/email-tagger-monitor/api-request-key API request key for incoming requests https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/email-tagger-monitor/api-request-key/description?region=us-east-1&tab=Table /automation-engine/dev/email-tagger-monitor/api-request-signature-secret-key API signature secret key for incoming requests https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/email-tagger-monitor/api-request-signature-secret-key/description?region=us-east-1&tab=Table /automation-engine/dev/external-secrets/iam-role-arn The ARN of the AWS IAM role necessary to manage parameter store and secret manager https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/external-secrets/iam-role-arn/description?region=us-east-1&tab=Table /automation-engine/dev/fraud-monitor/observed-inbox-email-address E-mail account that receives Fraud e-mails for later analysis https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/fraud-monitor/observed-inbox-email-address/description?region=us-east-1&tab=Table /automation-engine/dev/gateway-monitor/monitored-velocloud-hosts VeloCloud hosts whose gateways will be monitored https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/gateway-monitor/monitored-velocloud-hosts/description?region=us-east-1&tab=Table /automation-engine/dev/hawkeye-customer-cache/duplicate-inventories-recipient E-mail address that will get e-mails with a relation of service numbers that have multiple Bruin inventories https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/hawkeye-customer-cache/duplicate-inventories-recipient/description?region=us-east-1&tab=Table /automation-engine/dev/intermapper-outage-monitor/observed-inbox-email-address E-mail account that receives InterMapper events for later analysis https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/intermapper-outage-monitor/observed-inbox-email-address/description?region=us-east-1&tab=Table /automation-engine/dev/last-contact-report/monitored-velocloud-hosts VeloCloud hosts whose edges will be used to build the report https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/last-contact-report/monitored-velocloud-hosts/description?region=us-east-1&tab=Table /automation-engine/dev/last-contact-report/report-recipient Email address to send the report to https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/last-contact-report/report-recipient/description?region=us-east-1&tab=Table /automation-engine/dev/email-bridge/monitorable-email-accounts Mapping of e-mail addresses and passwords whose inboxes can be read for later analysis https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/email-bridge/monitorable-email-accounts/description?region=us-east-1&tab=Table /automation-engine/dev/notifications-bridge/slack-webhook-url Slack webhook to send messages https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/notifications-bridge/slack-webhook-url/description?region=us-east-1&tab=Table /automation-engine/dev/papertrail/enabled Enable/Disable Papertrail logs https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/papertrail/enabled/description?region=us-east-1&tab=Table /automation-engine/dev/redis/customer-cache-hostname Customer Cache Redis hostname https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/redis/customer-cache-hostname/description?region=us-east-1&tab=Table /automation-engine/dev/redis/email-tagger-hostname Email Tagger Redis Hostname https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/redis/email-tagger-hostname/description?region=us-east-1&tab=Table /automation-engine/dev/redis/main-hostname Main Redis server for Automation-Engine https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/redis/main-hostname/description?region=us-east-1&tab=Table /automation-engine/dev/redis/tnba-feedback-hostname TNBA Feedback hostname https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/redis/tnba-feedback-hostname/description?region=us-east-1&tab=Table /automation-engine/dev/repair-tickets-kre-bridge/kre-base-url Base URL for RTA's KRE https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/repair-tickets-kre-bridge/kre-base-url/description?region=us-east-1&tab=Table /automation-engine/dev/service-affecting/monitor/monitored-velocloud-hosts VeloCloud hosts whose edges will be monitored https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/service-affecting/monitor/monitored-velocloud-hosts/description?region=us-east-1&tab=Table /automation-engine/dev/service-outage/monitor/blacklisted-edges List of edges that are excluded from Service Outage monitoring https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/service-outage/monitor/blacklisted-edges/description?region=us-east-1&tab=Table /automation-engine/dev/service-outage/monitor/monitored-velocloud-hosts VeloCloud hosts whose edges will be monitored https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/service-outage/monitor/monitored-velocloud-hosts/description?region=us-east-1&tab=Table /automation-engine/dev/service-outage/triage/monitored-velocloud-hosts VeloCloud hosts whose edges will be monitored https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/service-outage/triage/monitored-velocloud-hosts/description?region=us-east-1&tab=Table /automation-engine/dev/servicenow-bridge/base-url Base URL for the ServiceNow API https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/servicenow-bridge/base-url/description?region=us-east-1&tab=Table /automation-engine/dev/servicenow-bridge/client-id OAuth client ID for the ServiceNow API https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/servicenow-bridge/client-id/description?region=us-east-1&tab=Table /automation-engine/dev/servicenow-bridge/client-secret OAuth client secret for the ServiceNow API https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/servicenow-bridge/client-secret/description?region=us-east-1&tab=Table /automation-engine/dev/servicenow-bridge/password Password for the ServiceNow API https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/servicenow-bridge/password/description?region=us-east-1&tab=Table /automation-engine/dev/servicenow-bridge/username Username for the ServiceNow API https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/servicenow-bridge/username/description?region=us-east-1&tab=Table /automation-engine/dev/t7-bridge/kre-base-url Base URL for TNBA's KRE https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/t7-bridge/kre-base-url/description?region=us-east-1&tab=Table /automation-engine/dev/tnba-feedback/monitored-velocloud-hosts VeloCloud hosts whose edges will be monitored https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/tnba-feedback/monitored-velocloud-hosts/description?region=us-east-1&tab=Table /automation-engine/dev/tnba-monitor/blacklisted-edges List of edges that are excluded from TNBA monitoring https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/tnba-monitor/blacklisted-edges/description?region=us-east-1&tab=Table /automation-engine/dev/tnba-monitor/monitored-velocloud-hosts VeloCloud hosts whose edges will be monitored https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/tnba-monitor/monitored-velocloud-hosts/description?region=us-east-1&tab=Table /automation-engine/dev/velocloud-bridge/velocloud-credentials Velocloud credentials https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/dev/velocloud-bridge/velocloud-credentials/description?region=us-east-1&tab=Table /automation-engine/pro/bruin-bridge/base-url https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/bruin-bridge/base-url/description?region=us-east-1&tab=Table /automation-engine/pro/bruin-bridge/client-id https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/bruin-bridge/client-id/description?region=us-east-1&tab=Table /automation-engine/pro/bruin-bridge/client-secret https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/bruin-bridge/client-secret/description?region=us-east-1&tab=Table /automation-engine/pro/bruin-bridge/login-url https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/bruin-bridge/login-url/description?region=us-east-1&tab=Table /automation-engine/pro/bruin-bridge/test-base-url https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/bruin-bridge/test-base-url/description?region=us-east-1&tab=Table /automation-engine/pro/bruin-bridge/test-client-id https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/bruin-bridge/test-client-id/description?region=us-east-1&tab=Table /automation-engine/pro/bruin-bridge/test-client-secret https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/bruin-bridge/test-client-secret/description?region=us-east-1&tab=Table /automation-engine/pro/bruin-bridge/test-login-url https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/bruin-bridge/test-login-url/description?region=us-east-1&tab=Table /automation-engine/pro/customer-cache/blacklisted-clients-with-pending-status https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/customer-cache/blacklisted-clients-with-pending-status/description?region=us-east-1&tab=Table /automation-engine/pro/customer-cache/blacklisted-edges https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/customer-cache/blacklisted-edges/description?region=us-east-1&tab=Table /automation-engine/pro/customer-cache/duplicate-inventories-recipient https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/customer-cache/duplicate-inventories-recipient/description?region=us-east-1&tab=Table /automation-engine/pro/customer-cache/velocloud-hosts https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/customer-cache/velocloud-hosts/description?region=us-east-1&tab=Table /automation-engine/pro/digi-bridge/digi-reboot-api-base-url https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/digi-bridge/digi-reboot-api-base-url/description?region=us-east-1&tab=Table /automation-engine/pro/digi-bridge/digi-reboot-api-client-id https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/digi-bridge/digi-reboot-api-client-id/description?region=us-east-1&tab=Table /automation-engine/pro/digi-bridge/digi-reboot-api-client-secret https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/digi-bridge/digi-reboot-api-client-secret/description?region=us-east-1&tab=Table /automation-engine/pro/digi-reboot-report/report-recipient https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/digi-reboot-report/report-recipient/description?region=us-east-1&tab=Table /automation-engine/pro/email-tagger-kre-bridge/kre-base-url https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/email-tagger-kre-bridge/kre-base-url/description?region=us-east-1&tab=Table /automation-engine/pro/digi-bridge/digi-reboot-api-base-url https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/digi-bridge/digi-reboot-api-base-url/description?region=us-east-1&tab=Table /automation-engine/pro/digi-reboot-report/report-recipient https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/digi-reboot-report/report-recipient/description?region=us-east-1&tab=Table /automation-engine/pro/email-tagger-kre-bridge/kre-base-url https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/email-tagger-kre-bridge/kre-base-url/description?region=us-east-1&tab=Table /automation-engine/pro/email-tagger-monitor/api-request-key https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/email-tagger-monitor/api-request-key/description?region=us-east-1&tab=Table /automation-engine/pro/email-tagger-monitor/api-request-signature-secret-key https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/email-tagger-monitor/api-request-signature-secret-key/description?region=us-east-1&tab=Table /automation-engine/pro/external-secrets/iam-role-arn The ARN of the AWS IAM role necessary to manage parameter store and secret manager https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/external-secrets/iam-role-arn/description?region=us-east-1&tab=Table /automation-engine/pro/fraud-monitor/observed-inbox-email-address https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/fraud-monitor/observed-inbox-email-address/description?region=us-east-1&tab=Table /automation-engine/pro/gateway-monitor/monitored-velocloud-hosts VeloCloud hosts whose gateways will be monitored https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/gateway-monitor/monitored-velocloud-hosts/description?region=us-east-1&tab=Table /automation-engine/pro/hawkeye-customer-cache/duplicate-inventories-recipient https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/hawkeye-customer-cache/duplicate-inventories-recipient/description?region=us-east-1&tab=Table /automation-engine/pro/intermapper-outage-monitor/observed-inbox-email-address https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/intermapper-outage-monitor/observed-inbox-email-address/description?region=us-east-1&tab=Table /automation-engine/pro/last-contact-report/monitored-velocloud-hosts https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/last-contact-report/monitored-velocloud-hosts/description?region=us-east-1&tab=Table /automation-engine/pro/last-contact-report/report-recipient https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/last-contact-report/report-recipient/description?region=us-east-1&tab=Table /automation-engine/pro/email-bridge/monitorable-email-accounts https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/email-bridge/monitorable-email-accounts/description?region=us-east-1&tab=Table /automation-engine/pro/notifications-bridge/slack-webhook-url https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/notifications-bridge/slack-webhook-url/description?region=us-east-1&tab=Table /automation-engine/pro/papertrail/enabled https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/papertrail/enabled/description?region=us-east-1&tab=Table /automation-engine/pro/redis/customer-cache-hostname https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/redis/customer-cache-hostname/description?region=us-east-1&tab=Table /automation-engine/pro/redis/email-tagger-hostname https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/redis/email-tagger-hostname/description?region=us-east-1&tab=Table /automation-engine/pro/redis/main-hostname https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/redis/main-hostname/description?region=us-east-1&tab=Table /automation-engine/pro/redis/tnba-feedback-hostname https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/redis/tnba-feedback-hostname/description?region=us-east-1&tab=Table /automation-engine/pro/repair-tickets-kre-bridge/kre-base-url https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/repair-tickets-kre-bridge/kre-base-url/description?region=us-east-1&tab=Table /automation-engine/pro/service-affecting/monitor/monitored-velocloud-hosts https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/service-affecting/monitor/monitored-velocloud-hosts/description?region=us-east-1&tab=Table /automation-engine/pro/service-outage/monitor/blacklisted-edges https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/service-outage/monitor/blacklisted-edges/description?region=us-east-1&tab=Table /automation-engine/pro/service-outage/monitor/monitored-velocloud-hosts https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/service-outage/monitor/monitored-velocloud-hosts/description?region=us-east-1&tab=Table /automation-engine/pro/service-outage/triage/monitored-velocloud-hosts https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/service-outage/triage/monitored-velocloud-hosts/description?region=us-east-1&tab=Table /automation-engine/pro/t7-bridge/kre-base-url https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/t7-bridge/kre-base-url/description?region=us-east-1&tab=Table /automation-engine/pro/tnba-feedback/monitored-velocloud-hosts https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/tnba-feedback/monitored-velocloud-hosts/description?region=us-east-1&tab=Table /automation-engine/pro/tnba-monitor/blacklisted-edges https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/tnba-monitor/blacklisted-edges/description?region=us-east-1&tab=Table /automation-engine/pro/tnba-monitor/monitored-velocloud-hosts https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/tnba-monitor/monitored-velocloud-hosts/description?region=us-east-1&tab=Table /automation-engine/pro/velocloud-bridge/velocloud-credentials https://us-east-1.console.aws.amazon.com/systems-manager/parameters/automation-engine/pro/velocloud-bridge/velocloud-credentials/description?region=us-east-1&tab=Table /data-highway/develop/metrics-velocloud-api/ALLOW_ORIGINS Metrics allow origins https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/develop/metrics-velocloud-api/ALLOW_ORIGINS/description?region=us-east-1&tab=Table /data-highway/develop/metrics-velocloud-api/WAREHOUSE Metrics velocloud api snowflake warehouse to execute the queries https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/develop/metrics-velocloud-api/WAREHOUSE/description?region=us-east-1&tab=Table /data-highway/develop/shared/SECRET_JWT Velocloud hosts to fetch data from https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/develop/shared/SECRET_JWT/description?region=us-east-1&tab=Table /data-highway/develop/velocloud-fetcher/BLACKLISTED_VENDORS Blacklisted vendors https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/develop/velocloud-fetcher/BLACKLISTED_VENDORS/description?region=us-east-1&tab=Table /data-highway/develop/velocloud-fetcher/BOOTSTRAP_SERVERS Bootstrap servers https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/develop/velocloud-fetcher/BOOTSTRAP_SERVERS/description?region=us-east-1&tab=Table /data-highway/develop/velocloud-fetcher/KAFKA_PASSWORD Kafka develop password to publish velocloud data on Kafka https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/develop/velocloud-fetcher/KAFKA_PASSWORD/description?region=us-east-1&tab=Table /data-highway/develop/velocloud-fetcher/KAFKA_REGISTRY_SCHEMA_CREDENTIALS Kafka registry credential https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/develop/velocloud-fetcher/KAFKA_REGISTRY_SCHEMA_CREDENTIALS/description?region=us-east-1&tab=Table /data-highway/develop/velocloud-fetcher/KAFKA_REGISTRY_SCHEMA_URL Kafka registry URL https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/develop/velocloud-fetcher/KAFKA_REGISTRY_SCHEMA_URL/description?region=us-east-1&tab=Table /data-highway/develop/velocloud-fetcher/KAFKA_SSL_CA_FILE Kafka develop ssl ca path of Kafka https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/develop/velocloud-fetcher/KAFKA_SSL_CA_FILE/description?region=us-east-1&tab=Table /data-highway/develop/velocloud-fetcher/KAFKA_USERNAME Kafka develop username to publish velocloud data on kafka https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/develop/velocloud-fetcher/KAFKA_USERNAME/description?region=us-east-1&tab=Table /data-highway/develop/velocloud-fetcher/METRICS_LIST Metrics list https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/develop/velocloud-fetcher/METRICS_LIST/description?region=us-east-1&tab=Table /data-highway/develop/velocloud-fetcher/VELOCLOUD_CREDENTIALS Velocloud hosts credentials https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/develop/velocloud-fetcher/VELOCLOUD_CREDENTIALS/description?region=us-east-1&tab=Table /data-highway/develop/velocloud-fetcher/VELOCLOUD_FETCHER_BYPASS_AVRO_ENFORCEMENT_FOR_SCHEMAS Bypass velocloud pruner for schemas https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/develop/velocloud-fetcher/VELOCLOUD_FETCHER_BYPASS_AVRO_ENFORCEMENT_FOR_SCHEMAS/description?region=us-east-1&tab=Table /data-highway/develop/velocloud-fetcher/VELOCLOUD_FETCHER_BYPASS_PRUNER_FOR_SCHEMAS Metrics list https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/develop/velocloud-fetcher/VELOCLOUD_FETCHER_BYPASS_PRUNER_FOR_SCHEMAS/description?region=us-east-1&tab=Table /data-highway/develop/velocloud-fetcher/VELOCLOUD_HOSTS Velocloud hosts to fetch data from https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/develop/velocloud-fetcher/VELOCLOUD_HOSTS/description?region=us-east-1&tab=Table /data-highway/develop/velocloud-fetcher/VELOCLOUD_VERIFY_SSL Velocloud verify ssl https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/develop/velocloud-fetcher/VELOCLOUD_VERIFY_SSL/description?region=us-east-1&tab=Table /data-highway/master/metrics-velocloud-api/ALLOW_ORIGINS Metrics allow origins https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/master/metrics-velocloud-api/ALLOW_ORIGINS/description?region=us-east-1&tab=Table /data-highway/master/metrics-velocloud-api/WAREHOUSE Metrics velocloud api snowflake warehouse to execute the queries https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/master/metrics-velocloud-api/WAREHOUSE/description?region=us-east-1&tab=Table /data-highway/master/shared/SECRET_JWT Velocloud hosts to fetch data from https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/master/shared/SECRET_JWT/description?region=us-east-1&tab=Table /data-highway/master/velocloud-fetcher/BOOTSTRAP_SERVERS Bootstrap servers https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/master/velocloud-fetcher/BOOTSTRAP_SERVERS/description?region=us-east-1&tab=Table /data-highway/master/velocloud-fetcher/ENTERPRISES_ID Enterprises IDs https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/master/velocloud-fetcher/ENTERPRISES_ID/description?region=us-east-1&tab=Table /data-highway/master/velocloud-fetcher/KAFKA_PASSWORD Kafka master password to publish velocloud data on Kafka https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/master/velocloud-fetcher/KAFKA_PASSWORD/description?region=us-east-1&tab=Table /data-highway/master/velocloud-fetcher/KAFKA_REGISTRY_SCHEMA_CREDENTIALS Kafka registry credential https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/master/velocloud-fetcher/KAFKA_REGISTRY_SCHEMA_CREDENTIALS/description?region=us-east-1&tab=Table /data-highway/master/velocloud-fetcher/KAFKA_REGISTRY_SCHEMA_URL Kafka registry URL https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/master/velocloud-fetcher/KAFKA_REGISTRY_SCHEMA_URL/description?region=us-east-1&tab=Table /data-highway/master/velocloud-fetcher/KAFKA_SSL_CA_FILE Kafka master ssl ca path of Kafka https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/master/velocloud-fetcher/KAFKA_SSL_CA_FILE/description?region=us-east-1&tab=Table /data-highway/master/velocloud-fetcher/KAFKA_USERNAME Kafka master username to publish velocloud data on kafka https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/master/velocloud-fetcher/KAFKA_USERNAME/description?region=us-east-1&tab=Table /data-highway/master/velocloud-fetcher/VELOCLOUD_CREDENTIALS Velocloud hosts credentials https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/master/velocloud-fetcher/VELOCLOUD_CREDENTIALS/description?region=us-east-1&tab=Table /data-highway/master/velocloud-fetcher/VELOCLOUD_FETCHER_BYPASS_AVRO_ENFORCEMENT_FOR_SCHEMAS Bypass velocloud pruner for schemas https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/master/velocloud-fetcher/VELOCLOUD_FETCHER_BYPASS_AVRO_ENFORCEMENT_FOR_SCHEMAS/description?region=us-east-1&tab=Table /data-highway/master/velocloud-fetcher/VELOCLOUD_FETCHER_BYPASS_PRUNER_FOR_SCHEMAS Metrics list https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/master/velocloud-fetcher/VELOCLOUD_FETCHER_BYPASS_PRUNER_FOR_SCHEMAS/description?region=us-east-1&tab=Table /data-highway/master/velocloud-fetcher/VELOCLOUD_HOSTS Velocloud hosts to fetch data from https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/master/velocloud-fetcher/VELOCLOUD_HOSTS/description?region=us-east-1&tab=Table /data-highway/master/velocloud-fetcher/VELOCLOUD_VERIFY_SSL Velocloud verify ssl https://us-east-1.console.aws.amazon.com/systems-manager/parameters/data-highway/master/velocloud-fetcher/VELOCLOUD_VERIFY_SSL/description?region=us-east-1&tab=Table","title":"Parameter Store parameters"},{"location":"pipeline/BASIC_CI_CONFIGURATION/","text":"1. CI/CD PROJECT CONFIGURATION FROM 0 To release this project an make it work we need to configure next stuff: - semantic release - AIVEN - AWS 1.1 Semantic Release Semantic release is depending of a base image in this repository to be faster on this project CI/CD. The only two configurations we need to make it work here is: - Have prepared the base image repository and point to that image in the .gitlab-ci.yml(variable SEMANTIC_RELEASE_IMAGE) - Get an access token on the project (Settings/Access tokens) and get all permissions to interacts with the API. Create a variable called GITLAB_TOKEN and put the token you crete there. 1.2 AIVEN TODO 1.3 AWS It's recommended to create an account for terraform and a group of permissions with admin access, also it's necessary to create an S3 bucket that the user can access to. To accomplish aws connection in some steps of the CI/CD we need to add next variables (on the settings section, not in the YAML) in the CI: - AWS_ACCESS_KEY_ID - AWS_SECRET_ACCESS_KEY It's necessary to connect to the S3 from amazon, where we store the tfstate files to maintain the state of our infrastructure deployments. 1.4 Snowflake","title":"Basic configurations"},{"location":"pipeline/BASIC_CI_CONFIGURATION/#1-cicd-project-configuration-from-0","text":"To release this project an make it work we need to configure next stuff: - semantic release - AIVEN - AWS","title":"1. CI/CD PROJECT CONFIGURATION FROM 0"},{"location":"pipeline/BASIC_CI_CONFIGURATION/#11-semantic-release","text":"Semantic release is depending of a base image in this repository to be faster on this project CI/CD. The only two configurations we need to make it work here is: - Have prepared the base image repository and point to that image in the .gitlab-ci.yml(variable SEMANTIC_RELEASE_IMAGE) - Get an access token on the project (Settings/Access tokens) and get all permissions to interacts with the API. Create a variable called GITLAB_TOKEN and put the token you crete there.","title":"1.1 Semantic Release"},{"location":"pipeline/BASIC_CI_CONFIGURATION/#12-aiven","text":"TODO","title":"1.2 AIVEN"},{"location":"pipeline/BASIC_CI_CONFIGURATION/#13-aws","text":"It's recommended to create an account for terraform and a group of permissions with admin access, also it's necessary to create an S3 bucket that the user can access to. To accomplish aws connection in some steps of the CI/CD we need to add next variables (on the settings section, not in the YAML) in the CI: - AWS_ACCESS_KEY_ID - AWS_SECRET_ACCESS_KEY It's necessary to connect to the S3 from amazon, where we store the tfstate files to maintain the state of our infrastructure deployments.","title":"1.3 AWS"},{"location":"pipeline/BASIC_CI_CONFIGURATION/#14-snowflake","text":"","title":"1.4 Snowflake"},{"location":"pipeline/PIPELINE_RULES/","text":"PIPELINES RULES Add new section To add new section of jobs in the pipeline, we must include the section adding an included in the general .gitlab-ci.yml: include : - local : microservices/.gitlab-ci.yml Could be possible that an included .gitlab-ci.yml of another section include more sub-sections(Example microservices): include : - local : microservices/fetchers/velocloud/.gitlab-ci.yml We should follow this organization technique to isolate code to their respective area and avoid big files with spaghetti code. Add new template To add a new template we should take a look in the folder structure: # templates (folder where project templating is going to be saved) ## gitlab (section of the templating) Inside gitlab folder we should create template YAML files that fits with a section, for example, for microservices we created a microservice-ci.yml to store the templates of that section. Same in infrastructure. Also, we should include new templates in the index.yml in templates/index.yml include : # CI templates - local : templates/gitlab/microservice-ci.yml - local : templates/gitlab/infrastructure-ci.yml","title":"Pipeline rules"},{"location":"pipeline/PIPELINE_RULES/#pipelines-rules","text":"","title":"PIPELINES RULES"},{"location":"pipeline/PIPELINE_RULES/#add-new-section","text":"To add new section of jobs in the pipeline, we must include the section adding an included in the general .gitlab-ci.yml: include : - local : microservices/.gitlab-ci.yml Could be possible that an included .gitlab-ci.yml of another section include more sub-sections(Example microservices): include : - local : microservices/fetchers/velocloud/.gitlab-ci.yml We should follow this organization technique to isolate code to their respective area and avoid big files with spaghetti code.","title":"Add new section"},{"location":"pipeline/PIPELINE_RULES/#add-new-template","text":"To add a new template we should take a look in the folder structure: # templates (folder where project templating is going to be saved) ## gitlab (section of the templating) Inside gitlab folder we should create template YAML files that fits with a section, for example, for microservices we created a microservice-ci.yml to store the templates of that section. Same in infrastructure. Also, we should include new templates in the index.yml in templates/index.yml include : # CI templates - local : templates/gitlab/microservice-ci.yml - local : templates/gitlab/infrastructure-ci.yml","title":"Add new template"},{"location":"snowflake/","text":"1. Create a private key for a user/service To create a new user follow the link from snowflake about key creation It's only allowed to create users with keys to automate connection between services. If we need a key for testing purposes should be a temporary user or in a development infrastructure. Important to know that only a SECURITYADMIN user can modify users to have a key pair access. 2. Key rotation policy Key rotation is a must to have a high security standard, at this moment is important to know is a manual process, each first week of the month should be a calendar task in the devops team to change it a redeployment the infrastructure with these new keys. Right now is not automated because no make sense to do it, you have to have a static user that can modify these stuff manually in the web, if we discover a way to do it automatically without a static user or a bastion one we could think about it. 3. Add a New provider 4. Rules Each private key must have a passphrase. Each new provider must have their own key Devops team must renew keys each month and redeploy the infra.","title":"Datalake"},{"location":"snowflake/#1-create-a-private-key-for-a-userservice","text":"To create a new user follow the link from snowflake about key creation It's only allowed to create users with keys to automate connection between services. If we need a key for testing purposes should be a temporary user or in a development infrastructure. Important to know that only a SECURITYADMIN user can modify users to have a key pair access.","title":"1. Create a private key for a user/service"},{"location":"snowflake/#2-key-rotation-policy","text":"Key rotation is a must to have a high security standard, at this moment is important to know is a manual process, each first week of the month should be a calendar task in the devops team to change it a redeployment the infrastructure with these new keys. Right now is not automated because no make sense to do it, you have to have a static user that can modify these stuff manually in the web, if we discover a way to do it automatically without a static user or a bastion one we could think about it.","title":"2. Key rotation policy"},{"location":"snowflake/#3-add-a-new-provider","text":"","title":"3. Add a New provider"},{"location":"snowflake/#4-rules","text":"Each private key must have a passphrase. Each new provider must have their own key Devops team must renew keys each month and redeploy the infra.","title":"4. Rules"},{"location":"snowflake/queries/QoE/qoe/","text":"QOE Snowflake query USE DATABASE METTEL_DEVELOP ; USE SCHEMA VELOCLOUD ; SELECT TOP 1 * FROM LINKS_QOE_METRICS_PLAIN ; Results: * RECORD_METADATA * CreateTime: Unix time. Time the record was pull from velocloud. * Offset: Index of the data in Kafka. * Partition: kafka partition parent. * Topic: kafka queue streaming the data. Example of RECORD_METADATA: { \"CreateTime\" : 1657092759530 , \"offset\" : 2430 , \"partition\" : 1 , \"topic\" : \"velocloud_get_links_qoe_metrics_plain_develop\" } RECORD_CONTENT The schema of the data is equal to the body response from the Velocloud API: Link: Velocloud API Link Section: POST /linkQualityEvent/getLinkQualityEvents (see attached file QoE.json for a sample of QoE content) Sample queries Find host and enterprise ID by company name: SELECT * FROM V_COMPANY_IDENTIFIERS WHERE COMPANY LIKE '%FIS%' ; Discover edges for FIS SELECT RECORD_CONTENT : edge_id FROM LINKS_QOE_METRICS_PLAIN WHERE RECORD_CONTENT : host LIKE 'metvco04.mettel.net' AND RECORD_CONTENT : enterprise_id = 269 GROUP BY RECORD_CONTENT : edge_id ; All edges data for one FIS instance SELECT * FROM LINKS_QOE_METRICS_PLAIN WHERE RECORD_CONTENT : host LIKE 'metvco04.mettel.net' AND RECORD_CONTENT : enterprise_id = 269 ;","title":"Qoe"},{"location":"snowflake/queries/QoE/qoe/#qoe","text":"Snowflake query USE DATABASE METTEL_DEVELOP ; USE SCHEMA VELOCLOUD ; SELECT TOP 1 * FROM LINKS_QOE_METRICS_PLAIN ; Results: * RECORD_METADATA * CreateTime: Unix time. Time the record was pull from velocloud. * Offset: Index of the data in Kafka. * Partition: kafka partition parent. * Topic: kafka queue streaming the data. Example of RECORD_METADATA: { \"CreateTime\" : 1657092759530 , \"offset\" : 2430 , \"partition\" : 1 , \"topic\" : \"velocloud_get_links_qoe_metrics_plain_develop\" } RECORD_CONTENT The schema of the data is equal to the body response from the Velocloud API: Link: Velocloud API Link Section: POST /linkQualityEvent/getLinkQualityEvents (see attached file QoE.json for a sample of QoE content)","title":"QOE"},{"location":"snowflake/queries/QoE/qoe/#sample-queries","text":"Find host and enterprise ID by company name: SELECT * FROM V_COMPANY_IDENTIFIERS WHERE COMPANY LIKE '%FIS%' ; Discover edges for FIS SELECT RECORD_CONTENT : edge_id FROM LINKS_QOE_METRICS_PLAIN WHERE RECORD_CONTENT : host LIKE 'metvco04.mettel.net' AND RECORD_CONTENT : enterprise_id = 269 GROUP BY RECORD_CONTENT : edge_id ; All edges data for one FIS instance SELECT * FROM LINKS_QOE_METRICS_PLAIN WHERE RECORD_CONTENT : host LIKE 'metvco04.mettel.net' AND RECORD_CONTENT : enterprise_id = 269 ;","title":"Sample queries"}]}